{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transfert_Learning_Vgg16forSP500.ipynb",
      "provenance": [],
      "history_visible": true,
      "authorship_tag": "ABX9TyNV6M/6BpoLA+VBtPZzJ2TE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/imiled/DL_Tools_For_Finance/blob/master/Transfert_Learning_Vgg16forSP500.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QGkfWRfEIyvy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "outputId": "c1fc8d23-a2fa-4d1c-f243-f4dc7cb4e7a3"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dWRUvmdLI64s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "outputId": "f6f5246f-5bd1-4cf1-8d50-bdc954fab42d"
      },
      "source": [
        "!git clone https://github.com/imiled/DL_Tools_For_Finance.git\n",
        "%cd /content/DL_Tools_For_Finance  \n",
        "!git init\n",
        "!git status\n",
        "!git log "
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'DL_Tools_For_Finance'...\n",
            "remote: Enumerating objects: 123, done.\u001b[K\n",
            "remote: Counting objects: 100% (123/123), done.\u001b[K\n",
            "remote: Compressing objects: 100% (120/120), done.\u001b[K\n",
            "remote: Total 577 (delta 63), reused 7 (delta 3), pack-reused 454\u001b[K\n",
            "Receiving objects: 100% (577/577), 109.66 MiB | 23.52 MiB/s, done.\n",
            "Resolving deltas: 100% (297/297), done.\n",
            "/content/DL_Tools_For_Finance\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_dnJgtZMHHv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        },
        "outputId": "74528470-b54e-45af-fc10-afdab89f9064"
      },
      "source": [
        "%cd /content/DL_Tools_For_Finance  \n",
        "!git add .\n",
        "!git commit -m \"reorganisation of files\"\n",
        "!git config user.email miledismael@gmail.com\n",
        "!git config user.name imiled\n",
        "!git push https://github.com/imiled/DL_Tools_For_Finance.git"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mdatas\u001b[0m/                 setup.py\n",
            "\u001b[01;34mImagesIndexBehaviour\u001b[0m/  step1_generate_dataset_IndexImage.py\n",
            "LICENSE                step2_loadingtrainingdatas.py\n",
            "\u001b[01;34mMainNotebook\u001b[0m/          step3_vgg_transfert_modelandtraining.py\n",
            "MANIFEST.in            step4_evaluate_vggsp500_model.py\n",
            "\u001b[01;34mNotebooks\u001b[0m/             step5_guess_future_marketstate_from_image.py\n",
            "\u001b[01;34moldstuff\u001b[0m/              \u001b[01;34mtests\u001b[0m/\n",
            "README.md              \u001b[01;34mtrainer\u001b[0m/\n",
            "requirements.txt       versioneer.py\n",
            "setup.cfg              \u001b[01;34mvgg\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GM-Fn6fFNEEl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        },
        "outputId": "9beb66af-4fee-4871-c50c-150d6ea7002f"
      },
      "source": [
        "%cd /content/drive/My Drive/_sample_data\n",
        "%ls -l"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/_sample_data\n",
            "total 424784\n",
            "-rw------- 1 root root  18763426 Aug  3 08:37 298_2020_1980.xlsx\n",
            "-rw------- 1 root root  35920046 Aug 30 07:16 DataNomClean_200731.xlsx\n",
            "-rw------- 1 root root     63272 Aug 30 07:16 DataRefClean.xlsx\n",
            "drwx------ 2 root root      4096 Aug 29 14:22 \u001b[0m\u001b[01;34mdatas\u001b[0m/\n",
            "-rw------- 1 root root 320781432 Aug 29 13:11 df_ImageSP500_InputOutputNN.csv\n",
            "-rw------- 1 root root  38703970 Aug 29 13:11 df_ImageSP500_InputOutputNN.zip\n",
            "drwx------ 2 root root      4096 Aug 29 18:11 \u001b[01;34mImageM\u001b[0m/\n",
            "drwx------ 2 root root      4096 Aug 29 15:41 \u001b[01;34mmodel\u001b[0m/\n",
            "drwx------ 2 root root      4096 Aug 29 13:39 \u001b[01;34mpath_name\u001b[0m/\n",
            "-rw------- 1 root root   4142609 Aug 30 07:16 X_test_image2020_08_29_13_48_01_411284.csv\n",
            "-rw------- 1 root root  16539890 Aug 30 07:16 X_train_image2020_08_29_13_48_01_411284.csv\n",
            "-rw------- 1 root root      5924 Aug 29 13:48 Y_test_FutPredict_image2020_08_29_13_48_01_411284.csv\n",
            "-rw------- 1 root root      2988 Aug 29 13:48 Y_test_StateClass_image2020_08_29_13_48_01_411284.csv\n",
            "-rw------- 1 root root     23807 Aug 29 13:48 Y_train_FutPredict_image2020_08_29_13_48_01_411284.csv\n",
            "-rw------- 1 root root     11958 Aug 29 13:48 Y_train_StateClass_image2020_08_29_13_48_01_411284.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rnrVYuKyQors",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cp DataNomClean_200731.xlsx DataRefClean.xlsx  /content/DL_Tools_For_Finance/datas"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3-TqT4dQ0SY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cp X_test_image2020_08_29_13_48_01_411284.csv X_train_image2020_08_29_13_48_01_411284.csv /content/DL_Tools_For_Finance/datas\n",
        "%cp Y_test_StateClass_image2020_08_29_13_48_01_411284.csv Y_test_FutPredict_image2020_08_29_13_48_01_411284.csv /content/DL_Tools_For_Finance/datas\n",
        "%cp Y_train_StateClass_image2020_08_29_13_48_01_411284.csv Y_train_FutPredict_image2020_08_29_13_48_01_411284.csv /content/DL_Tools_For_Finance/datas"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZxHJhbPrOOSD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "06ee411d-2f5a-41d1-e208-130aef7d7ffb"
      },
      "source": [
        "%cd /content/DL_Tools_For_Finance/datas"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/DL_Tools_For_Finance/datas\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cp5VLQnWUBl1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%mv X_test_image2020_08_29_13_48_01_411284.csv X_test_image.csv \n",
        "%mv X_train_image2020_08_29_13_48_01_411284.csv X_train_image.csv \n",
        "%mv Y_train_StateClass_image2020_08_29_13_48_01_411284.csv Y_train_StateClass_image.csv \n",
        "%mv Y_test_StateClass_image2020_08_29_13_48_01_411284.csv Y_test_StateClass_image.csv \n",
        "%mv Y_train_FutPredict_image2020_08_29_13_48_01_411284.csv Y_train_FutPredict_image.csv \n",
        "%mv Y_test_FutPredict_image2020_08_29_13_48_01_411284.csv Y_test_FutPredict_image.csv \n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EEpibDu_Ovpv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "outputId": "2f0a06a3-834e-4846-96c4-dcd25ae8a9c6"
      },
      "source": [
        "%ls -l\n",
        "%cd /content/DL_Tools_For_Finance"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 73720\n",
            "-rw-r--r-- 1 root root 18763426 Aug 30 11:58 298_2020_1980.xlsx\n",
            "-rw------- 1 root root 35920046 Aug 30 12:10 DataNomClean_200731.xlsx\n",
            "-rw------- 1 root root    63272 Aug 30 12:10 DataRefClean.xlsx\n",
            "-rw------- 1 root root  4142609 Aug 30 12:10 X_test_image.csv\n",
            "-rw------- 1 root root 16539890 Aug 30 12:10 X_train_image.csv\n",
            "-rw------- 1 root root     5924 Aug 30 12:10 Y_test_FutPredict_image.csv\n",
            "-rw------- 1 root root     2988 Aug 30 12:10 Y_test_StateClass_image.csv\n",
            "-rw------- 1 root root    23807 Aug 30 12:10 Y_train_FutPredict_image.csv\n",
            "-rw------- 1 root root    11958 Aug 30 12:10 Y_train_StateClass_image.csv\n",
            "/content/DL_Tools_For_Finance\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FDjeaFj8VsSp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%mkdir model"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VehZVTphSljL",
        "colab_type": "text"
      },
      "source": [
        "###Requirement instalation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SdNljA10SDfU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "56f9a747-38c9-4b56-f7e7-d48026f333b1"
      },
      "source": [
        "!pip3 install -r requirements.txt  "
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[31mERROR: Could not open requirements file: [Errno 2] No such file or directory: 'requirements.txt'\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_SEuIXmtTG26",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "abe24dcf-a181-40e2-c5c4-c9032f665e3d"
      },
      "source": [
        "%cd /content/DL_Tools_For_Finance"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/DL_Tools_For_Finance\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T3FQ9vZN0t8I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "841220f5-dcc1-4d68-b711-8eac897004ba"
      },
      "source": [
        "!python3 step1_generate_dataset_IndexImage.py"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loop 2 image : step  44 market state fut market_state    3.0\n",
            "Name: 1932-03-03 00:00:00, dtype: float64  future value 0.6372262773722628\n",
            "loop 2 image : step  45 market state fut market_state    2.0\n",
            "Name: 1932-03-04 00:00:00, dtype: float64  future value 0.621897810218978\n",
            "loop 2 image : step  46 market state fut market_state    2.0\n",
            "Name: 1932-03-07 00:00:00, dtype: float64  future value 0.6065693430656935\n",
            "loop 2 image : step  47 market state fut market_state    2.0\n",
            "Name: 1932-03-08 00:00:00, dtype: float64  future value 0.6065693430656935\n",
            "loop 2 image : step  48 market state fut market_state    1.0\n",
            "Name: 1932-03-09 00:00:00, dtype: float64  future value 0.591970802919708\n",
            "loop 2 image : step  49 market state fut market_state    2.0\n",
            "Name: 1932-03-10 00:00:00, dtype: float64  future value 0.6043795620437956\n",
            "loop 2 image : step  50 market state fut market_state    1.0\n",
            "Name: 1932-03-11 00:00:00, dtype: float64  future value 0.5854014598540146\n",
            "loop 2 image : step  51 market state fut market_state    2.0\n",
            "Name: 1932-03-14 00:00:00, dtype: float64  future value 0.5883211678832118\n",
            "loop 2 image : step  52 market state fut market_state    2.0\n",
            "Name: 1932-03-15 00:00:00, dtype: float64  future value 0.5875912408759125\n",
            "loop 2 image : step  53 market state fut market_state    2.0\n",
            "Name: 1932-03-16 00:00:00, dtype: float64  future value 0.5795620437956205\n",
            "loop 2 image : step  54 market state fut market_state    2.0\n",
            "Name: 1932-03-17 00:00:00, dtype: float64  future value 0.5737226277372264\n",
            "loop 2 image : step  55 market state fut market_state    2.0\n",
            "Name: 1932-03-18 00:00:00, dtype: float64  future value 0.554014598540146\n",
            "loop 2 image : step  56 market state fut market_state    0.0\n",
            "Name: 1932-03-21 00:00:00, dtype: float64  future value 0.5532846715328468\n",
            "loop 2 image : step  57 market state fut market_state    0.0\n",
            "Name: 1932-03-22 00:00:00, dtype: float64  future value 0.5649635036496351\n",
            "loop 2 image : step  58 market state fut market_state    0.0\n",
            "Name: 1932-03-23 00:00:00, dtype: float64  future value 0.5335766423357664\n",
            "loop 2 image : step  59 market state fut market_state    0.0\n",
            "Name: 1932-03-24 00:00:00, dtype: float64  future value 0.5240875912408759\n",
            "loop 2 image : step  60 market state fut market_state    0.0\n",
            "Name: 1932-03-28 00:00:00, dtype: float64  future value 0.5153284671532846\n",
            "loop 2 image : step  61 market state fut market_state    0.0\n",
            "Name: 1932-03-29 00:00:00, dtype: float64  future value 0.49124087591240884\n",
            "loop 2 image : step  62 market state fut market_state    0.0\n",
            "Name: 1932-03-30 00:00:00, dtype: float64  future value 0.4766423357664234\n",
            "loop 2 image : step  63 market state fut market_state    0.0\n",
            "Name: 1932-03-31 00:00:00, dtype: float64  future value 0.47153284671532847\n",
            "loop 2 image : step  64 market state fut market_state    0.0\n",
            "Name: 1932-04-01 00:00:00, dtype: float64  future value 0.4569343065693431\n",
            "loop 2 image : step  65 market state fut market_state    0.0\n",
            "Name: 1932-04-04 00:00:00, dtype: float64  future value 0.443065693430657\n",
            "loop 2 image : step  66 market state fut market_state    0.0\n",
            "Name: 1932-04-05 00:00:00, dtype: float64  future value 0.44233576642335765\n",
            "loop 2 image : step  67 market state fut market_state    0.0\n",
            "Name: 1932-04-06 00:00:00, dtype: float64  future value 0.43649635036496354\n",
            "loop 2 image : step  68 market state fut market_state    0.0\n",
            "Name: 1932-04-07 00:00:00, dtype: float64  future value 0.4562043795620438\n",
            "loop 2 image : step  69 market state fut market_state    0.0\n",
            "Name: 1932-04-08 00:00:00, dtype: float64  future value 0.4686131386861314\n",
            "loop 2 image : step  70 market state fut market_state    0.0\n",
            "Name: 1932-04-11 00:00:00, dtype: float64  future value 0.44671532846715334\n",
            "loop 2 image : step  71 market state fut market_state    0.0\n",
            "Name: 1932-04-12 00:00:00, dtype: float64  future value 0.4401459854014599\n",
            "loop 2 image : step  72 market state fut market_state    0.0\n",
            "Name: 1932-04-13 00:00:00, dtype: float64  future value 0.4401459854014599\n",
            "loop 2 image : step  73 market state fut market_state    1.0\n",
            "Name: 1932-04-14 00:00:00, dtype: float64  future value 0.45547445255474456\n",
            "loop 2 image : step  74 market state fut market_state    0.0\n",
            "Name: 1932-04-15 00:00:00, dtype: float64  future value 0.435036496350365\n",
            "loop 2 image : step  75 market state fut market_state    1.0\n",
            "Name: 1932-04-18 00:00:00, dtype: float64  future value 0.4401459854014599\n",
            "loop 2 image : step  76 market state fut market_state    2.0\n",
            "Name: 1932-04-19 00:00:00, dtype: float64  future value 0.44671532846715334\n",
            "loop 2 image : step  77 market state fut market_state    2.0\n",
            "Name: 1932-04-20 00:00:00, dtype: float64  future value 0.4576642335766423\n",
            "loop 2 image : step  78 market state fut market_state    1.0\n",
            "Name: 1932-04-21 00:00:00, dtype: float64  future value 0.4401459854014599\n",
            "loop 2 image : step  79 market state fut market_state    0.0\n",
            "Name: 1932-04-22 00:00:00, dtype: float64  future value 0.4255474452554745\n",
            "loop 2 image : step  80 market state fut market_state    0.0\n",
            "Name: 1932-04-25 00:00:00, dtype: float64  future value 0.41897810218978104\n",
            "loop 2 image : step  81 market state fut market_state    0.0\n",
            "Name: 1932-04-26 00:00:00, dtype: float64  future value 0.4131386861313869\n",
            "loop 2 image : step  82 market state fut market_state    0.0\n",
            "Name: 1932-04-27 00:00:00, dtype: float64  future value 0.41897810218978104\n",
            "loop 2 image : step  83 market state fut market_state    0.0\n",
            "Name: 1932-04-28 00:00:00, dtype: float64  future value 0.4145985401459854\n",
            "loop 2 image : step  84 market state fut market_state    2.0\n",
            "Name: 1932-04-29 00:00:00, dtype: float64  future value 0.44452554744525546\n",
            "loop 2 image : step  85 market state fut market_state    2.0\n",
            "Name: 1932-05-02 00:00:00, dtype: float64  future value 0.435036496350365\n",
            "loop 2 image : step  86 market state fut market_state    2.0\n",
            "Name: 1932-05-03 00:00:00, dtype: float64  future value 0.4386861313868613\n",
            "loop 2 image : step  87 market state fut market_state    2.0\n",
            "Name: 1932-05-04 00:00:00, dtype: float64  future value 0.43795620437956206\n",
            "loop 2 image : step  88 market state fut market_state    2.0\n",
            "Name: 1932-05-05 00:00:00, dtype: float64  future value 0.4233576642335766\n",
            "loop 2 image : step  89 market state fut market_state    0.0\n",
            "Name: 1932-05-06 00:00:00, dtype: float64  future value 0.40875912408759124\n",
            "loop 2 image : step  90 market state fut market_state    0.0\n",
            "Name: 1932-05-09 00:00:00, dtype: float64  future value 0.40948905109489053\n",
            "loop 2 image : step  91 market state fut market_state    0.0\n",
            "Name: 1932-05-10 00:00:00, dtype: float64  future value 0.408029197080292\n",
            "loop 2 image : step  92 market state fut market_state    0.0\n",
            "Name: 1932-05-11 00:00:00, dtype: float64  future value 0.3978102189781022\n",
            "loop 2 image : step  93 market state fut market_state    0.0\n",
            "Name: 1932-05-12 00:00:00, dtype: float64  future value 0.4000000000000001\n",
            "loop 2 image : step  94 market state fut market_state    0.0\n",
            "Name: 1932-05-13 00:00:00, dtype: float64  future value 0.4000000000000001\n",
            "loop 2 image : step  95 market state fut market_state    0.0\n",
            "Name: 1932-05-16 00:00:00, dtype: float64  future value 0.3963503649635037\n",
            "loop 2 image : step  96 market state fut market_state    0.0\n",
            "Name: 1932-05-17 00:00:00, dtype: float64  future value 0.3802919708029197\n",
            "loop 2 image : step  97 market state fut market_state    0.0\n",
            "Name: 1932-05-18 00:00:00, dtype: float64  future value 0.3671532846715329\n",
            "loop 2 image : step  98 market state fut market_state    0.0\n",
            "Name: 1932-05-19 00:00:00, dtype: float64  future value 0.3729927007299271\n",
            "loop 2 image : step  99 market state fut market_state    0.0\n",
            "Name: 1932-05-20 00:00:00, dtype: float64  future value 0.35255474452554747\n",
            "loop 2 image : step  100 market state fut market_state    0.0\n",
            "Name: 1932-05-23 00:00:00, dtype: float64  future value 0.3262773722627737\n",
            "loop 2 image : step  101 market state fut market_state    0.0\n",
            "Name: 1932-05-24 00:00:00, dtype: float64  future value 0.3211678832116789\n",
            "loop 2 image : step  102 market state fut market_state    0.0\n",
            "Name: 1932-05-25 00:00:00, dtype: float64  future value 0.3386861313868613\n",
            "loop 2 image : step  103 market state fut market_state    0.0\n",
            "Name: 1932-05-26 00:00:00, dtype: float64  future value 0.35693430656934305\n",
            "loop 2 image : step  104 market state fut market_state    2.0\n",
            "Name: 1932-05-27 00:00:00, dtype: float64  future value 0.37007299270072996\n",
            "loop 2 image : step  105 market state fut market_state    2.0\n",
            "Name: 1932-05-31 00:00:00, dtype: float64  future value 0.354014598540146\n",
            "loop 2 image : step  106 market state fut market_state    2.0\n",
            "Name: 1932-06-01 00:00:00, dtype: float64  future value 0.33357664233576645\n",
            "loop 2 image : step  107 market state fut market_state    1.0\n",
            "Name: 1932-06-02 00:00:00, dtype: float64  future value 0.33357664233576645\n",
            "loop 2 image : step  108 market state fut market_state    2.0\n",
            "Name: 1932-06-03 00:00:00, dtype: float64  future value 0.35912408759124087\n",
            "loop 2 image : step  109 market state fut market_state    1.0\n",
            "Name: 1932-06-06 00:00:00, dtype: float64  future value 0.35182481751824823\n",
            "loop 2 image : step  110 market state fut market_state    2.0\n",
            "Name: 1932-06-07 00:00:00, dtype: float64  future value 0.36058394160583945\n",
            "loop 2 image : step  111 market state fut market_state    2.0\n",
            "Name: 1932-06-08 00:00:00, dtype: float64  future value 0.3737226277372263\n",
            "loop 2 image : step  112 market state fut market_state    2.0\n",
            "Name: 1932-06-09 00:00:00, dtype: float64  future value 0.3737226277372263\n",
            "loop 2 image : step  113 market state fut market_state    1.0\n",
            "Name: 1932-06-10 00:00:00, dtype: float64  future value 0.35255474452554747\n",
            "loop 2 image : step  114 market state fut market_state    2.0\n",
            "Name: 1932-06-13 00:00:00, dtype: float64  future value 0.35693430656934305\n",
            "loop 2 image : step  115 market state fut market_state    1.0\n",
            "Name: 1932-06-14 00:00:00, dtype: float64  future value 0.34817518248175183\n",
            "loop 2 image : step  116 market state fut market_state    1.0\n",
            "Name: 1932-06-15 00:00:00, dtype: float64  future value 0.34817518248175183\n",
            "loop 2 image : step  117 market state fut market_state    1.0\n",
            "Name: 1932-06-16 00:00:00, dtype: float64  future value 0.35036496350364965\n",
            "loop 2 image : step  118 market state fut market_state    1.0\n",
            "Name: 1932-06-17 00:00:00, dtype: float64  future value 0.3357664233576642\n",
            "error at index 119\n",
            "loop 2 image : step  120 market state fut market_state    1.0\n",
            "Name: 1932-06-21 00:00:00, dtype: float64  future value 0.32408759124087594\n",
            "loop 2 image : step  121 market state fut market_state    1.0\n",
            "Name: 1932-06-22 00:00:00, dtype: float64  future value 0.3291970802919708\n",
            "loop 2 image : step  122 market state fut market_state    1.0\n",
            "Name: 1932-06-23 00:00:00, dtype: float64  future value 0.32335766423357665\n",
            "loop 2 image : step  123 market state fut market_state    2.0\n",
            "Name: 1932-06-24 00:00:00, dtype: float64  future value 0.3357664233576642\n",
            "loop 2 image : step  124 market state fut market_state    2.0\n",
            "Name: 1932-06-27 00:00:00, dtype: float64  future value 0.3284671532846716\n",
            "loop 2 image : step  125 market state fut market_state    2.0\n",
            "Name: 1932-06-28 00:00:00, dtype: float64  future value 0.3357664233576642\n",
            "loop 2 image : step  126 market state fut market_state    1.0\n",
            "Name: 1932-06-29 00:00:00, dtype: float64  future value 0.32481751824817523\n",
            "loop 2 image : step  127 market state fut market_state    1.0\n",
            "Name: 1932-06-30 00:00:00, dtype: float64  future value 0.3218978102189781\n",
            "loop 2 image : step  128 market state fut market_state    2.0\n",
            "Name: 1932-07-01 00:00:00, dtype: float64  future value 0.3357664233576642\n",
            "loop 2 image : step  129 market state fut market_state    2.0\n",
            "Name: 1932-07-05 00:00:00, dtype: float64  future value 0.3357664233576642\n",
            "loop 2 image : step  130 market state fut market_state    3.0\n",
            "Name: 1932-07-06 00:00:00, dtype: float64  future value 0.35182481751824823\n",
            "loop 2 image : step  131 market state fut market_state    3.0\n",
            "Name: 1932-07-07 00:00:00, dtype: float64  future value 0.34963503649635036\n",
            "loop 2 image : step  132 market state fut market_state    3.0\n",
            "Name: 1932-07-08 00:00:00, dtype: float64  future value 0.35985401459854016\n",
            "^C\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jKbZEi02Ti5r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "9294a39f-d249-496e-e9f7-4b3c50b6ba09"
      },
      "source": [
        "!python3 step2_loadingtrainingdatas.py"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-08-30 12:26:22.937960: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1tSf769yTxpr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9e92ea7d-45e4-4c25-b9e3-a8cd8eec6d19"
      },
      "source": [
        "!python3 step3_vgg_transfert_modelandtraining.py"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-08-30 12:28:37.911992: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-08-30 12:28:39.419351: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1\n",
            "2020-08-30 12:28:39.422503: E tensorflow/stream_executor/cuda/cuda_driver.cc:314] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "2020-08-30 12:28:39.422554: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (8c505239c639): /proc/driver/nvidia/version does not exist\n",
            "2020-08-30 12:28:39.429294: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2300000000 Hz\n",
            "2020-08-30 12:28:39.429541: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x30c2a00 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-08-30 12:28:39.429606: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 32, 32, 64)        1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 32, 32, 64)        36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 16, 16, 128)       73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 16, 16, 128)       147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 8, 8, 256)         295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 8, 8, 256)         590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 8, 8, 256)         590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 4, 4, 256)         0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 4, 4, 512)         1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 2, 2, 512)         0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 1, 1, 512)         0         \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 0\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n",
            "Traceback (most recent call last):\n",
            "  File \"step3_vgg_transfert_modelandtraining.py\", line 39, in <module>\n",
            "    y_train = np_utils.to_categorical(y_train, nb_classes)\n",
            "NameError: name 'y_train' is not defined\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CjSc-KxlVc0L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "outputId": "c7c98e68-1246-4e5a-93ff-89f8ed4c5179"
      },
      "source": [
        "!python3 step4_evaluate_vggsp500_model.py"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-08-30 12:27:14.276488: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "Traceback (most recent call last):\n",
            "  File \"step4_evaluate_vggsp500_model.py\", line 74, in <module>\n",
            "    vggsp500model = load_model(trained_model_path)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/save.py\", line 186, in load_model\n",
            "    loader_impl.parse_saved_model(filepath)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/loader_impl.py\", line 113, in parse_saved_model\n",
            "    constants.SAVED_MODEL_FILENAME_PB))\n",
            "OSError: SavedModel file does not exist at: model/vggforsp500.h5/{saved_model.pbtxt|saved_model.pb}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1n0vJA_lL-Xv",
        "colab_type": "text"
      },
      "source": [
        "##Step 1 : Generate Dataset of the Image and the Future maket state"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7jbsgi1Qa6Rg",
        "colab_type": "text"
      },
      "source": [
        "In this part we are generating the training and testing dataset.\n",
        "First we download the historical prices of the sp500 from 1927 to 31 July 2020 and built the image of 15 days historical graph also we get the 5 days future price evolution of the sp500. \n",
        "From the future price evolution, we calculate a future state which can be splitted in 6 classes :\n",
        "\n",
        "Sell-Sell | Sell- Neutral | Neutral | Neutral -Buy | Buy -Buy (and the Error class)\n",
        "\n",
        "The objective is to get the following files which represent a dataframe in the data/ repertory:\n",
        "\n",
        "X_train_image.csv , X_test_image.csv a 3072 column time serie dataframe  of the image (32 x 32 x3) of the sp500 closing price \n",
        "\n",
        "Y_test_StateClass.csv, Y_train_StateClass.csv a 1 column time serie dataframe of the future state value betwwen -1 to 4\n",
        "\n",
        "We generate also the following files but we won´t use it in this project - more fore RNN & price prediction - Y_test_FutPredict.csv Y_train_FutPredict.csv\n",
        "\n",
        "the testing and training time serie dataset are shuffled by the date of reference with a split number of 0.8\n",
        "\n",
        "Please note that: \n",
        "1. We can increase the dataset taking into account the evolution very liquid stocks or other indices as long as we have very high the liquidity and number of participants \n",
        "2. The calculation of the dataset can take more than 6 hours of calulation as the code is not optimized so far, we can quickly implement parallel computing and rapid image setup instead of using matplotlib library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_7hN1p8cJY_3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "905a4289-5f7f-497a-cd6c-30c7d33a2a5d"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import bs4 as bs\n",
        "import requests\n",
        "import yfinance as yf\n",
        "import fix_yahoo_finance as yf\n",
        "import datetime\n",
        "import io\n",
        "import cv2\n",
        "import skimage\n",
        "import datetime\n",
        "from PIL import Image\n",
        "from pandas_datareader import data as pdr\n",
        "from skimage import measure\n",
        "from skimage.measure import block_reduce\n",
        "from datetime import datetime\n",
        "\n",
        "'''\n",
        "Functions to be used for data generation \n",
        "'''\n",
        "\n",
        "def get_img_from_fig(fig, dpi=180):\n",
        "# get_img_from_fig is function which returns an image as numpy array from figure\n",
        "    buf = io.BytesIO()\n",
        "    fig.savefig(buf, format=\"png\", dpi=dpi)\n",
        "    buf.seek(0)\n",
        "    img_arr = np.frombuffer(buf.getvalue(), dtype=np.uint8)\n",
        "    buf.close()\n",
        "    img = cv2.imdecode(img_arr, 1)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    return img\n",
        "\n",
        "def build_image(stockindex, idate=10, pastlag=10, futlag=3,nb_dates=1000):\n",
        "# Build image from a table stockindex price list \n",
        "#return a (32,32,3) np.array representing the image in color\n",
        "#ising idate as a starting point\n",
        "#paslag futlag number of days to consider for translate\n",
        "  sp500close=stockindex\n",
        "  nb_days=nb_dates\n",
        "\n",
        "  x_datas=[]\n",
        "  x_datas=np.zeros((32,32,3))\n",
        "  i=idate\n",
        "  \n",
        "  fig=plt.figure()\n",
        "  ax=fig.add_subplot(111)\n",
        "  ax.plot(sp500close[(i-pastlag):i])\n",
        "  plot_img_np = get_img_from_fig(fig)\n",
        "  x_tmp= skimage.measure.block_reduce(plot_img_np[90:620,140:970], (18,28,1), np.mean)\n",
        "  (x_datas[1:-1])[:,1:-1][:]=x_tmp\n",
        "  fig.clear()\n",
        "  plt.close(fig)\n",
        "    \n",
        "  x_datas=x_datas/255\n",
        "  return x_datas\n",
        "  \n",
        "'''\n",
        "MAIN FUNCTION OF CLASSIFICATION \n",
        "build y state y fut \n",
        "and x  \n",
        "'''\n",
        "def class_shortterm_returnfut(x, yfut, indexforpast,tpastlag):\n",
        "#this function is use to classifiy the future state based on the position of future value with the past range \n",
        "#Put the value from the 2 boxes (max min) or (open close) on the time range  and check if it is within\n",
        "#go down go up or exit the box\n",
        "#the fucntion return 5 state depending on the future value position on the boxes and one state for error cases\n",
        "\n",
        "  xpast_min=np.min(x[(indexforpast-tpastlag):indexforpast])\n",
        "  xpast_max=np.max(x[(indexforpast-tpastlag):indexforpast])\n",
        "  x_open=x[int(indexforpast-tpastlag)]\n",
        "  x_close=x[indexforpast]\n",
        "  \n",
        "  if (yfut < xpast_min ): return 0\n",
        "  elif  (yfut < min(x_open,x_close)): return 1\n",
        "  elif  (yfut < max(x_open,x_close)): return 2\n",
        "  elif  (yfut < xpast_max): return 3\n",
        "  elif  (yfut > xpast_max): return 4\n",
        "  else  : return -1\n",
        "\n",
        "def main_class_shortterm_returnfut(iterable):\n",
        "  return class_shortterm_returnfut(sp500close, iterable, pastlag,futlag)\n",
        "\n",
        "\n",
        "\n",
        "def normalise_df_image(xdf):\n",
        "#normalisation to 0,1 range of the equity index\n",
        "  df_tmp=xdf\n",
        "  maxval=np.max(df_tmp)\n",
        "  df_tmp=df_tmp/maxval\n",
        "  return df_tmp, maxval\n",
        "\n",
        "def build_image(stockindex, idate=10, pastlag=10, futlag=3):\n",
        "#another version of returning image from a data frame index\n",
        "#using the pastlag as range for the graph\n",
        "#ising idate as a starting point\n",
        "#return a (32,32,3) np array\n",
        "\n",
        "  #number of days to consider for translate\n",
        "  sp500close=stockindex\n",
        "  x_datas=[]\n",
        "  x_datas=np.zeros((32,32,3))\n",
        "  i=idate\n",
        "  \n",
        "  fig=plt.figure()\n",
        "  ax=fig.add_subplot(111)\n",
        "  ax.plot(sp500close[(i-pastlag):i])\n",
        "  plot_img_np = get_img_from_fig(fig)\n",
        "  x_tmp= skimage.measure.block_reduce(plot_img_np[90:620,140:970], (18,28,1), np.mean)\n",
        "  (x_datas[1:-1])[:,1:-1][:]=x_tmp\n",
        "  fig.clear()\n",
        "  plt.close(fig)\n",
        "    \n",
        "  x_datas=x_datas/255\n",
        "  return x_datas\n",
        "\n",
        "def build_image_optimfig(fig, stockindex, idate=10, pastlag=10, futlag=3):\n",
        "#version of returning image from a data frame index\n",
        "#using the pastlag as range for the graph\n",
        "#ising idate as a starting point\n",
        "#return a (32,32,3) np array\n",
        "#this one is optimisng the use of ram \n",
        "\n",
        "  #number of days to consider for translate\n",
        "  sp500close=stockindex\n",
        "  x_datas=[]\n",
        "  x_datas=np.zeros((32,32,3))\n",
        "  i=idate\n",
        "  \n",
        "  plt.plot(sp500close[(i-pastlag):i])\n",
        "  plot_img_np = get_img_from_fig(fig)\n",
        "  x_tmp= skimage.measure.block_reduce(plot_img_np[90:620,140:970], (18,28,1), np.mean)\n",
        "  (x_datas[1:-1])[:,1:-1][:]=x_tmp\n",
        "    \n",
        "  x_datas=x_datas/255\n",
        "  return x_datas\n",
        "\n",
        "def build_image_df(xdf, past_step,fut_step) :\n",
        "  '''\n",
        "  returning a dictionary of time series dataframes to be used in setup_input_NN_image so a to generate \n",
        "  Input X Result Y_StateClass, Y_FutPredict\n",
        "  pastlag as range for the graph\n",
        "  fut _step the future value lag in time to predict or to check the financial state of the market \n",
        "  #times series to get information from the stock index value\n",
        "  'stock_value':the time serie of the index normalised on the whole period\n",
        "  'moving_average':  time serie of the rolling moving average value of the index for past step image\n",
        "  \"max\": time serie of the rolling max  value of the index for past step image\n",
        "  \"min\": time serie of the rolling  min value of the index for past step image\n",
        "  'volatility':  time serie of the rolling  vol value of the index for past step image\n",
        "          \n",
        "  'df_x_image': is a time series of flattened (1, ) calculed from images (32, 32, 3) list \n",
        "  #I had to flatten it because panda does not create table with this format\n",
        "  'market_state': future markket state to be predicted time lag is futlag\n",
        "  'future_value': future value of stock price to predict  time lag is futlag\n",
        "  'future_volatility':  time serie of the future volatility of the index time lag is futlag\n",
        "  '''\n",
        "\n",
        "  df_stockvaluecorrected=xdf\n",
        "  df_stockvaluecorrected, _ = normalise_df_image(df_stockvaluecorrected)\n",
        "  df_pctchge = df_stockvaluecorrected.pct_change(periods=past_step)\n",
        "  df_movave = df_stockvaluecorrected.rolling(window=past_step).mean()\n",
        "  df_volaty = np.sqrt(252)*df_pctchge.rolling(window=past_step).std()\n",
        "  df_max =df_stockvaluecorrected.rolling(window=past_step).max()\n",
        "  df_min =df_stockvaluecorrected.rolling(window=past_step).min()\n",
        "  df_Fut_value =df_stockvaluecorrected.shift(periods=-fut_step)\n",
        "  df_Fut_value.name='future_value'\n",
        "  df_Fut_volaty =df_volaty.shift(periods=-fut_step)\n",
        "  \n",
        "  df_market_state=pd.DataFrame(index=df_stockvaluecorrected.index,columns=['market_state'],dtype=np.float64)\n",
        "  \n",
        "  tmpimage=build_image(df_stockvaluecorrected,past_step+1,pastlag=past_step,futlag=fut_step)\n",
        "  flatten_image=np.reshape(tmpimage,(1,-1))\n",
        "  colname_d_x_image_flattened = ['Image Col'+str(j) for j in range(flatten_image.shape[1])]\n",
        "\n",
        "  np_x_image=np.zeros((len(df_stockvaluecorrected.index),flatten_image.shape[1]))\n",
        "  \n",
        "  for i in range(len(df_stockvaluecorrected.index)):\n",
        "        yfut=df_Fut_value.iloc[i]\n",
        "        df_market_state.iloc[i]=class_shortterm_returnfut(df_stockvaluecorrected,yfut, i,tpastlag=past_step)\n",
        "        print(\"loop 1 market state :\", \"step \",i,\"market state fut\", df_market_state.iloc[i],\" future value\",df_Fut_value.iloc[i] )\n",
        "  df_market_state.index=df_Fut_value.index\n",
        "\n",
        "  fig=plt.figure()\n",
        "  for i in range(len(df_stockvaluecorrected.index)):\n",
        "        try:\n",
        "          tmpimage=build_image_optimfig(fig, df_stockvaluecorrected,i,pastlag=past_step,futlag=fut_step)\n",
        "          np_x_image[i,:]=np.reshape(tmpimage,(1,-1))\n",
        "          print(\"loop 2 image :\", \"step \",i,\"market state fut\", df_market_state.iloc[i],\" future value\",df_Fut_value.iloc[i] )\n",
        "        except:\n",
        "           print(\"error at index\", i)\n",
        "           \n",
        "\n",
        "  df_x_image=pd.DataFrame(data=np_x_image,columns=colname_d_x_image_flattened, index=df_stockvaluecorrected.index)\n",
        "  fig.clear\n",
        "  plt.close(fig)\n",
        "\n",
        "\n",
        "  df_data= {\n",
        "          'stock_value': df_stockvaluecorrected, \n",
        "          'moving_average': df_movave, \n",
        "          \"max\": df_max, \n",
        "          \"min\": df_max,\n",
        "          'volatility': df_volaty,\n",
        "          'future_volatility': df_Fut_volaty,\n",
        "          \n",
        "          'df_x_image':df_x_image,\n",
        "          'market_state':df_market_state,\n",
        "          'future_value': df_Fut_value,\n",
        "\n",
        "          }\n",
        "\n",
        "  return df_data\n",
        "\n",
        "def build_image_clean(stockindex_ohlcv, ret_image_size=(32,32,3), idate=10, pastlag=32):\n",
        "  '''\n",
        "  TO BE COMPLETED\n",
        "  NOT USED NOW\n",
        "  \n",
        "  change one date into an array (32,32,3)\n",
        "  Each absciss pixel is one day\n",
        "  in ordinate the min value of ohlc shall be 0 (volume is tabled on the third image) \n",
        "  in ordinate the max value of ohlc shall be  (volume is tabled on the third image) \n",
        "  1st image: 32 x32\n",
        "    based on each day we place the open and close point\n",
        "    in ordinate int (255 * price /max ohlc)\n",
        "    with value of  255 for close and 127 for open\n",
        "  2nd image: 32 x32\n",
        "    based on each day we place the high low point \n",
        "    in ordinate int (255 * price /max ohlc)\n",
        "    with 64 for high and 32 for low\n",
        "  3rd image: 32 x32\n",
        "    each column value is a equal to int 255* volume of day / volume max period)\n",
        "  '''\n",
        "  #number of days to consider for translate\n",
        "  tsindexstock=stockindex_ohlcv.iloc[(idate-pastlag):idate]\n",
        "  valmax=np.max(np.array(tsindexstock[tsindexstock.columns[:-1]]))\n",
        "  valmin=np.min(np.array(tsindexstock[tsindexstock.columns[:-1]]))\n",
        "  vol=tsindexstock[tsindexstock.columns[-1]]\n",
        "  \n",
        "  x_datas=np.zeros(ret_image_size)\n",
        "  \n",
        "  return x_datas\n",
        "  \n",
        "def setup_input_NN_image(xdf, past_step=25,fut_step=5, split=0.8):\n",
        "  '''\n",
        "  this function the time serie of the index price \n",
        "  and generate the random dataset with split value from the whole time serie\n",
        "  X is a time serie of the flattened 32, 32 ,3 image list\n",
        "  Y_StateClass is a time serie of future state to predict with a classification made with class_shortterm_returnfut\n",
        "  Y_FutPredict is the time serie of stocke index shifted in time to be predicted\n",
        "  we randomize the dates and retun 2 set of dataframes\n",
        "  '''\n",
        "  xdf_data=build_image_df(xdf,past_step,fut_step)\n",
        "  \n",
        "  tmp_data=pd.concat([xdf_data['market_state'],xdf_data['future_value'],xdf_data['df_x_image']],axis=1)\n",
        "  tmp_data=tmp_data.dropna()\n",
        "\n",
        "  Y_StateClass= tmp_data['market_state']\n",
        "  Y_FutPredict= tmp_data['future_value']  \n",
        "  X=tmp_data.drop(columns=['market_state','future_value'])\n",
        "\n",
        "  nb_dates=len(Y_StateClass.index)\n",
        "  rng = np.random.default_rng()\n",
        "  list_shuffle = np.arange(nb_dates)\n",
        "  rng.shuffle(list_shuffle)\n",
        "  split_index=int(split*nb_dates)\n",
        "    \n",
        "  train_split=list_shuffle[:split_index]\n",
        "  test_split=list_shuffle[(split_index+1):]\n",
        "\n",
        "  X_train=(X.iloc[train_split])\n",
        "  Y_train_StateClass=(Y_StateClass.iloc[train_split])\n",
        "  Y_train_FutPredict=(Y_FutPredict.iloc[train_split])\n",
        "\n",
        "  X_test=(X.iloc[test_split])\n",
        "  Y_test_StateClass=(Y_StateClass.iloc[test_split])\n",
        "  Y_test_FutPredict=(Y_FutPredict.iloc[test_split])\n",
        "\n",
        "  return (X_train, Y_train_StateClass, Y_train_FutPredict), (X_test, Y_test_StateClass, Y_test_FutPredict)\n",
        "\n",
        "def change_X_df__nparray_image(df_X_train_image_flattened ):\n",
        "  '''\n",
        "  setup_input_NN_image returns a dataframe of flaten image for x train and xtest\n",
        "  then this function will change each date into a nparray list of images with 32, 32, 3 size \n",
        "  '''\n",
        "  X_train_image=df_X_train_image_flattened\n",
        "  nb_train=len(X_train_image.index)\n",
        "  \n",
        "  x_train=np.zeros((nb_train,32,32,3))\n",
        "  for i in range(nb_train):\n",
        "    tmp=np.array(X_train_image.iloc[i])\n",
        "    tmp=tmp.reshape(32,32,3)\n",
        "    x_train[i]=tmp\n",
        "  return x_train\n",
        "\n",
        "\n",
        "'''\n",
        "COMMAND NOW FOR THE DATSET GENERATION\n",
        "'''\n",
        "\n",
        "#Recuperation from yahoo of sp500 large history\n",
        "start = datetime(1920,1,1)\n",
        "end = datetime(2020,7,31)\n",
        "yf.pdr_override() # <== that's all it takes :-)\n",
        "sp500 = pdr.get_data_yahoo('^GSPC', \n",
        "                           start,\n",
        "                             end)\n",
        "\n",
        "#generate the dataset it can take 6 - 8 hours\n",
        "#Need to be optimzed with more time\n",
        "testsp500=(sp500['Close'])[1000:2000]\n",
        "(X_train_image, Y_train_StateClass_image, Y_train_FutPredict_image) , (X_test_image, Y_test_StateClass_image, Y_test_FutPredict_image) = setup_input_NN_image(testsp500)\n",
        "\n",
        "#copy the datafrae dataset in csv format to be used after\n",
        "#dateTimeObj = datetime.now()\n",
        "#timeStr = dateTimeObj.strftime(\"%Y_%m_%d_%H_%M_%S_%f\")\n",
        "\n",
        "X_train_image.to_csv('datas/X_train_image.csv')\n",
        "Y_train_StateClass_image.to_csv('datas/Y_train_StateClass_image.csv')\n",
        "Y_train_FutPredict_image.to_csv('datas/Y_train_FutPredict_image.csv')\n",
        "\n",
        "X_test_image.to_csv('datas/X_test_image.csv')\n",
        "Y_test_StateClass_image.to_csv('datas/Y_test_StateClass_image.csv')\n",
        "Y_test_FutPredict_image.to_csv('datas/Y_test_FutPredict_image.csv')\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-2c9080b177c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbs4\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mbs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0myfinance\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0myf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfix_yahoo_finance\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0myf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'yfinance'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V_QcOSjqMHSy",
        "colab_type": "text"
      },
      "source": [
        "##Step 2: Loading training datas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MTfVYoKBaQzZ",
        "colab_type": "text"
      },
      "source": [
        "This part is for loading the training dataset as it is better to generate it once for all in step 1 because of it time consuming process.\n",
        "\n",
        "This part also configure back the X_train datas from dataframe based on columns to a (32,32,3) np. array for the input of the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZaTlBZjJp61",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pylab as plt\n",
        "import pandas as pd\n",
        "\n",
        "from keras.datasets import cifar10\n",
        "from keras.utils import np_utils\n",
        "from keras.models import Sequential\n",
        "from keras import optimizers\n",
        "from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
        "from keras.layers import Dropout, Flatten, GlobalAveragePooling2D\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "'''\n",
        "UTILITY FUNCTIONS\n",
        "'''\n",
        "\n",
        "def change_X_df__nparray_image(df_X_train_image_flattened ):\n",
        "  '''\n",
        "  setup_input_NN_image returns a dataframe of flaten image for x train and xtest\n",
        "  then this function will change each date into a nparray list of images with 32, 32, 3 size \n",
        "  '''\n",
        "  X_train_image=df_X_train_image_flattened\n",
        "  nb_train=len(X_train_image.index)\n",
        "  \n",
        "  x_train=np.zeros((nb_train,32,32,3))\n",
        "  for i in range(nb_train):\n",
        "    tmp=np.array(X_train_image.iloc[i])\n",
        "    tmp=tmp.reshape(32,32,3)\n",
        "    x_train[i]=tmp\n",
        "  return x_train\n",
        "\n",
        "'''\n",
        "MAIN EXECUTIONS\n",
        "'''\n",
        "#recuperation of datas \n",
        "X_train_image=pd.read_csv('datas/X_train_image.csv')\n",
        "Y_train_StateClass_image=pd.read_csv('datas/Y_train_StateClass_image.csv')\n",
        "Y_train_FutPredict_image=pd.read_csv('datas/Y_train_FutPredict_image.csv')\n",
        "\n",
        "\n",
        "#setting up the index to Date\n",
        "X_train_image=X_train_image.set_index(\"Date\")\n",
        "Y_train_StateClass_image=Y_train_StateClass_image.set_index(\"Date\")\n",
        "Y_train_FutPredict_image=Y_train_FutPredict_image.set_index(\"Date\")\n",
        "\n",
        "#modify dataset to np array for input to NN\n",
        "x_train=change_X_df__nparray_image(X_train_image)\n",
        "y_train_state=np.array(Y_train_StateClass_image)\n",
        "y_train_value=np.array(Y_train_FutPredict_image)\n",
        "\n",
        "##Setting up xtrain and ytrain\n",
        "#Here we focus on predicting the future state Y_train_StateClass_image\n",
        "nb_train=len(X_train_image.index)\n",
        "x_train=np.zeros((nb_train,32,32,3))\n",
        "for i in range(nb_train):\n",
        "  tmp=np.array(X_train_image.iloc[i])\n",
        "  tmp=tmp.reshape(32,32,3)\n",
        "  x_train[i]=tmp\n",
        "  \n",
        "y_train=np.array(Y_train_StateClass_image)\n",
        "#y_train=np.array(Y_train_FutPredict_image)\n",
        "\n",
        "nb_train=len(X_train_image.index)\n",
        "x_train=np.zeros((nb_train,32,32,3))\n",
        "for i in range(nb_train):\n",
        "  tmp=np.array(X_train_image.iloc[i])\n",
        "  tmp=tmp.reshape(32,32,3)\n",
        "  x_train[i]=tmp\n",
        "\n",
        "y_train=np.array(Y_train_StateClass_image)\n",
        "#y_train=np.array(Y_train_FutPredict_image)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6Z8846EWC3F",
        "colab_type": "text"
      },
      "source": [
        "##Step 3: Build up of the VGGsp500 model and train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tbRtrFYtaDI5",
        "colab_type": "text"
      },
      "source": [
        "In this part we suppose that we have the training dataset taken from step 2. We use a Transfert model for vgg16 and some other layers. we use for this example a categorical_crossentropy loss and rmsprop optimizer. This part can be fined tuned for each financial index or stock index (layers, optimmizer, metrics, dropout) but in this case we introduced a simplier case. We train and save the model, please refer to XX to see the convergence of the model.\n",
        "\n",
        "We have 14.7M parameters and 66k trainable parametres. the size of training input is 571M only for the image not including rolling volatility, moving average etc\n",
        "\n",
        "NB: If you have an error on size of input of the ytrain you have to reload the input executing  step 2 once again"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nKB6wsOjMTys",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "e2aed461-5d97-4b4e-84bc-c6af4176a1a6"
      },
      "source": [
        "\n",
        "import numpy as np\n",
        "import pylab as plt\n",
        "import pandas as pd\n",
        "\n",
        "from keras.datasets import cifar10\n",
        "from keras.utils import np_utils\n",
        "from keras.models import Sequential\n",
        "from keras import optimizers\n",
        "from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
        "from keras.layers import Dropout, Flatten, GlobalAveragePooling2D\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "'''\n",
        "we suppose that we have loaded xtrain and ytrain\n",
        "This part is based on the Design of the NN\n",
        "Her we find the Vgg16 quite usefull\n",
        "'''\n",
        "\n",
        "#Importing the VGG16 model\n",
        "from keras.applications.vgg16 import VGG16, preprocess_input\n",
        "\n",
        "#Importing the VGG16 model\n",
        "from keras.applications.vgg16 import VGG16, preprocess_input\n",
        "\n",
        "batch_size=32\n",
        "epochs=50\n",
        "\n",
        "\n",
        "#Loading the VGG16 model with pre-trained ImageNet weights\n",
        "vgg_model = VGG16(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n",
        "vgg_model.trainable = False # remove if you want to retrain vgg weights\n",
        "\n",
        "vgg_model.summary()\n",
        "\n",
        "#At this stage we have x and y to train the model\n",
        "#In our example we need to y into categorical as it has 6 categories\n",
        "nb_classes=6\n",
        "y_train = np_utils.to_categorical(y_train, nb_classes)\n",
        "\n",
        "##Transfert model from vgg\n",
        "transfer_model = Sequential()\n",
        "transfer_model.add(vgg_model)\n",
        "transfer_model.add(Flatten())\n",
        "transfer_model.add(Dense(128, activation='relu'))\n",
        "transfer_model.add(Dropout(0.2))\n",
        "transfer_model.add(Dense(6, activation='softmax'))\n",
        "\n",
        "##Display summary of neural network\n",
        "transfer_model.summary()\n",
        "\n",
        "transfer_model.compile(loss='categorical_crossentropy', optimizer='rmsprop',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "##Fitting the model on the train data and labels.\n",
        "history = transfer_model.fit(x_train, y_train, \\\n",
        "                              batch_size=batch_size, epochs=epochs, \\\n",
        "                              validation_split=0.2, verbose=1, shuffle=True)\n",
        "\n",
        "# Saving themodel\n",
        "transfer_model.save('model/vggforsp500.h5')\n",
        "\n",
        "\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 32, 32, 64)        1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 32, 32, 64)        36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 16, 16, 128)       73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 16, 16, 128)       147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 8, 8, 256)         295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 8, 8, 256)         590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 8, 8, 256)         590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 4, 4, 256)         0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 4, 4, 512)         1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 2, 2, 512)         0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 1, 1, 512)         0         \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 0\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "vgg16 (Functional)           (None, 1, 1, 512)         14714688  \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 128)               65664     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 6)                 774       \n",
            "=================================================================\n",
            "Total params: 14,781,126\n",
            "Trainable params: 66,438\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "20/20 [==============================] - 9s 427ms/step - loss: 1.5354 - accuracy: 0.3286 - val_loss: 1.3667 - val_accuracy: 0.3875\n",
            "Epoch 2/50\n",
            "20/20 [==============================] - 8s 415ms/step - loss: 1.4616 - accuracy: 0.3695 - val_loss: 1.3693 - val_accuracy: 0.4125\n",
            "Epoch 3/50\n",
            "20/20 [==============================] - 8s 414ms/step - loss: 1.4453 - accuracy: 0.3632 - val_loss: 1.3463 - val_accuracy: 0.4313\n",
            "Epoch 4/50\n",
            "20/20 [==============================] - 8s 415ms/step - loss: 1.4183 - accuracy: 0.3695 - val_loss: 1.3449 - val_accuracy: 0.4437\n",
            "Epoch 5/50\n",
            "20/20 [==============================] - 8s 415ms/step - loss: 1.4130 - accuracy: 0.3553 - val_loss: 1.3103 - val_accuracy: 0.4938\n",
            "Epoch 6/50\n",
            "20/20 [==============================] - 8s 418ms/step - loss: 1.4119 - accuracy: 0.4104 - val_loss: 1.3332 - val_accuracy: 0.3562\n",
            "Epoch 7/50\n",
            "20/20 [==============================] - 8s 414ms/step - loss: 1.4071 - accuracy: 0.3805 - val_loss: 1.2946 - val_accuracy: 0.4750\n",
            "Epoch 8/50\n",
            "20/20 [==============================] - 8s 415ms/step - loss: 1.3952 - accuracy: 0.3915 - val_loss: 1.3242 - val_accuracy: 0.4250\n",
            "Epoch 9/50\n",
            "20/20 [==============================] - 8s 413ms/step - loss: 1.3815 - accuracy: 0.4041 - val_loss: 1.3043 - val_accuracy: 0.4500\n",
            "Epoch 10/50\n",
            "20/20 [==============================] - 8s 411ms/step - loss: 1.3853 - accuracy: 0.4167 - val_loss: 1.3139 - val_accuracy: 0.4437\n",
            "Epoch 11/50\n",
            "20/20 [==============================] - 8s 415ms/step - loss: 1.3872 - accuracy: 0.3915 - val_loss: 1.3434 - val_accuracy: 0.4563\n",
            "Epoch 12/50\n",
            "20/20 [==============================] - 8s 414ms/step - loss: 1.3725 - accuracy: 0.4198 - val_loss: 1.3158 - val_accuracy: 0.4500\n",
            "Epoch 13/50\n",
            "20/20 [==============================] - 8s 412ms/step - loss: 1.3509 - accuracy: 0.4355 - val_loss: 1.3276 - val_accuracy: 0.4437\n",
            "Epoch 14/50\n",
            "20/20 [==============================] - 8s 414ms/step - loss: 1.3434 - accuracy: 0.4277 - val_loss: 1.2914 - val_accuracy: 0.4500\n",
            "Epoch 15/50\n",
            "20/20 [==============================] - 8s 413ms/step - loss: 1.3612 - accuracy: 0.3978 - val_loss: 1.2883 - val_accuracy: 0.4437\n",
            "Epoch 16/50\n",
            "20/20 [==============================] - 8s 414ms/step - loss: 1.3427 - accuracy: 0.4182 - val_loss: 1.2976 - val_accuracy: 0.4437\n",
            "Epoch 17/50\n",
            "20/20 [==============================] - 8s 414ms/step - loss: 1.3575 - accuracy: 0.4025 - val_loss: 1.3017 - val_accuracy: 0.4375\n",
            "Epoch 18/50\n",
            "20/20 [==============================] - 8s 416ms/step - loss: 1.3434 - accuracy: 0.4340 - val_loss: 1.3173 - val_accuracy: 0.4313\n",
            "Epoch 19/50\n",
            "20/20 [==============================] - 8s 420ms/step - loss: 1.3547 - accuracy: 0.4261 - val_loss: 1.2896 - val_accuracy: 0.4437\n",
            "Epoch 20/50\n",
            "20/20 [==============================] - 8s 416ms/step - loss: 1.3317 - accuracy: 0.4465 - val_loss: 1.3003 - val_accuracy: 0.4250\n",
            "Epoch 21/50\n",
            "20/20 [==============================] - 8s 417ms/step - loss: 1.3344 - accuracy: 0.4245 - val_loss: 1.3428 - val_accuracy: 0.4625\n",
            "Epoch 22/50\n",
            "20/20 [==============================] - 8s 415ms/step - loss: 1.3373 - accuracy: 0.4292 - val_loss: 1.2990 - val_accuracy: 0.4938\n",
            "Epoch 23/50\n",
            "20/20 [==============================] - 8s 418ms/step - loss: 1.3266 - accuracy: 0.4277 - val_loss: 1.3137 - val_accuracy: 0.4313\n",
            "Epoch 24/50\n",
            "20/20 [==============================] - 9s 433ms/step - loss: 1.3303 - accuracy: 0.4355 - val_loss: 1.2784 - val_accuracy: 0.4750\n",
            "Epoch 25/50\n",
            "20/20 [==============================] - 8s 416ms/step - loss: 1.3324 - accuracy: 0.4355 - val_loss: 1.2697 - val_accuracy: 0.4563\n",
            "Epoch 26/50\n",
            "20/20 [==============================] - 8s 417ms/step - loss: 1.3152 - accuracy: 0.4324 - val_loss: 1.2584 - val_accuracy: 0.4812\n",
            "Epoch 27/50\n",
            "20/20 [==============================] - 8s 414ms/step - loss: 1.3165 - accuracy: 0.4245 - val_loss: 1.2948 - val_accuracy: 0.4500\n",
            "Epoch 28/50\n",
            "20/20 [==============================] - 8s 415ms/step - loss: 1.3048 - accuracy: 0.4403 - val_loss: 1.2593 - val_accuracy: 0.4812\n",
            "Epoch 29/50\n",
            "20/20 [==============================] - 8s 413ms/step - loss: 1.2991 - accuracy: 0.4418 - val_loss: 1.2362 - val_accuracy: 0.4437\n",
            "Epoch 30/50\n",
            "20/20 [==============================] - 8s 414ms/step - loss: 1.3245 - accuracy: 0.4119 - val_loss: 1.2505 - val_accuracy: 0.5000\n",
            "Epoch 31/50\n",
            "20/20 [==============================] - 8s 414ms/step - loss: 1.3094 - accuracy: 0.4292 - val_loss: 1.2253 - val_accuracy: 0.4563\n",
            "Epoch 32/50\n",
            "20/20 [==============================] - 8s 416ms/step - loss: 1.3129 - accuracy: 0.4355 - val_loss: 1.2512 - val_accuracy: 0.4625\n",
            "Epoch 33/50\n",
            "20/20 [==============================] - 9s 431ms/step - loss: 1.2887 - accuracy: 0.4560 - val_loss: 1.2367 - val_accuracy: 0.4812\n",
            "Epoch 34/50\n",
            "20/20 [==============================] - 9s 433ms/step - loss: 1.3010 - accuracy: 0.4418 - val_loss: 1.2666 - val_accuracy: 0.4750\n",
            "Epoch 35/50\n",
            "20/20 [==============================] - 8s 417ms/step - loss: 1.2900 - accuracy: 0.4403 - val_loss: 1.2435 - val_accuracy: 0.5000\n",
            "Epoch 36/50\n",
            "20/20 [==============================] - 8s 412ms/step - loss: 1.3021 - accuracy: 0.4261 - val_loss: 1.2368 - val_accuracy: 0.4625\n",
            "Epoch 37/50\n",
            "20/20 [==============================] - 8s 414ms/step - loss: 1.2931 - accuracy: 0.4292 - val_loss: 1.2723 - val_accuracy: 0.4750\n",
            "Epoch 38/50\n",
            "20/20 [==============================] - 8s 414ms/step - loss: 1.2900 - accuracy: 0.4575 - val_loss: 1.2066 - val_accuracy: 0.4812\n",
            "Epoch 39/50\n",
            "20/20 [==============================] - 8s 415ms/step - loss: 1.2893 - accuracy: 0.4198 - val_loss: 1.2442 - val_accuracy: 0.4812\n",
            "Epoch 40/50\n",
            "20/20 [==============================] - 8s 415ms/step - loss: 1.2849 - accuracy: 0.4355 - val_loss: 1.2229 - val_accuracy: 0.4437\n",
            "Epoch 41/50\n",
            "20/20 [==============================] - 8s 412ms/step - loss: 1.2904 - accuracy: 0.4355 - val_loss: 1.2392 - val_accuracy: 0.4563\n",
            "Epoch 42/50\n",
            "20/20 [==============================] - 8s 415ms/step - loss: 1.2864 - accuracy: 0.4403 - val_loss: 1.2397 - val_accuracy: 0.5000\n",
            "Epoch 43/50\n",
            "20/20 [==============================] - 8s 413ms/step - loss: 1.2847 - accuracy: 0.4465 - val_loss: 1.2310 - val_accuracy: 0.4688\n",
            "Epoch 44/50\n",
            "20/20 [==============================] - 8s 414ms/step - loss: 1.2692 - accuracy: 0.4497 - val_loss: 1.2496 - val_accuracy: 0.4750\n",
            "Epoch 45/50\n",
            "20/20 [==============================] - 8s 414ms/step - loss: 1.2782 - accuracy: 0.4340 - val_loss: 1.2076 - val_accuracy: 0.4750\n",
            "Epoch 46/50\n",
            "20/20 [==============================] - 8s 413ms/step - loss: 1.2708 - accuracy: 0.4403 - val_loss: 1.2284 - val_accuracy: 0.4812\n",
            "Epoch 47/50\n",
            "20/20 [==============================] - 8s 413ms/step - loss: 1.2798 - accuracy: 0.4560 - val_loss: 1.2055 - val_accuracy: 0.4688\n",
            "Epoch 48/50\n",
            "20/20 [==============================] - 8s 413ms/step - loss: 1.2614 - accuracy: 0.4481 - val_loss: 1.2250 - val_accuracy: 0.5063\n",
            "Epoch 49/50\n",
            "20/20 [==============================] - 8s 416ms/step - loss: 1.2672 - accuracy: 0.4638 - val_loss: 1.1949 - val_accuracy: 0.5000\n",
            "Epoch 50/50\n",
            "20/20 [==============================] - 8s 413ms/step - loss: 1.2695 - accuracy: 0.4560 - val_loss: 1.2073 - val_accuracy: 0.4688\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R2_xo8psY5Iy",
        "colab_type": "text"
      },
      "source": [
        "##Step 4: Evaluate the VGGsp500 model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PXXUYNbwZ4TX",
        "colab_type": "text"
      },
      "source": [
        "This part will evaluate the model with the testing dataset that we generated in first step. We show the accuracy, the confusion matrix and the classification report"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yxMUW3tCMVBM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "e06aeb9e-d403-4ee5-84dd-b9cedcdb1ad4"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from keras.utils import np_utils\n",
        "from keras.models import load_model\n",
        "from keras import backend as K\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "'''\n",
        "Here we have a trained model model/vggforsp500.h5 and datas for testing \n",
        "datas/X_test_image.csv\n",
        "datas/Y_test_StateClass_image.csv\n",
        "datas/Y_test_FutPredict_image.csv\n",
        "\n",
        "'''\n",
        "\n",
        "##\n",
        "'''\n",
        "UTILITY FUNCTIONS\n",
        "to put in another file\n",
        "'''\n",
        "\n",
        "def change_X_df__nparray_image(df_X_train_image_flattened ):\n",
        "  '''\n",
        "  setup_input_NN_image returns a dataframe of flaten image for x train and xtest\n",
        "  then this function will change each date into a nparray list of images with 32, 32, 3 size \n",
        "  '''\n",
        "  X_train_image=df_X_train_image_flattened\n",
        "  nb_train=len(X_train_image.index)\n",
        "  \n",
        "  x_train=np.zeros((nb_train,32,32,3))\n",
        "  for i in range(nb_train):\n",
        "    tmp=np.array(X_train_image.iloc[i])\n",
        "    tmp=tmp.reshape(32,32,3)\n",
        "    x_train[i]=tmp\n",
        "  return x_train\n",
        "##\n",
        "\n",
        "\n",
        "trained_model_path='model/vggforsp500.h5'\n",
        "\n",
        "#recuperation of testing datas and organising it \n",
        "X_test_image=pd.read_csv('datas/X_test_image.csv')\n",
        "Y_test_StateClass_image=pd.read_csv('datas/Y_test_StateClass_image.csv')\n",
        "Y_test_FutPredict_image=pd.read_csv('datas/Y_test_FutPredict_image.csv')\n",
        "\n",
        "#setting up the index to Date\n",
        "X_test_image=X_test_image.set_index(\"Date\")\n",
        "Y_test_StateClass_image=Y_test_StateClass_image.set_index(\"Date\")\n",
        "Y_test_FutPredict_image=Y_test_FutPredict_image.set_index(\"Date\")\n",
        "\n",
        "#modify dataset to np array for input to NN\n",
        "x_test=change_X_df__nparray_image(X_test_image)\n",
        "y_test_state=np.array(Y_test_StateClass_image)\n",
        "y_test_value=np.array(Y_test_FutPredict_image)\n",
        "\n",
        "##Setting up xtest and ytest\n",
        "#Here we focus on predicting the future state Y_train_StateClass_image\n",
        "nb_test=len(X_test_image.index)\n",
        "x_test=np.zeros((nb_test,32,32,3))\n",
        "for i in range(nb_test):\n",
        "  tmp=np.array(X_test_image.iloc[i])\n",
        "  tmp=tmp.reshape(32,32,3)\n",
        "  x_test[i]=tmp\n",
        "\n",
        "y_test=np.array(Y_test_StateClass_image)\n",
        "#y_test=np.array(Y_test_FutPredict_image)\n",
        "\n",
        "#In our example we need to y into categorical as it has 6 categories\n",
        "nb_classes=6\n",
        "y_test_m = np_utils.to_categorical(y_test, nb_classes)\n",
        "############\n",
        "#recuperation of model\n",
        "vggsp500model = load_model(trained_model_path)\n",
        "\n",
        "#Evaluate the model on the test data\n",
        "score  = vggsp500model.evaluate(x_test, y_test_m)\n",
        "\n",
        "\n",
        "Y_pred = vggsp500model.predict(x_test)\n",
        "y_pred = np.argmax(Y_pred, axis=1)\n",
        "y= np.argmax(y_test_m,axis=1)\n",
        "\n",
        "\n",
        "print('Confusion Matrix')\n",
        "\n",
        "target_state = ['SS', 'SN', 'N','NB','BB']\n",
        "\n",
        "def statetostring(x):\n",
        "  return target_state[int(x)]\n",
        "\n",
        "sY_pred=[statetostring(i) for i in y_pred]\n",
        "sY_real=[statetostring(i) for i in y]\n",
        "\n",
        "#matrice  de confusion\n",
        "mat=confusion_matrix(sY_real, sY_pred, normalize='true', labels=target_state)\n",
        "df_confmat=pd.DataFrame(mat,index=target_state, columns=target_state)\n",
        "\n",
        "#Accuracy on test data\n",
        "print('Accuracy on the Test Images: ', score[1])\n",
        "#matrice  de confusion\n",
        "print(df_confmat)\n",
        "\n",
        "# Classification report\n",
        "print('classification report')\n",
        "print(classification_report(sY_real, sY_pred, target_names=target_state))\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7/7 [==============================] - 2s 260ms/step - loss: 1.3113 - accuracy: 0.4293\n",
            "Confusion Matrix\n",
            "Accuracy on the Test Images:  0.4292929172515869\n",
            "          SS        SN         N   NB        BB\n",
            "SS  0.000000  0.000000  0.266667  0.0  0.733333\n",
            "SN  0.000000  0.117647  0.470588  0.0  0.411765\n",
            "N   0.016667  0.066667  0.200000  0.0  0.716667\n",
            "NB  0.000000  0.000000  0.151515  0.0  0.848485\n",
            "BB  0.000000  0.000000  0.027397  0.0  0.972603\n",
            "classification report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          SS       0.44      0.97      0.61        73\n",
            "          SN       0.39      0.20      0.26        60\n",
            "           N       0.00      0.00      0.00        33\n",
            "          NB       0.33      0.12      0.17        17\n",
            "          BB       0.00      0.00      0.00        15\n",
            "\n",
            "    accuracy                           0.43       198\n",
            "   macro avg       0.23      0.26      0.21       198\n",
            "weighted avg       0.31      0.43      0.32       198\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TIz78gePZY76",
        "colab_type": "text"
      },
      "source": [
        "##Step 5: Guess future market state from random image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ulkwESoxZm1z",
        "colab_type": "text"
      },
      "source": [
        "Take an image of an historical graph from a market webpage like investing.com and save it to the ImageM/ folder with name image1.PNG or you can change the value of image_path to the link you need.\n",
        "\n",
        "This execution tell us which market state in the future is the best representative."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvqRijItZML8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "outputId": "e6dfc436-d1d2-4d4c-fb1f-4959443e378a"
      },
      "source": [
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "#path for trained model\n",
        "trained_model_path='model/vggforsp500.h5'\n",
        "\n",
        "#path for the image taken by the user\n",
        "image_path='ImageM/image1.PNG'\n",
        "\n",
        "#Load the image and resize it to 32x32 and taking off the transparency\n",
        "load_img_rz = np.array(Image.open(image_path).resize((32,32)))\n",
        "#Image.fromarray(load_img_rz).save('/content/drive/My Drive/_sample_data/ImageM/image1.PNG')\n",
        "image=load_img_rz[:,:,:3]/255\n",
        "print(\"After resizing:\",image.shape)\n",
        "\n",
        "#petite astuce pour ne pas avoir d erreur avec les types list, tensors,  nparray et dataframe\n",
        "doubleimage=np.array([image,image])\n",
        "############\n",
        "#recuperation of the model\n",
        "vggsp500model = load_model(trained_model_path)\n",
        "Y_pred = vggsp500model.predict(doubleimage)\n",
        "y_pred = np.argmax(Y_pred, axis=1)\n",
        "\n",
        "target_state = ['SS', 'SN', 'N','NB','BB','Error']\n",
        "df_result=pd.DataFrame((Y_pred))\n",
        "\n",
        "df_result.columns=target_state\n",
        "df_result.index=[image_path, image_path+'1']\n",
        "print (\"for \",image_path, \"the best result is \", target_state[int(y_pred[0])] )\n",
        "df_result"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "After resizing: (32, 32, 3)\n",
            "WARNING:tensorflow:5 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7eff7fae6ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "for  ImageM/image1.PNG the best result is  SN\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SS</th>\n",
              "      <th>SN</th>\n",
              "      <th>N</th>\n",
              "      <th>NB</th>\n",
              "      <th>BB</th>\n",
              "      <th>Error</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>ImageM/image1.PNG</th>\n",
              "      <td>0.038353</td>\n",
              "      <td>0.492284</td>\n",
              "      <td>0.381727</td>\n",
              "      <td>0.065877</td>\n",
              "      <td>0.021758</td>\n",
              "      <td>6.625338e-07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ImageM/image1.PNG1</th>\n",
              "      <td>0.038353</td>\n",
              "      <td>0.492284</td>\n",
              "      <td>0.381727</td>\n",
              "      <td>0.065877</td>\n",
              "      <td>0.021758</td>\n",
              "      <td>6.625352e-07</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                          SS        SN  ...        BB         Error\n",
              "ImageM/image1.PNG   0.038353  0.492284  ...  0.021758  6.625338e-07\n",
              "ImageM/image1.PNG1  0.038353  0.492284  ...  0.021758  6.625352e-07\n",
              "\n",
              "[2 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBOG00tVbHS7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}