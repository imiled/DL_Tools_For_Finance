{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transfert_Learning_Vgg16forSP500.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/imiled/DL_Tools_For_Finance/blob/master/Transfert_Learning_Reload_Cleaned_SP500.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QGkfWRfEIyvy",
        "outputId": "66a4aaf0-b497-4c12-8742-65b27fcb9195",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cAHcIW__zC2D"
      },
      "source": [
        "Downloading the project from github"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dWRUvmdLI64s",
        "outputId": "7e6e1338-d1e7-4ebb-bd41-6c84bba499da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "!git clone https://github.com/imiled/DL_Tools_For_Finance.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'DL_Tools_For_Finance'...\n",
            "remote: Enumerating objects: 305, done.\u001b[K\n",
            "remote: Counting objects: 100% (305/305), done.\u001b[K\n",
            "remote: Compressing objects: 100% (97/97), done.\u001b[K\n",
            "remote: Total 985 (delta 264), reused 204 (delta 204), pack-reused 680\u001b[K\n",
            "Receiving objects: 100% (985/985), 207.38 MiB | 40.18 MiB/s, done.\n",
            "Resolving deltas: 100% (550/550), done.\n",
            "Checking out files: 100% (63/63), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nr7TjeHXy80v"
      },
      "source": [
        "Saving dataset from drive to local"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3TiNDoAbMJx2",
        "outputId": "2461143e-2974-4951-d714-b6fd52a07124",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "%cd /content/drive/My Drive/A_transfertTFMVggSP500\n",
        "%cp DatasetVggSP500.zip /content/DL_Tools_For_Finance/datas\n",
        "%cd /content/DL_Tools_For_Finance/datas\n",
        "!unzip DatasetVggSP500.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/A_transfertTFMVggSP500\n",
            "/content/DL_Tools_For_Finance/datas\n",
            "Archive:  DatasetVggSP500.zip\n",
            "replace X_test_image.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n",
            "  inflating: X_test_image.csv        \n",
            "  inflating: X_train_image.csv       \n",
            "  inflating: Y_test_FutPredict_image.csv  \n",
            "  inflating: Y_test_StateClass_image.csv  \n",
            "  inflating: Y_train_FutPredict_image.csv  \n",
            "  inflating: Y_train_StateClass_image.csv  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mq_ZXp4zzQ7l"
      },
      "source": [
        "Saving latest model from drive to local"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iSxPytYKNjKH",
        "outputId": "be7754fe-5473-4898-a83b-df7e6c673fe3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "source": [
        "%cd /content/drive/My Drive/A_transfertTFMVggSP500 \n",
        "%cp model/final_modelcategorical_crossentropy_adam_32.h5 /content/DL_Tools_For_Finance/model\n",
        "%cp vggforsp500.h5 /content/DL_Tools_For_Finance/model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: '/content/drive/My Drive/A_transfertTFMVggSP500'\n",
            "/content/DL_Tools_For_Finance/datas\n",
            "cp: cannot stat 'model/final_modelcategorical_crossentropy_adam_32.h5': No such file or directory\n",
            "cp: cannot stat 'vggforsp500.h5': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VehZVTphSljL"
      },
      "source": [
        "###Requirement instalation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eYhh8KRGZXgO",
        "outputId": "0ca8113a-5e85-4bb8-bea1-08cba23e4c1f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "#for gpu google colab\n",
        "%cd /content/DL_Tools_For_Finance\n",
        "!pip3 install -r gpu_requirements.txt  "
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/DL_Tools_For_Finance\n",
            "\u001b[31mERROR: Invalid requirement: 'tensorflow=2.3.0' (from line 2 of gpu_requirements.txt)\n",
            "Hint: = is not a valid operator. Did you mean == ?\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EEpibDu_Ovpv"
      },
      "source": [
        "#for cpu\n",
        "%cd /content/DL_Tools_For_Finance\n",
        "!pip3 install -r requirements.txt  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dTwxPiI4zLz3"
      },
      "source": [
        "##Part with all steps through python command##"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_SEuIXmtTG26",
        "outputId": "35fef0a0-efce-4166-8dd0-77856a90d251",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "%cd /content/DL_Tools_For_Finance\n",
        "!python3 step1_generate_dataset_IndexImage.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: '/content/DL_Tools_For_Finance'\n",
            "/content\n",
            "python3: can't open file 'step1_generate_dataset_IndexImage.py': [Errno 2] No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jKbZEi02Ti5r",
        "outputId": "fd6b1d56-610a-4156-cc40-48381fc4c2b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "%cd /content/DL_Tools_For_Finance\n",
        "!python3 step2_loadingtrainingdatas_vgg_transfert_modelandtraining.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/DL_Tools_For_Finance\n",
            "2020-08-31 14:00:07.536779: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-08-31 14:00:23.283485: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1\n",
            "2020-08-31 14:00:23.354418: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-31 14:00:23.355305: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\n",
            "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.73GiB deviceMemoryBandwidth: 298.08GiB/s\n",
            "2020-08-31 14:00:23.355378: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-08-31 14:00:23.618262: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
            "2020-08-31 14:00:23.772071: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
            "2020-08-31 14:00:23.799494: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
            "2020-08-31 14:00:24.091903: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-08-31 14:00:24.121391: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-08-31 14:00:24.631937: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-08-31 14:00:24.632162: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-31 14:00:24.632916: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-31 14:00:24.633516: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\n",
            "2020-08-31 14:00:24.633867: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX512F\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2020-08-31 14:00:24.655218: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2000125000 Hz\n",
            "2020-08-31 14:00:24.655444: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1b70f40 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-08-31 14:00:24.655479: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2020-08-31 14:00:24.794351: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-31 14:00:24.795101: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1b70d80 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2020-08-31 14:00:24.795132: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "2020-08-31 14:00:24.796328: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-31 14:00:24.796900: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\n",
            "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.73GiB deviceMemoryBandwidth: 298.08GiB/s\n",
            "2020-08-31 14:00:24.796955: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-08-31 14:00:24.796995: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
            "2020-08-31 14:00:24.797016: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
            "2020-08-31 14:00:24.797040: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
            "2020-08-31 14:00:24.797060: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-08-31 14:00:24.797078: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-08-31 14:00:24.797098: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-08-31 14:00:24.797174: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-31 14:00:24.797845: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-31 14:00:24.798390: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\n",
            "2020-08-31 14:00:24.804305: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-08-31 14:00:28.654055: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-08-31 14:00:28.654111: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 \n",
            "2020-08-31 14:00:28.654124: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N \n",
            "2020-08-31 14:00:28.661735: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-31 14:00:28.662361: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-31 14:00:28.662893: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2020-08-31 14:00:28.662938: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13962 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 1s 0us/step\n",
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 32, 32, 64)        1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 32, 32, 64)        36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 16, 16, 128)       73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 16, 16, 128)       147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 8, 8, 256)         295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 8, 8, 256)         590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 8, 8, 256)         590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 4, 4, 256)         0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 4, 4, 512)         1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 2, 2, 512)         0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 1, 1, 512)         0         \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 0\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/50\n",
            "2020-08-31 14:00:30.921687: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
            "2020-08-31 14:00:32.390571: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
            "149/149 [==============================] - ETA: 0s - loss: 2.0473 - accuracy: 0.3377\n",
            "Epoch 00001: loss improved from inf to 2.04734, saving model to model/best_modelcategorical_crossentropy_adam_Batch100_LR0.1_0.99.hdf5\n",
            "149/149 [==============================] - 3s 21ms/step - loss: 2.0473 - accuracy: 0.3377 - val_loss: 1.4949 - val_accuracy: 0.3399\n",
            "Epoch 2/50\n",
            "145/149 [============================>.] - ETA: 0s - loss: 1.5323 - accuracy: 0.3433\n",
            "Epoch 00002: loss improved from 2.04734 to 1.53141, saving model to model/best_modelcategorical_crossentropy_adam_Batch100_LR0.1_0.99.hdf5\n",
            "149/149 [==============================] - 3s 17ms/step - loss: 1.5314 - accuracy: 0.3436 - val_loss: 1.4906 - val_accuracy: 0.3399\n",
            "Epoch 3/50\n",
            "149/149 [==============================] - ETA: 0s - loss: 1.5308 - accuracy: 0.3436\n",
            "Epoch 00003: loss improved from 1.53141 to 1.53084, saving model to model/best_modelcategorical_crossentropy_adam_Batch100_LR0.1_0.99.hdf5\n",
            "149/149 [==============================] - 3s 17ms/step - loss: 1.5308 - accuracy: 0.3436 - val_loss: 1.4926 - val_accuracy: 0.3399\n",
            "Epoch 4/50\n",
            "149/149 [==============================] - ETA: 0s - loss: 1.5320 - accuracy: 0.3436\n",
            "Epoch 00004: loss did not improve from 1.53084\n",
            "149/149 [==============================] - 2s 16ms/step - loss: 1.5320 - accuracy: 0.3436 - val_loss: 1.4935 - val_accuracy: 0.3399\n",
            "Epoch 5/50\n",
            "145/149 [============================>.] - ETA: 0s - loss: 1.5321 - accuracy: 0.3389\n",
            "Epoch 00005: loss did not improve from 1.53084\n",
            "149/149 [==============================] - 2s 16ms/step - loss: 1.5314 - accuracy: 0.3394 - val_loss: 1.5005 - val_accuracy: 0.3399\n",
            "Epoch 6/50\n",
            "145/149 [============================>.] - ETA: 0s - loss: 1.5315 - accuracy: 0.3385\n",
            "Epoch 00006: loss did not improve from 1.53084\n",
            "149/149 [==============================] - 2s 16ms/step - loss: 1.5321 - accuracy: 0.3381 - val_loss: 1.5235 - val_accuracy: 0.3399\n",
            "Epoch 7/50\n",
            "149/149 [==============================] - ETA: 0s - loss: 1.5318 - accuracy: 0.3414\n",
            "Epoch 00007: loss did not improve from 1.53084\n",
            "149/149 [==============================] - 2s 16ms/step - loss: 1.5318 - accuracy: 0.3414 - val_loss: 1.5054 - val_accuracy: 0.3399\n",
            "Epoch 8/50\n",
            "149/149 [==============================] - ETA: 0s - loss: 1.5345 - accuracy: 0.3360\n",
            "Epoch 00008: loss did not improve from 1.53084\n",
            "149/149 [==============================] - 2s 17ms/step - loss: 1.5345 - accuracy: 0.3360 - val_loss: 1.4982 - val_accuracy: 0.3399\n",
            "Epoch 9/50\n",
            "145/149 [============================>.] - ETA: 0s - loss: 1.5337 - accuracy: 0.3428\n",
            "Epoch 00009: loss did not improve from 1.53084\n",
            "149/149 [==============================] - 2s 17ms/step - loss: 1.5329 - accuracy: 0.3436 - val_loss: 1.5099 - val_accuracy: 0.3399\n",
            "Epoch 10/50\n",
            "149/149 [==============================] - ETA: 0s - loss: 1.5336 - accuracy: 0.3358\n",
            "Epoch 00010: loss did not improve from 1.53084\n",
            "149/149 [==============================] - 2s 16ms/step - loss: 1.5336 - accuracy: 0.3358 - val_loss: 1.4912 - val_accuracy: 0.3399\n",
            "Epoch 11/50\n",
            "145/149 [============================>.] - ETA: 0s - loss: 1.5348 - accuracy: 0.3426\n",
            "Epoch 00011: loss did not improve from 1.53084\n",
            "149/149 [==============================] - 2s 16ms/step - loss: 1.5333 - accuracy: 0.3436 - val_loss: 1.4965 - val_accuracy: 0.3399\n",
            "Epoch 12/50\n",
            "145/149 [============================>.] - ETA: 0s - loss: 1.5330 - accuracy: 0.3417\n",
            "Epoch 00012: loss did not improve from 1.53084\n",
            "149/149 [==============================] - 2s 16ms/step - loss: 1.5326 - accuracy: 0.3422 - val_loss: 1.5040 - val_accuracy: 0.3399\n",
            "Epoch 13/50\n",
            "145/149 [============================>.] - ETA: 0s - loss: 1.5341 - accuracy: 0.3383\n",
            "Epoch 00013: loss did not improve from 1.53084\n",
            "149/149 [==============================] - 2s 16ms/step - loss: 1.5341 - accuracy: 0.3381 - val_loss: 1.4915 - val_accuracy: 0.3399\n",
            "Epoch 14/50\n",
            "145/149 [============================>.] - ETA: 0s - loss: 1.5342 - accuracy: 0.3352\n",
            "Epoch 00014: loss did not improve from 1.53084\n",
            "149/149 [==============================] - 2s 16ms/step - loss: 1.5330 - accuracy: 0.3366 - val_loss: 1.5078 - val_accuracy: 0.3399\n",
            "Epoch 15/50\n",
            "149/149 [==============================] - ETA: 0s - loss: 1.5326 - accuracy: 0.3412\n",
            "Epoch 00015: loss did not improve from 1.53084\n",
            "149/149 [==============================] - 2s 16ms/step - loss: 1.5326 - accuracy: 0.3412 - val_loss: 1.5212 - val_accuracy: 0.3399\n",
            "Epoch 16/50\n",
            "149/149 [==============================] - ETA: 0s - loss: 1.5344 - accuracy: 0.3402\n",
            "Epoch 00016: loss did not improve from 1.53084\n",
            "149/149 [==============================] - 2s 16ms/step - loss: 1.5344 - accuracy: 0.3402 - val_loss: 1.5016 - val_accuracy: 0.3399\n",
            "Epoch 17/50\n",
            "149/149 [==============================] - ETA: 0s - loss: 1.5320 - accuracy: 0.3436\n",
            "Epoch 00017: loss did not improve from 1.53084\n",
            "149/149 [==============================] - 2s 17ms/step - loss: 1.5320 - accuracy: 0.3436 - val_loss: 1.4908 - val_accuracy: 0.3399\n",
            "Epoch 18/50\n",
            "145/149 [============================>.] - ETA: 0s - loss: 1.5335 - accuracy: 0.3357\n",
            "Epoch 00018: loss did not improve from 1.53084\n",
            "149/149 [==============================] - 2s 16ms/step - loss: 1.5332 - accuracy: 0.3360 - val_loss: 1.5041 - val_accuracy: 0.3399\n",
            "Epoch 19/50\n",
            "149/149 [==============================] - ETA: 0s - loss: 1.5333 - accuracy: 0.3388\n",
            "Epoch 00019: loss did not improve from 1.53084\n",
            "149/149 [==============================] - 2s 16ms/step - loss: 1.5333 - accuracy: 0.3388 - val_loss: 1.4987 - val_accuracy: 0.3399\n",
            "Epoch 20/50\n",
            "145/149 [============================>.] - ETA: 0s - loss: 1.5306 - accuracy: 0.3443\n",
            "Epoch 00020: loss improved from 1.53084 to 1.53068, saving model to model/best_modelcategorical_crossentropy_adam_Batch100_LR0.1_0.99.hdf5\n",
            "149/149 [==============================] - 3s 17ms/step - loss: 1.5307 - accuracy: 0.3436 - val_loss: 1.4947 - val_accuracy: 0.3399\n",
            "Epoch 21/50\n",
            "149/149 [==============================] - ETA: 0s - loss: 1.5315 - accuracy: 0.3436\n",
            "Epoch 00021: loss did not improve from 1.53068\n",
            "149/149 [==============================] - 3s 17ms/step - loss: 1.5315 - accuracy: 0.3436 - val_loss: 1.4899 - val_accuracy: 0.3399\n",
            "Epoch 22/50\n",
            "145/149 [============================>.] - ETA: 0s - loss: 1.5312 - accuracy: 0.3430\n",
            "Epoch 00022: loss did not improve from 1.53068\n",
            "149/149 [==============================] - 2s 17ms/step - loss: 1.5323 - accuracy: 0.3421 - val_loss: 1.5026 - val_accuracy: 0.3399\n",
            "Epoch 23/50\n",
            "145/149 [============================>.] - ETA: 0s - loss: 1.5311 - accuracy: 0.3438\n",
            "Epoch 00023: loss did not improve from 1.53068\n",
            "149/149 [==============================] - 2s 17ms/step - loss: 1.5313 - accuracy: 0.3436 - val_loss: 1.5046 - val_accuracy: 0.3399\n",
            "Epoch 24/50\n",
            "149/149 [==============================] - ETA: 0s - loss: 1.5319 - accuracy: 0.3413\n",
            "Epoch 00024: loss did not improve from 1.53068\n",
            "149/149 [==============================] - 2s 17ms/step - loss: 1.5319 - accuracy: 0.3413 - val_loss: 1.5038 - val_accuracy: 0.3399\n",
            "Epoch 25/50\n",
            "145/149 [============================>.] - ETA: 0s - loss: 1.5322 - accuracy: 0.3435\n",
            "Epoch 00025: loss did not improve from 1.53068\n",
            "149/149 [==============================] - 2s 17ms/step - loss: 1.5322 - accuracy: 0.3436 - val_loss: 1.5049 - val_accuracy: 0.3399\n",
            "Epoch 26/50\n",
            "149/149 [==============================] - ETA: 0s - loss: 1.5319 - accuracy: 0.3436\n",
            "Epoch 00026: loss did not improve from 1.53068\n",
            "149/149 [==============================] - 2s 17ms/step - loss: 1.5319 - accuracy: 0.3436 - val_loss: 1.4944 - val_accuracy: 0.3399\n",
            "Epoch 27/50\n",
            "149/149 [==============================] - ETA: 0s - loss: 1.5332 - accuracy: 0.3436\n",
            "Epoch 00027: loss did not improve from 1.53068\n",
            "149/149 [==============================] - 2s 17ms/step - loss: 1.5332 - accuracy: 0.3436 - val_loss: 1.5045 - val_accuracy: 0.3399\n",
            "Epoch 28/50\n",
            "145/149 [============================>.] - ETA: 0s - loss: 1.5328 - accuracy: 0.3399\n",
            "Epoch 00028: loss did not improve from 1.53068\n",
            "149/149 [==============================] - 2s 17ms/step - loss: 1.5326 - accuracy: 0.3402 - val_loss: 1.4924 - val_accuracy: 0.3399\n",
            "Epoch 29/50\n",
            "149/149 [==============================] - ETA: 0s - loss: 1.5317 - accuracy: 0.3436\n",
            "Epoch 00029: loss did not improve from 1.53068\n",
            "149/149 [==============================] - 2s 17ms/step - loss: 1.5317 - accuracy: 0.3436 - val_loss: 1.4979 - val_accuracy: 0.3399\n",
            "Epoch 30/50\n",
            "145/149 [============================>.] - ETA: 0s - loss: 1.5314 - accuracy: 0.3441\n",
            "Epoch 00030: loss did not improve from 1.53068\n",
            "149/149 [==============================] - 2s 17ms/step - loss: 1.5317 - accuracy: 0.3436 - val_loss: 1.4978 - val_accuracy: 0.3399\n",
            "Epoch 31/50\n",
            "149/149 [==============================] - ETA: 0s - loss: 1.5328 - accuracy: 0.3383\n",
            "Epoch 00031: loss did not improve from 1.53068\n",
            "149/149 [==============================] - 2s 17ms/step - loss: 1.5328 - accuracy: 0.3383 - val_loss: 1.5141 - val_accuracy: 0.3399\n",
            "Epoch 32/50\n",
            "149/149 [==============================] - ETA: 0s - loss: 1.5315 - accuracy: 0.3410\n",
            "Epoch 00032: loss did not improve from 1.53068\n",
            "149/149 [==============================] - 2s 17ms/step - loss: 1.5315 - accuracy: 0.3410 - val_loss: 1.4968 - val_accuracy: 0.3399\n",
            "Epoch 33/50\n",
            "149/149 [==============================] - ETA: 0s - loss: 1.5342 - accuracy: 0.3372\n",
            "Epoch 00033: loss did not improve from 1.53068\n",
            "149/149 [==============================] - 2s 17ms/step - loss: 1.5342 - accuracy: 0.3372 - val_loss: 1.4964 - val_accuracy: 0.3399\n",
            "Epoch 34/50\n",
            "149/149 [==============================] - ETA: 0s - loss: 1.5337 - accuracy: 0.3420\n",
            "Epoch 00034: loss did not improve from 1.53068\n",
            "149/149 [==============================] - 3s 17ms/step - loss: 1.5337 - accuracy: 0.3420 - val_loss: 1.4939 - val_accuracy: 0.3399\n",
            "Epoch 35/50\n",
            "149/149 [==============================] - ETA: 0s - loss: 1.5328 - accuracy: 0.3436\n",
            "Epoch 00035: loss did not improve from 1.53068\n",
            "149/149 [==============================] - 2s 17ms/step - loss: 1.5328 - accuracy: 0.3436 - val_loss: 1.4953 - val_accuracy: 0.3399\n",
            "Epoch 36/50\n",
            "145/149 [============================>.] - ETA: 0s - loss: 1.5336 - accuracy: 0.3441\n",
            "Epoch 00036: loss did not improve from 1.53068\n",
            "149/149 [==============================] - 3s 17ms/step - loss: 1.5341 - accuracy: 0.3436 - val_loss: 1.5010 - val_accuracy: 0.3399\n",
            "Epoch 37/50\n",
            "149/149 [==============================] - ETA: 0s - loss: 1.5328 - accuracy: 0.3399\n",
            "Epoch 00037: loss did not improve from 1.53068\n",
            "149/149 [==============================] - 3s 17ms/step - loss: 1.5328 - accuracy: 0.3399 - val_loss: 1.4952 - val_accuracy: 0.3399\n",
            "Epoch 38/50\n",
            "149/149 [==============================] - ETA: 0s - loss: 1.5319 - accuracy: 0.3415\n",
            "Epoch 00038: loss did not improve from 1.53068\n",
            "149/149 [==============================] - 2s 17ms/step - loss: 1.5319 - accuracy: 0.3415 - val_loss: 1.5012 - val_accuracy: 0.3399\n",
            "Epoch 39/50\n",
            "149/149 [==============================] - ETA: 0s - loss: 1.5335 - accuracy: 0.3417\n",
            "Epoch 00039: loss did not improve from 1.53068\n",
            "149/149 [==============================] - 3s 17ms/step - loss: 1.5335 - accuracy: 0.3417 - val_loss: 1.4931 - val_accuracy: 0.3399\n",
            "Epoch 40/50\n",
            "149/149 [==============================] - ETA: 0s - loss: 1.5328 - accuracy: 0.3427\n",
            "Epoch 00040: loss did not improve from 1.53068\n",
            "149/149 [==============================] - 3s 17ms/step - loss: 1.5328 - accuracy: 0.3427 - val_loss: 1.5152 - val_accuracy: 0.3399\n",
            "Epoch 41/50\n",
            "149/149 [==============================] - ETA: 0s - loss: 1.5332 - accuracy: 0.3414\n",
            "Epoch 00041: loss did not improve from 1.53068\n",
            "149/149 [==============================] - 3s 17ms/step - loss: 1.5332 - accuracy: 0.3414 - val_loss: 1.4931 - val_accuracy: 0.3399\n",
            "Epoch 42/50\n",
            "149/149 [==============================] - ETA: 0s - loss: 1.5312 - accuracy: 0.3436\n",
            "Epoch 00042: loss did not improve from 1.53068\n",
            "149/149 [==============================] - 3s 17ms/step - loss: 1.5312 - accuracy: 0.3436 - val_loss: 1.5019 - val_accuracy: 0.3399\n",
            "Epoch 43/50\n",
            "149/149 [==============================] - ETA: 0s - loss: 1.5320 - accuracy: 0.3397\n",
            "Epoch 00043: loss did not improve from 1.53068\n",
            "149/149 [==============================] - 3s 17ms/step - loss: 1.5320 - accuracy: 0.3397 - val_loss: 1.5109 - val_accuracy: 0.3399\n",
            "Epoch 44/50\n",
            "149/149 [==============================] - ETA: 0s - loss: 1.5329 - accuracy: 0.3436\n",
            "Epoch 00044: loss did not improve from 1.53068\n",
            "149/149 [==============================] - 3s 17ms/step - loss: 1.5329 - accuracy: 0.3436 - val_loss: 1.5056 - val_accuracy: 0.3399\n",
            "Epoch 45/50\n",
            "149/149 [==============================] - ETA: 0s - loss: 1.5321 - accuracy: 0.3436\n",
            "Epoch 00045: loss did not improve from 1.53068\n",
            "149/149 [==============================] - 3s 17ms/step - loss: 1.5321 - accuracy: 0.3436 - val_loss: 1.5010 - val_accuracy: 0.3399\n",
            "Epoch 46/50\n",
            "149/149 [==============================] - ETA: 0s - loss: 1.5316 - accuracy: 0.3409\n",
            "Epoch 00046: loss did not improve from 1.53068\n",
            "149/149 [==============================] - 3s 17ms/step - loss: 1.5316 - accuracy: 0.3409 - val_loss: 1.4912 - val_accuracy: 0.3399\n",
            "Epoch 47/50\n",
            "149/149 [==============================] - ETA: 0s - loss: 1.5313 - accuracy: 0.3436\n",
            "Epoch 00047: loss did not improve from 1.53068\n",
            "149/149 [==============================] - 3s 17ms/step - loss: 1.5313 - accuracy: 0.3436 - val_loss: 1.4899 - val_accuracy: 0.3399\n",
            "Epoch 48/50\n",
            "145/149 [============================>.] - ETA: 0s - loss: 1.5329 - accuracy: 0.3438\n",
            "Epoch 00048: loss did not improve from 1.53068\n",
            "149/149 [==============================] - 3s 17ms/step - loss: 1.5331 - accuracy: 0.3436 - val_loss: 1.5025 - val_accuracy: 0.3399\n",
            "Epoch 49/50\n",
            "145/149 [============================>.] - ETA: 0s - loss: 1.5322 - accuracy: 0.3412\n",
            "Epoch 00049: loss did not improve from 1.53068\n",
            "149/149 [==============================] - 3s 17ms/step - loss: 1.5326 - accuracy: 0.3408 - val_loss: 1.5109 - val_accuracy: 0.3399\n",
            "Epoch 50/50\n",
            "149/149 [==============================] - ETA: 0s - loss: 1.5326 - accuracy: 0.3436\n",
            "Epoch 00050: loss did not improve from 1.53068\n",
            "149/149 [==============================] - 3s 17ms/step - loss: 1.5326 - accuracy: 0.3436 - val_loss: 1.4915 - val_accuracy: 0.3399\n",
            "Traceback (most recent call last):\n",
            "  File \"step2_loadingtrainingdatas_vgg_transfert_modelandtraining.py\", line 160, in <module>\n",
            "    transfer_model.save(\"model/\"+datetime.now().strftime(\"%Y%m%d-%H%M%S\")+\"vggforsp500.h5\")\n",
            "NameError: name 'datetime' is not defined\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CjSc-KxlVc0L",
        "outputId": "b639276e-8b87-4388-99ea-a75aba35a86f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "%cd /content/DL_Tools_For_Finance\n",
        "!python3 step3_evaluate_vggsp500_model.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/DL_Tools_For_Finance\n",
            "2020-08-31 14:02:47.233647: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-08-31 14:02:51.669914: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1\n",
            "2020-08-31 14:02:51.704030: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-31 14:02:51.704632: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\n",
            "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.73GiB deviceMemoryBandwidth: 298.08GiB/s\n",
            "2020-08-31 14:02:51.704688: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-08-31 14:02:51.706171: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
            "2020-08-31 14:02:51.707708: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
            "2020-08-31 14:02:51.708035: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
            "2020-08-31 14:02:51.709428: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-08-31 14:02:51.710185: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-08-31 14:02:51.713048: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-08-31 14:02:51.713172: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-31 14:02:51.713766: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-31 14:02:51.714261: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\n",
            "2020-08-31 14:02:51.714718: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX512F\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2020-08-31 14:02:51.719389: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2000125000 Hz\n",
            "2020-08-31 14:02:51.719605: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x28f6bc0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-08-31 14:02:51.719633: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2020-08-31 14:02:51.807725: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-31 14:02:51.808365: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x28f6a00 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2020-08-31 14:02:51.808401: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "2020-08-31 14:02:51.808620: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-31 14:02:51.809133: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\n",
            "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.73GiB deviceMemoryBandwidth: 298.08GiB/s\n",
            "2020-08-31 14:02:51.809188: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-08-31 14:02:51.809222: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
            "2020-08-31 14:02:51.809244: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
            "2020-08-31 14:02:51.809264: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
            "2020-08-31 14:02:51.809287: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-08-31 14:02:51.809306: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-08-31 14:02:51.809326: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-08-31 14:02:51.809405: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-31 14:02:51.810022: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-31 14:02:51.810533: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\n",
            "2020-08-31 14:02:51.810597: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-08-31 14:02:52.339278: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-08-31 14:02:52.339335: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 \n",
            "2020-08-31 14:02:52.339348: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N \n",
            "2020-08-31 14:02:52.339561: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-31 14:02:52.340218: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-31 14:02:52.340755: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2020-08-31 14:02:52.340796: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13962 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "2020-08-31 14:02:52.849852: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
            "2020-08-31 14:02:53.190922: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
            "146/146 [==============================] - 1s 9ms/step - loss: 2.0681 - accuracy: 0.2512\n",
            "Confusion Matrix\n",
            "Accuracy on the Test Images:  0.25123897194862366\n",
            "             SS  ...  Error\n",
            "SS     0.152104  ...    0.0\n",
            "SN     0.175889  ...    0.0\n",
            "N      0.157669  ...    0.0\n",
            "NB     0.157421  ...    0.0\n",
            "BB     0.150538  ...    0.0\n",
            "Error  0.000000  ...    0.0\n",
            "\n",
            "[6 rows x 6 columns]\n",
            "classification report\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          SS       0.26      0.47      0.33      1209\n",
            "          SN       0.00      0.00      0.00        11\n",
            "           N       0.36      0.26      0.30      1630\n",
            "          NB       0.14      0.10      0.12       667\n",
            "          BB       0.52      0.02      0.05       506\n",
            "       Error       0.13      0.15      0.14       618\n",
            "\n",
            "    accuracy                           0.25      4641\n",
            "   macro avg       0.23      0.17      0.16      4641\n",
            "weighted avg       0.29      0.25      0.23      4641\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MfSMBNcGxMF2",
        "outputId": "c3008cb3-6bfe-4259-ce16-c9adcf367400",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 988
        }
      },
      "source": [
        "%cd /content/DL_Tools_For_Finance\n",
        "!python3 step4_guess_future_marketstate_from_image.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/DL_Tools_For_Finance\n",
            "2020-08-31 14:03:08.385690: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "After resizing: (32, 32, 3)\n",
            "2020-08-31 14:03:09.535186: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1\n",
            "2020-08-31 14:03:09.574599: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-31 14:03:09.575181: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\n",
            "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.73GiB deviceMemoryBandwidth: 298.08GiB/s\n",
            "2020-08-31 14:03:09.575244: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-08-31 14:03:09.576673: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
            "2020-08-31 14:03:09.585531: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
            "2020-08-31 14:03:09.585899: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
            "2020-08-31 14:03:09.591997: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-08-31 14:03:09.592918: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-08-31 14:03:09.602832: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-08-31 14:03:09.602955: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-31 14:03:09.603582: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-31 14:03:09.604090: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\n",
            "2020-08-31 14:03:09.604397: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX512F\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2020-08-31 14:03:09.610479: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2000125000 Hz\n",
            "2020-08-31 14:03:09.610705: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1354bc0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-08-31 14:03:09.610739: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2020-08-31 14:03:09.722558: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-31 14:03:09.723230: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1354d80 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2020-08-31 14:03:09.723264: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "2020-08-31 14:03:09.723464: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-31 14:03:09.724073: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\n",
            "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.73GiB deviceMemoryBandwidth: 298.08GiB/s\n",
            "2020-08-31 14:03:09.724132: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-08-31 14:03:09.724172: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
            "2020-08-31 14:03:09.724199: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
            "2020-08-31 14:03:09.724224: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
            "2020-08-31 14:03:09.724253: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-08-31 14:03:09.724275: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-08-31 14:03:09.724305: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-08-31 14:03:09.724386: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-31 14:03:09.725011: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-31 14:03:09.725535: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\n",
            "2020-08-31 14:03:09.725602: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-08-31 14:03:10.322458: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-08-31 14:03:10.322529: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 \n",
            "2020-08-31 14:03:10.322543: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N \n",
            "2020-08-31 14:03:10.322768: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-31 14:03:10.323702: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-31 14:03:10.324428: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2020-08-31 14:03:10.324484: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13962 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "2020-08-31 14:03:10.764422: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
            "2020-08-31 14:03:11.077927: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
            "for  ImageM/image1.PNG the best result is  N\n",
            "                          SS  ...     Error\n",
            "ImageM/image1.PNG   0.209848  ...  0.000418\n",
            "ImageM/image1.PNG1  0.209848  ...  0.000418\n",
            "\n",
            "[2 rows x 6 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1n0vJA_lL-Xv"
      },
      "source": [
        "##Step 1 : Generate Dataset of the Image and the Future maket state"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7jbsgi1Qa6Rg"
      },
      "source": [
        "In this part we are generating the training and testing dataset.\n",
        "First we download the historical prices of the sp500 from 1927 to 31 July 2020 and built the image of 15 days historical graph also we get the 5 days future price evolution of the sp500. \n",
        "From the future price evolution, we calculate a future state which can be splitted in 6 classes :\n",
        "\n",
        "Sell-Sell | Sell- Neutral | Neutral | Neutral -Buy | Buy -Buy (and the Error class)\n",
        "\n",
        "The objective is to get the following files which represent a dataframe in the data/ repertory:\n",
        "\n",
        "X_train_image.csv , X_test_image.csv a 3072 column time serie dataframe  of the image (32 x 32 x3) of the sp500 closing price \n",
        "\n",
        "Y_test_StateClass.csv, Y_train_StateClass.csv a 1 column time serie dataframe of the future state value betwwen -1 to 4\n",
        "\n",
        "We generate also the following files but we won´t use it in this project - more fore RNN & price prediction - Y_test_FutPredict.csv Y_train_FutPredict.csv\n",
        "\n",
        "the testing and training time serie dataset are shuffled by the date of reference with a split number of 0.8\n",
        "\n",
        "Please note that: \n",
        "1. We can increase the dataset taking into account the evolution very liquid stocks or other indices as long as we have very high the liquidity and number of participants \n",
        "2. The calculation of the dataset can take more than 6 hours of calulation as the code is not optimized so far, we can quickly implement parallel computing and rapid image setup instead of using matplotlib library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ginct2uD8lzF",
        "outputId": "5407f74f-56af-46f8-98fd-94a66583964e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import bs4 as bs\n",
        "import requests\n",
        "import yfinance as yf\n",
        "import datetime\n",
        "import io\n",
        "import cv2\n",
        "import skimage\n",
        "import datetime\n",
        "import os.path as path\n",
        "from PIL import Image\n",
        "from pandas_datareader import data as pdr\n",
        "from skimage import measure\n",
        "from skimage.measure import block_reduce\n",
        "from datetime import datetime\n",
        "from tempfile import mkdtemp"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-e2611a232fad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbs4\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mbs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0myfinance\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0myf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'yfinance'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TxWv2FXrO1fo"
      },
      "source": [
        "#@title Default variable for input\n",
        "@index='^GSPC'\n",
        "@past_step=25\n",
        "@fut_step=5\n",
        "@start_date=\"01/01/1920\"\n",
        "@end_date=\"01/01/2020\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_7hN1p8cJY_3"
      },
      "source": [
        "'''\n",
        "Functions to be used for data generation \n",
        "'''\n",
        "\n",
        "def get_img_from_fig(fig, dpi=180):\n",
        "   # get_img_from_fig is function which returns an image as numpy array from figure\n",
        "    buf = io.BytesIO()\n",
        "    fig.savefig(buf, format=\"png\", dpi=dpi)\n",
        "    buf.seek(0)\n",
        "    img_arr = np.frombuffer(buf.getvalue(), dtype=np.uint8)\n",
        "    buf.close()\n",
        "    img = cv2.imdecode(img_arr, 1)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    return img\n",
        "\n",
        "def build_image(stockindex, idate=10, pastlag=10, futlag=3):\n",
        "  #another version of returning image from a data frame index\n",
        "  #using the pastlag as range for the graph\n",
        "  #ising idate as a starting point\n",
        "  #return a (32,32,3) np array\n",
        "\n",
        "  #number of days to consider for translate\n",
        "  sp500close=stockindex\n",
        "  x_datas=[]\n",
        "  x_datas=np.zeros((32,32,3))\n",
        "  i=idate\n",
        "  \n",
        "  fig=plt.figure()\n",
        "  ax=fig.add_subplot(111)\n",
        "  ax.plot(sp500close[(i-pastlag):i])\n",
        "  plot_img_np = get_img_from_fig(fig)\n",
        "  x_tmp= skimage.measure.block_reduce(plot_img_np[90:620,140:970], (18,28,1), np.mean)\n",
        "  (x_datas[1:-1])[:,1:-1][:]=x_tmp\n",
        "  fig.clear()\n",
        "  plt.close(fig)\n",
        "    \n",
        "  x_datas=x_datas/255\n",
        "  return x_datas\n",
        "\n",
        "'''\n",
        "MAIN FUNCTION OF CLASSIFICATION \n",
        "build y state y fut \n",
        "and x  \n",
        "'''\n",
        "def class_shortterm_returnfut(x, yfut, indexforpast,tpastlag):\n",
        "  '''\n",
        "  #this function is use to classifiy the future state based on the position of future value with the past range \n",
        "  #Put the value from the 2 boxes (max min) or (open close) on the time range  and check if it is within\n",
        "  #go down go up or exit the box\n",
        "  #the fucntion return 5 state depending on the future value position on the boxes and one state for error cases\n",
        "  '''\n",
        "\n",
        "  xpast_min=np.min(x[(indexforpast-tpastlag):indexforpast])\n",
        "  xpast_max=np.max(x[(indexforpast-tpastlag):indexforpast])\n",
        "  x_open=x[int(indexforpast-tpastlag)]\n",
        "  x_close=x[indexforpast]\n",
        "  \n",
        "  if (yfut < xpast_min ): return 0\n",
        "  elif  (yfut < min(x_open,x_close)): return 1\n",
        "  elif  (yfut < max(x_open,x_close)): return 2\n",
        "  elif  (yfut < xpast_max): return 3\n",
        "  elif  (yfut > xpast_max): return 4\n",
        "  else  : return -1\n",
        "\n",
        "def main_class_shortterm_returnfut(iterable):\n",
        "  return class_shortterm_returnfut(sp500close, iterable, pastlag,futlag)\n",
        "\n",
        "def normalise_df_image(xdf):\n",
        "  #normalisation to 0,1 range of the equity index\n",
        "  df_tmp=xdf\n",
        "  maxval=np.max(df_tmp)\n",
        "  df_tmp=df_tmp/maxval\n",
        "  return df_tmp, maxval\n",
        "\n",
        "def build_image_df(xdf, past_step,fut_step) :\n",
        "  '''\n",
        "  returning a dictionary of time series dataframes to be used in setup_input_NN_image so a to generate \n",
        "  Input X Result Y_StateClass, Y_FutPredict\n",
        "  pastlag as range for the graph\n",
        "  fut _step the future value lag in time to predict or to check the financial state of the market \n",
        "  #times series to get information from the stock index value\n",
        "  'stock_value':the time serie of the index normalised on the whole period\n",
        "  'moving_average':  time serie of the rolling moving average value of the index for past step image\n",
        "  \"max\": time serie of the rolling max  value of the index for past step image\n",
        "  \"min\": time serie of the rolling  min value of the index for past step image\n",
        "  'volatility':  time serie of the rolling  vol value of the index for past step image\n",
        "          \n",
        "  'df_x_image': is a time series of flattened (1, ) calculed from images (32, 32, 3) list \n",
        "  #I had to flatten it because panda does not create table with this format\n",
        "  'market_state': future markket state to be predicted time lag is futlag\n",
        "  'future_value': future value of stock price to predict  time lag is futlag\n",
        "  'future_volatility':  time serie of the future volatility of the index time lag is futlag\n",
        "  '''\n",
        "\n",
        "  df_stockvaluecorrected=xdf\n",
        "  df_stockvaluecorrected, _ = normalise_df_image(df_stockvaluecorrected)\n",
        "  df_pctchge = df_stockvaluecorrected.pct_change(periods=past_step)\n",
        "  df_movave = df_stockvaluecorrected.rolling(window=past_step).mean()\n",
        "  df_volaty = np.sqrt(252)*df_pctchge.rolling(window=past_step).std()\n",
        "  df_max =df_stockvaluecorrected.rolling(window=past_step).max()\n",
        "  df_min =df_stockvaluecorrected.rolling(window=past_step).min()\n",
        "  df_Fut_value =df_stockvaluecorrected.shift(periods=-fut_step)\n",
        "  df_Fut_value.name='future_value'\n",
        "  df_Fut_volaty =df_volaty.shift(periods=-fut_step)\n",
        "  \n",
        "  df_market_state=pd.DataFrame(index=df_stockvaluecorrected.index,columns=['market_state'],dtype=np.float64)\n",
        "  \n",
        "  tmpimage=np.zeros((255,255))\n",
        "  flatten_image=np.reshape(tmpimage,(1,-1))\n",
        "  colname_d_x_image_flattened = ['Image Col'+str(j) for j in range(flatten_image.shape[1])]\n",
        "\n",
        "  #write frile in drive instead of RAMmemory\n",
        "  filename = path.join(mkdtemp(), 'np_x_image.dat')\n",
        "  np_x_image=np.memmap(filename,  dtype='float32', mode='w+', shape=(len(df_stockvaluecorrected.index),flatten_image.shape[1]))\n",
        "  \n",
        "  for i in range(len(df_stockvaluecorrected.index)):\n",
        "        yfut=df_Fut_value.iloc[i]\n",
        "        df_market_state.iloc[i]=class_shortterm_returnfut(df_stockvaluecorrected,yfut, i,tpastlag=past_step)\n",
        "        print(\"loop 1 market state :\", \"step \",i,\"market state fut\", df_market_state.iloc[i],\" future value\",df_Fut_value.iloc[i] )\n",
        "  df_market_state.index=df_Fut_value.index\n",
        "\n",
        "  fig=plt.figure()\n",
        "  \n",
        "  '''\n",
        "  for i in range(len(df_stockvaluecorrected.index)):\n",
        "        try:\n",
        "          tmpimage=build_image_optimfig(fig, df_stockvaluecorrected,i,pastlag=past_step,futlag=fut_step)\n",
        "          np_x_image[i,:]=np.reshape(tmpimage,(1,-1))\n",
        "          print(\"loop 2 image :\", \"step \",i,\"market state fut\", df_market_state.iloc[i],\" future value\",df_Fut_value.iloc[i] )\n",
        "        except:\n",
        "           print(\"error at index\", i)\n",
        "  '''           \n",
        "  \n",
        "  def build_image_optimfig_simplified(i_index):\n",
        "    return build_image_optimfig(fig, df_stockvaluecorrected,i_index,pastlag=past_step,futlag=fut_step)\n",
        "\n",
        "  def quick_build_image_from_index(indexstart, index_end, np_x_image):\n",
        "        if (indexstart==index_end):\n",
        "            tmpimage=build_image_optimfig_simplified(indexstart)\n",
        "            np_x_image[indexstart,:]=np.reshape(tmpimage,(1,-1))\n",
        "            print(\"loop 2 image :\", \"step \",indexstart)\n",
        "        else :\n",
        "            i_split=indexstart+(index_end-indexstart)//2\n",
        "            quick_build_image_from_index(indexstart, i_split,np_x_image)\n",
        "            quick_build_image_from_index(i_split+1, index_end,np_x_image)\n",
        "\n",
        "  quick_build_image_from_index(0, len(df_stockvaluecorrected.index)-1, np_x_image)\n",
        "\n",
        "  df_x_image=pd.DataFrame(data=np_x_image,columns=colname_d_x_image_flattened, index=df_stockvaluecorrected.index)\n",
        "  fig.clear\n",
        "  plt.close(fig)\n",
        "\n",
        "\n",
        "  df_data= {\n",
        "          'stock_value': df_stockvaluecorrected, \n",
        "          'moving_average': df_movave, \n",
        "          \"max\": df_max, \n",
        "          \"min\": df_max,\n",
        "          'volatility': df_volaty,\n",
        "          'future_volatility': df_Fut_volaty,\n",
        "          \n",
        "          'df_x_image':df_x_image,\n",
        "          'market_state':df_market_state,\n",
        "          'future_value': df_Fut_value,\n",
        "\n",
        "          }\n",
        "\n",
        "  return df_data\n",
        "\n",
        "def change_X_df__nparray_image(df_X_train_image_flattened ):\n",
        "  '''\n",
        "  setup_input_NN_image returns a dataframe of flaten image for x train and xtest\n",
        "  then this function will change each date into a nparray list of images with 32, 32, 3 size \n",
        "  '''\n",
        "  X_train_image=df_X_train_image_flattened\n",
        "  nb_train=len(X_train_image.index)\n",
        "  \n",
        "  x_train=np.zeros((nb_train,255,255,1))\n",
        "  for i in range(nb_train):\n",
        "    tmp=np.array(X_train_image.iloc[i])\n",
        "    tmp=tmp.reshape(255,255,1)\n",
        "    x_train[i]=tmp\n",
        "  return x_train\n",
        "  \n",
        "def change_X_df__nparray_image(df_X_train_image_flattened ):\n",
        "  '''\n",
        "  setup_input_NN_image returns a dataframe of flaten image for x train and xtest\n",
        "  then this function will change each date into a nparray list of images with 32, 32, 3 size \n",
        "  '''\n",
        "  X_train_image=df_X_train_image_flattened\n",
        "  nb_train=len(X_train_image.index)\n",
        "  \n",
        "  x_train=np.zeros((nb_train,255,255,1))\n",
        "  for i in range(nb_train):\n",
        "    tmp=np.array(X_train_image.iloc[i])\n",
        "    tmp=tmp.reshape(255,255,1)\n",
        "    x_train[i]=tmp\n",
        "  return x_train\n",
        "\n",
        "def build_image_optimfig(fig, stockindex, idate=10, pastlag=10, futlag=3):\n",
        "  '''\n",
        "  #version of returning image from a data frame index\n",
        "  #using the pastlag as range for the graph\n",
        "  #ising idate as a starting point\n",
        "  #return a (32,32,3) np array\n",
        "  #this one is optimisng the use of ram \n",
        "  '''\n",
        "\n",
        "  #number of days to consider for translate\n",
        "  sp500close=stockindex\n",
        "  x_datas=[]\n",
        "  x_datas=np.zeros((255,255,3))\n",
        "  i=idate\n",
        "  \n",
        "  plt.plot(sp500close[(i-pastlag):i])\n",
        "  plot_img_np = get_img_from_fig(fig)\n",
        "  #x_tmp= skimage.measure.block_reduce(plot_img_np[90:620,140:970], (18,28,1), np.mean)\n",
        "  x_tmp= skimage.measure.block_reduce(plot_img_np[90:620,140:970], (2,3,1), np.mean)\n",
        "  (x_datas[:])[:,:][:]=(x_tmp[5:-5])[:,11:-11][:]\n",
        "    \n",
        "  x_datas=x_datas[:,:,0]/255\n",
        "  return x_datas\n",
        "\n",
        "def setup_input_NN_image(xdf, past_step=25,fut_step=5, split=0.8, is_shuffle=False):\n",
        "  '''\n",
        "  this function the time serie of the index price \n",
        "  and generate the random dataset with split value from the whole time serie\n",
        "  X is a time serie of the flattened 32, 32 ,3 image list\n",
        "  Y_StateClass is a time serie of future state to predict with a classification made with class_shortterm_returnfut\n",
        "  Y_FutPredict is the time serie of stocke index shifted in time to be predicted\n",
        "  we randomize the dates and retun 2 set of dataframes\n",
        "  '''\n",
        "  xdf_data=build_image_df(xdf,past_step,fut_step)\n",
        "  \n",
        "  tmp_data=pd.concat([xdf_data['market_state'],xdf_data['future_value'],xdf_data['df_x_image']],axis=1)\n",
        "  tmp_data=tmp_data.dropna()\n",
        "\n",
        "  Y_StateClass= tmp_data['market_state']\n",
        "  Y_FutPredict= tmp_data['future_value']  \n",
        "  X=tmp_data.drop(columns=['market_state','future_value'])\n",
        "\n",
        "  nb_dates=len(Y_StateClass.index)\n",
        "  split_index=int(split*nb_dates)\n",
        "  list_shuffle = np.arange(nb_dates)\n",
        "  rng = np.random.default_rng()\n",
        "\n",
        "  if (is_shuffle==True) : rng.shuffle(list_shuffle)\n",
        "  train_split=list_shuffle[:split_index]\n",
        "  test_split=list_shuffle[(split_index+1):]\t\t\n",
        "\n",
        "  X_train=(X.iloc[train_split])\n",
        "  Y_train_StateClass=(Y_StateClass.iloc[train_split])\n",
        "  Y_train_FutPredict=(Y_FutPredict.iloc[train_split])\n",
        "\n",
        "  X_test=(X.iloc[test_split])\n",
        "  Y_test_StateClass=(Y_StateClass.iloc[test_split])\n",
        "  Y_test_FutPredict=(Y_FutPredict.iloc[test_split])\n",
        "\n",
        "  return (X_train, Y_train_StateClass, Y_train_FutPredict), (X_test, Y_test_StateClass, Y_test_FutPredict)\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2NDZQA070amA"
      },
      "source": [
        "\n",
        "def splitted_NN(index, nb_split):\n",
        "\t\n",
        "\tdef launch_splitted(i_index, i_last, indexstock):\n",
        "\t\tif i_index==i_last:\n",
        "\t\t\ttestsp500=indexstock[i_index:]\n",
        "\t\telse:\n",
        "\t\t\ttestsp500=indexstock[i_index:i_last]\n",
        "\t\t_ , (X_test_image, Y_test_StateClass_image, Y_test_FutPredict_image) = setup_input_NN_image(testsp500, split=0)\n",
        "\t\treturn X_test_image, Y_test_StateClass_image, Y_test_FutPredict_image\n",
        "\t\t\n",
        "\tnb_dates=len(index)\n",
        "\tnb_block=nb_dates//nb_split\n",
        "\t#First parts\n",
        "\tfor i in range(nb_split) :\n",
        "\t\tif i==(nb_split-1) : nb_final=i*nb_block\n",
        "\t\telse : nb_final=(i+1)*nb_block\n",
        "\n",
        "\t\tX_image, Y_StateClass_image, Y_FutPredict_image =launch_splitted(0+i*nb_block,(i+1)*nb_block,index)\n",
        "\t\tX_image.to_csv('tmp/x_image/out'+str(i)+'.csv', mode='w')\n",
        "\t\tY_StateClass_image.to_csv('tmp/y_state/out'+str(i)+'.csv', mode='w')\n",
        "\t\tY_FutPredict_image.to_csv('tmp/y_forward/out'+str(i)+'.csv', mode='w')\n",
        "\t\tprint(\"blabla\"+str(i))\n",
        "   \n",
        "\treturn x_image, y_StateClass_image, y_futurepredict_image\n",
        "\n",
        "def load_data_from_filename(filename='out0.csv'):\n",
        "  x_image=pd.read_csv('tmp/x_image/'+filename)\n",
        "  y_StateClass_image=pd.read_csv('tmp/y_state/'+filename)\n",
        "  y_futurepredict_image=pd.read_csv('tmp/y_forward/'+filename) \n",
        "  x_image=x_image.set_index('Date')\n",
        "  y_StateClass_image=y_StateClass_image.set_index('Date')\n",
        "  y_futurepredict_image=y_futurepredict_image.set_index('Date')\n",
        "  \n",
        "  return x_image, y_StateClass_image, y_futurepredict_image\n",
        "\n",
        "def load_data_from_splitted_directory_sources(filename='out0.csv'):\n",
        "  dfList=[]\n",
        "  y_StateClass_image=pd.DataFrame()\n",
        "  x_image=pd.DataFrame()\n",
        "  y_futurepredict_image=pd.DataFrame()\n",
        "\n",
        "  for filename in ['tmp/x_image/'+x for x in os.listdir('tmp/x_image/')]:\n",
        "    dfList.append(pd.read_csv(filename))\n",
        "  x_image.concat(dfList,axis=1)\n",
        "\n",
        "  dfList=[]\n",
        "  for filename in ['tmp/y_state/'+x for x in os.listdir('tmp/y_state/')]:\n",
        "    dfList.append(pd.read_csv(filename))\n",
        "  y_StateClass_image.concat(dfList,axis=1)\n",
        "\n",
        "  dfList=[]\n",
        "  for filename in ['tmp/y_forward/'+x for x in os.listdir('tmp/y_forward/')]:\n",
        "    dfList.append(pd.read_csv(filename))\n",
        "  y_futurepredict_image.concat(dfList,axis=1)\n",
        "\n",
        "  x_image=x_image.set_index('Date')\n",
        "  y_StateClass_image=y_StateClass_image.set_index('Date')\n",
        "  y_futurepredict_image=y_futurepredict_image.set_index('Date')\n",
        " \n",
        "  return x_image, y_StateClass_image, y_futurepredict_image\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BYrSOF8l8gxV"
      },
      "source": [
        "def download_history(index_code='^GSPC',start_t=datetime(2000,1,1),end_t=datetime(2020,1,1)):\n",
        "\t'''\n",
        "\tCOMMAND NOW FOR DOWNLOADING HISTORICAL DATAS FOR SP500\n",
        "\t'''\n",
        "\t#Recuperation from yahoo of sp500 large history\n",
        "\n",
        "\tyf.pdr_override() # <== that's all it takes :-)\n",
        "\tsp500 = pdr.get_data_yahoo('^GSPC', start,end)\n",
        "\ttestsp500=(sp500['Close'])[:]\n",
        "\treturn testsp500\n",
        "\t#generate the dataset it can take 6 - 8 hours\n",
        "\t#Need to be optimzed with more time\n",
        "\n",
        "def write_image_in_directory(index, start_index,nb_split):\n",
        "\tx_image, y_StateClass_image, y_futurepredict_image=splitted_NN(index, nb_split=nb_split)\n",
        "\n",
        "def split_write_datas_for_each_state(x_image, y_StateClass_image, y_futurepredict_image,name_ref=''):\n",
        "\t#group by y state the x_image \n",
        "\t#count the min of the of each state \n",
        "\t#construct a directory for each block like cat, dog etc\n",
        "\n",
        "\t\n",
        "\tnon_monotonic_index =pd.Index(list(y_StateClass_image['market_state']))\n",
        "\n",
        "\tdef localize_index_from_state(non_monotonic_index, state=0):\n",
        "\t  state_loc=non_monotonic_index.get_loc(state)\n",
        "\t  return [i for i in range(0,state_loc.size) if state_loc[i]]\n",
        "\n",
        "\ttry : \n",
        "\t  state_error_loc=localize_index_from_state(non_monotonic_index,-1) \n",
        "\t  y_StateClass_image_error =y_StateClass_image.iloc[state_error_loc]\n",
        "\t  x_image_State_is_error =x_image.iloc[state_error_loc]\n",
        "\t  y_futpredict_image_is_error =y_futurepredict_image.iloc[state_error_loc]\n",
        "\t  print(\"dataset class -1 size is :\",y_StateClass_image_error.size, \"and for x \", x_image_State_is_error.index.size)\n",
        "\t  #print_data_class(state=-1)\n",
        "      \n",
        "\texcept :\n",
        "\t  print(\"No value for error state\")\n",
        "\n",
        "\tstate_zero_loc=localize_index_from_state(non_monotonic_index, 0)\n",
        "\tstate_one_loc=localize_index_from_state(non_monotonic_index, 1)\n",
        "\tstate_two_loc=localize_index_from_state(non_monotonic_index, 2)\n",
        "\tstate_three_loc=localize_index_from_state(non_monotonic_index, 3)\n",
        "\tstate_four_loc=localize_index_from_state(non_monotonic_index, 4)\n",
        "\n",
        "\t#Build up class for the dataset\n",
        "\ty_StateClass_image_0 =y_StateClass_image.iloc[state_zero_loc]\n",
        "\ty_StateClass_image_1 =y_StateClass_image.iloc[state_one_loc]\n",
        "\ty_StateClass_image_2 =y_StateClass_image.iloc[state_two_loc]\n",
        "\ty_StateClass_image_3 =y_StateClass_image.iloc[state_three_loc]\n",
        "\ty_StateClass_image_4 =y_StateClass_image.iloc[state_four_loc]\n",
        "\n",
        "\tx_image_State_is_0 =x_image.iloc[state_zero_loc]\n",
        "\tx_image_State_is_1 =x_image.iloc[state_one_loc]\n",
        "\tx_image_State_is_2 =x_image.iloc[state_two_loc]\n",
        "\tx_image_State_is_3 =x_image.iloc[state_three_loc]\n",
        "\tx_image_State_is_4 =x_image.iloc[state_four_loc]\n",
        "\n",
        "\ty_futpredict_image_0 =y_futurepredict_image.iloc[state_zero_loc]\n",
        "\ty_futpredict_image_1 =y_futurepredict_image.iloc[state_one_loc]\n",
        "\ty_futpredict_image_2 =y_futurepredict_image.iloc[state_two_loc]\n",
        "\ty_futpredict_image_3 =y_futurepredict_image.iloc[state_three_loc]\n",
        "\ty_futpredict_image_4 =y_futurepredict_image.iloc[state_four_loc]\n",
        "\n",
        "\t#print size of each dataset\n",
        "\tprint(\"dataset class 0 size is :\",y_StateClass_image_0.size, \"and for x \", x_image_State_is_0.index.size)\n",
        "\tprint(\"dataset class 1 size is :\",y_StateClass_image_1.size, \"and for x \", x_image_State_is_1.index.size)\n",
        "\tprint(\"dataset class 2 size is :\",y_StateClass_image_2.size, \"and for x \", x_image_State_is_2.index.size)\n",
        "\tprint(\"dataset class 3 size is :\",y_StateClass_image_3.size, \"and for x \", x_image_State_is_3.index.size)\n",
        "\tprint(\"dataset class 4 size is :\",y_StateClass_image_4.size, \"and for x \", x_image_State_is_4.index.size)\n",
        "\n",
        "\t#write dataset for each set  in corresponding folder\n",
        "\tdef print_data_class(state=0,write_path='datas/state_is_') :\n",
        "\t  state_zero_loc=localize_index_from_state(non_monotonic_index, state)\n",
        "\t  y_StateClass_image_0 =y_StateClass_image.iloc[state_zero_loc]\n",
        "\t  x_image_State_is_0 =x_image.iloc[state_zero_loc]\n",
        "\t  y_futpredict_image_0 =y_futurepredict_image.iloc[state_zero_loc]\n",
        "\t  y_StateClass_image_0.to_csv(write_path+str(state)+'/'+name_ref+'y_stateclass.zip',compression='zip')\n",
        "\t  x_image_State_is_0.to_csv(write_path+str(state)+'/'+name_ref+'x_image.zip',compression='zip')\n",
        "\t  y_futpredict_image_0.to_csv(write_path+str(state)+'/'+name_ref+'y_future.zip',compression='zip')\n",
        "\n",
        "\t\n",
        "\tprint_data_class(state=0)\n",
        "\tprint_data_class(state=1)\n",
        "\tprint_data_class(state=2)\n",
        "\tprint_data_class(state=3)\n",
        "\tprint_data_class(state=4)\n",
        "\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iA_9dsFM1_0d"
      },
      "source": [
        "%cd /content/drive/My Drive/A_transfertTFM\n",
        "start = datetime(1920,1,1)\n",
        "end = datetime(2020,7,31)\n",
        " \n",
        "testsp500=download_history(index_code='^GSPC', start_t=start,end_t=end)\n",
        "write_image_in_directory(index=testsp500,start_index=0,nb_split=10)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7H72C23-57M",
        "outputId": "a3db9fa8-9b5d-43e0-aca0-64781d12da08",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd /content/drive/My Drive/A_transfertTFM\n",
        "x_image, y_StateClass_image, y_futurepredict_image=load_data_from_filename(filename='out0.csv')\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/A_transfertTFM\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXS50sNKRLHb",
        "outputId": "01003f91-6e91-47a8-d19b-06f6555474d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "%cd /content/drive/My Drive/A_transfertTFM\n",
        "split_write_datas_for_each_state(x_image, y_StateClass_image, y_futurepredict_image,name_ref='out0_')"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/A_transfertTFM\n",
            "dataset class -1 size is : 18 and for x  18\n",
            "No value for error state\n",
            "dataset class 0 size is : 333 and for x  333\n",
            "dataset class 1 size is : 312 and for x  312\n",
            "dataset class 2 size is : 776 and for x  776\n",
            "dataset class 3 size is : 307 and for x  307\n",
            "dataset class 4 size is : 573 and for x  573\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RDOxutiuQNYM",
        "outputId": "c6eaf171-834c-4e8a-9a94-e13fb6b1abeb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "%cd /content/drive/My Drive/A_transfertTFM\n",
        "for i in range(0,10) :\n",
        "  print('block dataset'+i)\n",
        "  x_image, y_StateClass_image, y_futurepredict_image=load_data_from_filename(filename='out'+str(i)+'.csv')\n",
        "  split_write_datas_for_each_state(x_image, y_StateClass_image, y_futurepredict_image,name_ref='out'+str(i)+'_')"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/A_transfertTFM\n",
            "dataset class -1 size is : 10 and for x  10\n",
            "No value for error state\n",
            "dataset class 0 size is : 355 and for x  355\n",
            "dataset class 1 size is : 274 and for x  274\n",
            "dataset class 2 size is : 858 and for x  858\n",
            "dataset class 3 size is : 308 and for x  308\n",
            "dataset class 4 size is : 514 and for x  514\n",
            "dataset class -1 size is : 10 and for x  10\n",
            "No value for error state\n",
            "dataset class 0 size is : 257 and for x  257\n",
            "dataset class 1 size is : 239 and for x  239\n",
            "dataset class 2 size is : 791 and for x  791\n",
            "dataset class 3 size is : 329 and for x  329\n",
            "dataset class 4 size is : 693 and for x  693\n",
            "dataset class -1 size is : 6 and for x  6\n",
            "No value for error state\n",
            "dataset class 0 size is : 326 and for x  326\n",
            "dataset class 1 size is : 213 and for x  213\n",
            "dataset class 2 size is : 758 and for x  758\n",
            "dataset class 3 size is : 300 and for x  300\n",
            "dataset class 4 size is : 716 and for x  716\n",
            "dataset class -1 size is : 6 and for x  6\n",
            "No value for error state\n",
            "dataset class 0 size is : 410 and for x  410\n",
            "dataset class 1 size is : 281 and for x  281\n",
            "dataset class 2 size is : 801 and for x  801\n",
            "dataset class 3 size is : 231 and for x  231\n",
            "dataset class 4 size is : 590 and for x  590\n",
            "dataset class -1 size is : 4 and for x  4\n",
            "No value for error state\n",
            "dataset class 0 size is : 431 and for x  431\n",
            "dataset class 1 size is : 232 and for x  232\n",
            "dataset class 2 size is : 775 and for x  775\n",
            "dataset class 3 size is : 320 and for x  320\n",
            "dataset class 4 size is : 557 and for x  557\n",
            "No value for error state\n",
            "dataset class 0 size is : 249 and for x  249\n",
            "dataset class 1 size is : 295 and for x  295\n",
            "dataset class 2 size is : 835 and for x  835\n",
            "dataset class 3 size is : 340 and for x  340\n",
            "dataset class 4 size is : 600 and for x  600\n",
            "No value for error state\n",
            "dataset class 0 size is : 223 and for x  223\n",
            "dataset class 1 size is : 276 and for x  276\n",
            "dataset class 2 size is : 830 and for x  830\n",
            "dataset class 3 size is : 380 and for x  380\n",
            "dataset class 4 size is : 610 and for x  610\n",
            "No value for error state\n",
            "dataset class 0 size is : 349 and for x  349\n",
            "dataset class 1 size is : 264 and for x  264\n",
            "dataset class 2 size is : 788 and for x  788\n",
            "dataset class 3 size is : 327 and for x  327\n",
            "dataset class 4 size is : 591 and for x  591\n",
            "No value for error state\n",
            "dataset class 0 size is : 209 and for x  209\n",
            "dataset class 1 size is : 234 and for x  234\n",
            "dataset class 2 size is : 777 and for x  777\n",
            "dataset class 3 size is : 339 and for x  339\n",
            "dataset class 4 size is : 760 and for x  760\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LqaU9Lp_KVcb"
      },
      "source": [
        "###Check version for parralelisation and improvement"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y2kRNyYG42Ti"
      },
      "source": [
        "value on file instead of ram memory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OyzAFCoi0hFD"
      },
      "source": [
        "#https://www.machinelearningplus.com/python/parallel-processing-python/\n",
        "import multiprocessing as mp\n",
        "print(\"Number of processors: \", mp.cpu_count())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s3QOy0bOuvE2"
      },
      "source": [
        "import numpy as np\n",
        "from time import time\n",
        "\n",
        "# Prepare data\n",
        "np.random.RandomState(100)\n",
        "arr = np.random.randint(0, 10, size=[200000, 5])\n",
        "data = arr.tolist()\n",
        "data[:5]\n",
        "\n",
        "# Solution Without Paralleization\n",
        "\n",
        "def howmany_within_range(row, minimum, maximum):\n",
        "    \"\"\"Returns how many numbers lie within `maximum` and `minimum` in a given `row`\"\"\"\n",
        "    count = 0\n",
        "    for n in row:\n",
        "        if minimum <= n <= maximum:\n",
        "            count = count + 1\n",
        "    return count\n",
        "\n",
        "results = []\n",
        "for row in data:\n",
        "    results.append(howmany_within_range(row, minimum=4, maximum=8))\n",
        "\n",
        "print(results[:10])\n",
        "#> [3, 1, 4, 4, 4, 2, 1, 1, 3, 3]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ZBdzGDBuPDf",
        "outputId": "227496df-22c6-4f30-e4f4-c30ab950f344",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Parallelizing using Pool.apply()\n",
        "\n",
        "import multiprocessing as mp\n",
        "\n",
        "# Step 1: Init multiprocessing.Pool()\n",
        "pool = mp.Pool(mp.cpu_count())\n",
        "\n",
        "# Step 2: `pool.apply` the `howmany_within_range()`\n",
        "results = [pool.apply(howmany_within_range, args=(row, 4, 8)) for row in data]\n",
        "\n",
        "# Step 3: Don't forget to close\n",
        "pool.close()    \n",
        "\n",
        "print(results[:10])\n",
        "#> [3, 1, 4, 4, 4, 2, 1, 1, 3, 3]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1, 4, 3, 0, 4, 1, 3, 1, 1, 2]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m8r2Npc1KbiC"
      },
      "source": [
        "###Main Launch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_B0t9M5EBD3-"
      },
      "source": [
        "####test write"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dh6EqvRiBH5K"
      },
      "source": [
        "####end test write"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V_QcOSjqMHSy"
      },
      "source": [
        "##Step 2: Loading training datas with vgg16 transfert model and training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R98_pBo02L2-"
      },
      "source": [
        "####List of model utilisation of main example resnet \n",
        "https://towardsdatascience.com/understanding-and-coding-a-resnet-in-keras-446d7ff84d33"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fI7gHLdU15Bb"
      },
      "source": [
        "\n",
        "![1_NdCntZms6S2pBmQ3j_wyuw.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1R3sN7G1IWIK"
      },
      "source": [
        "####Loading and Cleaning Training Datas "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MTfVYoKBaQzZ"
      },
      "source": [
        "This part is for loading the training dataset as it is better to generate it once for all in step 1 because of it time consuming process.\n",
        "\n",
        "This part also configure back the X_train datas from dataframe based on columns to a (32,32,3) np. array for the input of the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m1aNcB9LdFxN"
      },
      "source": [
        "'''\n",
        "UTILITY FUNCTIONS\n",
        "'''\n",
        "\n",
        "def change_X_df__nparray_image(df_X_train_image_flattened ):\n",
        "  '''\n",
        "  setup_input_NN_image returns a dataframe of flaten image for x train and xtest\n",
        "  then this function will change each date into a nparray list of images with 32, 32, 3 size \n",
        "  '''\n",
        "  X_train_image=df_X_train_image_flattened\n",
        "  nb_train=len(X_train_image.index)\n",
        "  \n",
        "  x_train=np.zeros((nb_train,255,255,1))\n",
        "  for i in range(nb_train):\n",
        "    tmp=np.array(X_train_image.iloc[i])\n",
        "    tmp=tmp.reshape(255,255,1)\n",
        "    x_train[i]=tmp\n",
        "  return x_train\n",
        "\n",
        "def split_by_perc(nb_dates, validation_split=0.2):\n",
        "  split_index=int(validation_split*nb_dates)\n",
        "  list_shuffle = np.arange(nb_dates)\n",
        "  rng = np.random.default_rng()\n",
        "\n",
        "  rng.shuffle(list_shuffle)\n",
        "  test_split=list_shuffle[:split_index]\n",
        "  train_split=list_shuffle[(split_index+1):]\t\t\n",
        "  return train_split, test_split\n",
        "\n",
        "def split_by_number(nb_dates, case_number_for_validation):\n",
        "  list_shuffle = np.arange(nb_dates)\n",
        "  rng = np.random.default_rng()\n",
        "\n",
        "  rng.shuffle(list_shuffle)\n",
        "  train_split=list_shuffle[:(nb_dates-case_number_for_validation-1)]\n",
        "  test_split=list_shuffle[((nb_dates-case_number_for_validation)):]\t\t\n",
        "  return train_split, test_split\n",
        "\n",
        "  X_train=(X.iloc[train_split])\n",
        "  Y_train_StateClass=(Y_StateClass.iloc[train_split])\n",
        "  Y_train_FutPredict=(Y_FutPredict.iloc[train_split])\n",
        "\n",
        "def read_datas_splitted(y_name='y_stateclass.csv.zip'):\n",
        "  dfList=[]\n",
        "  df_x=pd.DataFrame()\n",
        "  df_y=pd.DataFrame()\n",
        "  for filename in ['datas/state_is_'+str(j)+'/out'+str(i)+'_' for i in range(2,3) for j in range(5)]:\n",
        "    df_y_tmp=pd.read_csv(filename+y_name).set_index('Date')\n",
        "    df_y=pd.concat([df_y,df_y_tmp],axis=0)\n",
        "  return df_y\n",
        "\n",
        "def read_and_create_dataset_by_perc(x_name='x_image.zip', y_name='y_stateclass.csv.zip',validation_split=0.2):\n",
        "  \n",
        "  df_x_train=pd.DataFrame()\n",
        "  df_y_train=pd.DataFrame()\n",
        "  df_x_test=pd.DataFrame()\n",
        "  df_y_test=pd.DataFrame()\n",
        "\n",
        "  for filename in ['datas/state_is_'+str(j)+'/out'+str(i)+'_' for i in range(2,3) for j in range(5)]:\n",
        "    df_x_tmp=pd.read_csv(filename+x_name).set_index('Date')\n",
        "    df_y_tmp=pd.read_csv(filename+y_name).set_index('Date')\n",
        "    \n",
        "    nb_dates=len(df_y_tmp.values)\n",
        "    print(nb_dates)\n",
        "    train_split, test_split=split_by_perc(nb_dates, validation_split)\n",
        "\n",
        "    df_x_train=pd.concat([df_x_train,df_x_tmp.iloc[train_split]],axis=0)\n",
        "    df_x_test=pd.concat([df_x_test,df_x_tmp.iloc[test_split]],axis=0)\n",
        "    df_y_train=pd.concat([df_y_train,df_y_tmp.iloc[train_split]],axis=0)\n",
        "    df_y_test=pd.concat([df_y_test,df_y_tmp.iloc[test_split]],axis=0)\n",
        "\n",
        "  df_x_train.to_csv('datas/dataset_by_perc/train/'+'x_train.zip',compression='zip')\n",
        "  df_y_train.to_csv('datas/dataset_by_perc/train/'+'y_train.zip',compression='zip')\n",
        "  df_x_test.to_csv('datas/dataset_by_perc/test/'+'x_test.zip',compression='zip')\n",
        "  df_y_test.to_csv('datas/dataset_by_perc/test/'+'y_test.zip',compression='zip')\n",
        "  return df_x_train.values, df_y_train.values, df_x_test.values, df_y_test.values\n",
        "\n",
        "def read_and_create_dataset_by_number(x_name='x_image.zip', y_name='y_stateclass.csv.zip',nb_case_by_state_block=50):\n",
        "  \n",
        "  df_x_train=pd.DataFrame()\n",
        "  df_y_train=pd.DataFrame()\n",
        "  df_x_test=pd.DataFrame()\n",
        "  df_y_test=pd.DataFrame()\n",
        "\n",
        "  for filename in ['datas/state_is_'+str(j)+'/out'+str(i)+'_' for i in range(2,3) for j in range(5)]:\n",
        "    df_x_tmp=pd.read_csv(filename+x_name).set_index('Date')\n",
        "    df_y_tmp=pd.read_csv(filename+y_name).set_index('Date')\n",
        "    \n",
        "    nb_dates=len(df_y_tmp.values)\n",
        "    print(nb_dates)\n",
        "    train_split, test_split=split_by_number(nb_dates, nb_case_by_state_block)\n",
        "\n",
        "    df_x_train=pd.concat([df_x_train,df_x_tmp.iloc[train_split]],axis=0)\n",
        "    df_x_test=pd.concat([df_x_test,df_x_tmp.iloc[test_split]],axis=0)\n",
        "    df_y_train=pd.concat([df_y_train,df_y_tmp.iloc[train_split]],axis=0)\n",
        "    df_y_test=pd.concat([df_y_test,df_y_tmp.iloc[test_split]],axis=0)\n",
        "\n",
        "  df_x_train.to_csv('datas/dataset_by_number/train/'+'x_train.zip',compression='zip')\n",
        "  df_y_train.to_csv('datas/dataset_by_number/train/'+'y_train.zip',compression='zip')\n",
        "  df_x_test.to_csv('datas/dataset_by_number/test/'+'x_test.zip',compression='zip')\n",
        "  df_y_test.to_csv('datas/dataset_by_number/test/'+'y_test.zip',compression='zip')\n",
        "  return df_x_train.values, df_y_train.values, df_x_test.values, df_y_test.values\n",
        "\n",
        "def read_dataset_by_path(path='/content/drive/My Drive/A_transfertTFM/datas/dataset_by_number'):\n",
        "    x_train=(pd.read_csv(path+'/train/x_train.zip').set_index('Date')).values\n",
        "    x_test=(pd.read_csv(path+'/test/x_test.zip').set_index('Date')).values\n",
        "    y_train=(pd.read_csv(path+'/train/y_train.zip').set_index('Date')).values\n",
        "    y_test=(pd.read_csv(path+'/test/x_test.zip').set_index('Date')).values  \n",
        "    return x_train, y_train, x_test, y_test\n",
        "\n",
        "def plot_example_image(x_train_image):\n",
        "  fig2 = mplt.figure(figsize=(10, 6))\n",
        "  x_datas=x_train_image[np.random.randint(low=10,high=1000,size=8)]\n",
        "  for i in range(0,8):\n",
        "    img = x_datas[i][:][:]\n",
        "    fig2.add_subplot(2, 4, i+1)\n",
        "    plt.imshow(img[:,:,0])\n",
        "\n",
        "def line_to_image255(x_train):\n",
        "  nb_train=x_train.shape[0]\n",
        "  x_train_image=np.zeros((nb_train,255,255,1))\n",
        "  for i in range(nb_train):\n",
        "    tmp=x_train[i,]\n",
        "    tmp=tmp.reshape(255,255,1)\n",
        "    x_train_image[i]=tmp\n",
        "  return x_train_image"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_7Gva4uwV5Oj"
      },
      "source": [
        "import numpy as np\n",
        "import pylab as plt\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as mplt\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AUmFaImJ4Gid"
      },
      "source": [
        "# WRITE DATAS DATASET TRAIN TEST IN DRIVE\n",
        "%cd /content/drive/My Drive/A_transfertTFM\n",
        "ydf=read_datas_splitted('y_stateclass.csv.zip')\n",
        "x_train, y_train, x_test, y_test=read_and_create_dataset_by_perc(x_name='x_image.zip', y_name='y_stateclass.csv.zip',validation_split=0.2)\n",
        "#x_train2, y_train2, x_test2, y_test2=read_and_create_dataset_by_number(x_name='x_image.zip', y_name='y_stateclass.csv.zip',nb_case_by_state_block=25)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jp0_855PpN3S",
        "outputId": "91cd49b5-b42c-4ffc-f95c-f85f717f0aa3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# LOAD DATASET TRAIN TEST FROM DRIVE\n",
        "%cd /content/drive/My Drive/A_transfertTFM\n",
        "x_train, y_train, x_test, y_test =read_dataset_by_path(path='/content/drive/My Drive/A_transfertTFM/datas/dataset_by_number')"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/A_transfertTFM\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OiGYdJFX-aEC"
      },
      "source": [
        "Now we check the datas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hgPmeKohS-pk",
        "outputId": "201f1507-8c0b-4c6f-bc15-3f3f5dafb201",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        }
      },
      "source": [
        "# CHECK DATASET\n",
        "#get images from train and test datas\n",
        "x_train_image=line_to_image255(x_train)\n",
        "x_test_image=line_to_image255(x_test)\n",
        "\n",
        "plot_example_image(x_train_image=x_train_image)\n",
        "print('Shape of each image in the training data: ', x_train_image.shape[:])\n",
        "print(\"number of train datas\",len(y_train))\n",
        "print(\"number of dates actual\",len(y_train))\n",
        "print(\"shape of y and x train\", y_train.shape, \" and \", x_train.shape)\n",
        "print(\"min value of datas\", np.min(y_train), \", max value of datas\",np.max(y_train))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of each image in the training data:  (2179, 255, 255, 1)\n",
            "number of train datas 2179\n",
            "number of dates actual 2179\n",
            "shape of y and x train (2179, 1)  and  (2179, 65025)\n",
            "min value of datas 0.0 , max value of datas 4.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x432 with 8 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zhYfxRLZa9CV",
        "outputId": "c0de667f-ca37-4704-998c-58dc2fde5625",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "255*255*2179"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "141689475"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNxzMBMEanwp",
        "outputId": "9dd15b82-c272-46b5-df8a-80e5199c9821",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x_train_image.shape"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2179, 255, 255, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6Z8846EWC3F"
      },
      "source": [
        "####Build up and training of the NN model "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tbRtrFYtaDI5"
      },
      "source": [
        "In this part we suppose that we have the training dataset taken from step 2. We use a Transfert model for vgg16 and some other layers. we use for this example a categorical_crossentropy loss and rmsprop optimizer. This part can be fined tuned for each financial index or stock index (layers, optimmizer, metrics, dropout) but in this case we introduced a simplier case. We train and save the model, please refer to XX to see the convergence of the model.\n",
        "\n",
        "We have 14.7M parameters and 66k trainable parametres. the size of training input is 571M only for the image not including rolling volatility, moving average etc\n",
        "\n",
        "NB: If you have an error on size of input of the ytrain you have to reload the input executing  step 2 once again"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gTHxq8RVg-vE"
      },
      "source": [
        "import numpy as np\n",
        "import pylab as plt\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import tensorboard\n",
        "\n",
        "from datetime import datetime\n",
        "\n",
        "from tensorflow import keras\n",
        "from keras.utils import np_utils\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.layers import Dropout, GlobalAveragePooling2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras import applications\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-2BAtxzmPpe"
      },
      "source": [
        "'''\n",
        "PARAMETERS to change so as to improve the training\n",
        "'''\n",
        "\n",
        "#We can modify batch size and epochs to adjust improve the training\n",
        "batch_size=64\n",
        "epochs=5\n",
        "sp500_learning_rate=0.001\n",
        "\n",
        "#Use of exponential decay for learning rate\n",
        "#https://keras.io/api/optimizers/learning_rate_schedules/exponential_decay/\n",
        "\n",
        "lr_schedule = sp500_learning_rate  #or lr_scheduleExp\n",
        "sp500_decay_rate=0.90\n",
        "lr_scheduleExp = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "    sp500_learning_rate,\n",
        "    decay_steps=100,\n",
        "    decay_rate=sp500_decay_rate,\n",
        "    staircase=True)\n",
        "\n",
        "##https://keras.io/api/losses/\n",
        "sp500loss='categorical_crossentropy'                                 \n",
        "\n",
        "##https://keras.io/api/optimizers/\n",
        "sp500optimizer_name='Adam'\n",
        "sp500optimizer='Adam'\n",
        "#sp500optimizer=keras.optimizers.Adam(learning_rate=lr_schedule)  \n",
        "\n",
        "##https://keras.io/api/metrics/\n",
        "sp500metrics=['accuracy']                                           \n"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7cRVj5gY5R3E"
      },
      "source": [
        "###Version with resnet\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jb4RPnakjSgk"
      },
      "source": [
        "?ResNet50"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9dBDC-Pb5Vi1",
        "outputId": "a0563224-b7b5-4146-a60c-bf5a61329c62",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "%cd /content/drive/My Drive/A_transfertTFM\n",
        "\n",
        "'''\n",
        "PART 3 Resnet TRAINING AND SAVING\n",
        "we suppose that we have loaded xtrain and ytrain\n",
        "This part is based on the Design of the NN\n",
        "Her we find the  quite usefull\n",
        "'''\n",
        "\n",
        "#In our example we need to y into categorical as it has 6 categories\n",
        "nb_classes=6\n",
        "\n",
        "m_x_train=x_train_image\n",
        "m_y_train=np_utils.to_categorical(y_train, nb_classes)\n",
        "\n",
        "\n",
        "del transfer_model1\n",
        "#Loading the resnet50 model with pre-trained ImageNet weights\n",
        "resnet_model = ResNet50()\n",
        "resnet_model.trainable = True # remove if you want to retrain resnet weights\n",
        "\n",
        "\n",
        "##Transfert model from resnet\n",
        "transfer_model1 = Sequential()\n",
        "transfer_model1.add(Dense(3, activation='relu'))\n",
        "transfer_model1.add(resnet_model)\n",
        "transfer_model1.add(Flatten())\n",
        "transfer_model1.add(Dense(128, activation='relu'))\n",
        "transfer_model1.add(Dropout(0.2))\n",
        "transfer_model1.add(Dense(6, activation='softmax'))\n",
        "\n",
        "\n",
        "#Transfert model 2\n",
        "'''\n",
        "img_height,img_width=255,255\n",
        "num_classes=6\n",
        "base_model = ResNet50(weights= None, include_top=False, input_shape= (img_height,img_width,1))\n",
        "\n",
        "x = Dense(64,activation='relu')\n",
        "x=  base_model(x)\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dropout(0.2)(x)\n",
        "predictions = Dense(num_classes, activation= 'softmax')(x)\n",
        "transfer_model2 = Model(inputs = base_model.input, outputs = predictions)\n",
        "'''\n",
        "###compilation model\n",
        "transfer_model=transfer_model1\n",
        "transfer_model.compile(loss=sp500loss, optimizer=sp500optimizer, metrics=sp500metrics)\n",
        "\n",
        "#Save initial weight to reinitialize it after when we trying to find the best set of parameters\n",
        "#transfer_model.save_weights('model/initial_weights.h5')\n",
        "#model.load_weights('my_model_weights.h5')\n",
        "\n",
        "##Saving the best model for each parameters\n",
        "checkpoint = ModelCheckpoint(\"model/best_model\"+sp500loss+\"_\"+sp500optimizer_name+\"_Batch\"+\\\n",
        "                             str(batch_size)+\"_LR\"+str(sp500_learning_rate)+\"_\"+str(sp500_decay_rate)+\".hdf5\", \\\n",
        "                                monitor='loss', verbose=1, \\\n",
        "                                save_best_only=True, mode='auto', period=1)\n",
        "\n",
        "# Load the TensorBoard notebook extension.\n",
        "%load_ext tensorboard\n",
        "#!rm -rf ./logs/ \n",
        "\n",
        " # Define the Keras TensorBoard callback.\n",
        "logdir=\"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir, histogram_freq=1)\n",
        "\n",
        "##Fitting the model on the train data and labels.\n",
        "#reinitialise xtrain, ytrain to avoid change of type from np.array to tensor by keras\n",
        "\n",
        "\n",
        "history = transfer_model.fit(m_x_train, m_y_train, \\\n",
        "                              batch_size=batch_size, epochs=epochs, \\\n",
        "                              validation_split=0.2, verbose=1, shuffle=True, \\\n",
        "                              callbacks=[checkpoint, tensorboard_callback])\n",
        "\n",
        "# Saving themodel\n",
        "transfer_model.save('model/resnetforsp500.h5')\n",
        "\n",
        "#Display the graph of the model\n",
        "tf.keras.utils.plot_model(transfer_model)\n",
        "\n",
        "##Display summary of neural network\n",
        "#transfer_model.summary()"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/A_transfertTFM\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "The tensorboard extension is already loaded. To reload it, use:\n",
            "  %reload_ext tensorboard\n",
            "Epoch 1/5\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 224, 224, 3) for input Tensor(\"input_11:0\", shape=(None, 224, 224, 3), dtype=float32), but it was called on an input with incompatible shape (None, 255, 255, 3).\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 224, 224, 3) for input Tensor(\"input_11:0\", shape=(None, 224, 224, 3), dtype=float32), but it was called on an input with incompatible shape (None, 255, 255, 3).\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 224, 224, 3) for input Tensor(\"input_11:0\", shape=(None, 224, 224, 3), dtype=float32), but it was called on an input with incompatible shape (None, 255, 255, 3).\n",
            " 1/28 [>.............................] - ETA: 0s - loss: 1.7924 - accuracy: 0.0938WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
            "Instructions for updating:\n",
            "use `tf.profiler.experimental.stop` instead.\n",
            " 2/28 [=>............................] - ETA: 15s - loss: 1.7883 - accuracy: 0.2422WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.3145s vs `on_train_batch_end` time: 0.8604s). Check your callbacks.\n",
            "28/28 [==============================] - ETA: 0s - loss: 1.7110 - accuracy: 0.4045WARNING:tensorflow:Model was constructed with shape (None, 224, 224, 3) for input Tensor(\"input_11:0\", shape=(None, 224, 224, 3), dtype=float32), but it was called on an input with incompatible shape (None, 255, 255, 3).\n",
            "\n",
            "Epoch 00001: loss improved from inf to 1.71096, saving model to model/best_modelcategorical_crossentropy_Adam_Batch64_LR0.001_0.9.hdf5\n",
            "28/28 [==============================] - 31s 1s/step - loss: 1.7110 - accuracy: 0.4045 - val_loss: 1.9382 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/5\n",
            "28/28 [==============================] - ETA: 0s - loss: 1.5807 - accuracy: 0.4389\n",
            "Epoch 00002: loss improved from 1.71096 to 1.58071, saving model to model/best_modelcategorical_crossentropy_Adam_Batch64_LR0.001_0.9.hdf5\n",
            "28/28 [==============================] - 29s 1s/step - loss: 1.5807 - accuracy: 0.4389 - val_loss: 2.1038 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/5\n",
            "28/28 [==============================] - ETA: 0s - loss: 1.5129 - accuracy: 0.4389\n",
            "Epoch 00003: loss improved from 1.58071 to 1.51292, saving model to model/best_modelcategorical_crossentropy_Adam_Batch64_LR0.001_0.9.hdf5\n",
            "28/28 [==============================] - 29s 1s/step - loss: 1.5129 - accuracy: 0.4389 - val_loss: 1.8888 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/5\n",
            "28/28 [==============================] - ETA: 0s - loss: 1.5005 - accuracy: 0.4389\n",
            "Epoch 00004: loss improved from 1.51292 to 1.50049, saving model to model/best_modelcategorical_crossentropy_Adam_Batch64_LR0.001_0.9.hdf5\n",
            "28/28 [==============================] - 29s 1s/step - loss: 1.5005 - accuracy: 0.4389 - val_loss: 2.0660 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/5\n",
            "28/28 [==============================] - ETA: 0s - loss: 1.4867 - accuracy: 0.4389\n",
            "Epoch 00005: loss improved from 1.50049 to 1.48672, saving model to model/best_modelcategorical_crossentropy_Adam_Batch64_LR0.001_0.9.hdf5\n",
            "28/28 [==============================] - 29s 1s/step - loss: 1.4867 - accuracy: 0.4389 - val_loss: 2.0897 - val_accuracy: 0.0000e+00\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sqRbJ1lTWRD7",
        "outputId": "cce77f57-a0b0-49da-8b6f-1ae87b0bf723",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "%cd /content/drive/My Drive/A_transfertTFM\n",
        "ls -l model/\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 837925\n",
            "-rw------- 1 root root  97839904 Sep 19 14:40 best_modelcategorical_crossentropy_Adam_Batch32_LR0.0001_0.98.hdf5\n",
            "-rw------- 1 root root  97839896 Sep 19 13:15 best_modelcategorical_crossentropy_Adam_Batch32_LR0.01_0.98.hdf5\n",
            "-rw------- 1 root root 283765328 Sep 19 17:08 best_modelcategorical_crossentropy_Adam_Batch64_LR0.001_0.9.hdf5\n",
            "-rw------- 1 root root  94822472 Sep 19 15:40 initial_weights.h5\n",
            "-rw------- 1 root root 283765328 Sep 19 17:08 resnetforsp500.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uhuotgb6WcNZ"
      },
      "source": [
        "%cp model/best_modelcategorical_crossentropy_Adam_Batch64_LR0.001_0.9.hdf5  /content/DL_Tools_For_Finance/model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "weqAP7PdW1On"
      },
      "source": [
        "transfer_model.save('model/initial_weights.h5')"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EoXEJAXifsEm"
      },
      "source": [
        "###Search of the best parameters for training and evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ar_MVI2_EyWh"
      },
      "source": [
        "%cd /content/drive/My Drive/A_transfertTFM\n",
        "#delete or not the log for tensorboard\n",
        "# !rm -rf ./logs/ "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KFsOIkkBfsEr",
        "outputId": "e57929da-cef7-4ded-ba79-51ae61aea9c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "%cd /content/drive/My Drive/A_transfertTFM\n",
        "# Load the TensorBoard notebook extension.\n",
        "%reload_ext tensorboard\n",
        "\n",
        "#We can modify batch size and epochs to adjust improve the training\n",
        "l_batch_size=[25,50,100]\n",
        "l_epochs=[25,50,100]\n",
        "l_learning_rate=[0.001,0.01,0.1]\n",
        "l_optimizer_name=[keras.optimizers.SGD, keras.optimizers.RMSprop, keras.optimizers.Adam, keras.optimizers.Adagrad, keras.optimizers.Adamax, keras.optimizers.Ftrl]\n",
        "\n",
        "Tabres={}\n",
        "#In our example we need to y into categorical as it has 6 categories\n",
        "nb_classes=6\n",
        "\n",
        "for x_batch_size in l_batch_size :\n",
        "  for  x_epochs in l_epochs:\n",
        "    for x_learning_rate in l_learning_rate:\n",
        "      for x_optimizer_name in l_optimizer_name :\n",
        "        \n",
        "        ##Fitting the model on the train data and labels.\n",
        "        m_x_train=x_train_image\n",
        "        m_y_train=np_utils.to_categorical(y_train, nb_classes)\n",
        "        \n",
        "        batch_size= x_batch_size\n",
        "        epochs= x_epochs\n",
        "        lr_schedule =  x_learning_rate\n",
        "        \n",
        "\n",
        "        ##https://keras.io/api/losses/\n",
        "        sp500loss='categorical_crossentropy'                             \n",
        "\n",
        "        ##https://keras.io/api/optimizers/\n",
        "        sp500optimizer_name=x_optimizer_name(learning_rate=x_learning_rate)\n",
        "        \n",
        "        ##https://keras.io/api/metrics/\n",
        "        sp500metrics=['accuracy']                                           \n",
        "        \n",
        "        \n",
        "        ##ACTUALISATION OF THE MODEL AND BY EACH SET OF PARAMETERS\n",
        "        \n",
        "        #First we initialize weight for each set of param see abpve where we had saved it\n",
        "        transfer_model.load_weights('model/initial_weights.h5')\n",
        "        transfer_model.compile(loss=sp500loss, optimizer=sp500optimizer_name,\n",
        "                      metrics=sp500metrics)\n",
        "\n",
        "        ##Saving the best model for each parameters\n",
        "        nameof_intermediarymodel=\"best_model\"+sp500loss+\"_\"+str(sp500optimizer_name)+\"_Batch\"+\\\n",
        "                                    str(batch_size)+\"_LR\"+str(x_learning_rate)+\"_Epochs\"+str(epochs)\n",
        "        checkpoint = ModelCheckpoint('model/'+nameof_intermediarymodel+\".hdf5\", \\\n",
        "                                        monitor='loss', verbose=1, \\\n",
        "                                        save_best_only=True, mode='auto', period=1)\n",
        "\n",
        "        \n",
        "        # Define the Keras TensorBoard callback.\n",
        "        logdir=\"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "        tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir, histogram_freq=1)\n",
        "\n",
        "        \n",
        "\n",
        "        history = transfer_model.fit(m_x_train, m_y_train, \\\n",
        "                                      batch_size=batch_size, epochs=epochs, \\\n",
        "                                      validation_split=0.2, verbose=1, shuffle=True, \\\n",
        "                                      callbacks=[checkpoint,tensorboard_callback])\n",
        "        # Saving themodel\n",
        "        transfer_model.save('model/'+nameof_intermediarymodel+'resnetforsp500'+'.h5')\n",
        "        Tabres.update({nameof_intermediarymodel:history.history})\n",
        "\n"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/A_transfertTFM\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/25\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 224, 224, 3) for input Tensor(\"input_11:0\", shape=(None, 224, 224, 3), dtype=float32), but it was called on an input with incompatible shape (None, 255, 255, 3).\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 224, 224, 3) for input Tensor(\"input_11:0\", shape=(None, 224, 224, 3), dtype=float32), but it was called on an input with incompatible shape (None, 255, 255, 3).\n",
            " 2/70 [..............................] - ETA: 21s - loss: 1.5028 - accuracy: 0.4600WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1411s vs `on_train_batch_end` time: 0.4911s). Check your callbacks.\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4837 - accuracy: 0.4389WARNING:tensorflow:Model was constructed with shape (None, 224, 224, 3) for input Tensor(\"input_11:0\", shape=(None, 224, 224, 3), dtype=float32), but it was called on an input with incompatible shape (None, 255, 255, 3).\n",
            "\n",
            "Epoch 00001: loss improved from inf to 1.48369, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f28921bbd68>_Batch25_LR0.001_Epochs25.hdf5\n",
            "70/70 [==============================] - 31s 446ms/step - loss: 1.4837 - accuracy: 0.4389 - val_loss: 2.0857 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4797 - accuracy: 0.4389\n",
            "Epoch 00002: loss improved from 1.48369 to 1.47968, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f28921bbd68>_Batch25_LR0.001_Epochs25.hdf5\n",
            "70/70 [==============================] - 29s 412ms/step - loss: 1.4797 - accuracy: 0.4389 - val_loss: 2.0610 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4795 - accuracy: 0.4389\n",
            "Epoch 00003: loss improved from 1.47968 to 1.47951, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f28921bbd68>_Batch25_LR0.001_Epochs25.hdf5\n",
            "70/70 [==============================] - 29s 416ms/step - loss: 1.4795 - accuracy: 0.4389 - val_loss: 1.9967 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4803 - accuracy: 0.4389\n",
            "Epoch 00004: loss did not improve from 1.47951\n",
            "70/70 [==============================] - 28s 394ms/step - loss: 1.4803 - accuracy: 0.4389 - val_loss: 1.9341 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4806 - accuracy: 0.4389\n",
            "Epoch 00005: loss did not improve from 1.47951\n",
            "70/70 [==============================] - 27s 392ms/step - loss: 1.4806 - accuracy: 0.4389 - val_loss: 1.9076 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4811 - accuracy: 0.4389\n",
            "Epoch 00006: loss did not improve from 1.47951\n",
            "70/70 [==============================] - 27s 393ms/step - loss: 1.4811 - accuracy: 0.4389 - val_loss: 1.8964 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4759 - accuracy: 0.4389\n",
            "Epoch 00007: loss improved from 1.47951 to 1.47591, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f28921bbd68>_Batch25_LR0.001_Epochs25.hdf5\n",
            "70/70 [==============================] - 29s 413ms/step - loss: 1.4759 - accuracy: 0.4389 - val_loss: 1.8925 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4815 - accuracy: 0.4389\n",
            "Epoch 00008: loss did not improve from 1.47591\n",
            "70/70 [==============================] - 27s 392ms/step - loss: 1.4815 - accuracy: 0.4389 - val_loss: 1.8892 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4769 - accuracy: 0.4389\n",
            "Epoch 00009: loss did not improve from 1.47591\n",
            "70/70 [==============================] - 27s 392ms/step - loss: 1.4769 - accuracy: 0.4389 - val_loss: 1.8865 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4775 - accuracy: 0.4389\n",
            "Epoch 00010: loss did not improve from 1.47591\n",
            "70/70 [==============================] - 27s 392ms/step - loss: 1.4775 - accuracy: 0.4389 - val_loss: 1.8793 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4752 - accuracy: 0.4389\n",
            "Epoch 00011: loss improved from 1.47591 to 1.47518, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f28921bbd68>_Batch25_LR0.001_Epochs25.hdf5\n",
            "70/70 [==============================] - 29s 413ms/step - loss: 1.4752 - accuracy: 0.4389 - val_loss: 1.8658 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4820 - accuracy: 0.4389\n",
            "Epoch 00012: loss did not improve from 1.47518\n",
            "70/70 [==============================] - 27s 393ms/step - loss: 1.4820 - accuracy: 0.4389 - val_loss: 1.8483 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4790 - accuracy: 0.4389\n",
            "Epoch 00013: loss did not improve from 1.47518\n",
            "70/70 [==============================] - 28s 395ms/step - loss: 1.4790 - accuracy: 0.4389 - val_loss: 1.8384 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4770 - accuracy: 0.4389\n",
            "Epoch 00014: loss did not improve from 1.47518\n",
            "70/70 [==============================] - 28s 393ms/step - loss: 1.4770 - accuracy: 0.4389 - val_loss: 1.8356 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4754 - accuracy: 0.4389\n",
            "Epoch 00015: loss did not improve from 1.47518\n",
            "70/70 [==============================] - 27s 392ms/step - loss: 1.4754 - accuracy: 0.4389 - val_loss: 1.8370 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4752 - accuracy: 0.4389\n",
            "Epoch 00016: loss did not improve from 1.47518\n",
            "70/70 [==============================] - 28s 393ms/step - loss: 1.4752 - accuracy: 0.4389 - val_loss: 1.8857 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4784 - accuracy: 0.4389\n",
            "Epoch 00017: loss did not improve from 1.47518\n",
            "70/70 [==============================] - 28s 394ms/step - loss: 1.4784 - accuracy: 0.4389 - val_loss: 1.8957 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4757 - accuracy: 0.4389\n",
            "Epoch 00018: loss did not improve from 1.47518\n",
            "70/70 [==============================] - 28s 393ms/step - loss: 1.4757 - accuracy: 0.4389 - val_loss: 1.9192 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4777 - accuracy: 0.4389\n",
            "Epoch 00019: loss did not improve from 1.47518\n",
            "70/70 [==============================] - 28s 393ms/step - loss: 1.4777 - accuracy: 0.4389 - val_loss: 2.0208 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4762 - accuracy: 0.4389\n",
            "Epoch 00020: loss did not improve from 1.47518\n",
            "70/70 [==============================] - 28s 393ms/step - loss: 1.4762 - accuracy: 0.4389 - val_loss: 2.0722 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4753 - accuracy: 0.4389\n",
            "Epoch 00021: loss did not improve from 1.47518\n",
            "70/70 [==============================] - 28s 393ms/step - loss: 1.4753 - accuracy: 0.4389 - val_loss: 2.0720 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4781 - accuracy: 0.4389\n",
            "Epoch 00022: loss did not improve from 1.47518\n",
            "70/70 [==============================] - 27s 393ms/step - loss: 1.4781 - accuracy: 0.4389 - val_loss: 2.0711 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4743 - accuracy: 0.4389\n",
            "Epoch 00023: loss improved from 1.47518 to 1.47432, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f28921bbd68>_Batch25_LR0.001_Epochs25.hdf5\n",
            "70/70 [==============================] - 29s 414ms/step - loss: 1.4743 - accuracy: 0.4389 - val_loss: 2.0704 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4788 - accuracy: 0.4389\n",
            "Epoch 00024: loss did not improve from 1.47432\n",
            "70/70 [==============================] - 27s 392ms/step - loss: 1.4788 - accuracy: 0.4389 - val_loss: 2.0702 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4744 - accuracy: 0.4389\n",
            "Epoch 00025: loss did not improve from 1.47432\n",
            "70/70 [==============================] - 28s 394ms/step - loss: 1.4744 - accuracy: 0.4389 - val_loss: 2.0704 - val_accuracy: 0.0000e+00\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/25\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 224, 224, 3) for input Tensor(\"input_11:0\", shape=(None, 224, 224, 3), dtype=float32), but it was called on an input with incompatible shape (None, 255, 255, 3).\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 224, 224, 3) for input Tensor(\"input_11:0\", shape=(None, 224, 224, 3), dtype=float32), but it was called on an input with incompatible shape (None, 255, 255, 3).\n",
            " 2/70 [..............................] - ETA: 41s - loss: 1.4695 - accuracy: 0.4400WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2402s vs `on_train_batch_end` time: 0.9331s). Check your callbacks.\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4742 - accuracy: 0.4389WARNING:tensorflow:Model was constructed with shape (None, 224, 224, 3) for input Tensor(\"input_11:0\", shape=(None, 224, 224, 3), dtype=float32), but it was called on an input with incompatible shape (None, 255, 255, 3).\n",
            "\n",
            "Epoch 00001: loss improved from inf to 1.47417, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f270733f668>_Batch25_LR0.001_Epochs25.hdf5\n",
            "70/70 [==============================] - 31s 448ms/step - loss: 1.4742 - accuracy: 0.4389 - val_loss: 2.0048 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4686 - accuracy: 0.4389\n",
            "Epoch 00002: loss improved from 1.47417 to 1.46860, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f270733f668>_Batch25_LR0.001_Epochs25.hdf5\n",
            "70/70 [==============================] - 31s 441ms/step - loss: 1.4686 - accuracy: 0.4389 - val_loss: 2.0436 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4671 - accuracy: 0.4389\n",
            "Epoch 00003: loss improved from 1.46860 to 1.46706, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f270733f668>_Batch25_LR0.001_Epochs25.hdf5\n",
            "70/70 [==============================] - 30s 433ms/step - loss: 1.4671 - accuracy: 0.4389 - val_loss: 1.9797 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4619 - accuracy: 0.4389\n",
            "Epoch 00004: loss improved from 1.46706 to 1.46188, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f270733f668>_Batch25_LR0.001_Epochs25.hdf5\n",
            "70/70 [==============================] - 31s 437ms/step - loss: 1.4619 - accuracy: 0.4389 - val_loss: 1.8807 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4644 - accuracy: 0.4389\n",
            "Epoch 00005: loss did not improve from 1.46188\n",
            "70/70 [==============================] - 28s 404ms/step - loss: 1.4644 - accuracy: 0.4389 - val_loss: 1.8476 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4610 - accuracy: 0.4389\n",
            "Epoch 00006: loss improved from 1.46188 to 1.46096, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f270733f668>_Batch25_LR0.001_Epochs25.hdf5\n",
            "70/70 [==============================] - 30s 434ms/step - loss: 1.4610 - accuracy: 0.4389 - val_loss: 1.8645 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4617 - accuracy: 0.4389\n",
            "Epoch 00007: loss did not improve from 1.46096\n",
            "70/70 [==============================] - 28s 404ms/step - loss: 1.4617 - accuracy: 0.4389 - val_loss: 1.8764 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4603 - accuracy: 0.4389\n",
            "Epoch 00008: loss improved from 1.46096 to 1.46031, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f270733f668>_Batch25_LR0.001_Epochs25.hdf5\n",
            "70/70 [==============================] - 30s 436ms/step - loss: 1.4603 - accuracy: 0.4389 - val_loss: 1.7958 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4591 - accuracy: 0.4389\n",
            "Epoch 00009: loss improved from 1.46031 to 1.45911, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f270733f668>_Batch25_LR0.001_Epochs25.hdf5\n",
            "70/70 [==============================] - 31s 436ms/step - loss: 1.4591 - accuracy: 0.4389 - val_loss: 1.8506 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4654 - accuracy: 0.4389\n",
            "Epoch 00010: loss did not improve from 1.45911\n",
            "70/70 [==============================] - 28s 405ms/step - loss: 1.4654 - accuracy: 0.4389 - val_loss: 1.8258 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4629 - accuracy: 0.4389\n",
            "Epoch 00011: loss did not improve from 1.45911\n",
            "70/70 [==============================] - 28s 405ms/step - loss: 1.4629 - accuracy: 0.4389 - val_loss: 1.7952 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4608 - accuracy: 0.4389\n",
            "Epoch 00012: loss did not improve from 1.45911\n",
            "70/70 [==============================] - 28s 404ms/step - loss: 1.4608 - accuracy: 0.4389 - val_loss: 1.7781 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4624 - accuracy: 0.4389\n",
            "Epoch 00013: loss did not improve from 1.45911\n",
            "70/70 [==============================] - 28s 405ms/step - loss: 1.4624 - accuracy: 0.4389 - val_loss: 1.7778 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4659 - accuracy: 0.4389\n",
            "Epoch 00014: loss did not improve from 1.45911\n",
            "70/70 [==============================] - 28s 405ms/step - loss: 1.4659 - accuracy: 0.4389 - val_loss: 1.7599 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4596 - accuracy: 0.4389\n",
            "Epoch 00015: loss did not improve from 1.45911\n",
            "70/70 [==============================] - 28s 404ms/step - loss: 1.4596 - accuracy: 0.4389 - val_loss: 1.7508 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4630 - accuracy: 0.4389\n",
            "Epoch 00016: loss did not improve from 1.45911\n",
            "70/70 [==============================] - 28s 404ms/step - loss: 1.4630 - accuracy: 0.4389 - val_loss: 1.8196 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4614 - accuracy: 0.4389\n",
            "Epoch 00017: loss did not improve from 1.45911\n",
            "70/70 [==============================] - 28s 404ms/step - loss: 1.4614 - accuracy: 0.4389 - val_loss: 1.8228 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4646 - accuracy: 0.4389\n",
            "Epoch 00018: loss did not improve from 1.45911\n",
            "70/70 [==============================] - 28s 405ms/step - loss: 1.4646 - accuracy: 0.4389 - val_loss: 1.8602 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4637 - accuracy: 0.4389\n",
            "Epoch 00019: loss did not improve from 1.45911\n",
            "70/70 [==============================] - 28s 404ms/step - loss: 1.4637 - accuracy: 0.4389 - val_loss: 1.9916 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4607 - accuracy: 0.4389\n",
            "Epoch 00020: loss did not improve from 1.45911\n",
            "70/70 [==============================] - 28s 404ms/step - loss: 1.4607 - accuracy: 0.4389 - val_loss: 2.0696 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4630 - accuracy: 0.4389\n",
            "Epoch 00021: loss did not improve from 1.45911\n",
            "70/70 [==============================] - 28s 404ms/step - loss: 1.4630 - accuracy: 0.4389 - val_loss: 2.0140 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4646 - accuracy: 0.4389\n",
            "Epoch 00022: loss did not improve from 1.45911\n",
            "70/70 [==============================] - 28s 405ms/step - loss: 1.4646 - accuracy: 0.4389 - val_loss: 1.9853 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4603 - accuracy: 0.4389\n",
            "Epoch 00023: loss did not improve from 1.45911\n",
            "70/70 [==============================] - 28s 405ms/step - loss: 1.4603 - accuracy: 0.4389 - val_loss: 2.0331 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4634 - accuracy: 0.4389\n",
            "Epoch 00024: loss did not improve from 1.45911\n",
            "70/70 [==============================] - 28s 405ms/step - loss: 1.4634 - accuracy: 0.4389 - val_loss: 1.9828 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4634 - accuracy: 0.4389\n",
            "Epoch 00025: loss did not improve from 1.45911\n",
            "70/70 [==============================] - 28s 405ms/step - loss: 1.4634 - accuracy: 0.4389 - val_loss: 2.0400 - val_accuracy: 0.0000e+00\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/25\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 224, 224, 3) for input Tensor(\"input_11:0\", shape=(None, 224, 224, 3), dtype=float32), but it was called on an input with incompatible shape (None, 255, 255, 3).\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 224, 224, 3) for input Tensor(\"input_11:0\", shape=(None, 224, 224, 3), dtype=float32), but it was called on an input with incompatible shape (None, 255, 255, 3).\n",
            " 2/70 [..............................] - ETA: 30s - loss: 1.5599 - accuracy: 0.3800WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1348s vs `on_train_batch_end` time: 0.6006s). Check your callbacks.\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4758 - accuracy: 0.4389WARNING:tensorflow:Model was constructed with shape (None, 224, 224, 3) for input Tensor(\"input_11:0\", shape=(None, 224, 224, 3), dtype=float32), but it was called on an input with incompatible shape (None, 255, 255, 3).\n",
            "\n",
            "Epoch 00001: loss improved from inf to 1.47582, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f28944ff080>_Batch25_LR0.001_Epochs25.hdf5\n",
            "70/70 [==============================] - 31s 442ms/step - loss: 1.4758 - accuracy: 0.4389 - val_loss: 2.0630 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4682 - accuracy: 0.4389\n",
            "Epoch 00002: loss improved from 1.47582 to 1.46823, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f28944ff080>_Batch25_LR0.001_Epochs25.hdf5\n",
            "70/70 [==============================] - 31s 443ms/step - loss: 1.4682 - accuracy: 0.4389 - val_loss: 1.9632 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4677 - accuracy: 0.4389\n",
            "Epoch 00003: loss improved from 1.46823 to 1.46773, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f28944ff080>_Batch25_LR0.001_Epochs25.hdf5\n",
            "70/70 [==============================] - 31s 440ms/step - loss: 1.4677 - accuracy: 0.4389 - val_loss: 1.9402 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4661 - accuracy: 0.4389\n",
            "Epoch 00004: loss improved from 1.46773 to 1.46607, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f28944ff080>_Batch25_LR0.001_Epochs25.hdf5\n",
            "70/70 [==============================] - 31s 441ms/step - loss: 1.4661 - accuracy: 0.4389 - val_loss: 1.8840 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4600 - accuracy: 0.4389\n",
            "Epoch 00005: loss improved from 1.46607 to 1.45995, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f28944ff080>_Batch25_LR0.001_Epochs25.hdf5\n",
            "70/70 [==============================] - 31s 444ms/step - loss: 1.4600 - accuracy: 0.4389 - val_loss: 1.8222 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4639 - accuracy: 0.4389\n",
            "Epoch 00006: loss did not improve from 1.45995\n",
            "70/70 [==============================] - 28s 399ms/step - loss: 1.4639 - accuracy: 0.4389 - val_loss: 1.8269 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4636 - accuracy: 0.4389\n",
            "Epoch 00007: loss did not improve from 1.45995\n",
            "70/70 [==============================] - 28s 398ms/step - loss: 1.4636 - accuracy: 0.4389 - val_loss: 1.8561 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4628 - accuracy: 0.4389\n",
            "Epoch 00008: loss did not improve from 1.45995\n",
            "70/70 [==============================] - 28s 397ms/step - loss: 1.4628 - accuracy: 0.4389 - val_loss: 1.8037 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4645 - accuracy: 0.4389\n",
            "Epoch 00009: loss did not improve from 1.45995\n",
            "70/70 [==============================] - 28s 400ms/step - loss: 1.4645 - accuracy: 0.4389 - val_loss: 1.8244 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4657 - accuracy: 0.4389\n",
            "Epoch 00010: loss did not improve from 1.45995\n",
            "70/70 [==============================] - 28s 395ms/step - loss: 1.4657 - accuracy: 0.4389 - val_loss: 1.8059 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4620 - accuracy: 0.4389\n",
            "Epoch 00011: loss did not improve from 1.45995\n",
            "70/70 [==============================] - 28s 395ms/step - loss: 1.4620 - accuracy: 0.4389 - val_loss: 1.8143 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4625 - accuracy: 0.4389\n",
            "Epoch 00012: loss did not improve from 1.45995\n",
            "70/70 [==============================] - 28s 394ms/step - loss: 1.4625 - accuracy: 0.4389 - val_loss: 1.7927 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4619 - accuracy: 0.4389\n",
            "Epoch 00013: loss did not improve from 1.45995\n",
            "70/70 [==============================] - 28s 396ms/step - loss: 1.4619 - accuracy: 0.4389 - val_loss: 1.7699 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4631 - accuracy: 0.4389\n",
            "Epoch 00014: loss did not improve from 1.45995\n",
            "70/70 [==============================] - 28s 394ms/step - loss: 1.4631 - accuracy: 0.4389 - val_loss: 1.7722 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4627 - accuracy: 0.4389\n",
            "Epoch 00015: loss did not improve from 1.45995\n",
            "70/70 [==============================] - 28s 394ms/step - loss: 1.4627 - accuracy: 0.4389 - val_loss: 1.7857 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4620 - accuracy: 0.4389\n",
            "Epoch 00016: loss did not improve from 1.45995\n",
            "70/70 [==============================] - 28s 395ms/step - loss: 1.4620 - accuracy: 0.4389 - val_loss: 1.8329 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4624 - accuracy: 0.4389\n",
            "Epoch 00017: loss did not improve from 1.45995\n",
            "70/70 [==============================] - 28s 395ms/step - loss: 1.4624 - accuracy: 0.4389 - val_loss: 1.8398 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4620 - accuracy: 0.4389\n",
            "Epoch 00018: loss did not improve from 1.45995\n",
            "70/70 [==============================] - 28s 394ms/step - loss: 1.4620 - accuracy: 0.4389 - val_loss: 1.8465 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4627 - accuracy: 0.4389\n",
            "Epoch 00019: loss did not improve from 1.45995\n",
            "70/70 [==============================] - 28s 399ms/step - loss: 1.4627 - accuracy: 0.4389 - val_loss: 1.9983 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4605 - accuracy: 0.4389\n",
            "Epoch 00020: loss did not improve from 1.45995\n",
            "70/70 [==============================] - 28s 393ms/step - loss: 1.4605 - accuracy: 0.4389 - val_loss: 2.0491 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4605 - accuracy: 0.4389\n",
            "Epoch 00021: loss did not improve from 1.45995\n",
            "70/70 [==============================] - 28s 394ms/step - loss: 1.4605 - accuracy: 0.4389 - val_loss: 2.0354 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4647 - accuracy: 0.4389\n",
            "Epoch 00022: loss did not improve from 1.45995\n",
            "70/70 [==============================] - 28s 395ms/step - loss: 1.4647 - accuracy: 0.4389 - val_loss: 2.0026 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4621 - accuracy: 0.4389\n",
            "Epoch 00023: loss did not improve from 1.45995\n",
            "70/70 [==============================] - 28s 394ms/step - loss: 1.4621 - accuracy: 0.4389 - val_loss: 2.0399 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4625 - accuracy: 0.4389\n",
            "Epoch 00024: loss did not improve from 1.45995\n",
            "70/70 [==============================] - 28s 394ms/step - loss: 1.4625 - accuracy: 0.4389 - val_loss: 2.0621 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4632 - accuracy: 0.4389\n",
            "Epoch 00025: loss did not improve from 1.45995\n",
            "70/70 [==============================] - 27s 392ms/step - loss: 1.4632 - accuracy: 0.4389 - val_loss: 1.9739 - val_accuracy: 0.0000e+00\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/25\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 224, 224, 3) for input Tensor(\"input_11:0\", shape=(None, 224, 224, 3), dtype=float32), but it was called on an input with incompatible shape (None, 255, 255, 3).\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 224, 224, 3) for input Tensor(\"input_11:0\", shape=(None, 224, 224, 3), dtype=float32), but it was called on an input with incompatible shape (None, 255, 255, 3).\n",
            " 2/70 [..............................] - ETA: 35s - loss: 1.4912 - accuracy: 0.4600WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1570s vs `on_train_batch_end` time: 0.7093s). Check your callbacks.\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4827 - accuracy: 0.4389WARNING:tensorflow:Model was constructed with shape (None, 224, 224, 3) for input Tensor(\"input_11:0\", shape=(None, 224, 224, 3), dtype=float32), but it was called on an input with incompatible shape (None, 255, 255, 3).\n",
            "\n",
            "Epoch 00001: loss improved from inf to 1.48267, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f2707bab588>_Batch25_LR0.001_Epochs25.hdf5\n",
            "70/70 [==============================] - 30s 428ms/step - loss: 1.4827 - accuracy: 0.4389 - val_loss: 2.0854 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4813 - accuracy: 0.4389\n",
            "Epoch 00002: loss improved from 1.48267 to 1.48130, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f2707bab588>_Batch25_LR0.001_Epochs25.hdf5\n",
            "70/70 [==============================] - 30s 424ms/step - loss: 1.4813 - accuracy: 0.4389 - val_loss: 2.0586 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4805 - accuracy: 0.4389\n",
            "Epoch 00003: loss improved from 1.48130 to 1.48047, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f2707bab588>_Batch25_LR0.001_Epochs25.hdf5\n",
            "70/70 [==============================] - 29s 421ms/step - loss: 1.4805 - accuracy: 0.4389 - val_loss: 1.9915 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4838 - accuracy: 0.4389\n",
            "Epoch 00004: loss did not improve from 1.48047\n",
            "70/70 [==============================] - 27s 389ms/step - loss: 1.4838 - accuracy: 0.4389 - val_loss: 1.9279 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4796 - accuracy: 0.4389\n",
            "Epoch 00005: loss improved from 1.48047 to 1.47957, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f2707bab588>_Batch25_LR0.001_Epochs25.hdf5\n",
            "70/70 [==============================] - 30s 423ms/step - loss: 1.4796 - accuracy: 0.4389 - val_loss: 1.9015 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4776 - accuracy: 0.4389\n",
            "Epoch 00006: loss improved from 1.47957 to 1.47759, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f2707bab588>_Batch25_LR0.001_Epochs25.hdf5\n",
            "70/70 [==============================] - 30s 422ms/step - loss: 1.4776 - accuracy: 0.4389 - val_loss: 1.8902 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4783 - accuracy: 0.4389\n",
            "Epoch 00007: loss did not improve from 1.47759\n",
            "70/70 [==============================] - 27s 391ms/step - loss: 1.4783 - accuracy: 0.4389 - val_loss: 1.8844 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4765 - accuracy: 0.4389\n",
            "Epoch 00008: loss improved from 1.47759 to 1.47654, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f2707bab588>_Batch25_LR0.001_Epochs25.hdf5\n",
            "70/70 [==============================] - 30s 425ms/step - loss: 1.4765 - accuracy: 0.4389 - val_loss: 1.8824 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4762 - accuracy: 0.4389\n",
            "Epoch 00009: loss improved from 1.47654 to 1.47622, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f2707bab588>_Batch25_LR0.001_Epochs25.hdf5\n",
            "70/70 [==============================] - 30s 423ms/step - loss: 1.4762 - accuracy: 0.4389 - val_loss: 1.8788 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4756 - accuracy: 0.4389\n",
            "Epoch 00010: loss improved from 1.47622 to 1.47557, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f2707bab588>_Batch25_LR0.001_Epochs25.hdf5\n",
            "70/70 [==============================] - 30s 424ms/step - loss: 1.4756 - accuracy: 0.4389 - val_loss: 1.8724 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4785 - accuracy: 0.4389\n",
            "Epoch 00011: loss did not improve from 1.47557\n",
            "70/70 [==============================] - 27s 392ms/step - loss: 1.4785 - accuracy: 0.4389 - val_loss: 1.8590 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4769 - accuracy: 0.4389\n",
            "Epoch 00012: loss did not improve from 1.47557\n",
            "70/70 [==============================] - 28s 398ms/step - loss: 1.4769 - accuracy: 0.4389 - val_loss: 1.8416 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4769 - accuracy: 0.4389\n",
            "Epoch 00013: loss did not improve from 1.47557\n",
            "70/70 [==============================] - 28s 401ms/step - loss: 1.4769 - accuracy: 0.4389 - val_loss: 1.8316 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4742 - accuracy: 0.4389\n",
            "Epoch 00014: loss improved from 1.47557 to 1.47417, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f2707bab588>_Batch25_LR0.001_Epochs25.hdf5\n",
            "70/70 [==============================] - 30s 434ms/step - loss: 1.4742 - accuracy: 0.4389 - val_loss: 1.8288 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4739 - accuracy: 0.4389\n",
            "Epoch 00015: loss improved from 1.47417 to 1.47393, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f2707bab588>_Batch25_LR0.001_Epochs25.hdf5\n",
            "70/70 [==============================] - 30s 434ms/step - loss: 1.4739 - accuracy: 0.4389 - val_loss: 1.8304 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4767 - accuracy: 0.4389\n",
            "Epoch 00016: loss did not improve from 1.47393\n",
            "70/70 [==============================] - 28s 399ms/step - loss: 1.4767 - accuracy: 0.4389 - val_loss: 1.8791 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4720 - accuracy: 0.4389\n",
            "Epoch 00017: loss improved from 1.47393 to 1.47205, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f2707bab588>_Batch25_LR0.001_Epochs25.hdf5\n",
            "70/70 [==============================] - 30s 430ms/step - loss: 1.4720 - accuracy: 0.4389 - val_loss: 1.8883 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4741 - accuracy: 0.4389\n",
            "Epoch 00018: loss did not improve from 1.47205\n",
            "70/70 [==============================] - 28s 397ms/step - loss: 1.4741 - accuracy: 0.4389 - val_loss: 1.9114 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4751 - accuracy: 0.4389\n",
            "Epoch 00019: loss did not improve from 1.47205\n",
            "70/70 [==============================] - 28s 398ms/step - loss: 1.4751 - accuracy: 0.4389 - val_loss: 2.0114 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4750 - accuracy: 0.4389\n",
            "Epoch 00020: loss did not improve from 1.47205\n",
            "70/70 [==============================] - 28s 397ms/step - loss: 1.4750 - accuracy: 0.4389 - val_loss: 2.0623 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4747 - accuracy: 0.4389\n",
            "Epoch 00021: loss did not improve from 1.47205\n",
            "70/70 [==============================] - 28s 397ms/step - loss: 1.4747 - accuracy: 0.4389 - val_loss: 2.0623 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4738 - accuracy: 0.4389\n",
            "Epoch 00022: loss did not improve from 1.47205\n",
            "70/70 [==============================] - 28s 398ms/step - loss: 1.4738 - accuracy: 0.4389 - val_loss: 2.0614 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4767 - accuracy: 0.4389\n",
            "Epoch 00023: loss did not improve from 1.47205\n",
            "70/70 [==============================] - 28s 398ms/step - loss: 1.4767 - accuracy: 0.4389 - val_loss: 2.0607 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4742 - accuracy: 0.4389\n",
            "Epoch 00024: loss did not improve from 1.47205\n",
            "70/70 [==============================] - 28s 399ms/step - loss: 1.4742 - accuracy: 0.4389 - val_loss: 2.0599 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4732 - accuracy: 0.4389\n",
            "Epoch 00025: loss did not improve from 1.47205\n",
            "70/70 [==============================] - 28s 397ms/step - loss: 1.4732 - accuracy: 0.4389 - val_loss: 2.0592 - val_accuracy: 0.0000e+00\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/25\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 224, 224, 3) for input Tensor(\"input_11:0\", shape=(None, 224, 224, 3), dtype=float32), but it was called on an input with incompatible shape (None, 255, 255, 3).\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 224, 224, 3) for input Tensor(\"input_11:0\", shape=(None, 224, 224, 3), dtype=float32), but it was called on an input with incompatible shape (None, 255, 255, 3).\n",
            " 2/70 [..............................] - ETA: 34s - loss: 1.4325 - accuracy: 0.4800WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1719s vs `on_train_batch_end` time: 0.6998s). Check your callbacks.\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4750 - accuracy: 0.4389WARNING:tensorflow:Model was constructed with shape (None, 224, 224, 3) for input Tensor(\"input_11:0\", shape=(None, 224, 224, 3), dtype=float32), but it was called on an input with incompatible shape (None, 255, 255, 3).\n",
            "\n",
            "Epoch 00001: loss improved from inf to 1.47500, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f26f12a22e8>_Batch25_LR0.001_Epochs25.hdf5\n",
            "70/70 [==============================] - 31s 448ms/step - loss: 1.4750 - accuracy: 0.4389 - val_loss: 2.0546 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4716 - accuracy: 0.4389\n",
            "Epoch 00002: loss improved from 1.47500 to 1.47160, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f26f12a22e8>_Batch25_LR0.001_Epochs25.hdf5\n",
            "70/70 [==============================] - 31s 443ms/step - loss: 1.4716 - accuracy: 0.4389 - val_loss: 2.0046 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4693 - accuracy: 0.4389\n",
            "Epoch 00003: loss improved from 1.47160 to 1.46931, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f26f12a22e8>_Batch25_LR0.001_Epochs25.hdf5\n",
            "70/70 [==============================] - 31s 440ms/step - loss: 1.4693 - accuracy: 0.4389 - val_loss: 1.9625 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4623 - accuracy: 0.4389\n",
            "Epoch 00004: loss improved from 1.46931 to 1.46226, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f26f12a22e8>_Batch25_LR0.001_Epochs25.hdf5\n",
            "70/70 [==============================] - 31s 444ms/step - loss: 1.4623 - accuracy: 0.4389 - val_loss: 1.8938 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4636 - accuracy: 0.4389\n",
            "Epoch 00005: loss did not improve from 1.46226\n",
            "70/70 [==============================] - 28s 397ms/step - loss: 1.4636 - accuracy: 0.4389 - val_loss: 1.8529 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4650 - accuracy: 0.4389\n",
            "Epoch 00006: loss did not improve from 1.46226\n",
            "70/70 [==============================] - 28s 397ms/step - loss: 1.4650 - accuracy: 0.4389 - val_loss: 1.8284 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4634 - accuracy: 0.4389\n",
            "Epoch 00007: loss did not improve from 1.46226\n",
            "70/70 [==============================] - 28s 397ms/step - loss: 1.4634 - accuracy: 0.4389 - val_loss: 1.8390 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4610 - accuracy: 0.4389\n",
            "Epoch 00008: loss improved from 1.46226 to 1.46097, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f26f12a22e8>_Batch25_LR0.001_Epochs25.hdf5\n",
            "70/70 [==============================] - 31s 443ms/step - loss: 1.4610 - accuracy: 0.4389 - val_loss: 1.8362 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4614 - accuracy: 0.4389\n",
            "Epoch 00009: loss did not improve from 1.46097\n",
            "70/70 [==============================] - 28s 399ms/step - loss: 1.4614 - accuracy: 0.4389 - val_loss: 1.8367 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4638 - accuracy: 0.4389\n",
            "Epoch 00010: loss did not improve from 1.46097\n",
            "70/70 [==============================] - 28s 398ms/step - loss: 1.4638 - accuracy: 0.4389 - val_loss: 1.8178 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4627 - accuracy: 0.4389\n",
            "Epoch 00011: loss did not improve from 1.46097\n",
            "70/70 [==============================] - 28s 396ms/step - loss: 1.4627 - accuracy: 0.4389 - val_loss: 1.8027 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4617 - accuracy: 0.4389\n",
            "Epoch 00012: loss did not improve from 1.46097\n",
            "70/70 [==============================] - 28s 397ms/step - loss: 1.4617 - accuracy: 0.4389 - val_loss: 1.7897 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4604 - accuracy: 0.4389\n",
            "Epoch 00013: loss improved from 1.46097 to 1.46035, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f26f12a22e8>_Batch25_LR0.001_Epochs25.hdf5\n",
            "70/70 [==============================] - 31s 447ms/step - loss: 1.4604 - accuracy: 0.4389 - val_loss: 1.7743 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4618 - accuracy: 0.4389\n",
            "Epoch 00014: loss did not improve from 1.46035\n",
            "70/70 [==============================] - 28s 397ms/step - loss: 1.4618 - accuracy: 0.4389 - val_loss: 1.7726 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4612 - accuracy: 0.4389\n",
            "Epoch 00015: loss did not improve from 1.46035\n",
            "70/70 [==============================] - 28s 398ms/step - loss: 1.4612 - accuracy: 0.4389 - val_loss: 1.7748 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4652 - accuracy: 0.4389\n",
            "Epoch 00016: loss did not improve from 1.46035\n",
            "70/70 [==============================] - 28s 395ms/step - loss: 1.4652 - accuracy: 0.4389 - val_loss: 1.8336 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4627 - accuracy: 0.4389\n",
            "Epoch 00017: loss did not improve from 1.46035\n",
            "70/70 [==============================] - 28s 398ms/step - loss: 1.4627 - accuracy: 0.4389 - val_loss: 1.9861 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4616 - accuracy: 0.4389\n",
            "Epoch 00018: loss did not improve from 1.46035\n",
            "70/70 [==============================] - 28s 398ms/step - loss: 1.4616 - accuracy: 0.4389 - val_loss: 2.0381 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4641 - accuracy: 0.4389\n",
            "Epoch 00019: loss did not improve from 1.46035\n",
            "70/70 [==============================] - 28s 397ms/step - loss: 1.4641 - accuracy: 0.4389 - val_loss: 2.0340 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4615 - accuracy: 0.4389\n",
            "Epoch 00020: loss did not improve from 1.46035\n",
            "70/70 [==============================] - 28s 398ms/step - loss: 1.4615 - accuracy: 0.4389 - val_loss: 2.0192 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4629 - accuracy: 0.4389\n",
            "Epoch 00021: loss did not improve from 1.46035\n",
            "70/70 [==============================] - 28s 397ms/step - loss: 1.4629 - accuracy: 0.4389 - val_loss: 2.0255 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4606 - accuracy: 0.4389\n",
            "Epoch 00022: loss did not improve from 1.46035\n",
            "70/70 [==============================] - 28s 396ms/step - loss: 1.4606 - accuracy: 0.4389 - val_loss: 2.0108 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4617 - accuracy: 0.4389\n",
            "Epoch 00023: loss did not improve from 1.46035\n",
            "70/70 [==============================] - 28s 397ms/step - loss: 1.4617 - accuracy: 0.4389 - val_loss: 2.0260 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4599 - accuracy: 0.4389\n",
            "Epoch 00024: loss improved from 1.46035 to 1.45994, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f26f12a22e8>_Batch25_LR0.001_Epochs25.hdf5\n",
            "70/70 [==============================] - 31s 444ms/step - loss: 1.4599 - accuracy: 0.4389 - val_loss: 2.0231 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4613 - accuracy: 0.4389\n",
            "Epoch 00025: loss did not improve from 1.45994\n",
            "70/70 [==============================] - 28s 399ms/step - loss: 1.4613 - accuracy: 0.4389 - val_loss: 2.0249 - val_accuracy: 0.0000e+00\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/25\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 224, 224, 3) for input Tensor(\"input_11:0\", shape=(None, 224, 224, 3), dtype=float32), but it was called on an input with incompatible shape (None, 255, 255, 3).\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 224, 224, 3) for input Tensor(\"input_11:0\", shape=(None, 224, 224, 3), dtype=float32), but it was called on an input with incompatible shape (None, 255, 255, 3).\n",
            " 2/70 [..............................] - ETA: 1:23 - loss: 1.6457 - accuracy: 0.2400WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1825s vs `on_train_batch_end` time: 2.1426s). Check your callbacks.\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.7838 - accuracy: 0.4309WARNING:tensorflow:Model was constructed with shape (None, 224, 224, 3) for input Tensor(\"input_11:0\", shape=(None, 224, 224, 3), dtype=float32), but it was called on an input with incompatible shape (None, 255, 255, 3).\n",
            "\n",
            "Epoch 00001: loss improved from inf to 1.78382, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f26ee042a90>_Batch25_LR0.001_Epochs25.hdf5\n",
            "70/70 [==============================] - 31s 443ms/step - loss: 1.7838 - accuracy: 0.4309 - val_loss: 1.7941 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.7838 - accuracy: 0.4389\n",
            "Epoch 00002: loss improved from 1.78382 to 1.78379, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f26ee042a90>_Batch25_LR0.001_Epochs25.hdf5\n",
            "70/70 [==============================] - 29s 409ms/step - loss: 1.7838 - accuracy: 0.4389 - val_loss: 1.7954 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.7810 - accuracy: 0.4389\n",
            "Epoch 00003: loss improved from 1.78379 to 1.78101, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f26ee042a90>_Batch25_LR0.001_Epochs25.hdf5\n",
            "70/70 [==============================] - 28s 406ms/step - loss: 1.7810 - accuracy: 0.4389 - val_loss: 1.7964 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.7788 - accuracy: 0.4389\n",
            "Epoch 00004: loss improved from 1.78101 to 1.77877, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f26ee042a90>_Batch25_LR0.001_Epochs25.hdf5\n",
            "70/70 [==============================] - 29s 409ms/step - loss: 1.7788 - accuracy: 0.4389 - val_loss: 1.7973 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.7769 - accuracy: 0.4389\n",
            "Epoch 00005: loss improved from 1.77877 to 1.77685, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f26ee042a90>_Batch25_LR0.001_Epochs25.hdf5\n",
            "70/70 [==============================] - 29s 408ms/step - loss: 1.7769 - accuracy: 0.4389 - val_loss: 1.7981 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.7751 - accuracy: 0.4389\n",
            "Epoch 00006: loss improved from 1.77685 to 1.77514, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f26ee042a90>_Batch25_LR0.001_Epochs25.hdf5\n",
            "70/70 [==============================] - 29s 410ms/step - loss: 1.7751 - accuracy: 0.4389 - val_loss: 1.7988 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.7736 - accuracy: 0.4389\n",
            "Epoch 00007: loss improved from 1.77514 to 1.77358, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f26ee042a90>_Batch25_LR0.001_Epochs25.hdf5\n",
            "70/70 [==============================] - 29s 411ms/step - loss: 1.7736 - accuracy: 0.4389 - val_loss: 1.7995 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.7721 - accuracy: 0.4389\n",
            "Epoch 00008: loss improved from 1.77358 to 1.77214, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f26ee042a90>_Batch25_LR0.001_Epochs25.hdf5\n",
            "70/70 [==============================] - 29s 410ms/step - loss: 1.7721 - accuracy: 0.4389 - val_loss: 1.8001 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.7708 - accuracy: 0.4389\n",
            "Epoch 00009: loss improved from 1.77214 to 1.77079, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f26ee042a90>_Batch25_LR0.001_Epochs25.hdf5\n",
            "70/70 [==============================] - 29s 414ms/step - loss: 1.7708 - accuracy: 0.4389 - val_loss: 1.8007 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.7695 - accuracy: 0.4389\n",
            "Epoch 00010: loss improved from 1.77079 to 1.76953, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f26ee042a90>_Batch25_LR0.001_Epochs25.hdf5\n",
            "70/70 [==============================] - 29s 409ms/step - loss: 1.7695 - accuracy: 0.4389 - val_loss: 1.8013 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.7683 - accuracy: 0.4389\n",
            "Epoch 00011: loss improved from 1.76953 to 1.76833, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f26ee042a90>_Batch25_LR0.001_Epochs25.hdf5\n",
            "70/70 [==============================] - 29s 414ms/step - loss: 1.7683 - accuracy: 0.4389 - val_loss: 1.8018 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.7672 - accuracy: 0.4389\n",
            "Epoch 00012: loss improved from 1.76833 to 1.76719, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f26ee042a90>_Batch25_LR0.001_Epochs25.hdf5\n",
            "70/70 [==============================] - 29s 410ms/step - loss: 1.7672 - accuracy: 0.4389 - val_loss: 1.8024 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.7661 - accuracy: 0.4389\n",
            "Epoch 00013: loss improved from 1.76719 to 1.76611, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f26ee042a90>_Batch25_LR0.001_Epochs25.hdf5\n",
            "70/70 [==============================] - 29s 411ms/step - loss: 1.7661 - accuracy: 0.4389 - val_loss: 1.8029 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.7651 - accuracy: 0.4389\n",
            "Epoch 00014: loss improved from 1.76611 to 1.76507, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f26ee042a90>_Batch25_LR0.001_Epochs25.hdf5\n",
            "70/70 [==============================] - 29s 412ms/step - loss: 1.7651 - accuracy: 0.4389 - val_loss: 1.8033 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.7641 - accuracy: 0.4389\n",
            "Epoch 00015: loss improved from 1.76507 to 1.76407, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f26ee042a90>_Batch25_LR0.001_Epochs25.hdf5\n",
            "70/70 [==============================] - 29s 410ms/step - loss: 1.7641 - accuracy: 0.4389 - val_loss: 1.8038 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.7631 - accuracy: 0.4389\n",
            "Epoch 00016: loss improved from 1.76407 to 1.76310, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f26ee042a90>_Batch25_LR0.001_Epochs25.hdf5\n",
            "70/70 [==============================] - 29s 416ms/step - loss: 1.7631 - accuracy: 0.4389 - val_loss: 1.8043 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.7622 - accuracy: 0.4389\n",
            "Epoch 00017: loss improved from 1.76310 to 1.76217, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f26ee042a90>_Batch25_LR0.001_Epochs25.hdf5\n",
            "70/70 [==============================] - 29s 411ms/step - loss: 1.7622 - accuracy: 0.4389 - val_loss: 1.8047 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.7613 - accuracy: 0.4389\n",
            "Epoch 00018: loss improved from 1.76217 to 1.76127, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f26ee042a90>_Batch25_LR0.001_Epochs25.hdf5\n",
            "70/70 [==============================] - 29s 410ms/step - loss: 1.7613 - accuracy: 0.4389 - val_loss: 1.8051 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.7604 - accuracy: 0.4389\n",
            "Epoch 00019: loss improved from 1.76127 to 1.76040, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f26ee042a90>_Batch25_LR0.001_Epochs25.hdf5\n",
            "70/70 [==============================] - 29s 413ms/step - loss: 1.7604 - accuracy: 0.4389 - val_loss: 1.8056 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.7595 - accuracy: 0.4389\n",
            "Epoch 00020: loss improved from 1.76040 to 1.75955, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f26ee042a90>_Batch25_LR0.001_Epochs25.hdf5\n",
            "70/70 [==============================] - 29s 414ms/step - loss: 1.7595 - accuracy: 0.4389 - val_loss: 1.8060 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.7587 - accuracy: 0.4389\n",
            "Epoch 00021: loss improved from 1.75955 to 1.75872, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f26ee042a90>_Batch25_LR0.001_Epochs25.hdf5\n",
            "70/70 [==============================] - 29s 410ms/step - loss: 1.7587 - accuracy: 0.4389 - val_loss: 1.8064 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.7579 - accuracy: 0.4389\n",
            "Epoch 00022: loss improved from 1.75872 to 1.75792, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f26ee042a90>_Batch25_LR0.001_Epochs25.hdf5\n",
            "70/70 [==============================] - 29s 410ms/step - loss: 1.7579 - accuracy: 0.4389 - val_loss: 1.8068 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.7571 - accuracy: 0.4389\n",
            "Epoch 00023: loss improved from 1.75792 to 1.75713, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f26ee042a90>_Batch25_LR0.001_Epochs25.hdf5\n",
            "70/70 [==============================] - 29s 410ms/step - loss: 1.7571 - accuracy: 0.4389 - val_loss: 1.8072 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.7564 - accuracy: 0.4389\n",
            "Epoch 00024: loss improved from 1.75713 to 1.75637, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f26ee042a90>_Batch25_LR0.001_Epochs25.hdf5\n",
            "70/70 [==============================] - 29s 412ms/step - loss: 1.7564 - accuracy: 0.4389 - val_loss: 1.8076 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.7556 - accuracy: 0.4389\n",
            "Epoch 00025: loss improved from 1.75637 to 1.75562, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f26ee042a90>_Batch25_LR0.001_Epochs25.hdf5\n",
            "70/70 [==============================] - 29s 413ms/step - loss: 1.7556 - accuracy: 0.4389 - val_loss: 1.8079 - val_accuracy: 0.0000e+00\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/25\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 224, 224, 3) for input Tensor(\"input_11:0\", shape=(None, 224, 224, 3), dtype=float32), but it was called on an input with incompatible shape (None, 255, 255, 3).\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 224, 224, 3) for input Tensor(\"input_11:0\", shape=(None, 224, 224, 3), dtype=float32), but it was called on an input with incompatible shape (None, 255, 255, 3).\n",
            " 2/70 [..............................] - ETA: 1:05 - loss: 1.4443 - accuracy: 0.4800WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2469s vs `on_train_batch_end` time: 1.5560s). Check your callbacks.\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4781 - accuracy: 0.4389WARNING:tensorflow:Model was constructed with shape (None, 224, 224, 3) for input Tensor(\"input_11:0\", shape=(None, 224, 224, 3), dtype=float32), but it was called on an input with incompatible shape (None, 255, 255, 3).\n",
            "\n",
            "Epoch 00001: loss improved from inf to 1.47815, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f26f16eb358>_Batch25_LR0.01_Epochs25.hdf5\n",
            "70/70 [==============================] - 31s 442ms/step - loss: 1.4781 - accuracy: 0.4389 - val_loss: 2.0779 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4791 - accuracy: 0.4389\n",
            "Epoch 00002: loss did not improve from 1.47815\n",
            "70/70 [==============================] - 28s 397ms/step - loss: 1.4791 - accuracy: 0.4389 - val_loss: 2.0498 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4757 - accuracy: 0.4389\n",
            "Epoch 00003: loss improved from 1.47815 to 1.47570, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f26f16eb358>_Batch25_LR0.01_Epochs25.hdf5\n",
            "70/70 [==============================] - 29s 411ms/step - loss: 1.4757 - accuracy: 0.4389 - val_loss: 1.9807 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4753 - accuracy: 0.4389\n",
            "Epoch 00004: loss improved from 1.47570 to 1.47532, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f26f16eb358>_Batch25_LR0.01_Epochs25.hdf5\n",
            "70/70 [==============================] - 29s 416ms/step - loss: 1.4753 - accuracy: 0.4389 - val_loss: 1.9118 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4745 - accuracy: 0.4389\n",
            "Epoch 00005: loss improved from 1.47532 to 1.47454, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f26f16eb358>_Batch25_LR0.01_Epochs25.hdf5\n",
            "70/70 [==============================] - 29s 416ms/step - loss: 1.4745 - accuracy: 0.4389 - val_loss: 1.8860 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4722 - accuracy: 0.4389\n",
            "Epoch 00006: loss improved from 1.47454 to 1.47224, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f26f16eb358>_Batch25_LR0.01_Epochs25.hdf5\n",
            "70/70 [==============================] - 29s 412ms/step - loss: 1.4722 - accuracy: 0.4389 - val_loss: 1.8743 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4718 - accuracy: 0.4389\n",
            "Epoch 00007: loss improved from 1.47224 to 1.47176, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f26f16eb358>_Batch25_LR0.01_Epochs25.hdf5\n",
            "70/70 [==============================] - 29s 415ms/step - loss: 1.4718 - accuracy: 0.4389 - val_loss: 1.8584 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4733 - accuracy: 0.4389\n",
            "Epoch 00008: loss did not improve from 1.47176\n",
            "70/70 [==============================] - 28s 395ms/step - loss: 1.4733 - accuracy: 0.4389 - val_loss: 1.8510 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4742 - accuracy: 0.4389\n",
            "Epoch 00009: loss did not improve from 1.47176\n",
            "70/70 [==============================] - 28s 395ms/step - loss: 1.4742 - accuracy: 0.4389 - val_loss: 1.8557 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4725 - accuracy: 0.4389\n",
            "Epoch 00010: loss did not improve from 1.47176\n",
            "70/70 [==============================] - 28s 395ms/step - loss: 1.4725 - accuracy: 0.4389 - val_loss: 1.8457 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4726 - accuracy: 0.4389\n",
            "Epoch 00011: loss did not improve from 1.47176\n",
            "70/70 [==============================] - 28s 395ms/step - loss: 1.4726 - accuracy: 0.4389 - val_loss: 1.8268 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4707 - accuracy: 0.4389\n",
            "Epoch 00012: loss improved from 1.47176 to 1.47075, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f26f16eb358>_Batch25_LR0.01_Epochs25.hdf5\n",
            "70/70 [==============================] - 29s 419ms/step - loss: 1.4707 - accuracy: 0.4389 - val_loss: 1.8077 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4708 - accuracy: 0.4389\n",
            "Epoch 00013: loss did not improve from 1.47075\n",
            "70/70 [==============================] - 28s 395ms/step - loss: 1.4708 - accuracy: 0.4389 - val_loss: 1.7977 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4691 - accuracy: 0.4389\n",
            "Epoch 00014: loss improved from 1.47075 to 1.46909, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f26f16eb358>_Batch25_LR0.01_Epochs25.hdf5\n",
            "70/70 [==============================] - 29s 414ms/step - loss: 1.4691 - accuracy: 0.4389 - val_loss: 1.7992 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4675 - accuracy: 0.4389\n",
            "Epoch 00015: loss improved from 1.46909 to 1.46754, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f26f16eb358>_Batch25_LR0.01_Epochs25.hdf5\n",
            "70/70 [==============================] - 29s 414ms/step - loss: 1.4675 - accuracy: 0.4389 - val_loss: 1.7956 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4680 - accuracy: 0.4389\n",
            "Epoch 00016: loss did not improve from 1.46754\n",
            "70/70 [==============================] - 28s 395ms/step - loss: 1.4680 - accuracy: 0.4389 - val_loss: 1.8397 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4691 - accuracy: 0.4389\n",
            "Epoch 00017: loss did not improve from 1.46754\n",
            "70/70 [==============================] - 28s 394ms/step - loss: 1.4691 - accuracy: 0.4389 - val_loss: 1.8433 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4682 - accuracy: 0.4389\n",
            "Epoch 00018: loss did not improve from 1.46754\n",
            "70/70 [==============================] - 28s 393ms/step - loss: 1.4682 - accuracy: 0.4389 - val_loss: 1.8736 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4687 - accuracy: 0.4389\n",
            "Epoch 00019: loss did not improve from 1.46754\n",
            "70/70 [==============================] - 28s 394ms/step - loss: 1.4687 - accuracy: 0.4389 - val_loss: 1.9636 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4694 - accuracy: 0.4389\n",
            "Epoch 00020: loss did not improve from 1.46754\n",
            "70/70 [==============================] - 28s 393ms/step - loss: 1.4694 - accuracy: 0.4389 - val_loss: 2.0179 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4665 - accuracy: 0.4389\n",
            "Epoch 00021: loss improved from 1.46754 to 1.46646, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f26f16eb358>_Batch25_LR0.01_Epochs25.hdf5\n",
            "70/70 [==============================] - 29s 412ms/step - loss: 1.4665 - accuracy: 0.4389 - val_loss: 2.0246 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4712 - accuracy: 0.4389\n",
            "Epoch 00022: loss did not improve from 1.46646\n",
            "70/70 [==============================] - 28s 394ms/step - loss: 1.4712 - accuracy: 0.4389 - val_loss: 2.0309 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4647 - accuracy: 0.4389\n",
            "Epoch 00023: loss improved from 1.46646 to 1.46467, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f26f16eb358>_Batch25_LR0.01_Epochs25.hdf5\n",
            "70/70 [==============================] - 29s 416ms/step - loss: 1.4647 - accuracy: 0.4389 - val_loss: 2.0309 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4690 - accuracy: 0.4389\n",
            "Epoch 00024: loss did not improve from 1.46467\n",
            "70/70 [==============================] - 28s 395ms/step - loss: 1.4690 - accuracy: 0.4389 - val_loss: 2.0329 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4638 - accuracy: 0.4389\n",
            "Epoch 00025: loss improved from 1.46467 to 1.46378, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f26f16eb358>_Batch25_LR0.01_Epochs25.hdf5\n",
            "70/70 [==============================] - 29s 413ms/step - loss: 1.4638 - accuracy: 0.4389 - val_loss: 2.0335 - val_accuracy: 0.0000e+00\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/25\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 224, 224, 3) for input Tensor(\"input_11:0\", shape=(None, 224, 224, 3), dtype=float32), but it was called on an input with incompatible shape (None, 255, 255, 3).\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 224, 224, 3) for input Tensor(\"input_11:0\", shape=(None, 224, 224, 3), dtype=float32), but it was called on an input with incompatible shape (None, 255, 255, 3).\n",
            " 2/70 [..............................] - ETA: 44s - loss: 1.5366 - accuracy: 0.3800WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2409s vs `on_train_batch_end` time: 1.0191s). Check your callbacks.\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4832 - accuracy: 0.4383WARNING:tensorflow:Model was constructed with shape (None, 224, 224, 3) for input Tensor(\"input_11:0\", shape=(None, 224, 224, 3), dtype=float32), but it was called on an input with incompatible shape (None, 255, 255, 3).\n",
            "\n",
            "Epoch 00001: loss improved from inf to 1.48319, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f26f179afd0>_Batch25_LR0.01_Epochs25.hdf5\n",
            "70/70 [==============================] - 32s 455ms/step - loss: 1.4832 - accuracy: 0.4383 - val_loss: 1.6685 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4756 - accuracy: 0.4389\n",
            "Epoch 00002: loss improved from 1.48319 to 1.47564, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f26f179afd0>_Batch25_LR0.01_Epochs25.hdf5\n",
            "70/70 [==============================] - 31s 439ms/step - loss: 1.4756 - accuracy: 0.4389 - val_loss: 1.9095 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4684 - accuracy: 0.4389\n",
            "Epoch 00003: loss improved from 1.47564 to 1.46843, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f26f179afd0>_Batch25_LR0.01_Epochs25.hdf5\n",
            "70/70 [==============================] - 30s 434ms/step - loss: 1.4684 - accuracy: 0.4389 - val_loss: 1.7727 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4692 - accuracy: 0.4389\n",
            "Epoch 00004: loss did not improve from 1.46843\n",
            "70/70 [==============================] - 29s 408ms/step - loss: 1.4692 - accuracy: 0.4389 - val_loss: 1.9634 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4689 - accuracy: 0.4389\n",
            "Epoch 00005: loss did not improve from 1.46843\n",
            "70/70 [==============================] - 28s 405ms/step - loss: 1.4689 - accuracy: 0.4389 - val_loss: 1.9037 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4666 - accuracy: 0.4389\n",
            "Epoch 00006: loss improved from 1.46843 to 1.46664, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f26f179afd0>_Batch25_LR0.01_Epochs25.hdf5\n",
            "70/70 [==============================] - 31s 439ms/step - loss: 1.4666 - accuracy: 0.4389 - val_loss: 1.9300 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4634 - accuracy: 0.4389\n",
            "Epoch 00007: loss improved from 1.46664 to 1.46345, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f26f179afd0>_Batch25_LR0.01_Epochs25.hdf5\n",
            "70/70 [==============================] - 31s 442ms/step - loss: 1.4634 - accuracy: 0.4389 - val_loss: 1.8722 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4647 - accuracy: 0.4389\n",
            "Epoch 00008: loss did not improve from 1.46345\n",
            "70/70 [==============================] - 28s 407ms/step - loss: 1.4647 - accuracy: 0.4389 - val_loss: 1.9824 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4660 - accuracy: 0.4389\n",
            "Epoch 00009: loss did not improve from 1.46345\n",
            "70/70 [==============================] - 28s 406ms/step - loss: 1.4660 - accuracy: 0.4389 - val_loss: 1.8927 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4655 - accuracy: 0.4389\n",
            "Epoch 00010: loss did not improve from 1.46345\n",
            "70/70 [==============================] - 28s 405ms/step - loss: 1.4655 - accuracy: 0.4389 - val_loss: 1.8570 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4586 - accuracy: 0.4389\n",
            "Epoch 00011: loss improved from 1.46345 to 1.45855, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f26f179afd0>_Batch25_LR0.01_Epochs25.hdf5\n",
            "70/70 [==============================] - 31s 439ms/step - loss: 1.4586 - accuracy: 0.4389 - val_loss: 1.8104 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4643 - accuracy: 0.4389\n",
            "Epoch 00012: loss did not improve from 1.45855\n",
            "70/70 [==============================] - 28s 406ms/step - loss: 1.4643 - accuracy: 0.4389 - val_loss: 1.9860 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4639 - accuracy: 0.4389\n",
            "Epoch 00013: loss did not improve from 1.45855\n",
            "70/70 [==============================] - 28s 407ms/step - loss: 1.4639 - accuracy: 0.4389 - val_loss: 1.8907 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4633 - accuracy: 0.4389\n",
            "Epoch 00014: loss did not improve from 1.45855\n",
            "70/70 [==============================] - 28s 405ms/step - loss: 1.4633 - accuracy: 0.4389 - val_loss: 1.9228 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4617 - accuracy: 0.4389\n",
            "Epoch 00015: loss did not improve from 1.45855\n",
            "70/70 [==============================] - 28s 405ms/step - loss: 1.4617 - accuracy: 0.4389 - val_loss: 1.9377 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4613 - accuracy: 0.4389\n",
            "Epoch 00016: loss did not improve from 1.45855\n",
            "70/70 [==============================] - 28s 405ms/step - loss: 1.4613 - accuracy: 0.4389 - val_loss: 1.9440 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4607 - accuracy: 0.4389\n",
            "Epoch 00017: loss did not improve from 1.45855\n",
            "70/70 [==============================] - 28s 406ms/step - loss: 1.4607 - accuracy: 0.4389 - val_loss: 2.0417 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4605 - accuracy: 0.4389\n",
            "Epoch 00018: loss did not improve from 1.45855\n",
            "70/70 [==============================] - 28s 407ms/step - loss: 1.4605 - accuracy: 0.4389 - val_loss: 1.9912 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4600 - accuracy: 0.4389\n",
            "Epoch 00019: loss did not improve from 1.45855\n",
            "70/70 [==============================] - 28s 407ms/step - loss: 1.4600 - accuracy: 0.4389 - val_loss: 2.0120 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4602 - accuracy: 0.4389\n",
            "Epoch 00020: loss did not improve from 1.45855\n",
            "70/70 [==============================] - 28s 405ms/step - loss: 1.4602 - accuracy: 0.4389 - val_loss: 1.9900 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4597 - accuracy: 0.4389\n",
            "Epoch 00021: loss did not improve from 1.45855\n",
            "70/70 [==============================] - 28s 394ms/step - loss: 1.4597 - accuracy: 0.4389 - val_loss: 1.9978 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4595 - accuracy: 0.4389\n",
            "Epoch 00022: loss did not improve from 1.45855\n",
            "70/70 [==============================] - 27s 393ms/step - loss: 1.4595 - accuracy: 0.4389 - val_loss: 2.0142 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4598 - accuracy: 0.4389\n",
            "Epoch 00023: loss did not improve from 1.45855\n",
            "70/70 [==============================] - 27s 393ms/step - loss: 1.4598 - accuracy: 0.4389 - val_loss: 2.0252 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4598 - accuracy: 0.4389\n",
            "Epoch 00024: loss did not improve from 1.45855\n",
            "70/70 [==============================] - 27s 393ms/step - loss: 1.4598 - accuracy: 0.4389 - val_loss: 2.0318 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4592 - accuracy: 0.4389\n",
            "Epoch 00025: loss did not improve from 1.45855\n",
            "70/70 [==============================] - 28s 393ms/step - loss: 1.4592 - accuracy: 0.4389 - val_loss: 2.0723 - val_accuracy: 0.0000e+00\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/25\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 224, 224, 3) for input Tensor(\"input_11:0\", shape=(None, 224, 224, 3), dtype=float32), but it was called on an input with incompatible shape (None, 255, 255, 3).\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 224, 224, 3) for input Tensor(\"input_11:0\", shape=(None, 224, 224, 3), dtype=float32), but it was called on an input with incompatible shape (None, 255, 255, 3).\n",
            " 2/70 [..............................] - ETA: 1:02 - loss: 1.5984 - accuracy: 0.3600WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1461s vs `on_train_batch_end` time: 1.4668s). Check your callbacks.\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4804 - accuracy: 0.4389WARNING:tensorflow:Model was constructed with shape (None, 224, 224, 3) for input Tensor(\"input_11:0\", shape=(None, 224, 224, 3), dtype=float32), but it was called on an input with incompatible shape (None, 255, 255, 3).\n",
            "\n",
            "Epoch 00001: loss improved from inf to 1.48035, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f26ee5cc9b0>_Batch25_LR0.01_Epochs25.hdf5\n",
            "70/70 [==============================] - 32s 461ms/step - loss: 1.4804 - accuracy: 0.4389 - val_loss: 1.8202 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4713 - accuracy: 0.4389\n",
            "Epoch 00002: loss improved from 1.48035 to 1.47135, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f26ee5cc9b0>_Batch25_LR0.01_Epochs25.hdf5\n",
            "70/70 [==============================] - 31s 446ms/step - loss: 1.4713 - accuracy: 0.4389 - val_loss: 2.2810 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4679 - accuracy: 0.4389\n",
            "Epoch 00003: loss improved from 1.47135 to 1.46788, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f26ee5cc9b0>_Batch25_LR0.01_Epochs25.hdf5\n",
            "70/70 [==============================] - 31s 443ms/step - loss: 1.4679 - accuracy: 0.4389 - val_loss: 2.0540 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4680 - accuracy: 0.4389\n",
            "Epoch 00004: loss did not improve from 1.46788\n",
            "70/70 [==============================] - 28s 401ms/step - loss: 1.4680 - accuracy: 0.4389 - val_loss: 1.9169 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4703 - accuracy: 0.4389\n",
            "Epoch 00005: loss did not improve from 1.46788\n",
            "70/70 [==============================] - 28s 399ms/step - loss: 1.4703 - accuracy: 0.4389 - val_loss: 1.9032 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4710 - accuracy: 0.4389\n",
            "Epoch 00006: loss did not improve from 1.46788\n",
            "70/70 [==============================] - 28s 399ms/step - loss: 1.4710 - accuracy: 0.4389 - val_loss: 1.8220 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4636 - accuracy: 0.4389\n",
            "Epoch 00007: loss improved from 1.46788 to 1.46362, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f26ee5cc9b0>_Batch25_LR0.01_Epochs25.hdf5\n",
            "70/70 [==============================] - 31s 449ms/step - loss: 1.4636 - accuracy: 0.4389 - val_loss: 1.9973 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4668 - accuracy: 0.4389\n",
            "Epoch 00008: loss did not improve from 1.46362\n",
            "70/70 [==============================] - 28s 399ms/step - loss: 1.4668 - accuracy: 0.4389 - val_loss: 1.8884 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4666 - accuracy: 0.4389\n",
            "Epoch 00009: loss did not improve from 1.46362\n",
            "70/70 [==============================] - 28s 399ms/step - loss: 1.4666 - accuracy: 0.4389 - val_loss: 1.8217 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4650 - accuracy: 0.4389\n",
            "Epoch 00010: loss did not improve from 1.46362\n",
            "70/70 [==============================] - 28s 397ms/step - loss: 1.4650 - accuracy: 0.4389 - val_loss: 1.8005 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4683 - accuracy: 0.4389\n",
            "Epoch 00011: loss did not improve from 1.46362\n",
            "70/70 [==============================] - 28s 400ms/step - loss: 1.4683 - accuracy: 0.4389 - val_loss: 1.8714 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4617 - accuracy: 0.4389\n",
            "Epoch 00012: loss improved from 1.46362 to 1.46173, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f26ee5cc9b0>_Batch25_LR0.01_Epochs25.hdf5\n",
            "70/70 [==============================] - 31s 446ms/step - loss: 1.4617 - accuracy: 0.4389 - val_loss: 1.8579 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4637 - accuracy: 0.4389\n",
            "Epoch 00013: loss did not improve from 1.46173\n",
            "70/70 [==============================] - 28s 400ms/step - loss: 1.4637 - accuracy: 0.4389 - val_loss: 1.9328 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4633 - accuracy: 0.4389\n",
            "Epoch 00014: loss did not improve from 1.46173\n",
            "70/70 [==============================] - 28s 400ms/step - loss: 1.4633 - accuracy: 0.4389 - val_loss: 2.1035 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4727 - accuracy: 0.4389\n",
            "Epoch 00015: loss did not improve from 1.46173\n",
            "70/70 [==============================] - 28s 395ms/step - loss: 1.4727 - accuracy: 0.4389 - val_loss: 2.1396 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4660 - accuracy: 0.4389\n",
            "Epoch 00016: loss did not improve from 1.46173\n",
            "70/70 [==============================] - 28s 396ms/step - loss: 1.4660 - accuracy: 0.4389 - val_loss: 1.9677 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4623 - accuracy: 0.4389\n",
            "Epoch 00017: loss did not improve from 1.46173\n",
            "70/70 [==============================] - 28s 395ms/step - loss: 1.4623 - accuracy: 0.4389 - val_loss: 2.0022 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4612 - accuracy: 0.4389\n",
            "Epoch 00018: loss improved from 1.46173 to 1.46118, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f26ee5cc9b0>_Batch25_LR0.01_Epochs25.hdf5\n",
            "70/70 [==============================] - 31s 440ms/step - loss: 1.4612 - accuracy: 0.4389 - val_loss: 1.9663 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4626 - accuracy: 0.4389\n",
            "Epoch 00019: loss did not improve from 1.46118\n",
            "70/70 [==============================] - 28s 396ms/step - loss: 1.4626 - accuracy: 0.4389 - val_loss: 1.9477 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4609 - accuracy: 0.4389\n",
            "Epoch 00020: loss improved from 1.46118 to 1.46089, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f26ee5cc9b0>_Batch25_LR0.01_Epochs25.hdf5\n",
            "70/70 [==============================] - 31s 443ms/step - loss: 1.4609 - accuracy: 0.4389 - val_loss: 1.9210 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4600 - accuracy: 0.4389\n",
            "Epoch 00021: loss improved from 1.46089 to 1.45998, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f26ee5cc9b0>_Batch25_LR0.01_Epochs25.hdf5\n",
            "70/70 [==============================] - 31s 438ms/step - loss: 1.4600 - accuracy: 0.4389 - val_loss: 2.0007 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4606 - accuracy: 0.4389\n",
            "Epoch 00022: loss did not improve from 1.45998\n",
            "70/70 [==============================] - 28s 398ms/step - loss: 1.4606 - accuracy: 0.4389 - val_loss: 1.9903 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4600 - accuracy: 0.4389\n",
            "Epoch 00023: loss did not improve from 1.45998\n",
            "70/70 [==============================] - 28s 394ms/step - loss: 1.4600 - accuracy: 0.4389 - val_loss: 1.9872 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4592 - accuracy: 0.4389\n",
            "Epoch 00024: loss improved from 1.45998 to 1.45917, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f26ee5cc9b0>_Batch25_LR0.01_Epochs25.hdf5\n",
            "70/70 [==============================] - 31s 440ms/step - loss: 1.4592 - accuracy: 0.4389 - val_loss: 2.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4608 - accuracy: 0.4389\n",
            "Epoch 00025: loss did not improve from 1.45917\n",
            "70/70 [==============================] - 28s 396ms/step - loss: 1.4608 - accuracy: 0.4389 - val_loss: 2.0352 - val_accuracy: 0.0000e+00\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/25\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 224, 224, 3) for input Tensor(\"input_11:0\", shape=(None, 224, 224, 3), dtype=float32), but it was called on an input with incompatible shape (None, 255, 255, 3).\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 224, 224, 3) for input Tensor(\"input_11:0\", shape=(None, 224, 224, 3), dtype=float32), but it was called on an input with incompatible shape (None, 255, 255, 3).\n",
            " 2/70 [..............................] - ETA: 56s - loss: 1.4267 - accuracy: 0.4800WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1510s vs `on_train_batch_end` time: 1.3214s). Check your callbacks.\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4767 - accuracy: 0.4389WARNING:tensorflow:Model was constructed with shape (None, 224, 224, 3) for input Tensor(\"input_11:0\", shape=(None, 224, 224, 3), dtype=float32), but it was called on an input with incompatible shape (None, 255, 255, 3).\n",
            "\n",
            "Epoch 00001: loss improved from inf to 1.47670, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f26eb9ae8d0>_Batch25_LR0.01_Epochs25.hdf5\n",
            "70/70 [==============================] - 31s 448ms/step - loss: 1.4767 - accuracy: 0.4389 - val_loss: 2.0871 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4770 - accuracy: 0.4389\n",
            "Epoch 00002: loss did not improve from 1.47670\n",
            "70/70 [==============================] - 28s 399ms/step - loss: 1.4770 - accuracy: 0.4389 - val_loss: 2.0119 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4712 - accuracy: 0.4389\n",
            "Epoch 00003: loss improved from 1.47670 to 1.47119, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f26eb9ae8d0>_Batch25_LR0.01_Epochs25.hdf5\n",
            "70/70 [==============================] - 30s 432ms/step - loss: 1.4712 - accuracy: 0.4389 - val_loss: 1.9381 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4713 - accuracy: 0.4389\n",
            "Epoch 00004: loss did not improve from 1.47119\n",
            "70/70 [==============================] - 28s 402ms/step - loss: 1.4713 - accuracy: 0.4389 - val_loss: 1.8826 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4719 - accuracy: 0.4389\n",
            "Epoch 00005: loss did not improve from 1.47119\n",
            "70/70 [==============================] - 28s 400ms/step - loss: 1.4719 - accuracy: 0.4389 - val_loss: 1.8589 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4673 - accuracy: 0.4389\n",
            "Epoch 00006: loss improved from 1.47119 to 1.46729, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f26eb9ae8d0>_Batch25_LR0.01_Epochs25.hdf5\n",
            "70/70 [==============================] - 30s 431ms/step - loss: 1.4673 - accuracy: 0.4389 - val_loss: 1.8443 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4708 - accuracy: 0.4389\n",
            "Epoch 00007: loss did not improve from 1.46729\n",
            "70/70 [==============================] - 28s 400ms/step - loss: 1.4708 - accuracy: 0.4389 - val_loss: 1.8391 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4677 - accuracy: 0.4389\n",
            "Epoch 00008: loss did not improve from 1.46729\n",
            "70/70 [==============================] - 28s 400ms/step - loss: 1.4677 - accuracy: 0.4389 - val_loss: 1.8372 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4712 - accuracy: 0.4389\n",
            "Epoch 00009: loss did not improve from 1.46729\n",
            "70/70 [==============================] - 28s 399ms/step - loss: 1.4712 - accuracy: 0.4389 - val_loss: 1.8303 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4651 - accuracy: 0.4389\n",
            "Epoch 00010: loss improved from 1.46729 to 1.46513, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f26eb9ae8d0>_Batch25_LR0.01_Epochs25.hdf5\n",
            "70/70 [==============================] - 30s 433ms/step - loss: 1.4651 - accuracy: 0.4389 - val_loss: 1.8259 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4699 - accuracy: 0.4389\n",
            "Epoch 00011: loss did not improve from 1.46513\n",
            "70/70 [==============================] - 28s 401ms/step - loss: 1.4699 - accuracy: 0.4389 - val_loss: 1.8154 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4699 - accuracy: 0.4389\n",
            "Epoch 00012: loss did not improve from 1.46513\n",
            "70/70 [==============================] - 28s 399ms/step - loss: 1.4699 - accuracy: 0.4389 - val_loss: 1.7925 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4693 - accuracy: 0.4389\n",
            "Epoch 00013: loss did not improve from 1.46513\n",
            "70/70 [==============================] - 28s 400ms/step - loss: 1.4693 - accuracy: 0.4389 - val_loss: 1.7877 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4650 - accuracy: 0.4389\n",
            "Epoch 00014: loss improved from 1.46513 to 1.46498, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f26eb9ae8d0>_Batch25_LR0.01_Epochs25.hdf5\n",
            "70/70 [==============================] - 30s 433ms/step - loss: 1.4650 - accuracy: 0.4389 - val_loss: 1.7839 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4627 - accuracy: 0.4389\n",
            "Epoch 00015: loss improved from 1.46498 to 1.46269, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f26eb9ae8d0>_Batch25_LR0.01_Epochs25.hdf5\n",
            "70/70 [==============================] - 30s 434ms/step - loss: 1.4627 - accuracy: 0.4389 - val_loss: 1.7875 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4651 - accuracy: 0.4389\n",
            "Epoch 00016: loss did not improve from 1.46269\n",
            "70/70 [==============================] - 28s 399ms/step - loss: 1.4651 - accuracy: 0.4389 - val_loss: 1.8380 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4654 - accuracy: 0.4389\n",
            "Epoch 00017: loss did not improve from 1.46269\n",
            "70/70 [==============================] - 28s 400ms/step - loss: 1.4654 - accuracy: 0.4389 - val_loss: 1.8490 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4643 - accuracy: 0.4389\n",
            "Epoch 00018: loss did not improve from 1.46269\n",
            "70/70 [==============================] - 28s 400ms/step - loss: 1.4643 - accuracy: 0.4389 - val_loss: 1.8739 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4689 - accuracy: 0.4389\n",
            "Epoch 00019: loss did not improve from 1.46269\n",
            "70/70 [==============================] - 28s 397ms/step - loss: 1.4689 - accuracy: 0.4389 - val_loss: 1.9804 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4656 - accuracy: 0.4389\n",
            "Epoch 00020: loss did not improve from 1.46269\n",
            "70/70 [==============================] - 28s 399ms/step - loss: 1.4656 - accuracy: 0.4389 - val_loss: 2.0145 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4690 - accuracy: 0.4389\n",
            "Epoch 00021: loss did not improve from 1.46269\n",
            "70/70 [==============================] - 28s 400ms/step - loss: 1.4690 - accuracy: 0.4389 - val_loss: 2.0269 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4640 - accuracy: 0.4389\n",
            "Epoch 00022: loss did not improve from 1.46269\n",
            "70/70 [==============================] - 28s 400ms/step - loss: 1.4640 - accuracy: 0.4389 - val_loss: 2.0273 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4686 - accuracy: 0.4389\n",
            "Epoch 00023: loss did not improve from 1.46269\n",
            "70/70 [==============================] - 28s 400ms/step - loss: 1.4686 - accuracy: 0.4389 - val_loss: 2.0278 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4656 - accuracy: 0.4389\n",
            "Epoch 00024: loss did not improve from 1.46269\n",
            "70/70 [==============================] - 28s 401ms/step - loss: 1.4656 - accuracy: 0.4389 - val_loss: 2.0255 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4645 - accuracy: 0.4389\n",
            "Epoch 00025: loss did not improve from 1.46269\n",
            "70/70 [==============================] - 28s 399ms/step - loss: 1.4645 - accuracy: 0.4389 - val_loss: 2.0334 - val_accuracy: 0.0000e+00\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/25\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 224, 224, 3) for input Tensor(\"input_11:0\", shape=(None, 224, 224, 3), dtype=float32), but it was called on an input with incompatible shape (None, 255, 255, 3).\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 224, 224, 3) for input Tensor(\"input_11:0\", shape=(None, 224, 224, 3), dtype=float32), but it was called on an input with incompatible shape (None, 255, 255, 3).\n",
            " 2/70 [..............................] - ETA: 45s - loss: 1.4861 - accuracy: 0.4000WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1843s vs `on_train_batch_end` time: 1.0161s). Check your callbacks.\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4739 - accuracy: 0.4389WARNING:tensorflow:Model was constructed with shape (None, 224, 224, 3) for input Tensor(\"input_11:0\", shape=(None, 224, 224, 3), dtype=float32), but it was called on an input with incompatible shape (None, 255, 255, 3).\n",
            "\n",
            "Epoch 00001: loss improved from inf to 1.47389, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f26efd8ec18>_Batch25_LR0.01_Epochs25.hdf5\n",
            "70/70 [==============================] - 32s 459ms/step - loss: 1.4739 - accuracy: 0.4389 - val_loss: 1.9343 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4659 - accuracy: 0.4389\n",
            "Epoch 00002: loss improved from 1.47389 to 1.46589, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f26efd8ec18>_Batch25_LR0.01_Epochs25.hdf5\n",
            "70/70 [==============================] - 30s 434ms/step - loss: 1.4659 - accuracy: 0.4389 - val_loss: 1.9765 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4719 - accuracy: 0.4389\n",
            "Epoch 00003: loss did not improve from 1.46589\n",
            "70/70 [==============================] - 28s 400ms/step - loss: 1.4719 - accuracy: 0.4389 - val_loss: 2.0723 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4642 - accuracy: 0.4389\n",
            "Epoch 00004: loss improved from 1.46589 to 1.46425, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f26efd8ec18>_Batch25_LR0.01_Epochs25.hdf5\n",
            "70/70 [==============================] - 30s 430ms/step - loss: 1.4642 - accuracy: 0.4389 - val_loss: 1.9368 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4656 - accuracy: 0.4389\n",
            "Epoch 00005: loss did not improve from 1.46425\n",
            "70/70 [==============================] - 28s 401ms/step - loss: 1.4656 - accuracy: 0.4389 - val_loss: 1.8691 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4631 - accuracy: 0.4389\n",
            "Epoch 00006: loss improved from 1.46425 to 1.46308, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f26efd8ec18>_Batch25_LR0.01_Epochs25.hdf5\n",
            "70/70 [==============================] - 30s 434ms/step - loss: 1.4631 - accuracy: 0.4389 - val_loss: 1.8219 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4617 - accuracy: 0.4389\n",
            "Epoch 00007: loss improved from 1.46308 to 1.46168, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f26efd8ec18>_Batch25_LR0.01_Epochs25.hdf5\n",
            "70/70 [==============================] - 31s 438ms/step - loss: 1.4617 - accuracy: 0.4389 - val_loss: 1.9098 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4678 - accuracy: 0.4389\n",
            "Epoch 00008: loss did not improve from 1.46168\n",
            "70/70 [==============================] - 28s 402ms/step - loss: 1.4678 - accuracy: 0.4389 - val_loss: 1.8584 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4630 - accuracy: 0.4389\n",
            "Epoch 00009: loss did not improve from 1.46168\n",
            "70/70 [==============================] - 28s 401ms/step - loss: 1.4630 - accuracy: 0.4389 - val_loss: 1.9517 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4670 - accuracy: 0.4389\n",
            "Epoch 00010: loss did not improve from 1.46168\n",
            "70/70 [==============================] - 28s 401ms/step - loss: 1.4670 - accuracy: 0.4389 - val_loss: 1.8154 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4634 - accuracy: 0.4389\n",
            "Epoch 00011: loss did not improve from 1.46168\n",
            "70/70 [==============================] - 28s 402ms/step - loss: 1.4634 - accuracy: 0.4389 - val_loss: 1.8383 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4657 - accuracy: 0.4389\n",
            "Epoch 00012: loss did not improve from 1.46168\n",
            "70/70 [==============================] - 28s 401ms/step - loss: 1.4657 - accuracy: 0.4389 - val_loss: 1.8447 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4648 - accuracy: 0.4389\n",
            "Epoch 00013: loss did not improve from 1.46168\n",
            "70/70 [==============================] - 28s 401ms/step - loss: 1.4648 - accuracy: 0.4389 - val_loss: 1.7604 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4637 - accuracy: 0.4389\n",
            "Epoch 00014: loss did not improve from 1.46168\n",
            "70/70 [==============================] - 28s 401ms/step - loss: 1.4637 - accuracy: 0.4389 - val_loss: 1.7812 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4658 - accuracy: 0.4389\n",
            "Epoch 00015: loss did not improve from 1.46168\n",
            "70/70 [==============================] - 28s 400ms/step - loss: 1.4658 - accuracy: 0.4389 - val_loss: 1.7804 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4616 - accuracy: 0.4389\n",
            "Epoch 00016: loss improved from 1.46168 to 1.46156, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f26efd8ec18>_Batch25_LR0.01_Epochs25.hdf5\n",
            "70/70 [==============================] - 30s 430ms/step - loss: 1.4616 - accuracy: 0.4389 - val_loss: 1.9007 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4658 - accuracy: 0.4389\n",
            "Epoch 00017: loss did not improve from 1.46156\n",
            "70/70 [==============================] - 28s 402ms/step - loss: 1.4658 - accuracy: 0.4389 - val_loss: 1.8472 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4623 - accuracy: 0.4389\n",
            "Epoch 00018: loss did not improve from 1.46156\n",
            "70/70 [==============================] - 28s 402ms/step - loss: 1.4623 - accuracy: 0.4389 - val_loss: 1.9174 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4649 - accuracy: 0.4389\n",
            "Epoch 00019: loss did not improve from 1.46156\n",
            "70/70 [==============================] - 28s 401ms/step - loss: 1.4649 - accuracy: 0.4389 - val_loss: 1.9494 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4659 - accuracy: 0.4389\n",
            "Epoch 00020: loss did not improve from 1.46156\n",
            "70/70 [==============================] - 28s 402ms/step - loss: 1.4659 - accuracy: 0.4389 - val_loss: 2.0829 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4633 - accuracy: 0.4389\n",
            "Epoch 00021: loss did not improve from 1.46156\n",
            "70/70 [==============================] - 28s 403ms/step - loss: 1.4633 - accuracy: 0.4389 - val_loss: 2.0331 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4662 - accuracy: 0.4389\n",
            "Epoch 00022: loss did not improve from 1.46156\n",
            "70/70 [==============================] - 28s 400ms/step - loss: 1.4662 - accuracy: 0.4389 - val_loss: 1.8817 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4617 - accuracy: 0.4389\n",
            "Epoch 00023: loss did not improve from 1.46156\n",
            "70/70 [==============================] - 28s 401ms/step - loss: 1.4617 - accuracy: 0.4389 - val_loss: 1.9964 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4626 - accuracy: 0.4389\n",
            "Epoch 00024: loss did not improve from 1.46156\n",
            "70/70 [==============================] - 28s 402ms/step - loss: 1.4626 - accuracy: 0.4389 - val_loss: 1.9730 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4617 - accuracy: 0.4389\n",
            "Epoch 00025: loss did not improve from 1.46156\n",
            "70/70 [==============================] - 28s 401ms/step - loss: 1.4617 - accuracy: 0.4389 - val_loss: 2.0541 - val_accuracy: 0.0000e+00\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/25\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 224, 224, 3) for input Tensor(\"input_11:0\", shape=(None, 224, 224, 3), dtype=float32), but it was called on an input with incompatible shape (None, 255, 255, 3).\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 224, 224, 3) for input Tensor(\"input_11:0\", shape=(None, 224, 224, 3), dtype=float32), but it was called on an input with incompatible shape (None, 255, 255, 3).\n",
            " 2/70 [..............................] - ETA: 37s - loss: 1.6112 - accuracy: 0.4000WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1761s vs `on_train_batch_end` time: 0.7777s). Check your callbacks.\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.7507 - accuracy: 0.4337WARNING:tensorflow:Model was constructed with shape (None, 224, 224, 3) for input Tensor(\"input_11:0\", shape=(None, 224, 224, 3), dtype=float32), but it was called on an input with incompatible shape (None, 255, 255, 3).\n",
            "\n",
            "Epoch 00001: loss improved from inf to 1.75074, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f26e7f7c588>_Batch25_LR0.01_Epochs25.hdf5\n",
            "70/70 [==============================] - 30s 435ms/step - loss: 1.7507 - accuracy: 0.4337 - val_loss: 1.8179 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.7187 - accuracy: 0.4389\n",
            "Epoch 00002: loss improved from 1.75074 to 1.71868, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f26e7f7c588>_Batch25_LR0.01_Epochs25.hdf5\n",
            "70/70 [==============================] - 29s 416ms/step - loss: 1.7187 - accuracy: 0.4389 - val_loss: 1.8330 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.6963 - accuracy: 0.4389\n",
            "Epoch 00003: loss improved from 1.71868 to 1.69630, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f26e7f7c588>_Batch25_LR0.01_Epochs25.hdf5\n",
            "70/70 [==============================] - 41s 583ms/step - loss: 1.6963 - accuracy: 0.4389 - val_loss: 1.8447 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.6793 - accuracy: 0.4389\n",
            "Epoch 00004: loss improved from 1.69630 to 1.67931, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f26e7f7c588>_Batch25_LR0.01_Epochs25.hdf5\n",
            "70/70 [==============================] - 29s 413ms/step - loss: 1.6793 - accuracy: 0.4389 - val_loss: 1.8547 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.6650 - accuracy: 0.4389\n",
            "Epoch 00005: loss improved from 1.67931 to 1.66504, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f26e7f7c588>_Batch25_LR0.01_Epochs25.hdf5\n",
            "70/70 [==============================] - 29s 417ms/step - loss: 1.6650 - accuracy: 0.4389 - val_loss: 1.8644 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.6518 - accuracy: 0.4389\n",
            "Epoch 00006: loss improved from 1.66504 to 1.65175, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f26e7f7c588>_Batch25_LR0.01_Epochs25.hdf5\n",
            "70/70 [==============================] - 29s 412ms/step - loss: 1.6518 - accuracy: 0.4389 - val_loss: 1.8750 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.6370 - accuracy: 0.4389\n",
            "Epoch 00007: loss improved from 1.65175 to 1.63702, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f26e7f7c588>_Batch25_LR0.01_Epochs25.hdf5\n",
            "70/70 [==============================] - 29s 413ms/step - loss: 1.6370 - accuracy: 0.4389 - val_loss: 1.8892 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.6184 - accuracy: 0.4389\n",
            "Epoch 00008: loss improved from 1.63702 to 1.61844, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f26e7f7c588>_Batch25_LR0.01_Epochs25.hdf5\n",
            "70/70 [==============================] - 29s 415ms/step - loss: 1.6184 - accuracy: 0.4389 - val_loss: 1.9101 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.5946 - accuracy: 0.4389\n",
            "Epoch 00009: loss improved from 1.61844 to 1.59459, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f26e7f7c588>_Batch25_LR0.01_Epochs25.hdf5\n",
            "70/70 [==============================] - 29s 413ms/step - loss: 1.5946 - accuracy: 0.4389 - val_loss: 1.9420 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.5686 - accuracy: 0.4389\n",
            "Epoch 00010: loss improved from 1.59459 to 1.56859, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f26e7f7c588>_Batch25_LR0.01_Epochs25.hdf5\n",
            "70/70 [==============================] - 29s 416ms/step - loss: 1.5686 - accuracy: 0.4389 - val_loss: 1.9838 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.5434 - accuracy: 0.4389\n",
            "Epoch 00011: loss improved from 1.56859 to 1.54338, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f26e7f7c588>_Batch25_LR0.01_Epochs25.hdf5\n",
            "70/70 [==============================] - 29s 416ms/step - loss: 1.5434 - accuracy: 0.4389 - val_loss: 2.0283 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.5279 - accuracy: 0.4389\n",
            "Epoch 00012: loss improved from 1.54338 to 1.52789, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f26e7f7c588>_Batch25_LR0.01_Epochs25.hdf5\n",
            "70/70 [==============================] - 29s 413ms/step - loss: 1.5279 - accuracy: 0.4389 - val_loss: 2.0615 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.5163 - accuracy: 0.4389\n",
            "Epoch 00013: loss improved from 1.52789 to 1.51632, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f26e7f7c588>_Batch25_LR0.01_Epochs25.hdf5\n",
            "70/70 [==============================] - 33s 475ms/step - loss: 1.5163 - accuracy: 0.4389 - val_loss: 2.0774 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.5092 - accuracy: 0.4389\n",
            "Epoch 00014: loss improved from 1.51632 to 1.50924, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f26e7f7c588>_Batch25_LR0.01_Epochs25.hdf5\n",
            "70/70 [==============================] - 29s 412ms/step - loss: 1.5092 - accuracy: 0.4389 - val_loss: 2.0921 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.5015 - accuracy: 0.4389\n",
            "Epoch 00015: loss improved from 1.50924 to 1.50154, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f26e7f7c588>_Batch25_LR0.01_Epochs25.hdf5\n",
            "70/70 [==============================] - 29s 415ms/step - loss: 1.5015 - accuracy: 0.4389 - val_loss: 2.0985 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4982 - accuracy: 0.4389\n",
            "Epoch 00016: loss improved from 1.50154 to 1.49816, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f26e7f7c588>_Batch25_LR0.01_Epochs25.hdf5\n",
            "70/70 [==============================] - 29s 412ms/step - loss: 1.4982 - accuracy: 0.4389 - val_loss: 2.0939 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4927 - accuracy: 0.4389\n",
            "Epoch 00017: loss improved from 1.49816 to 1.49271, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f26e7f7c588>_Batch25_LR0.01_Epochs25.hdf5\n",
            "70/70 [==============================] - 29s 417ms/step - loss: 1.4927 - accuracy: 0.4389 - val_loss: 2.0885 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4899 - accuracy: 0.4389\n",
            "Epoch 00018: loss improved from 1.49271 to 1.48993, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f26e7f7c588>_Batch25_LR0.01_Epochs25.hdf5\n",
            "70/70 [==============================] - 29s 415ms/step - loss: 1.4899 - accuracy: 0.4389 - val_loss: 2.0806 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4858 - accuracy: 0.4389\n",
            "Epoch 00019: loss improved from 1.48993 to 1.48577, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f26e7f7c588>_Batch25_LR0.01_Epochs25.hdf5\n",
            "70/70 [==============================] - 29s 415ms/step - loss: 1.4858 - accuracy: 0.4389 - val_loss: 2.0800 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4847 - accuracy: 0.4389\n",
            "Epoch 00020: loss improved from 1.48577 to 1.48469, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f26e7f7c588>_Batch25_LR0.01_Epochs25.hdf5\n",
            "70/70 [==============================] - 29s 414ms/step - loss: 1.4847 - accuracy: 0.4389 - val_loss: 2.0764 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4797 - accuracy: 0.4389\n",
            "Epoch 00021: loss improved from 1.48469 to 1.47968, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f26e7f7c588>_Batch25_LR0.01_Epochs25.hdf5\n",
            "70/70 [==============================] - 29s 413ms/step - loss: 1.4797 - accuracy: 0.4389 - val_loss: 2.0707 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4808 - accuracy: 0.4389\n",
            "Epoch 00022: loss did not improve from 1.47968\n",
            "70/70 [==============================] - 27s 382ms/step - loss: 1.4808 - accuracy: 0.4389 - val_loss: 2.0625 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4792 - accuracy: 0.4389\n",
            "Epoch 00023: loss improved from 1.47968 to 1.47922, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f26e7f7c588>_Batch25_LR0.01_Epochs25.hdf5\n",
            "70/70 [==============================] - 29s 416ms/step - loss: 1.4792 - accuracy: 0.4389 - val_loss: 2.0563 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4760 - accuracy: 0.4389\n",
            "Epoch 00024: loss improved from 1.47922 to 1.47603, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f26e7f7c588>_Batch25_LR0.01_Epochs25.hdf5\n",
            "70/70 [==============================] - 32s 454ms/step - loss: 1.4760 - accuracy: 0.4389 - val_loss: 2.0553 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4750 - accuracy: 0.4389\n",
            "Epoch 00025: loss improved from 1.47603 to 1.47503, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f26e7f7c588>_Batch25_LR0.01_Epochs25.hdf5\n",
            "70/70 [==============================] - 29s 415ms/step - loss: 1.4750 - accuracy: 0.4389 - val_loss: 2.0491 - val_accuracy: 0.0000e+00\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/25\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 224, 224, 3) for input Tensor(\"input_11:0\", shape=(None, 224, 224, 3), dtype=float32), but it was called on an input with incompatible shape (None, 255, 255, 3).\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 224, 224, 3) for input Tensor(\"input_11:0\", shape=(None, 224, 224, 3), dtype=float32), but it was called on an input with incompatible shape (None, 255, 255, 3).\n",
            " 2/70 [..............................] - ETA: 35s - loss: 1.3613 - accuracy: 0.5200WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1499s vs `on_train_batch_end` time: 0.6737s). Check your callbacks.\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4768 - accuracy: 0.4389WARNING:tensorflow:Model was constructed with shape (None, 224, 224, 3) for input Tensor(\"input_11:0\", shape=(None, 224, 224, 3), dtype=float32), but it was called on an input with incompatible shape (None, 255, 255, 3).\n",
            "\n",
            "Epoch 00001: loss improved from inf to 1.47684, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f26e1149ba8>_Batch25_LR0.1_Epochs25.hdf5\n",
            "70/70 [==============================] - 30s 431ms/step - loss: 1.4768 - accuracy: 0.4389 - val_loss: 2.0754 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4711 - accuracy: 0.4389\n",
            "Epoch 00002: loss improved from 1.47684 to 1.47107, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f26e1149ba8>_Batch25_LR0.1_Epochs25.hdf5\n",
            "70/70 [==============================] - 29s 413ms/step - loss: 1.4711 - accuracy: 0.4389 - val_loss: 1.9687 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4746 - accuracy: 0.4389\n",
            "Epoch 00003: loss did not improve from 1.47107\n",
            "70/70 [==============================] - 28s 400ms/step - loss: 1.4746 - accuracy: 0.4389 - val_loss: 1.8870 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4714 - accuracy: 0.4389\n",
            "Epoch 00004: loss did not improve from 1.47107\n",
            "70/70 [==============================] - 28s 400ms/step - loss: 1.4714 - accuracy: 0.4389 - val_loss: 1.7914 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4730 - accuracy: 0.4389\n",
            "Epoch 00005: loss did not improve from 1.47107\n",
            "70/70 [==============================] - 28s 400ms/step - loss: 1.4730 - accuracy: 0.4389 - val_loss: 1.8448 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4704 - accuracy: 0.4389\n",
            "Epoch 00006: loss improved from 1.47107 to 1.47042, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f26e1149ba8>_Batch25_LR0.1_Epochs25.hdf5\n",
            "70/70 [==============================] - 29s 410ms/step - loss: 1.4704 - accuracy: 0.4389 - val_loss: 1.8226 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4683 - accuracy: 0.4389\n",
            "Epoch 00007: loss improved from 1.47042 to 1.46830, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f26e1149ba8>_Batch25_LR0.1_Epochs25.hdf5\n",
            "70/70 [==============================] - 29s 409ms/step - loss: 1.4683 - accuracy: 0.4389 - val_loss: 1.8041 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4662 - accuracy: 0.4389\n",
            "Epoch 00008: loss improved from 1.46830 to 1.46622, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f26e1149ba8>_Batch25_LR0.1_Epochs25.hdf5\n",
            "70/70 [==============================] - 29s 412ms/step - loss: 1.4662 - accuracy: 0.4389 - val_loss: 1.8415 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4676 - accuracy: 0.4389\n",
            "Epoch 00009: loss did not improve from 1.46622\n",
            "70/70 [==============================] - 28s 397ms/step - loss: 1.4676 - accuracy: 0.4389 - val_loss: 1.8203 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4676 - accuracy: 0.4389\n",
            "Epoch 00010: loss did not improve from 1.46622\n",
            "70/70 [==============================] - 28s 402ms/step - loss: 1.4676 - accuracy: 0.4389 - val_loss: 1.8078 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4660 - accuracy: 0.4389\n",
            "Epoch 00011: loss improved from 1.46622 to 1.46601, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f26e1149ba8>_Batch25_LR0.1_Epochs25.hdf5\n",
            "70/70 [==============================] - 29s 410ms/step - loss: 1.4660 - accuracy: 0.4389 - val_loss: 1.8384 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4663 - accuracy: 0.4389\n",
            "Epoch 00012: loss did not improve from 1.46601\n",
            "70/70 [==============================] - 28s 398ms/step - loss: 1.4663 - accuracy: 0.4389 - val_loss: 1.7780 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4713 - accuracy: 0.4389\n",
            "Epoch 00013: loss did not improve from 1.46601\n",
            "70/70 [==============================] - 28s 399ms/step - loss: 1.4713 - accuracy: 0.4389 - val_loss: 1.6843 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4664 - accuracy: 0.4389\n",
            "Epoch 00014: loss did not improve from 1.46601\n",
            "70/70 [==============================] - 28s 397ms/step - loss: 1.4664 - accuracy: 0.4389 - val_loss: 1.7731 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4679 - accuracy: 0.4389\n",
            "Epoch 00015: loss did not improve from 1.46601\n",
            "70/70 [==============================] - 28s 397ms/step - loss: 1.4679 - accuracy: 0.4389 - val_loss: 1.8061 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4679 - accuracy: 0.4389\n",
            "Epoch 00016: loss did not improve from 1.46601\n",
            "70/70 [==============================] - 28s 398ms/step - loss: 1.4679 - accuracy: 0.4389 - val_loss: 1.8540 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/25\n",
            "70/70 [==============================] - ETA: 0s - loss: 1.4696 - accuracy: 0.4389\n",
            "Epoch 00017: loss did not improve from 1.46601\n",
            "70/70 [==============================] - 28s 401ms/step - loss: 1.4696 - accuracy: 0.4389 - val_loss: 1.8925 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/25\n",
            "15/70 [=====>........................] - ETA: 18s - loss: 1.4616 - accuracy: 0.4480"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-69e2e7e31395>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransfer_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm_x_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm_y_train\u001b[0m\u001b[0;34m,\u001b[0m                                       \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m                                       \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m                                       \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtensorboard_callback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0;31m# Saving themodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0mtransfer_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mnameof_intermediarymodel\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'resnetforsp500'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1101\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1103\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1104\u001b[0m         \u001b[0mepoch_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    438\u001b[0m     \"\"\"\n\u001b[1;32m    439\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    287\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unrecognized hook: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    307\u001b[0m       \u001b[0mbatch_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 309\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    340\u001b[0m       \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_supports_tf_logs'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m         \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    343\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnumpy_logs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Only convert once.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    959\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    960\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 961\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    962\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1014\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m       \u001b[0;31m# Only block async when verbose = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1016\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1017\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1018\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36mto_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    535\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 537\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 635\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    637\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 635\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    637\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    531\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 533\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    534\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1061\u001b[0m     \"\"\"\n\u001b[1;32m   1062\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1063\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1064\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1065\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1027\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1029\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1030\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cpCe5TSmDvjN"
      },
      "source": [
        "%tensorboard --logdir logs/fit"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3CXqx0rffsEz",
        "outputId": "f7f916b7-daa2-43bc-bb9e-fd19fd5f3de2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import json\n",
        "\n",
        "# as requested in comment\n",
        "with open('result_training.txt', 'w') as file:\n",
        "     file.write(json.dumps(Tabres)) # use `json.loads` to do the reverse"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WB-Z7YvbEFvB"
      },
      "source": [
        "%cd /content/drive/My Drive/A_transfertTFM\n",
        "ls -l model/\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v33y2bzsENXA"
      },
      "source": [
        "%cp model/best_modelcategorical_crossentropy_Adam_Batch64_LR0.001_0.9.hdf5  /content/DL_Tools_For_Finance/model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H6eFmzP24-vc"
      },
      "source": [
        "###Version with vgg16"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQNbUuu_ofxC",
        "outputId": "3941d1bd-a066-440b-f95a-155383bd8ab1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        }
      },
      "source": [
        "%cd /content/drive/My Drive/A_transfertTFMVggSP500\n",
        "\n",
        "'''\n",
        "PART 3 VGGSP500 TRAINING AND SAVING\n",
        "we suppose that we have loaded xtrain and ytrain\n",
        "This part is based on the Design of the NN\n",
        "Her we find the Vgg16 quite usefull\n",
        "'''\n",
        "\n",
        "#In our example we need to y into categorical as it has 6 categories\n",
        "nb_classes=6\n",
        "y_train = np_utils.to_categorical(y_train, nb_classes)\n",
        "\n",
        "\n",
        "#Loading the VGG16 model with pre-trained ImageNet weights\n",
        "vgg_model = VGG16(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n",
        "vgg_model.trainable = False # remove if you want to retrain vgg weights\n",
        "\n",
        "vgg_model.summary()\n",
        "\n",
        "\n",
        "##Transfert model from vgg\n",
        "transfer_model = Sequential()\n",
        "transfer_model.add(vgg_model)\n",
        "transfer_model.add(Flatten())\n",
        "transfer_model.add(Dense(128, activation='relu'))\n",
        "transfer_model.add(Dropout(0.2))\n",
        "transfer_model.add(Dense(6, activation='softmax'))\n",
        "\n",
        "\n",
        "\n",
        "transfer_model.compile(loss=vggsp500loss, optimizer=vggsp500optimizer,\n",
        "              metrics=vggsp500metrics)\n",
        "\n",
        "#Save initial weight to reinitialize it after when we trying to find the best set of parameters\n",
        "transfer_model.save_weights('model/initial_weights.h5')\n",
        "#model.load_weights('my_model_weights.h5'\n",
        "\n",
        "##Saving the best model for each parameters\n",
        "checkpoint = ModelCheckpoint(\"model/best_model\"+vggsp500loss+\"_\"+vggsp500optimizer_name+\"_Batch\"+\\\n",
        "                             str(batch_size)+\"_LR\"+str(vggsp500_learning_rate)+\"_\"+str(vggsp500_decay_rate)+\".hdf5\", \\\n",
        "                                monitor='loss', verbose=1, \\\n",
        "                                save_best_only=True, mode='auto', period=1)\n",
        "\n",
        "# Load the TensorBoard notebook extension.\n",
        "%load_ext tensorboard\n",
        "#!rm -rf ./logs/ \n",
        "\n",
        " # Define the Keras TensorBoard callback.\n",
        "logdir=\"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir, histogram_freq=1)\n",
        "\n",
        "##Fitting the model on the train data and labels.\n",
        "#reinitialise xtrain, ytrain to avoid change of type from np.array to tensor by keras\n",
        "m_x_train=x_train\n",
        "m_y_train=y_train\n",
        "\n",
        "history = transfer_model.fit(m_x_train, m_y_train, \\\n",
        "                              batch_size=batch_size, epochs=epochs, \\\n",
        "                              validation_split=0.2, verbose=1, shuffle=True, \\\n",
        "                              callbacks=[checkpoint, tensorboard_callback])\n",
        "\n",
        "# Saving themodel\n",
        "transfer_model.save('model/vggforsp500.h5')\n",
        "\n",
        "#Display the graph of the model\n",
        "tf.keras.utils.plot_model(transfer_model)\n",
        "\n",
        "##Display summary of neural network\n",
        "transfer_model.summary()\n",
        "\n",
        "#Display Tensorboard\n",
        "%tensorboard --logdir logs"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: '/content/drive/My Drive/A_transfertTFMVggSP500'\n",
            "/content/drive/My Drive/A_transfertTFM\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-fc4a051994b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m#Importing the VGG16 model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVGG16\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mVGG16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess_input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mResNet50\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keras.VGG16'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FiDWq98sOAb-",
        "outputId": "8dd22b9f-623a-4064-a28d-32540227c049",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%load_ext tensorboard"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The tensorboard extension is already loaded. To reload it, use:\n",
            "  %reload_ext tensorboard\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pJfc1EgdOIn8"
      },
      "source": [
        "#here you have with the logs in drive link where you can launch tensorboard and see the training process\n",
        "%cd /content/drive/My Drive/A_transfertTFMVggSP500\n",
        "%tensorboard --logdir logs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n4hYLydW_XH2"
      },
      "source": [
        "history.history['loss']\n",
        "history.history"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SgkpclptyV7A"
      },
      "source": [
        "**IN CASE OF ERROR OF SHAPE OF INPUT**\n",
        "\n",
        "please note that if some error in shape of the input you have to execute the loading datas once again\n",
        "there is a update of type between tensor and np.array of y_train and x_train\n",
        "\n",
        "Go back to\n",
        "\n",
        "Step 2: Loading training datas with vgg16 transfert model and training\n",
        "\n",
        "Loading and Cleaning Training Datas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IuzuOOsaLAsO"
      },
      "source": [
        "####Search of the best parameters for training and evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQD_FVuIK--C",
        "outputId": "450c342a-0c91-41ed-c32a-a902c34f04bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "%cd /content/drive/My Drive/A_transfertTFMVggSP500\n",
        "# Load the TensorBoard notebook extension.\n",
        "%reload_ext tensorboard\n",
        "!rm -rf ./logs/ \n",
        "\n",
        "#We can modify batch size and epochs to adjust improve the training\n",
        "l_batch_size=[25,50,100]\n",
        "l_epochs=[25,50,100]\n",
        "l_learning_rate=[0.001,0.01,0.1]\n",
        "l_optimizer_name=[keras.optimizers.SGD, keras.optimizers.RMSprop, keras.optimizers.Adam, keras.optimizers.Adagrad, keras.optimizers.Adamax, keras.optimizers.Ftrl]\n",
        "\n",
        "Tabres={}\n",
        "\n",
        "for x_batch_size in l_batch_size :\n",
        "  for  x_epochs in l_epochs:\n",
        "    for x_learning_rate in l_learning_rate:\n",
        "      for x_optimizer_name in l_optimizer_name :\n",
        "        batch_size= x_batch_size\n",
        "        epochs= x_epochs\n",
        "        lr_schedule =  x_learning_rate\n",
        "        \n",
        "        ##https://keras.io/api/losses/\n",
        "        vggsp500loss='categorical_crossentropy'                             \n",
        "\n",
        "        ##https://keras.io/api/optimizers/\n",
        "        vggsp500optimizer_name=x_optimizer_name(learning_rate=x_learning_rate)\n",
        "        \n",
        "        ##https://keras.io/api/metrics/\n",
        "        vggsp500metrics=['accuracy']                                           \n",
        "        \n",
        "        \n",
        "        ##ACTUALISATION OF THE MODEL AND BY EACH SET OF PARAMETERS\n",
        "        \n",
        "        #First we initialize weight for each set of param see abpve where we had saved it\n",
        "        transfer_model.load_weights('model/initial_weights.h5')\n",
        "        transfer_model.compile(loss=vggsp500loss, optimizer=vggsp500optimizer_name,\n",
        "                      metrics=vggsp500metrics)\n",
        "\n",
        "        ##Saving the best model for each parameters\n",
        "        nameof_intermediarymodel=\"best_model\"+vggsp500loss+\"_\"+str(vggsp500optimizer_name)+\"_Batch\"+\\\n",
        "                                    str(batch_size)+\"_LR\"+str(x_learning_rate)+\"_Epochs\"+str(epochs)\n",
        "        checkpoint = ModelCheckpoint('model/'+nameof_intermediarymodel+\".hdf5\", \\\n",
        "                                        monitor='loss', verbose=1, \\\n",
        "                                        save_best_only=True, mode='auto', period=1)\n",
        "\n",
        "        \n",
        "        # Define the Keras TensorBoard callback.\n",
        "        logdir=\"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "        tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir, histogram_freq=1)\n",
        "\n",
        "        ##Fitting the model on the train data and labels.\n",
        "        m_x_train=x_train\n",
        "        m_y_train=y_train\n",
        "\n",
        "        history = transfer_model.fit(m_x_train, m_y_train, \\\n",
        "                                      batch_size=batch_size, epochs=epochs, \\\n",
        "                                      validation_split=0.2, verbose=1, shuffle=True, \\\n",
        "                                      callbacks=[checkpoint,tensorboard_callback])\n",
        "        # Saving themodel\n",
        "        transfer_model.save('model/'+nameof_intermediarymodel+'vggforsp500'+'.h5')\n",
        "        Tabres.update({nameof_intermediarymodel:history.history})\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/A_transfertTFMVggSP500\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/25\n",
            "  2/595 [..............................] - ETA: 34s - loss: 2.4315 - accuracy: 0.0400WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0145s vs `on_train_batch_end` time: 0.1003s). Check your callbacks.\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.6045 - accuracy: 0.3101\n",
            "Epoch 00001: loss improved from inf to 1.60393, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f5b6204e8d0>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.6039 - accuracy: 0.3110 - val_loss: 1.5135 - val_accuracy: 0.3399\n",
            "Epoch 2/25\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5611 - accuracy: 0.3199\n",
            "Epoch 00002: loss improved from 1.60393 to 1.56054, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f5b6204e8d0>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5605 - accuracy: 0.3201 - val_loss: 1.5102 - val_accuracy: 0.3399\n",
            "Epoch 3/25\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5548 - accuracy: 0.3293\n",
            "Epoch 00003: loss improved from 1.56054 to 1.55448, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f5b6204e8d0>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5545 - accuracy: 0.3294 - val_loss: 1.5035 - val_accuracy: 0.3399\n",
            "Epoch 4/25\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5459 - accuracy: 0.3327\n",
            "Epoch 00004: loss improved from 1.55448 to 1.54585, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f5b6204e8d0>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5459 - accuracy: 0.3326 - val_loss: 1.5065 - val_accuracy: 0.3399\n",
            "Epoch 5/25\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5430 - accuracy: 0.3321\n",
            "Epoch 00005: loss improved from 1.54585 to 1.54320, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f5b6204e8d0>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5432 - accuracy: 0.3318 - val_loss: 1.5075 - val_accuracy: 0.3399\n",
            "Epoch 6/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5411 - accuracy: 0.3384\n",
            "Epoch 00006: loss improved from 1.54320 to 1.54099, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f5b6204e8d0>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5410 - accuracy: 0.3387 - val_loss: 1.5053 - val_accuracy: 0.3399\n",
            "Epoch 7/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5378 - accuracy: 0.3389\n",
            "Epoch 00007: loss improved from 1.54099 to 1.53811, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f5b6204e8d0>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5381 - accuracy: 0.3387 - val_loss: 1.5027 - val_accuracy: 0.3399\n",
            "Epoch 8/25\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5351 - accuracy: 0.3378\n",
            "Epoch 00008: loss improved from 1.53811 to 1.53514, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f5b6204e8d0>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5351 - accuracy: 0.3379 - val_loss: 1.5048 - val_accuracy: 0.3399\n",
            "Epoch 9/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5381 - accuracy: 0.3386\n",
            "Epoch 00009: loss did not improve from 1.53514\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5382 - accuracy: 0.3388 - val_loss: 1.5061 - val_accuracy: 0.3399\n",
            "Epoch 10/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5370 - accuracy: 0.3422\n",
            "Epoch 00010: loss did not improve from 1.53514\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5366 - accuracy: 0.3422 - val_loss: 1.5034 - val_accuracy: 0.3399\n",
            "Epoch 11/25\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5342 - accuracy: 0.3403\n",
            "Epoch 00011: loss improved from 1.53514 to 1.53396, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f5b6204e8d0>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5340 - accuracy: 0.3404 - val_loss: 1.5014 - val_accuracy: 0.3399\n",
            "Epoch 12/25\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5354 - accuracy: 0.3381\n",
            "Epoch 00012: loss did not improve from 1.53396\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5354 - accuracy: 0.3381 - val_loss: 1.5010 - val_accuracy: 0.3399\n",
            "Epoch 13/25\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5326 - accuracy: 0.3406\n",
            "Epoch 00013: loss improved from 1.53396 to 1.53260, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f5b6204e8d0>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5326 - accuracy: 0.3406 - val_loss: 1.5043 - val_accuracy: 0.3399\n",
            "Epoch 14/25\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5333 - accuracy: 0.3436\n",
            "Epoch 00014: loss did not improve from 1.53260\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5329 - accuracy: 0.3442 - val_loss: 1.5033 - val_accuracy: 0.3399\n",
            "Epoch 15/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5314 - accuracy: 0.3414\n",
            "Epoch 00015: loss improved from 1.53260 to 1.53111, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f5b6204e8d0>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5311 - accuracy: 0.3417 - val_loss: 1.5036 - val_accuracy: 0.3399\n",
            "Epoch 16/25\n",
            "589/595 [============================>.] - ETA: 0s - loss: 1.5308 - accuracy: 0.3419\n",
            "Epoch 00016: loss improved from 1.53111 to 1.53053, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f5b6204e8d0>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5305 - accuracy: 0.3425 - val_loss: 1.5035 - val_accuracy: 0.3399\n",
            "Epoch 17/25\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5306 - accuracy: 0.3430\n",
            "Epoch 00017: loss did not improve from 1.53053\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5306 - accuracy: 0.3430 - val_loss: 1.5025 - val_accuracy: 0.3399\n",
            "Epoch 18/25\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5305 - accuracy: 0.3426\n",
            "Epoch 00018: loss did not improve from 1.53053\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5305 - accuracy: 0.3426 - val_loss: 1.5024 - val_accuracy: 0.3399\n",
            "Epoch 19/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5305 - accuracy: 0.3420\n",
            "Epoch 00019: loss improved from 1.53053 to 1.53039, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f5b6204e8d0>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5304 - accuracy: 0.3421 - val_loss: 1.5016 - val_accuracy: 0.3399\n",
            "Epoch 20/25\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5282 - accuracy: 0.3417\n",
            "Epoch 00020: loss improved from 1.53039 to 1.52811, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f5b6204e8d0>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5281 - accuracy: 0.3420 - val_loss: 1.5025 - val_accuracy: 0.3399\n",
            "Epoch 21/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5292 - accuracy: 0.3424\n",
            "Epoch 00021: loss did not improve from 1.52811\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5293 - accuracy: 0.3422 - val_loss: 1.5011 - val_accuracy: 0.3399\n",
            "Epoch 22/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5287 - accuracy: 0.3414\n",
            "Epoch 00022: loss did not improve from 1.52811\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5283 - accuracy: 0.3416 - val_loss: 1.5029 - val_accuracy: 0.3399\n",
            "Epoch 23/25\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5282 - accuracy: 0.3419\n",
            "Epoch 00023: loss did not improve from 1.52811\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5282 - accuracy: 0.3419 - val_loss: 1.4992 - val_accuracy: 0.3399\n",
            "Epoch 24/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5283 - accuracy: 0.3428\n",
            "Epoch 00024: loss did not improve from 1.52811\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5281 - accuracy: 0.3428 - val_loss: 1.4994 - val_accuracy: 0.3399\n",
            "Epoch 25/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5271 - accuracy: 0.3417\n",
            "Epoch 00025: loss improved from 1.52811 to 1.52711, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f5b6204e8d0>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5271 - accuracy: 0.3418 - val_loss: 1.4991 - val_accuracy: 0.3399\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/25\n",
            "  2/595 [..............................] - ETA: 39s - loss: 2.0196 - accuracy: 0.0800WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0155s vs `on_train_batch_end` time: 0.1178s). Check your callbacks.\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5473 - accuracy: 0.3327\n",
            "Epoch 00001: loss improved from inf to 1.54702, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f59cc45efd0>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5470 - accuracy: 0.3329 - val_loss: 1.5068 - val_accuracy: 0.3399\n",
            "Epoch 2/25\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5284 - accuracy: 0.3414\n",
            "Epoch 00002: loss improved from 1.54702 to 1.52771, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f59cc45efd0>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5277 - accuracy: 0.3420 - val_loss: 1.4969 - val_accuracy: 0.3399\n",
            "Epoch 3/25\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5241 - accuracy: 0.3425\n",
            "Epoch 00003: loss improved from 1.52771 to 1.52421, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f59cc45efd0>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5242 - accuracy: 0.3423 - val_loss: 1.5041 - val_accuracy: 0.3399\n",
            "Epoch 4/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5199 - accuracy: 0.3434\n",
            "Epoch 00004: loss improved from 1.52421 to 1.52004, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f59cc45efd0>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5200 - accuracy: 0.3435 - val_loss: 1.4919 - val_accuracy: 0.3442\n",
            "Epoch 5/25\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5180 - accuracy: 0.3408\n",
            "Epoch 00005: loss improved from 1.52004 to 1.51803, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f59cc45efd0>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5180 - accuracy: 0.3408 - val_loss: 1.4974 - val_accuracy: 0.3358\n",
            "Epoch 6/25\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5138 - accuracy: 0.3458\n",
            "Epoch 00006: loss improved from 1.51803 to 1.51346, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f59cc45efd0>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5135 - accuracy: 0.3451 - val_loss: 1.4893 - val_accuracy: 0.3415\n",
            "Epoch 7/25\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5116 - accuracy: 0.3461\n",
            "Epoch 00007: loss improved from 1.51346 to 1.51201, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f59cc45efd0>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5120 - accuracy: 0.3457 - val_loss: 1.4988 - val_accuracy: 0.3286\n",
            "Epoch 8/25\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5121 - accuracy: 0.3473\n",
            "Epoch 00008: loss improved from 1.51201 to 1.51195, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f59cc45efd0>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5120 - accuracy: 0.3475 - val_loss: 1.5162 - val_accuracy: 0.3372\n",
            "Epoch 9/25\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5079 - accuracy: 0.3443\n",
            "Epoch 00009: loss improved from 1.51195 to 1.50823, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f59cc45efd0>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5082 - accuracy: 0.3443 - val_loss: 1.5151 - val_accuracy: 0.3224\n",
            "Epoch 10/25\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5068 - accuracy: 0.3448\n",
            "Epoch 00010: loss improved from 1.50823 to 1.50675, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f59cc45efd0>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5068 - accuracy: 0.3448 - val_loss: 1.5074 - val_accuracy: 0.3243\n",
            "Epoch 11/25\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5046 - accuracy: 0.3450\n",
            "Epoch 00011: loss improved from 1.50675 to 1.50467, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f59cc45efd0>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5047 - accuracy: 0.3451 - val_loss: 1.5108 - val_accuracy: 0.3229\n",
            "Epoch 12/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5039 - accuracy: 0.3482\n",
            "Epoch 00012: loss improved from 1.50467 to 1.50432, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f59cc45efd0>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5043 - accuracy: 0.3480 - val_loss: 1.4885 - val_accuracy: 0.3202\n",
            "Epoch 13/25\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5011 - accuracy: 0.3495\n",
            "Epoch 00013: loss improved from 1.50432 to 1.50177, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f59cc45efd0>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5018 - accuracy: 0.3493 - val_loss: 1.4918 - val_accuracy: 0.3294\n",
            "Epoch 14/25\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5013 - accuracy: 0.3525\n",
            "Epoch 00014: loss improved from 1.50177 to 1.50128, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f59cc45efd0>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5013 - accuracy: 0.3525 - val_loss: 1.5210 - val_accuracy: 0.3221\n",
            "Epoch 15/25\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.4995 - accuracy: 0.3475\n",
            "Epoch 00015: loss improved from 1.50128 to 1.49957, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f59cc45efd0>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.4996 - accuracy: 0.3473 - val_loss: 1.4979 - val_accuracy: 0.3200\n",
            "Epoch 16/25\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.4982 - accuracy: 0.3465\n",
            "Epoch 00016: loss improved from 1.49957 to 1.49825, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f59cc45efd0>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4982 - accuracy: 0.3465 - val_loss: 1.4987 - val_accuracy: 0.3305\n",
            "Epoch 17/25\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.4980 - accuracy: 0.3498\n",
            "Epoch 00017: loss improved from 1.49825 to 1.49805, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f59cc45efd0>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4980 - accuracy: 0.3498 - val_loss: 1.5270 - val_accuracy: 0.3251\n",
            "Epoch 18/25\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.4963 - accuracy: 0.3502\n",
            "Epoch 00018: loss improved from 1.49805 to 1.49669, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f59cc45efd0>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4967 - accuracy: 0.3495 - val_loss: 1.5085 - val_accuracy: 0.3272\n",
            "Epoch 19/25\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.4960 - accuracy: 0.3529\n",
            "Epoch 00019: loss improved from 1.49669 to 1.49595, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f59cc45efd0>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4960 - accuracy: 0.3529 - val_loss: 1.5233 - val_accuracy: 0.3369\n",
            "Epoch 20/25\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.4945 - accuracy: 0.3533\n",
            "Epoch 00020: loss improved from 1.49595 to 1.49452, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f59cc45efd0>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.4945 - accuracy: 0.3533 - val_loss: 1.5195 - val_accuracy: 0.3267\n",
            "Epoch 21/25\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.4946 - accuracy: 0.3554\n",
            "Epoch 00021: loss improved from 1.49452 to 1.49425, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f59cc45efd0>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4942 - accuracy: 0.3559 - val_loss: 1.5107 - val_accuracy: 0.3173\n",
            "Epoch 22/25\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.4921 - accuracy: 0.3575\n",
            "Epoch 00022: loss improved from 1.49425 to 1.49210, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f59cc45efd0>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4921 - accuracy: 0.3574 - val_loss: 1.5283 - val_accuracy: 0.3375\n",
            "Epoch 23/25\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.4911 - accuracy: 0.3549\n",
            "Epoch 00023: loss improved from 1.49210 to 1.49081, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f59cc45efd0>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.4908 - accuracy: 0.3552 - val_loss: 1.5110 - val_accuracy: 0.3393\n",
            "Epoch 24/25\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.4900 - accuracy: 0.3575\n",
            "Epoch 00024: loss improved from 1.49081 to 1.48945, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f59cc45efd0>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4894 - accuracy: 0.3578 - val_loss: 1.5388 - val_accuracy: 0.3122\n",
            "Epoch 25/25\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.4890 - accuracy: 0.3592\n",
            "Epoch 00025: loss improved from 1.48945 to 1.48899, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f59cc45efd0>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.4890 - accuracy: 0.3591 - val_loss: 1.5243 - val_accuracy: 0.3253\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/25\n",
            "  2/595 [..............................] - ETA: 34s - loss: 2.1772 - accuracy: 0.0800WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0163s vs `on_train_batch_end` time: 0.0981s). Check your callbacks.\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5496 - accuracy: 0.3283\n",
            "Epoch 00001: loss improved from inf to 1.54961, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f5b61ded208>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5496 - accuracy: 0.3283 - val_loss: 1.5036 - val_accuracy: 0.3399\n",
            "Epoch 2/25\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5277 - accuracy: 0.3429\n",
            "Epoch 00002: loss improved from 1.54961 to 1.52753, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f5b61ded208>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5275 - accuracy: 0.3429 - val_loss: 1.4948 - val_accuracy: 0.3399\n",
            "Epoch 3/25\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5233 - accuracy: 0.3418\n",
            "Epoch 00003: loss improved from 1.52753 to 1.52306, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f5b61ded208>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5231 - accuracy: 0.3420 - val_loss: 1.4904 - val_accuracy: 0.3224\n",
            "Epoch 4/25\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5196 - accuracy: 0.3423\n",
            "Epoch 00004: loss improved from 1.52306 to 1.51946, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f5b61ded208>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5195 - accuracy: 0.3424 - val_loss: 1.4875 - val_accuracy: 0.3372\n",
            "Epoch 5/25\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5168 - accuracy: 0.3432\n",
            "Epoch 00005: loss improved from 1.51946 to 1.51672, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f5b61ded208>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5167 - accuracy: 0.3432 - val_loss: 1.5036 - val_accuracy: 0.3372\n",
            "Epoch 6/25\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5151 - accuracy: 0.3447\n",
            "Epoch 00006: loss improved from 1.51672 to 1.51510, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f5b61ded208>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5151 - accuracy: 0.3447 - val_loss: 1.4885 - val_accuracy: 0.3372\n",
            "Epoch 7/25\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5128 - accuracy: 0.3461\n",
            "Epoch 00007: loss improved from 1.51510 to 1.51256, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f5b61ded208>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5126 - accuracy: 0.3463 - val_loss: 1.5083 - val_accuracy: 0.3361\n",
            "Epoch 8/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5114 - accuracy: 0.3440\n",
            "Epoch 00008: loss improved from 1.51256 to 1.51128, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f5b61ded208>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5113 - accuracy: 0.3439 - val_loss: 1.5006 - val_accuracy: 0.3348\n",
            "Epoch 9/25\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5086 - accuracy: 0.3468\n",
            "Epoch 00009: loss improved from 1.51128 to 1.50812, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f5b61ded208>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5081 - accuracy: 0.3469 - val_loss: 1.4871 - val_accuracy: 0.3302\n",
            "Epoch 10/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5065 - accuracy: 0.3476\n",
            "Epoch 00010: loss improved from 1.50812 to 1.50689, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f5b61ded208>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5069 - accuracy: 0.3473 - val_loss: 1.4937 - val_accuracy: 0.3369\n",
            "Epoch 11/25\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5041 - accuracy: 0.3462\n",
            "Epoch 00011: loss improved from 1.50689 to 1.50414, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f5b61ded208>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5041 - accuracy: 0.3462 - val_loss: 1.4974 - val_accuracy: 0.3345\n",
            "Epoch 12/25\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5026 - accuracy: 0.3454\n",
            "Epoch 00012: loss improved from 1.50414 to 1.50225, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f5b61ded208>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5023 - accuracy: 0.3457 - val_loss: 1.4946 - val_accuracy: 0.3219\n",
            "Epoch 13/25\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5018 - accuracy: 0.3485\n",
            "Epoch 00013: loss improved from 1.50225 to 1.50216, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f5b61ded208>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5022 - accuracy: 0.3481 - val_loss: 1.4966 - val_accuracy: 0.3294\n",
            "Epoch 14/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.4981 - accuracy: 0.3499\n",
            "Epoch 00014: loss improved from 1.50216 to 1.49781, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f5b61ded208>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4978 - accuracy: 0.3500 - val_loss: 1.5049 - val_accuracy: 0.3124\n",
            "Epoch 15/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.4988 - accuracy: 0.3509\n",
            "Epoch 00015: loss did not improve from 1.49781\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4990 - accuracy: 0.3507 - val_loss: 1.5013 - val_accuracy: 0.3200\n",
            "Epoch 16/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.4970 - accuracy: 0.3486\n",
            "Epoch 00016: loss improved from 1.49781 to 1.49698, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f5b61ded208>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.4970 - accuracy: 0.3484 - val_loss: 1.4958 - val_accuracy: 0.3294\n",
            "Epoch 17/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.4939 - accuracy: 0.3497\n",
            "Epoch 00017: loss improved from 1.49698 to 1.49405, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f5b61ded208>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4941 - accuracy: 0.3496 - val_loss: 1.5069 - val_accuracy: 0.3087\n",
            "Epoch 18/25\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.4930 - accuracy: 0.3517\n",
            "Epoch 00018: loss improved from 1.49405 to 1.49286, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f5b61ded208>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.4929 - accuracy: 0.3519 - val_loss: 1.4970 - val_accuracy: 0.3291\n",
            "Epoch 19/25\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.4932 - accuracy: 0.3467\n",
            "Epoch 00019: loss did not improve from 1.49286\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4931 - accuracy: 0.3466 - val_loss: 1.4949 - val_accuracy: 0.3130\n",
            "Epoch 20/25\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.4915 - accuracy: 0.3534\n",
            "Epoch 00020: loss improved from 1.49286 to 1.49150, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f5b61ded208>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.4915 - accuracy: 0.3534 - val_loss: 1.5029 - val_accuracy: 0.3081\n",
            "Epoch 21/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.4885 - accuracy: 0.3549\n",
            "Epoch 00021: loss improved from 1.49150 to 1.48841, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f5b61ded208>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4884 - accuracy: 0.3549 - val_loss: 1.5132 - val_accuracy: 0.3130\n",
            "Epoch 22/25\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.4871 - accuracy: 0.3521\n",
            "Epoch 00022: loss improved from 1.48841 to 1.48767, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f5b61ded208>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4877 - accuracy: 0.3516 - val_loss: 1.4946 - val_accuracy: 0.3315\n",
            "Epoch 23/25\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.4849 - accuracy: 0.3528\n",
            "Epoch 00023: loss improved from 1.48767 to 1.48474, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f5b61ded208>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.4847 - accuracy: 0.3528 - val_loss: 1.5146 - val_accuracy: 0.3221\n",
            "Epoch 24/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.4834 - accuracy: 0.3567\n",
            "Epoch 00024: loss improved from 1.48474 to 1.48375, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f5b61ded208>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4837 - accuracy: 0.3569 - val_loss: 1.5243 - val_accuracy: 0.3122\n",
            "Epoch 25/25\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.4833 - accuracy: 0.3565\n",
            "Epoch 00025: loss improved from 1.48375 to 1.48263, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f5b61ded208>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4826 - accuracy: 0.3568 - val_loss: 1.5092 - val_accuracy: 0.3399\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/25\n",
            "  2/595 [..............................] - ETA: 37s - loss: 2.1424 - accuracy: 0.1400WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0170s vs `on_train_batch_end` time: 0.1080s). Check your callbacks.\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5985 - accuracy: 0.3146\n",
            "Epoch 00001: loss improved from inf to 1.59869, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59d1b66c50>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5987 - accuracy: 0.3144 - val_loss: 1.5194 - val_accuracy: 0.3399\n",
            "Epoch 2/25\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5618 - accuracy: 0.3284\n",
            "Epoch 00002: loss improved from 1.59869 to 1.56176, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59d1b66c50>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 9s 15ms/step - loss: 1.5618 - accuracy: 0.3284 - val_loss: 1.5115 - val_accuracy: 0.3399\n",
            "Epoch 3/25\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5547 - accuracy: 0.3271\n",
            "Epoch 00003: loss improved from 1.56176 to 1.55475, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59d1b66c50>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5548 - accuracy: 0.3272 - val_loss: 1.5069 - val_accuracy: 0.3399\n",
            "Epoch 4/25\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5489 - accuracy: 0.3295\n",
            "Epoch 00004: loss improved from 1.55475 to 1.54948, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59d1b66c50>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5495 - accuracy: 0.3291 - val_loss: 1.5093 - val_accuracy: 0.3399\n",
            "Epoch 5/25\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5484 - accuracy: 0.3290\n",
            "Epoch 00005: loss improved from 1.54948 to 1.54797, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59d1b66c50>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5480 - accuracy: 0.3295 - val_loss: 1.5071 - val_accuracy: 0.3399\n",
            "Epoch 6/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5460 - accuracy: 0.3311\n",
            "Epoch 00006: loss improved from 1.54797 to 1.54594, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59d1b66c50>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5459 - accuracy: 0.3311 - val_loss: 1.5058 - val_accuracy: 0.3399\n",
            "Epoch 7/25\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5434 - accuracy: 0.3353\n",
            "Epoch 00007: loss improved from 1.54594 to 1.54391, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59d1b66c50>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5439 - accuracy: 0.3349 - val_loss: 1.5040 - val_accuracy: 0.3399\n",
            "Epoch 8/25\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5402 - accuracy: 0.3349\n",
            "Epoch 00008: loss improved from 1.54391 to 1.54047, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59d1b66c50>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5405 - accuracy: 0.3346 - val_loss: 1.5042 - val_accuracy: 0.3399\n",
            "Epoch 9/25\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5377 - accuracy: 0.3320\n",
            "Epoch 00009: loss improved from 1.54047 to 1.53778, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59d1b66c50>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5378 - accuracy: 0.3321 - val_loss: 1.5055 - val_accuracy: 0.3399\n",
            "Epoch 10/25\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5346 - accuracy: 0.3371\n",
            "Epoch 00010: loss improved from 1.53778 to 1.53518, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59d1b66c50>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5352 - accuracy: 0.3367 - val_loss: 1.5045 - val_accuracy: 0.3399\n",
            "Epoch 11/25\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5357 - accuracy: 0.3319\n",
            "Epoch 00011: loss did not improve from 1.53518\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5357 - accuracy: 0.3319 - val_loss: 1.5063 - val_accuracy: 0.3399\n",
            "Epoch 12/25\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5368 - accuracy: 0.3347\n",
            "Epoch 00012: loss did not improve from 1.53518\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5367 - accuracy: 0.3347 - val_loss: 1.5044 - val_accuracy: 0.3399\n",
            "Epoch 13/25\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5375 - accuracy: 0.3338\n",
            "Epoch 00013: loss did not improve from 1.53518\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5377 - accuracy: 0.3339 - val_loss: 1.5049 - val_accuracy: 0.3399\n",
            "Epoch 14/25\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5358 - accuracy: 0.3367\n",
            "Epoch 00014: loss did not improve from 1.53518\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5357 - accuracy: 0.3369 - val_loss: 1.5035 - val_accuracy: 0.3399\n",
            "Epoch 15/25\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5363 - accuracy: 0.3365\n",
            "Epoch 00015: loss did not improve from 1.53518\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5357 - accuracy: 0.3371 - val_loss: 1.5039 - val_accuracy: 0.3399\n",
            "Epoch 16/25\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5348 - accuracy: 0.3356\n",
            "Epoch 00016: loss improved from 1.53518 to 1.53487, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59d1b66c50>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5349 - accuracy: 0.3355 - val_loss: 1.5029 - val_accuracy: 0.3399\n",
            "Epoch 17/25\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5344 - accuracy: 0.3354\n",
            "Epoch 00017: loss improved from 1.53487 to 1.53424, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59d1b66c50>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5342 - accuracy: 0.3356 - val_loss: 1.5028 - val_accuracy: 0.3399\n",
            "Epoch 18/25\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5347 - accuracy: 0.3370\n",
            "Epoch 00018: loss did not improve from 1.53424\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5347 - accuracy: 0.3369 - val_loss: 1.5032 - val_accuracy: 0.3399\n",
            "Epoch 19/25\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5332 - accuracy: 0.3408\n",
            "Epoch 00019: loss improved from 1.53424 to 1.53361, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59d1b66c50>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5336 - accuracy: 0.3405 - val_loss: 1.5025 - val_accuracy: 0.3399\n",
            "Epoch 20/25\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5320 - accuracy: 0.3413\n",
            "Epoch 00020: loss improved from 1.53361 to 1.53176, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59d1b66c50>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5318 - accuracy: 0.3415 - val_loss: 1.5033 - val_accuracy: 0.3399\n",
            "Epoch 21/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5315 - accuracy: 0.3372\n",
            "Epoch 00021: loss improved from 1.53176 to 1.53164, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59d1b66c50>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5316 - accuracy: 0.3371 - val_loss: 1.5039 - val_accuracy: 0.3399\n",
            "Epoch 22/25\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5318 - accuracy: 0.3401\n",
            "Epoch 00022: loss did not improve from 1.53164\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5320 - accuracy: 0.3403 - val_loss: 1.5035 - val_accuracy: 0.3399\n",
            "Epoch 23/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5325 - accuracy: 0.3372\n",
            "Epoch 00023: loss did not improve from 1.53164\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5327 - accuracy: 0.3370 - val_loss: 1.5038 - val_accuracy: 0.3399\n",
            "Epoch 24/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5291 - accuracy: 0.3414\n",
            "Epoch 00024: loss improved from 1.53164 to 1.52933, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59d1b66c50>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5293 - accuracy: 0.3410 - val_loss: 1.5028 - val_accuracy: 0.3399\n",
            "Epoch 25/25\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5315 - accuracy: 0.3377\n",
            "Epoch 00025: loss did not improve from 1.52933\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5317 - accuracy: 0.3380 - val_loss: 1.5038 - val_accuracy: 0.3399\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/25\n",
            "  2/595 [..............................] - ETA: 35s - loss: 2.2563 - accuracy: 0.1000WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0149s vs `on_train_batch_end` time: 0.1030s). Check your callbacks.\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5564 - accuracy: 0.3263\n",
            "Epoch 00001: loss improved from inf to 1.55637, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f59c909e1d0>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5564 - accuracy: 0.3263 - val_loss: 1.5220 - val_accuracy: 0.3399\n",
            "Epoch 2/25\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5350 - accuracy: 0.3360\n",
            "Epoch 00002: loss improved from 1.55637 to 1.53484, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f59c909e1d0>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5348 - accuracy: 0.3358 - val_loss: 1.4980 - val_accuracy: 0.3399\n",
            "Epoch 3/25\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5294 - accuracy: 0.3424\n",
            "Epoch 00003: loss improved from 1.53484 to 1.52974, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f59c909e1d0>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5297 - accuracy: 0.3421 - val_loss: 1.4993 - val_accuracy: 0.3399\n",
            "Epoch 4/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5241 - accuracy: 0.3391\n",
            "Epoch 00004: loss improved from 1.52974 to 1.52419, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f59c909e1d0>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5242 - accuracy: 0.3391 - val_loss: 1.5081 - val_accuracy: 0.3399\n",
            "Epoch 5/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5219 - accuracy: 0.3428\n",
            "Epoch 00005: loss improved from 1.52419 to 1.52203, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f59c909e1d0>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5220 - accuracy: 0.3426 - val_loss: 1.4936 - val_accuracy: 0.3399\n",
            "Epoch 6/25\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5191 - accuracy: 0.3419\n",
            "Epoch 00006: loss improved from 1.52203 to 1.51928, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f59c909e1d0>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5193 - accuracy: 0.3418 - val_loss: 1.4924 - val_accuracy: 0.3399\n",
            "Epoch 7/25\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5171 - accuracy: 0.3422\n",
            "Epoch 00007: loss improved from 1.51928 to 1.51689, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f59c909e1d0>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5169 - accuracy: 0.3423 - val_loss: 1.4939 - val_accuracy: 0.3399\n",
            "Epoch 8/25\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5163 - accuracy: 0.3422\n",
            "Epoch 00008: loss improved from 1.51689 to 1.51610, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f59c909e1d0>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5161 - accuracy: 0.3422 - val_loss: 1.4942 - val_accuracy: 0.3372\n",
            "Epoch 9/25\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5140 - accuracy: 0.3438\n",
            "Epoch 00009: loss improved from 1.51610 to 1.51376, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f59c909e1d0>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5138 - accuracy: 0.3437 - val_loss: 1.4962 - val_accuracy: 0.3372\n",
            "Epoch 10/25\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5101 - accuracy: 0.3447\n",
            "Epoch 00010: loss improved from 1.51376 to 1.51026, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f59c909e1d0>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5103 - accuracy: 0.3445 - val_loss: 1.4937 - val_accuracy: 0.3380\n",
            "Epoch 11/25\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5095 - accuracy: 0.3437\n",
            "Epoch 00011: loss improved from 1.51026 to 1.50954, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f59c909e1d0>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5095 - accuracy: 0.3437 - val_loss: 1.4921 - val_accuracy: 0.3385\n",
            "Epoch 12/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5082 - accuracy: 0.3401\n",
            "Epoch 00012: loss improved from 1.50954 to 1.50815, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f59c909e1d0>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5081 - accuracy: 0.3402 - val_loss: 1.5015 - val_accuracy: 0.3375\n",
            "Epoch 13/25\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5081 - accuracy: 0.3456\n",
            "Epoch 00013: loss improved from 1.50815 to 1.50805, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f59c909e1d0>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5081 - accuracy: 0.3457 - val_loss: 1.4902 - val_accuracy: 0.3364\n",
            "Epoch 14/25\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5045 - accuracy: 0.3453\n",
            "Epoch 00014: loss improved from 1.50805 to 1.50479, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f59c909e1d0>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5048 - accuracy: 0.3457 - val_loss: 1.4946 - val_accuracy: 0.3356\n",
            "Epoch 15/25\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5048 - accuracy: 0.3452\n",
            "Epoch 00015: loss did not improve from 1.50479\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5049 - accuracy: 0.3452 - val_loss: 1.4905 - val_accuracy: 0.3361\n",
            "Epoch 16/25\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5027 - accuracy: 0.3489\n",
            "Epoch 00016: loss improved from 1.50479 to 1.50248, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f59c909e1d0>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 9s 14ms/step - loss: 1.5025 - accuracy: 0.3484 - val_loss: 1.4910 - val_accuracy: 0.3227\n",
            "Epoch 17/25\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5026 - accuracy: 0.3457\n",
            "Epoch 00017: loss did not improve from 1.50248\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5027 - accuracy: 0.3458 - val_loss: 1.4920 - val_accuracy: 0.3358\n",
            "Epoch 18/25\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5007 - accuracy: 0.3466\n",
            "Epoch 00018: loss improved from 1.50248 to 1.50078, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f59c909e1d0>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 9s 15ms/step - loss: 1.5008 - accuracy: 0.3465 - val_loss: 1.4932 - val_accuracy: 0.3237\n",
            "Epoch 19/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5007 - accuracy: 0.3476\n",
            "Epoch 00019: loss improved from 1.50078 to 1.50071, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f59c909e1d0>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5007 - accuracy: 0.3472 - val_loss: 1.4969 - val_accuracy: 0.3353\n",
            "Epoch 20/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.4983 - accuracy: 0.3464\n",
            "Epoch 00020: loss improved from 1.50071 to 1.49821, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f59c909e1d0>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4982 - accuracy: 0.3469 - val_loss: 1.5061 - val_accuracy: 0.3367\n",
            "Epoch 21/25\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.4974 - accuracy: 0.3492\n",
            "Epoch 00021: loss improved from 1.49821 to 1.49756, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f59c909e1d0>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4976 - accuracy: 0.3494 - val_loss: 1.4918 - val_accuracy: 0.3410\n",
            "Epoch 22/25\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.4949 - accuracy: 0.3558\n",
            "Epoch 00022: loss improved from 1.49756 to 1.49498, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f59c909e1d0>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4950 - accuracy: 0.3557 - val_loss: 1.4959 - val_accuracy: 0.3375\n",
            "Epoch 23/25\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.4952 - accuracy: 0.3508\n",
            "Epoch 00023: loss did not improve from 1.49498\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4954 - accuracy: 0.3505 - val_loss: 1.4967 - val_accuracy: 0.3356\n",
            "Epoch 24/25\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.4957 - accuracy: 0.3497\n",
            "Epoch 00024: loss did not improve from 1.49498\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4956 - accuracy: 0.3499 - val_loss: 1.4963 - val_accuracy: 0.3377\n",
            "Epoch 25/25\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.4926 - accuracy: 0.3525\n",
            "Epoch 00025: loss improved from 1.49498 to 1.49258, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f59c909e1d0>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.4926 - accuracy: 0.3526 - val_loss: 1.4902 - val_accuracy: 0.3283\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/25\n",
            "  2/595 [..............................] - ETA: 33s - loss: 2.1209 - accuracy: 0.0800WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0158s vs `on_train_batch_end` time: 0.0965s). Check your callbacks.\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.6698 - accuracy: 0.3214\n",
            "Epoch 00001: loss improved from inf to 1.66937, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f59c8cb1e80>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.6694 - accuracy: 0.3216 - val_loss: 1.5491 - val_accuracy: 0.3399\n",
            "Epoch 2/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5571 - accuracy: 0.3437\n",
            "Epoch 00002: loss improved from 1.66937 to 1.55727, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f59c8cb1e80>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5573 - accuracy: 0.3436 - val_loss: 1.5178 - val_accuracy: 0.3399\n",
            "Epoch 3/25\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5417 - accuracy: 0.3437\n",
            "Epoch 00003: loss improved from 1.55727 to 1.54183, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f59c8cb1e80>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5418 - accuracy: 0.3436 - val_loss: 1.5095 - val_accuracy: 0.3399\n",
            "Epoch 4/25\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5361 - accuracy: 0.3436\n",
            "Epoch 00004: loss improved from 1.54183 to 1.53613, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f59c8cb1e80>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5361 - accuracy: 0.3436 - val_loss: 1.5045 - val_accuracy: 0.3399\n",
            "Epoch 5/25\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5332 - accuracy: 0.3438\n",
            "Epoch 00005: loss improved from 1.53613 to 1.53350, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f59c8cb1e80>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5335 - accuracy: 0.3436 - val_loss: 1.5022 - val_accuracy: 0.3399\n",
            "Epoch 6/25\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5329 - accuracy: 0.3436\n",
            "Epoch 00006: loss improved from 1.53350 to 1.53267, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f59c8cb1e80>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5327 - accuracy: 0.3436 - val_loss: 1.5012 - val_accuracy: 0.3399\n",
            "Epoch 7/25\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5309 - accuracy: 0.3436\n",
            "Epoch 00007: loss improved from 1.53267 to 1.53082, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f59c8cb1e80>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5308 - accuracy: 0.3436 - val_loss: 1.4997 - val_accuracy: 0.3399\n",
            "Epoch 8/25\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5305 - accuracy: 0.3437\n",
            "Epoch 00008: loss improved from 1.53082 to 1.53056, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f59c8cb1e80>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5306 - accuracy: 0.3436 - val_loss: 1.4995 - val_accuracy: 0.3399\n",
            "Epoch 9/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5303 - accuracy: 0.3432\n",
            "Epoch 00009: loss improved from 1.53056 to 1.52996, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f59c8cb1e80>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5300 - accuracy: 0.3436 - val_loss: 1.4995 - val_accuracy: 0.3399\n",
            "Epoch 10/25\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5296 - accuracy: 0.3436\n",
            "Epoch 00010: loss improved from 1.52996 to 1.52963, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f59c8cb1e80>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5296 - accuracy: 0.3436 - val_loss: 1.4984 - val_accuracy: 0.3399\n",
            "Epoch 11/25\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5298 - accuracy: 0.3438\n",
            "Epoch 00011: loss did not improve from 1.52963\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5297 - accuracy: 0.3436 - val_loss: 1.4986 - val_accuracy: 0.3399\n",
            "Epoch 12/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5284 - accuracy: 0.3436\n",
            "Epoch 00012: loss improved from 1.52963 to 1.52869, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f59c8cb1e80>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5287 - accuracy: 0.3436 - val_loss: 1.4984 - val_accuracy: 0.3399\n",
            "Epoch 13/25\n",
            "589/595 [============================>.] - ETA: 0s - loss: 1.5289 - accuracy: 0.3438\n",
            "Epoch 00013: loss did not improve from 1.52869\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5289 - accuracy: 0.3436 - val_loss: 1.4982 - val_accuracy: 0.3399\n",
            "Epoch 14/25\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5291 - accuracy: 0.3441\n",
            "Epoch 00014: loss did not improve from 1.52869\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5294 - accuracy: 0.3436 - val_loss: 1.4981 - val_accuracy: 0.3399\n",
            "Epoch 15/25\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5292 - accuracy: 0.3434\n",
            "Epoch 00015: loss did not improve from 1.52869\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5291 - accuracy: 0.3436 - val_loss: 1.4987 - val_accuracy: 0.3399\n",
            "Epoch 16/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5290 - accuracy: 0.3437\n",
            "Epoch 00016: loss did not improve from 1.52869\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5291 - accuracy: 0.3436 - val_loss: 1.4984 - val_accuracy: 0.3399\n",
            "Epoch 17/25\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5290 - accuracy: 0.3436\n",
            "Epoch 00017: loss did not improve from 1.52869\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5290 - accuracy: 0.3436 - val_loss: 1.4980 - val_accuracy: 0.3399\n",
            "Epoch 18/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5293 - accuracy: 0.3434\n",
            "Epoch 00018: loss did not improve from 1.52869\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5292 - accuracy: 0.3436 - val_loss: 1.4981 - val_accuracy: 0.3399\n",
            "Epoch 19/25\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5284 - accuracy: 0.3436\n",
            "Epoch 00019: loss improved from 1.52869 to 1.52842, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f59c8cb1e80>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5284 - accuracy: 0.3436 - val_loss: 1.4979 - val_accuracy: 0.3399\n",
            "Epoch 20/25\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5287 - accuracy: 0.3438\n",
            "Epoch 00020: loss did not improve from 1.52842\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5285 - accuracy: 0.3437 - val_loss: 1.4980 - val_accuracy: 0.3399\n",
            "Epoch 21/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5288 - accuracy: 0.3436\n",
            "Epoch 00021: loss did not improve from 1.52842\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5287 - accuracy: 0.3436 - val_loss: 1.4978 - val_accuracy: 0.3399\n",
            "Epoch 22/25\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5292 - accuracy: 0.3433\n",
            "Epoch 00022: loss did not improve from 1.52842\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5291 - accuracy: 0.3436 - val_loss: 1.4980 - val_accuracy: 0.3399\n",
            "Epoch 23/25\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5290 - accuracy: 0.3436\n",
            "Epoch 00023: loss did not improve from 1.52842\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5291 - accuracy: 0.3436 - val_loss: 1.4981 - val_accuracy: 0.3399\n",
            "Epoch 24/25\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5285 - accuracy: 0.3436\n",
            "Epoch 00024: loss did not improve from 1.52842\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5285 - accuracy: 0.3436 - val_loss: 1.4979 - val_accuracy: 0.3399\n",
            "Epoch 25/25\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5289 - accuracy: 0.3436\n",
            "Epoch 00025: loss did not improve from 1.52842\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5287 - accuracy: 0.3436 - val_loss: 1.4977 - val_accuracy: 0.3399\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/25\n",
            "  2/595 [..............................] - ETA: 40s - loss: 2.1576 - accuracy: 0.0600WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0153s vs `on_train_batch_end` time: 0.1207s). Check your callbacks.\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5562 - accuracy: 0.3308\n",
            "Epoch 00001: loss improved from inf to 1.55579, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59c8dc0f60>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5558 - accuracy: 0.3309 - val_loss: 1.4990 - val_accuracy: 0.3399\n",
            "Epoch 2/25\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5389 - accuracy: 0.3372\n",
            "Epoch 00002: loss improved from 1.55579 to 1.53883, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59c8dc0f60>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5388 - accuracy: 0.3374 - val_loss: 1.5072 - val_accuracy: 0.3399\n",
            "Epoch 3/25\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5325 - accuracy: 0.3380\n",
            "Epoch 00003: loss improved from 1.53883 to 1.53253, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59c8dc0f60>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5325 - accuracy: 0.3380 - val_loss: 1.5163 - val_accuracy: 0.3399\n",
            "Epoch 4/25\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5314 - accuracy: 0.3427\n",
            "Epoch 00004: loss improved from 1.53253 to 1.53152, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59c8dc0f60>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5315 - accuracy: 0.3425 - val_loss: 1.5035 - val_accuracy: 0.3399\n",
            "Epoch 5/25\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5286 - accuracy: 0.3412\n",
            "Epoch 00005: loss improved from 1.53152 to 1.52848, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59c8dc0f60>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 9s 15ms/step - loss: 1.5285 - accuracy: 0.3415 - val_loss: 1.5018 - val_accuracy: 0.3399\n",
            "Epoch 6/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5268 - accuracy: 0.3419\n",
            "Epoch 00006: loss improved from 1.52848 to 1.52661, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59c8dc0f60>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5266 - accuracy: 0.3420 - val_loss: 1.4989 - val_accuracy: 0.3399\n",
            "Epoch 7/25\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5255 - accuracy: 0.3433\n",
            "Epoch 00007: loss improved from 1.52661 to 1.52547, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59c8dc0f60>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5255 - accuracy: 0.3433 - val_loss: 1.5056 - val_accuracy: 0.3399\n",
            "Epoch 8/25\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5247 - accuracy: 0.3436\n",
            "Epoch 00008: loss improved from 1.52547 to 1.52494, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59c8dc0f60>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5249 - accuracy: 0.3434 - val_loss: 1.5007 - val_accuracy: 0.3399\n",
            "Epoch 9/25\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5257 - accuracy: 0.3439\n",
            "Epoch 00009: loss did not improve from 1.52494\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5254 - accuracy: 0.3444 - val_loss: 1.5045 - val_accuracy: 0.3399\n",
            "Epoch 10/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5248 - accuracy: 0.3420\n",
            "Epoch 00010: loss improved from 1.52494 to 1.52479, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59c8dc0f60>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5248 - accuracy: 0.3418 - val_loss: 1.4934 - val_accuracy: 0.3396\n",
            "Epoch 11/25\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5240 - accuracy: 0.3430\n",
            "Epoch 00011: loss improved from 1.52479 to 1.52407, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59c8dc0f60>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5241 - accuracy: 0.3428 - val_loss: 1.5073 - val_accuracy: 0.3399\n",
            "Epoch 12/25\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5242 - accuracy: 0.3437\n",
            "Epoch 00012: loss improved from 1.52407 to 1.52375, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59c8dc0f60>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5238 - accuracy: 0.3440 - val_loss: 1.5033 - val_accuracy: 0.3399\n",
            "Epoch 13/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5226 - accuracy: 0.3438\n",
            "Epoch 00013: loss improved from 1.52375 to 1.52267, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59c8dc0f60>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5227 - accuracy: 0.3434 - val_loss: 1.4944 - val_accuracy: 0.3399\n",
            "Epoch 14/25\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5216 - accuracy: 0.3436\n",
            "Epoch 00014: loss improved from 1.52267 to 1.52157, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59c8dc0f60>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5216 - accuracy: 0.3436 - val_loss: 1.4969 - val_accuracy: 0.3399\n",
            "Epoch 15/25\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5215 - accuracy: 0.3424\n",
            "Epoch 00015: loss did not improve from 1.52157\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5217 - accuracy: 0.3422 - val_loss: 1.5020 - val_accuracy: 0.3399\n",
            "Epoch 16/25\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5214 - accuracy: 0.3443\n",
            "Epoch 00016: loss did not improve from 1.52157\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5217 - accuracy: 0.3442 - val_loss: 1.4994 - val_accuracy: 0.3399\n",
            "Epoch 17/25\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5212 - accuracy: 0.3424\n",
            "Epoch 00017: loss improved from 1.52157 to 1.52112, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59c8dc0f60>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5211 - accuracy: 0.3424 - val_loss: 1.4951 - val_accuracy: 0.3399\n",
            "Epoch 18/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5206 - accuracy: 0.3428\n",
            "Epoch 00018: loss improved from 1.52112 to 1.52049, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59c8dc0f60>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5205 - accuracy: 0.3429 - val_loss: 1.4941 - val_accuracy: 0.3399\n",
            "Epoch 19/25\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5202 - accuracy: 0.3428\n",
            "Epoch 00019: loss improved from 1.52049 to 1.52019, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59c8dc0f60>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5202 - accuracy: 0.3428 - val_loss: 1.5056 - val_accuracy: 0.3399\n",
            "Epoch 20/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5191 - accuracy: 0.3427\n",
            "Epoch 00020: loss improved from 1.52019 to 1.51922, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59c8dc0f60>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5192 - accuracy: 0.3430 - val_loss: 1.5182 - val_accuracy: 0.3399\n",
            "Epoch 21/25\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5188 - accuracy: 0.3432\n",
            "Epoch 00021: loss improved from 1.51922 to 1.51883, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59c8dc0f60>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5188 - accuracy: 0.3432 - val_loss: 1.4992 - val_accuracy: 0.3399\n",
            "Epoch 22/25\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5177 - accuracy: 0.3433\n",
            "Epoch 00022: loss improved from 1.51883 to 1.51818, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59c8dc0f60>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5182 - accuracy: 0.3432 - val_loss: 1.5033 - val_accuracy: 0.3399\n",
            "Epoch 23/25\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5161 - accuracy: 0.3443\n",
            "Epoch 00023: loss improved from 1.51818 to 1.51637, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59c8dc0f60>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5164 - accuracy: 0.3447 - val_loss: 1.5086 - val_accuracy: 0.3399\n",
            "Epoch 24/25\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5167 - accuracy: 0.3447\n",
            "Epoch 00024: loss did not improve from 1.51637\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5168 - accuracy: 0.3446 - val_loss: 1.4969 - val_accuracy: 0.3399\n",
            "Epoch 25/25\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5174 - accuracy: 0.3442\n",
            "Epoch 00025: loss did not improve from 1.51637\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5173 - accuracy: 0.3443 - val_loss: 1.5104 - val_accuracy: 0.3399\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/25\n",
            "  2/595 [..............................] - ETA: 50s - loss: 3.5273 - accuracy: 0.2000WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0208s vs `on_train_batch_end` time: 0.1441s). Check your callbacks.\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5615 - accuracy: 0.3328\n",
            "Epoch 00001: loss improved from inf to 1.56149, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f59c8aa62e8>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 9s 14ms/step - loss: 1.5615 - accuracy: 0.3328 - val_loss: 1.5115 - val_accuracy: 0.3399\n",
            "Epoch 2/25\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5301 - accuracy: 0.3432\n",
            "Epoch 00002: loss improved from 1.56149 to 1.52966, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f59c8aa62e8>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 9s 14ms/step - loss: 1.5297 - accuracy: 0.3436 - val_loss: 1.4937 - val_accuracy: 0.3399\n",
            "Epoch 3/25\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5294 - accuracy: 0.3435\n",
            "Epoch 00003: loss improved from 1.52966 to 1.52937, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f59c8aa62e8>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5294 - accuracy: 0.3436 - val_loss: 1.4940 - val_accuracy: 0.3399\n",
            "Epoch 4/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5294 - accuracy: 0.3441\n",
            "Epoch 00004: loss did not improve from 1.52937\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5295 - accuracy: 0.3436 - val_loss: 1.4967 - val_accuracy: 0.3399\n",
            "Epoch 5/25\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5297 - accuracy: 0.3436\n",
            "Epoch 00005: loss did not improve from 1.52937\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5295 - accuracy: 0.3436 - val_loss: 1.4932 - val_accuracy: 0.3399\n",
            "Epoch 6/25\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5296 - accuracy: 0.3437\n",
            "Epoch 00006: loss did not improve from 1.52937\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5297 - accuracy: 0.3436 - val_loss: 1.4963 - val_accuracy: 0.3399\n",
            "Epoch 7/25\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5295 - accuracy: 0.3439\n",
            "Epoch 00007: loss did not improve from 1.52937\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5295 - accuracy: 0.3436 - val_loss: 1.4966 - val_accuracy: 0.3399\n",
            "Epoch 8/25\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5300 - accuracy: 0.3431\n",
            "Epoch 00008: loss did not improve from 1.52937\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5298 - accuracy: 0.3436 - val_loss: 1.4957 - val_accuracy: 0.3399\n",
            "Epoch 9/25\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5299 - accuracy: 0.3436\n",
            "Epoch 00009: loss did not improve from 1.52937\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5297 - accuracy: 0.3436 - val_loss: 1.4959 - val_accuracy: 0.3399\n",
            "Epoch 10/25\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5302 - accuracy: 0.3436\n",
            "Epoch 00010: loss did not improve from 1.52937\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5302 - accuracy: 0.3436 - val_loss: 1.4923 - val_accuracy: 0.3399\n",
            "Epoch 11/25\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5304 - accuracy: 0.3436\n",
            "Epoch 00011: loss did not improve from 1.52937\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5305 - accuracy: 0.3436 - val_loss: 1.4912 - val_accuracy: 0.3399\n",
            "Epoch 12/25\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5307 - accuracy: 0.3435\n",
            "Epoch 00012: loss did not improve from 1.52937\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5306 - accuracy: 0.3436 - val_loss: 1.4987 - val_accuracy: 0.3399\n",
            "Epoch 13/25\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5302 - accuracy: 0.3436\n",
            "Epoch 00013: loss did not improve from 1.52937\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5302 - accuracy: 0.3436 - val_loss: 1.4929 - val_accuracy: 0.3399\n",
            "Epoch 14/25\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5303 - accuracy: 0.3438\n",
            "Epoch 00014: loss did not improve from 1.52937\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5302 - accuracy: 0.3436 - val_loss: 1.4968 - val_accuracy: 0.3399\n",
            "Epoch 15/25\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5299 - accuracy: 0.3436\n",
            "Epoch 00015: loss did not improve from 1.52937\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5299 - accuracy: 0.3436 - val_loss: 1.4945 - val_accuracy: 0.3399\n",
            "Epoch 16/25\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5303 - accuracy: 0.3436\n",
            "Epoch 00016: loss did not improve from 1.52937\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5303 - accuracy: 0.3436 - val_loss: 1.4920 - val_accuracy: 0.3399\n",
            "Epoch 17/25\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5296 - accuracy: 0.3439\n",
            "Epoch 00017: loss did not improve from 1.52937\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5299 - accuracy: 0.3436 - val_loss: 1.4910 - val_accuracy: 0.3399\n",
            "Epoch 18/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5309 - accuracy: 0.3438\n",
            "Epoch 00018: loss did not improve from 1.52937\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5310 - accuracy: 0.3436 - val_loss: 1.4943 - val_accuracy: 0.3399\n",
            "Epoch 19/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5307 - accuracy: 0.3431\n",
            "Epoch 00019: loss did not improve from 1.52937\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5303 - accuracy: 0.3436 - val_loss: 1.4973 - val_accuracy: 0.3399\n",
            "Epoch 20/25\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5301 - accuracy: 0.3438\n",
            "Epoch 00020: loss did not improve from 1.52937\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5301 - accuracy: 0.3436 - val_loss: 1.4909 - val_accuracy: 0.3399\n",
            "Epoch 21/25\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5302 - accuracy: 0.3439\n",
            "Epoch 00021: loss did not improve from 1.52937\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5301 - accuracy: 0.3436 - val_loss: 1.4938 - val_accuracy: 0.3399\n",
            "Epoch 22/25\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5303 - accuracy: 0.3432\n",
            "Epoch 00022: loss did not improve from 1.52937\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5298 - accuracy: 0.3436 - val_loss: 1.4922 - val_accuracy: 0.3399\n",
            "Epoch 23/25\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5295 - accuracy: 0.3436\n",
            "Epoch 00023: loss did not improve from 1.52937\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5295 - accuracy: 0.3436 - val_loss: 1.4925 - val_accuracy: 0.3399\n",
            "Epoch 24/25\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5305 - accuracy: 0.3432\n",
            "Epoch 00024: loss did not improve from 1.52937\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5303 - accuracy: 0.3436 - val_loss: 1.4978 - val_accuracy: 0.3399\n",
            "Epoch 25/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5299 - accuracy: 0.3436\n",
            "Epoch 00025: loss did not improve from 1.52937\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5297 - accuracy: 0.3436 - val_loss: 1.4975 - val_accuracy: 0.3399\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/25\n",
            "  2/595 [..............................] - ETA: 33s - loss: 1.9792 - accuracy: 0.2200WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0152s vs `on_train_batch_end` time: 0.1007s). Check your callbacks.\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5536 - accuracy: 0.3335\n",
            "Epoch 00001: loss improved from inf to 1.55335, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f59c8bc5828>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5533 - accuracy: 0.3338 - val_loss: 1.4947 - val_accuracy: 0.3323\n",
            "Epoch 2/25\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5327 - accuracy: 0.3410\n",
            "Epoch 00002: loss improved from 1.55335 to 1.53266, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f59c8bc5828>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5327 - accuracy: 0.3411 - val_loss: 1.5036 - val_accuracy: 0.3399\n",
            "Epoch 3/25\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5295 - accuracy: 0.3437\n",
            "Epoch 00003: loss improved from 1.53266 to 1.52941, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f59c8bc5828>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5294 - accuracy: 0.3436 - val_loss: 1.4982 - val_accuracy: 0.3399\n",
            "Epoch 4/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5288 - accuracy: 0.3439\n",
            "Epoch 00004: loss improved from 1.52941 to 1.52909, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f59c8bc5828>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5291 - accuracy: 0.3436 - val_loss: 1.4991 - val_accuracy: 0.3399\n",
            "Epoch 5/25\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5289 - accuracy: 0.3434\n",
            "Epoch 00005: loss improved from 1.52909 to 1.52907, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f59c8bc5828>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5291 - accuracy: 0.3436 - val_loss: 1.4947 - val_accuracy: 0.3399\n",
            "Epoch 6/25\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5291 - accuracy: 0.3436\n",
            "Epoch 00006: loss did not improve from 1.52907\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5291 - accuracy: 0.3436 - val_loss: 1.4954 - val_accuracy: 0.3399\n",
            "Epoch 7/25\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5288 - accuracy: 0.3436\n",
            "Epoch 00007: loss improved from 1.52907 to 1.52881, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f59c8bc5828>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5288 - accuracy: 0.3436 - val_loss: 1.4999 - val_accuracy: 0.3399\n",
            "Epoch 8/25\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5288 - accuracy: 0.3437\n",
            "Epoch 00008: loss did not improve from 1.52881\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5289 - accuracy: 0.3436 - val_loss: 1.4978 - val_accuracy: 0.3399\n",
            "Epoch 9/25\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5293 - accuracy: 0.3436\n",
            "Epoch 00009: loss did not improve from 1.52881\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5292 - accuracy: 0.3436 - val_loss: 1.5000 - val_accuracy: 0.3399\n",
            "Epoch 10/25\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5291 - accuracy: 0.3436\n",
            "Epoch 00010: loss did not improve from 1.52881\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5291 - accuracy: 0.3436 - val_loss: 1.4912 - val_accuracy: 0.3399\n",
            "Epoch 11/25\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5289 - accuracy: 0.3436\n",
            "Epoch 00011: loss did not improve from 1.52881\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5289 - accuracy: 0.3436 - val_loss: 1.4949 - val_accuracy: 0.3399\n",
            "Epoch 12/25\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5291 - accuracy: 0.3432\n",
            "Epoch 00012: loss did not improve from 1.52881\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5290 - accuracy: 0.3436 - val_loss: 1.4972 - val_accuracy: 0.3399\n",
            "Epoch 13/25\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5291 - accuracy: 0.3434\n",
            "Epoch 00013: loss did not improve from 1.52881\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5290 - accuracy: 0.3436 - val_loss: 1.4924 - val_accuracy: 0.3399\n",
            "Epoch 14/25\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5294 - accuracy: 0.3435\n",
            "Epoch 00014: loss did not improve from 1.52881\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5293 - accuracy: 0.3436 - val_loss: 1.4974 - val_accuracy: 0.3399\n",
            "Epoch 15/25\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5289 - accuracy: 0.3438\n",
            "Epoch 00015: loss did not improve from 1.52881\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5288 - accuracy: 0.3436 - val_loss: 1.5003 - val_accuracy: 0.3399\n",
            "Epoch 16/25\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5285 - accuracy: 0.3440\n",
            "Epoch 00016: loss improved from 1.52881 to 1.52861, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f59c8bc5828>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5286 - accuracy: 0.3436 - val_loss: 1.4977 - val_accuracy: 0.3399\n",
            "Epoch 17/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5289 - accuracy: 0.3435\n",
            "Epoch 00017: loss did not improve from 1.52861\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5292 - accuracy: 0.3436 - val_loss: 1.4991 - val_accuracy: 0.3399\n",
            "Epoch 18/25\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5294 - accuracy: 0.3436\n",
            "Epoch 00018: loss did not improve from 1.52861\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5293 - accuracy: 0.3436 - val_loss: 1.4997 - val_accuracy: 0.3399\n",
            "Epoch 19/25\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5286 - accuracy: 0.3438\n",
            "Epoch 00019: loss did not improve from 1.52861\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5289 - accuracy: 0.3436 - val_loss: 1.4967 - val_accuracy: 0.3399\n",
            "Epoch 20/25\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5289 - accuracy: 0.3437\n",
            "Epoch 00020: loss did not improve from 1.52861\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5291 - accuracy: 0.3436 - val_loss: 1.5008 - val_accuracy: 0.3399\n",
            "Epoch 21/25\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5289 - accuracy: 0.3438\n",
            "Epoch 00021: loss did not improve from 1.52861\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5290 - accuracy: 0.3436 - val_loss: 1.4944 - val_accuracy: 0.3399\n",
            "Epoch 22/25\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5288 - accuracy: 0.3437\n",
            "Epoch 00022: loss did not improve from 1.52861\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5289 - accuracy: 0.3436 - val_loss: 1.4968 - val_accuracy: 0.3399\n",
            "Epoch 23/25\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5291 - accuracy: 0.3436\n",
            "Epoch 00023: loss did not improve from 1.52861\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5289 - accuracy: 0.3436 - val_loss: 1.4975 - val_accuracy: 0.3399\n",
            "Epoch 24/25\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5289 - accuracy: 0.3436\n",
            "Epoch 00024: loss did not improve from 1.52861\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5289 - accuracy: 0.3436 - val_loss: 1.4962 - val_accuracy: 0.3399\n",
            "Epoch 25/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5288 - accuracy: 0.3440\n",
            "Epoch 00025: loss did not improve from 1.52861\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5287 - accuracy: 0.3436 - val_loss: 1.4947 - val_accuracy: 0.3399\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/25\n",
            "  2/595 [..............................] - ETA: 34s - loss: 2.0010 - accuracy: 0.1400WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0165s vs `on_train_batch_end` time: 0.0975s). Check your callbacks.\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5469 - accuracy: 0.3292\n",
            "Epoch 00001: loss improved from inf to 1.54695, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59c8ff0e80>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5469 - accuracy: 0.3292 - val_loss: 1.5165 - val_accuracy: 0.3399\n",
            "Epoch 2/25\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5330 - accuracy: 0.3392\n",
            "Epoch 00002: loss improved from 1.54695 to 1.53307, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59c8ff0e80>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5331 - accuracy: 0.3391 - val_loss: 1.5040 - val_accuracy: 0.3399\n",
            "Epoch 3/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5280 - accuracy: 0.3436\n",
            "Epoch 00003: loss improved from 1.53307 to 1.52826, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59c8ff0e80>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5283 - accuracy: 0.3430 - val_loss: 1.5046 - val_accuracy: 0.3399\n",
            "Epoch 4/25\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5257 - accuracy: 0.3422\n",
            "Epoch 00004: loss improved from 1.52826 to 1.52569, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59c8ff0e80>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5257 - accuracy: 0.3422 - val_loss: 1.5107 - val_accuracy: 0.3399\n",
            "Epoch 5/25\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5236 - accuracy: 0.3441\n",
            "Epoch 00005: loss improved from 1.52569 to 1.52361, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59c8ff0e80>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5236 - accuracy: 0.3441 - val_loss: 1.4989 - val_accuracy: 0.3399\n",
            "Epoch 6/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5225 - accuracy: 0.3432\n",
            "Epoch 00006: loss improved from 1.52361 to 1.52262, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59c8ff0e80>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5226 - accuracy: 0.3433 - val_loss: 1.5001 - val_accuracy: 0.3399\n",
            "Epoch 7/25\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5218 - accuracy: 0.3446\n",
            "Epoch 00007: loss improved from 1.52262 to 1.52158, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59c8ff0e80>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5216 - accuracy: 0.3443 - val_loss: 1.4977 - val_accuracy: 0.3399\n",
            "Epoch 8/25\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5198 - accuracy: 0.3424\n",
            "Epoch 00008: loss improved from 1.52158 to 1.51971, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59c8ff0e80>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5197 - accuracy: 0.3428 - val_loss: 1.5040 - val_accuracy: 0.3399\n",
            "Epoch 9/25\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5189 - accuracy: 0.3431\n",
            "Epoch 00009: loss improved from 1.51971 to 1.51921, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59c8ff0e80>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5192 - accuracy: 0.3434 - val_loss: 1.4987 - val_accuracy: 0.3399\n",
            "Epoch 10/25\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5179 - accuracy: 0.3433\n",
            "Epoch 00010: loss improved from 1.51921 to 1.51790, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59c8ff0e80>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5179 - accuracy: 0.3433 - val_loss: 1.4942 - val_accuracy: 0.3399\n",
            "Epoch 11/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5169 - accuracy: 0.3432\n",
            "Epoch 00011: loss improved from 1.51790 to 1.51679, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59c8ff0e80>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5168 - accuracy: 0.3434 - val_loss: 1.4967 - val_accuracy: 0.3399\n",
            "Epoch 12/25\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5161 - accuracy: 0.3459\n",
            "Epoch 00012: loss improved from 1.51679 to 1.51613, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59c8ff0e80>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5161 - accuracy: 0.3459 - val_loss: 1.4969 - val_accuracy: 0.3399\n",
            "Epoch 13/25\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5153 - accuracy: 0.3431\n",
            "Epoch 00013: loss improved from 1.51613 to 1.51543, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59c8ff0e80>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5154 - accuracy: 0.3430 - val_loss: 1.4968 - val_accuracy: 0.3399\n",
            "Epoch 14/25\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5139 - accuracy: 0.3450\n",
            "Epoch 00014: loss improved from 1.51543 to 1.51426, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59c8ff0e80>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5143 - accuracy: 0.3448 - val_loss: 1.4954 - val_accuracy: 0.3399\n",
            "Epoch 15/25\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5142 - accuracy: 0.3452\n",
            "Epoch 00015: loss did not improve from 1.51426\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5143 - accuracy: 0.3451 - val_loss: 1.4909 - val_accuracy: 0.3399\n",
            "Epoch 16/25\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5143 - accuracy: 0.3444\n",
            "Epoch 00016: loss improved from 1.51426 to 1.51413, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59c8ff0e80>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5141 - accuracy: 0.3443 - val_loss: 1.4950 - val_accuracy: 0.3399\n",
            "Epoch 17/25\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5128 - accuracy: 0.3468\n",
            "Epoch 00017: loss improved from 1.51413 to 1.51348, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59c8ff0e80>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5135 - accuracy: 0.3463 - val_loss: 1.4960 - val_accuracy: 0.3396\n",
            "Epoch 18/25\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5123 - accuracy: 0.3435\n",
            "Epoch 00018: loss improved from 1.51348 to 1.51233, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59c8ff0e80>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5123 - accuracy: 0.3435 - val_loss: 1.4957 - val_accuracy: 0.3399\n",
            "Epoch 19/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5118 - accuracy: 0.3470\n",
            "Epoch 00019: loss improved from 1.51233 to 1.51209, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59c8ff0e80>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5121 - accuracy: 0.3469 - val_loss: 1.4970 - val_accuracy: 0.3361\n",
            "Epoch 20/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5123 - accuracy: 0.3465\n",
            "Epoch 00020: loss did not improve from 1.51209\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5122 - accuracy: 0.3466 - val_loss: 1.4968 - val_accuracy: 0.3399\n",
            "Epoch 21/25\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5118 - accuracy: 0.3465\n",
            "Epoch 00021: loss improved from 1.51209 to 1.51166, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59c8ff0e80>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5117 - accuracy: 0.3469 - val_loss: 1.4954 - val_accuracy: 0.3399\n",
            "Epoch 22/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5104 - accuracy: 0.3455\n",
            "Epoch 00022: loss improved from 1.51166 to 1.51054, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59c8ff0e80>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5105 - accuracy: 0.3456 - val_loss: 1.4963 - val_accuracy: 0.3372\n",
            "Epoch 23/25\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5105 - accuracy: 0.3460\n",
            "Epoch 00023: loss did not improve from 1.51054\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5107 - accuracy: 0.3459 - val_loss: 1.4945 - val_accuracy: 0.3348\n",
            "Epoch 24/25\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5088 - accuracy: 0.3446\n",
            "Epoch 00024: loss improved from 1.51054 to 1.50878, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59c8ff0e80>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5088 - accuracy: 0.3447 - val_loss: 1.4971 - val_accuracy: 0.3369\n",
            "Epoch 25/25\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5100 - accuracy: 0.3434\n",
            "Epoch 00025: loss did not improve from 1.50878\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5100 - accuracy: 0.3434 - val_loss: 1.4946 - val_accuracy: 0.3358\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/25\n",
            "  2/595 [..............................] - ETA: 43s - loss: 2.1160 - accuracy: 0.2600WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0177s vs `on_train_batch_end` time: 0.1277s). Check your callbacks.\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5451 - accuracy: 0.3324\n",
            "Epoch 00001: loss improved from inf to 1.54523, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f59c8bcde48>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 9s 14ms/step - loss: 1.5452 - accuracy: 0.3324 - val_loss: 1.5013 - val_accuracy: 0.3399\n",
            "Epoch 2/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5313 - accuracy: 0.3397\n",
            "Epoch 00002: loss improved from 1.54523 to 1.53107, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f59c8bcde48>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5311 - accuracy: 0.3400 - val_loss: 1.4999 - val_accuracy: 0.3399\n",
            "Epoch 3/25\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5271 - accuracy: 0.3432\n",
            "Epoch 00003: loss improved from 1.53107 to 1.52712, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f59c8bcde48>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5271 - accuracy: 0.3432 - val_loss: 1.4883 - val_accuracy: 0.3399\n",
            "Epoch 4/25\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5238 - accuracy: 0.3425\n",
            "Epoch 00004: loss improved from 1.52712 to 1.52378, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f59c8bcde48>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5238 - accuracy: 0.3425 - val_loss: 1.4862 - val_accuracy: 0.3372\n",
            "Epoch 5/25\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5213 - accuracy: 0.3443\n",
            "Epoch 00005: loss improved from 1.52378 to 1.52140, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f59c8bcde48>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5214 - accuracy: 0.3441 - val_loss: 1.4954 - val_accuracy: 0.3372\n",
            "Epoch 6/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5191 - accuracy: 0.3420\n",
            "Epoch 00006: loss improved from 1.52140 to 1.51938, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f59c8bcde48>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5194 - accuracy: 0.3418 - val_loss: 1.4909 - val_accuracy: 0.3372\n",
            "Epoch 7/25\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5154 - accuracy: 0.3408\n",
            "Epoch 00007: loss improved from 1.51938 to 1.51537, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f59c8bcde48>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5154 - accuracy: 0.3408 - val_loss: 1.4971 - val_accuracy: 0.3380\n",
            "Epoch 8/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5163 - accuracy: 0.3457\n",
            "Epoch 00008: loss did not improve from 1.51537\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5169 - accuracy: 0.3457 - val_loss: 1.5035 - val_accuracy: 0.3380\n",
            "Epoch 9/25\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5146 - accuracy: 0.3439\n",
            "Epoch 00009: loss improved from 1.51537 to 1.51445, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f59c8bcde48>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5144 - accuracy: 0.3443 - val_loss: 1.5064 - val_accuracy: 0.3396\n",
            "Epoch 10/25\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5111 - accuracy: 0.3425\n",
            "Epoch 00010: loss improved from 1.51445 to 1.51114, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f59c8bcde48>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5111 - accuracy: 0.3427 - val_loss: 1.5258 - val_accuracy: 0.3334\n",
            "Epoch 11/25\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5105 - accuracy: 0.3425\n",
            "Epoch 00011: loss improved from 1.51114 to 1.51018, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f59c8bcde48>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5102 - accuracy: 0.3428 - val_loss: 1.4969 - val_accuracy: 0.3219\n",
            "Epoch 12/25\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5077 - accuracy: 0.3461\n",
            "Epoch 00012: loss improved from 1.51018 to 1.50776, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f59c8bcde48>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5078 - accuracy: 0.3461 - val_loss: 1.4837 - val_accuracy: 0.3399\n",
            "Epoch 13/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5055 - accuracy: 0.3414\n",
            "Epoch 00013: loss improved from 1.50776 to 1.50534, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f59c8bcde48>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5053 - accuracy: 0.3412 - val_loss: 1.4943 - val_accuracy: 0.3186\n",
            "Epoch 14/25\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5063 - accuracy: 0.3429\n",
            "Epoch 00014: loss did not improve from 1.50534\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5060 - accuracy: 0.3428 - val_loss: 1.4863 - val_accuracy: 0.3259\n",
            "Epoch 15/25\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5054 - accuracy: 0.3469\n",
            "Epoch 00015: loss did not improve from 1.50534\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5059 - accuracy: 0.3471 - val_loss: 1.4820 - val_accuracy: 0.3332\n",
            "Epoch 16/25\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5019 - accuracy: 0.3453\n",
            "Epoch 00016: loss improved from 1.50534 to 1.50112, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f59c8bcde48>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5011 - accuracy: 0.3459 - val_loss: 1.4956 - val_accuracy: 0.3332\n",
            "Epoch 17/25\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5033 - accuracy: 0.3467\n",
            "Epoch 00017: loss did not improve from 1.50112\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5033 - accuracy: 0.3467 - val_loss: 1.4913 - val_accuracy: 0.3393\n",
            "Epoch 18/25\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.4995 - accuracy: 0.3488\n",
            "Epoch 00018: loss improved from 1.50112 to 1.49953, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f59c8bcde48>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.4995 - accuracy: 0.3488 - val_loss: 1.4847 - val_accuracy: 0.3307\n",
            "Epoch 19/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.4992 - accuracy: 0.3455\n",
            "Epoch 00019: loss did not improve from 1.49953\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4996 - accuracy: 0.3453 - val_loss: 1.4983 - val_accuracy: 0.3057\n",
            "Epoch 20/25\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.4983 - accuracy: 0.3489\n",
            "Epoch 00020: loss improved from 1.49953 to 1.49826, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f59c8bcde48>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.4983 - accuracy: 0.3488 - val_loss: 1.4890 - val_accuracy: 0.3280\n",
            "Epoch 21/25\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.4995 - accuracy: 0.3503\n",
            "Epoch 00021: loss did not improve from 1.49826\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4990 - accuracy: 0.3504 - val_loss: 1.4883 - val_accuracy: 0.3280\n",
            "Epoch 22/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.4998 - accuracy: 0.3504\n",
            "Epoch 00022: loss did not improve from 1.49826\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4998 - accuracy: 0.3504 - val_loss: 1.4912 - val_accuracy: 0.3272\n",
            "Epoch 23/25\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.4991 - accuracy: 0.3470\n",
            "Epoch 00023: loss did not improve from 1.49826\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4993 - accuracy: 0.3469 - val_loss: 1.4950 - val_accuracy: 0.3114\n",
            "Epoch 24/25\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.4965 - accuracy: 0.3500\n",
            "Epoch 00024: loss improved from 1.49826 to 1.49655, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f59c8bcde48>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.4965 - accuracy: 0.3500 - val_loss: 1.4787 - val_accuracy: 0.3272\n",
            "Epoch 25/25\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.4977 - accuracy: 0.3492\n",
            "Epoch 00025: loss did not improve from 1.49655\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4978 - accuracy: 0.3492 - val_loss: 1.5022 - val_accuracy: 0.3253\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/25\n",
            "  2/595 [..............................] - ETA: 44s - loss: 2.1071 - accuracy: 0.1400WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0151s vs `on_train_batch_end` time: 0.1349s). Check your callbacks.\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5449 - accuracy: 0.3418\n",
            "Epoch 00001: loss improved from inf to 1.54494, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f59c45e9fd0>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5449 - accuracy: 0.3418 - val_loss: 1.4955 - val_accuracy: 0.3399\n",
            "Epoch 2/25\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5317 - accuracy: 0.3436\n",
            "Epoch 00002: loss improved from 1.54494 to 1.53172, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f59c45e9fd0>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5317 - accuracy: 0.3436 - val_loss: 1.4993 - val_accuracy: 0.3399\n",
            "Epoch 3/25\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5292 - accuracy: 0.3438\n",
            "Epoch 00003: loss improved from 1.53172 to 1.52936, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f59c45e9fd0>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5294 - accuracy: 0.3436 - val_loss: 1.5000 - val_accuracy: 0.3399\n",
            "Epoch 4/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5290 - accuracy: 0.3432\n",
            "Epoch 00004: loss improved from 1.52936 to 1.52877, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f59c45e9fd0>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5288 - accuracy: 0.3436 - val_loss: 1.4933 - val_accuracy: 0.3399\n",
            "Epoch 5/25\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5294 - accuracy: 0.3435\n",
            "Epoch 00005: loss did not improve from 1.52877\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5296 - accuracy: 0.3436 - val_loss: 1.4981 - val_accuracy: 0.3399\n",
            "Epoch 6/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5287 - accuracy: 0.3438\n",
            "Epoch 00006: loss improved from 1.52877 to 1.52867, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f59c45e9fd0>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 9s 14ms/step - loss: 1.5287 - accuracy: 0.3436 - val_loss: 1.4990 - val_accuracy: 0.3399\n",
            "Epoch 7/25\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5292 - accuracy: 0.3435\n",
            "Epoch 00007: loss did not improve from 1.52867\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5287 - accuracy: 0.3436 - val_loss: 1.4936 - val_accuracy: 0.3399\n",
            "Epoch 8/25\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5287 - accuracy: 0.3436\n",
            "Epoch 00008: loss did not improve from 1.52867\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5287 - accuracy: 0.3436 - val_loss: 1.5011 - val_accuracy: 0.3399\n",
            "Epoch 9/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5286 - accuracy: 0.3434\n",
            "Epoch 00009: loss improved from 1.52867 to 1.52862, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f59c45e9fd0>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5286 - accuracy: 0.3436 - val_loss: 1.5033 - val_accuracy: 0.3399\n",
            "Epoch 10/25\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5274 - accuracy: 0.3436\n",
            "Epoch 00010: loss improved from 1.52862 to 1.52737, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f59c45e9fd0>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5274 - accuracy: 0.3436 - val_loss: 1.5012 - val_accuracy: 0.3399\n",
            "Epoch 11/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5278 - accuracy: 0.3436\n",
            "Epoch 00011: loss did not improve from 1.52737\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5276 - accuracy: 0.3436 - val_loss: 1.4964 - val_accuracy: 0.3399\n",
            "Epoch 12/25\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5262 - accuracy: 0.3437\n",
            "Epoch 00012: loss improved from 1.52737 to 1.52624, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f59c45e9fd0>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5262 - accuracy: 0.3436 - val_loss: 1.4975 - val_accuracy: 0.3399\n",
            "Epoch 13/25\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5259 - accuracy: 0.3437\n",
            "Epoch 00013: loss improved from 1.52624 to 1.52591, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f59c45e9fd0>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5259 - accuracy: 0.3436 - val_loss: 1.5051 - val_accuracy: 0.3399\n",
            "Epoch 14/25\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5253 - accuracy: 0.3434\n",
            "Epoch 00014: loss improved from 1.52591 to 1.52517, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f59c45e9fd0>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5252 - accuracy: 0.3436 - val_loss: 1.4986 - val_accuracy: 0.3399\n",
            "Epoch 15/25\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5258 - accuracy: 0.3429\n",
            "Epoch 00015: loss did not improve from 1.52517\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5252 - accuracy: 0.3436 - val_loss: 1.4991 - val_accuracy: 0.3399\n",
            "Epoch 16/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5249 - accuracy: 0.3436\n",
            "Epoch 00016: loss improved from 1.52517 to 1.52484, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f59c45e9fd0>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5248 - accuracy: 0.3436 - val_loss: 1.4971 - val_accuracy: 0.3399\n",
            "Epoch 17/25\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5242 - accuracy: 0.3440\n",
            "Epoch 00017: loss improved from 1.52484 to 1.52430, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f59c45e9fd0>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5243 - accuracy: 0.3439 - val_loss: 1.5003 - val_accuracy: 0.3399\n",
            "Epoch 18/25\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5237 - accuracy: 0.3437\n",
            "Epoch 00018: loss improved from 1.52430 to 1.52390, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f59c45e9fd0>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5239 - accuracy: 0.3434 - val_loss: 1.5019 - val_accuracy: 0.3399\n",
            "Epoch 19/25\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5235 - accuracy: 0.3436\n",
            "Epoch 00019: loss improved from 1.52390 to 1.52346, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f59c45e9fd0>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5235 - accuracy: 0.3435 - val_loss: 1.5084 - val_accuracy: 0.3399\n",
            "Epoch 20/25\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5232 - accuracy: 0.3433\n",
            "Epoch 00020: loss improved from 1.52346 to 1.52335, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f59c45e9fd0>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5233 - accuracy: 0.3436 - val_loss: 1.5022 - val_accuracy: 0.3399\n",
            "Epoch 21/25\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5231 - accuracy: 0.3435\n",
            "Epoch 00021: loss improved from 1.52335 to 1.52314, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f59c45e9fd0>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5231 - accuracy: 0.3437 - val_loss: 1.5025 - val_accuracy: 0.3399\n",
            "Epoch 22/25\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5234 - accuracy: 0.3435\n",
            "Epoch 00022: loss improved from 1.52314 to 1.52314, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f59c45e9fd0>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5231 - accuracy: 0.3436 - val_loss: 1.5015 - val_accuracy: 0.3399\n",
            "Epoch 23/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5216 - accuracy: 0.3439\n",
            "Epoch 00023: loss improved from 1.52314 to 1.52189, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f59c45e9fd0>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5219 - accuracy: 0.3436 - val_loss: 1.5018 - val_accuracy: 0.3399\n",
            "Epoch 24/25\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5214 - accuracy: 0.3433\n",
            "Epoch 00024: loss improved from 1.52189 to 1.52137, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f59c45e9fd0>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5214 - accuracy: 0.3433 - val_loss: 1.4987 - val_accuracy: 0.3399\n",
            "Epoch 25/25\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5217 - accuracy: 0.3437\n",
            "Epoch 00025: loss did not improve from 1.52137\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5219 - accuracy: 0.3434 - val_loss: 1.4994 - val_accuracy: 0.3399\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/25\n",
            "  2/595 [..............................] - ETA: 32s - loss: 2.4005 - accuracy: 0.1800WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0155s vs `on_train_batch_end` time: 0.0944s). Check your callbacks.\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5523 - accuracy: 0.3327\n",
            "Epoch 00001: loss improved from inf to 1.55214, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59c422fa58>_Batch25_LR0.1_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5521 - accuracy: 0.3328 - val_loss: 1.4925 - val_accuracy: 0.3399\n",
            "Epoch 2/25\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5367 - accuracy: 0.3376\n",
            "Epoch 00002: loss improved from 1.55214 to 1.53694, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59c422fa58>_Batch25_LR0.1_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5369 - accuracy: 0.3373 - val_loss: 1.5014 - val_accuracy: 0.3399\n",
            "Epoch 3/25\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5341 - accuracy: 0.3391\n",
            "Epoch 00003: loss improved from 1.53694 to 1.53411, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59c422fa58>_Batch25_LR0.1_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5341 - accuracy: 0.3391 - val_loss: 1.5084 - val_accuracy: 0.3399\n",
            "Epoch 4/25\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5334 - accuracy: 0.3396\n",
            "Epoch 00004: loss improved from 1.53411 to 1.53265, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59c422fa58>_Batch25_LR0.1_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5327 - accuracy: 0.3397 - val_loss: 1.4998 - val_accuracy: 0.3022\n",
            "Epoch 5/25\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5321 - accuracy: 0.3426\n",
            "Epoch 00005: loss improved from 1.53265 to 1.53207, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59c422fa58>_Batch25_LR0.1_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5321 - accuracy: 0.3423 - val_loss: 1.4992 - val_accuracy: 0.3399\n",
            "Epoch 6/25\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5302 - accuracy: 0.3426\n",
            "Epoch 00006: loss improved from 1.53207 to 1.53019, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59c422fa58>_Batch25_LR0.1_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5302 - accuracy: 0.3428 - val_loss: 1.5037 - val_accuracy: 0.3399\n",
            "Epoch 7/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5271 - accuracy: 0.3424\n",
            "Epoch 00007: loss improved from 1.53019 to 1.52725, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59c422fa58>_Batch25_LR0.1_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5273 - accuracy: 0.3421 - val_loss: 1.5022 - val_accuracy: 0.3399\n",
            "Epoch 8/25\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5264 - accuracy: 0.3433\n",
            "Epoch 00008: loss improved from 1.52725 to 1.52629, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59c422fa58>_Batch25_LR0.1_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5263 - accuracy: 0.3431 - val_loss: 1.4939 - val_accuracy: 0.3399\n",
            "Epoch 9/25\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5257 - accuracy: 0.3422\n",
            "Epoch 00009: loss improved from 1.52629 to 1.52526, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59c422fa58>_Batch25_LR0.1_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5253 - accuracy: 0.3426 - val_loss: 1.4927 - val_accuracy: 0.3399\n",
            "Epoch 10/25\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5230 - accuracy: 0.3430\n",
            "Epoch 00010: loss improved from 1.52526 to 1.52312, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59c422fa58>_Batch25_LR0.1_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5231 - accuracy: 0.3428 - val_loss: 1.4917 - val_accuracy: 0.3399\n",
            "Epoch 11/25\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5228 - accuracy: 0.3435\n",
            "Epoch 00011: loss improved from 1.52312 to 1.52273, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59c422fa58>_Batch25_LR0.1_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5227 - accuracy: 0.3434 - val_loss: 1.5113 - val_accuracy: 0.3375\n",
            "Epoch 12/25\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5224 - accuracy: 0.3436\n",
            "Epoch 00012: loss improved from 1.52273 to 1.52245, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59c422fa58>_Batch25_LR0.1_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5225 - accuracy: 0.3438 - val_loss: 1.4849 - val_accuracy: 0.3372\n",
            "Epoch 13/25\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5213 - accuracy: 0.3436\n",
            "Epoch 00013: loss improved from 1.52245 to 1.52138, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59c422fa58>_Batch25_LR0.1_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5214 - accuracy: 0.3436 - val_loss: 1.4899 - val_accuracy: 0.3399\n",
            "Epoch 14/25\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5225 - accuracy: 0.3437\n",
            "Epoch 00014: loss did not improve from 1.52138\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5225 - accuracy: 0.3438 - val_loss: 1.5007 - val_accuracy: 0.3372\n",
            "Epoch 15/25\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5214 - accuracy: 0.3436\n",
            "Epoch 00015: loss improved from 1.52138 to 1.52136, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59c422fa58>_Batch25_LR0.1_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5214 - accuracy: 0.3436 - val_loss: 1.4860 - val_accuracy: 0.3372\n",
            "Epoch 16/25\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5194 - accuracy: 0.3440\n",
            "Epoch 00016: loss improved from 1.52136 to 1.51948, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59c422fa58>_Batch25_LR0.1_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5195 - accuracy: 0.3439 - val_loss: 1.4967 - val_accuracy: 0.3391\n",
            "Epoch 17/25\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5200 - accuracy: 0.3429\n",
            "Epoch 00017: loss did not improve from 1.51948\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5202 - accuracy: 0.3430 - val_loss: 1.5008 - val_accuracy: 0.3372\n",
            "Epoch 18/25\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5203 - accuracy: 0.3435\n",
            "Epoch 00018: loss did not improve from 1.51948\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5198 - accuracy: 0.3441 - val_loss: 1.4962 - val_accuracy: 0.3399\n",
            "Epoch 19/25\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5209 - accuracy: 0.3438\n",
            "Epoch 00019: loss did not improve from 1.51948\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5206 - accuracy: 0.3438 - val_loss: 1.4920 - val_accuracy: 0.3399\n",
            "Epoch 20/25\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5191 - accuracy: 0.3434\n",
            "Epoch 00020: loss improved from 1.51948 to 1.51934, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59c422fa58>_Batch25_LR0.1_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5193 - accuracy: 0.3434 - val_loss: 1.5000 - val_accuracy: 0.3372\n",
            "Epoch 21/25\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5197 - accuracy: 0.3425\n",
            "Epoch 00021: loss did not improve from 1.51934\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5196 - accuracy: 0.3430 - val_loss: 1.5052 - val_accuracy: 0.3240\n",
            "Epoch 22/25\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5190 - accuracy: 0.3434\n",
            "Epoch 00022: loss improved from 1.51934 to 1.51900, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59c422fa58>_Batch25_LR0.1_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5190 - accuracy: 0.3436 - val_loss: 1.5070 - val_accuracy: 0.3375\n",
            "Epoch 23/25\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5182 - accuracy: 0.3441\n",
            "Epoch 00023: loss improved from 1.51900 to 1.51820, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59c422fa58>_Batch25_LR0.1_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5182 - accuracy: 0.3439 - val_loss: 1.5042 - val_accuracy: 0.3291\n",
            "Epoch 24/25\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5170 - accuracy: 0.3444\n",
            "Epoch 00024: loss improved from 1.51820 to 1.51781, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59c422fa58>_Batch25_LR0.1_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5178 - accuracy: 0.3442 - val_loss: 1.4884 - val_accuracy: 0.3372\n",
            "Epoch 25/25\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5179 - accuracy: 0.3443\n",
            "Epoch 00025: loss did not improve from 1.51781\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5179 - accuracy: 0.3443 - val_loss: 1.5057 - val_accuracy: 0.3375\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/25\n",
            "  2/595 [..............................] - ETA: 2:01 - loss: 46.0505 - accuracy: 0.2800WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0155s vs `on_train_batch_end` time: 0.3925s). Check your callbacks.\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.8809 - accuracy: 0.3316\n",
            "Epoch 00001: loss improved from inf to 1.87838, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f59beee5978>_Batch25_LR0.1_Epochs25.hdf5\n",
            "595/595 [==============================] - 9s 15ms/step - loss: 1.8784 - accuracy: 0.3318 - val_loss: 1.4994 - val_accuracy: 0.3399\n",
            "Epoch 2/25\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5389 - accuracy: 0.3349\n",
            "Epoch 00002: loss improved from 1.87838 to 1.53868, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f59beee5978>_Batch25_LR0.1_Epochs25.hdf5\n",
            "595/595 [==============================] - 9s 14ms/step - loss: 1.5387 - accuracy: 0.3350 - val_loss: 1.5049 - val_accuracy: 0.3399\n",
            "Epoch 3/25\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5392 - accuracy: 0.3371\n",
            "Epoch 00003: loss did not improve from 1.53868\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5393 - accuracy: 0.3371 - val_loss: 1.5011 - val_accuracy: 0.3399\n",
            "Epoch 4/25\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5402 - accuracy: 0.3350\n",
            "Epoch 00004: loss did not improve from 1.53868\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5402 - accuracy: 0.3350 - val_loss: 1.4915 - val_accuracy: 0.3399\n",
            "Epoch 5/25\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5401 - accuracy: 0.3361\n",
            "Epoch 00005: loss did not improve from 1.53868\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5401 - accuracy: 0.3361 - val_loss: 1.5057 - val_accuracy: 0.3399\n",
            "Epoch 6/25\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5379 - accuracy: 0.3353\n",
            "Epoch 00006: loss improved from 1.53868 to 1.53809, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f59beee5978>_Batch25_LR0.1_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5381 - accuracy: 0.3352 - val_loss: 1.5420 - val_accuracy: 0.3399\n",
            "Epoch 7/25\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5385 - accuracy: 0.3364\n",
            "Epoch 00007: loss did not improve from 1.53809\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5385 - accuracy: 0.3364 - val_loss: 1.4961 - val_accuracy: 0.3399\n",
            "Epoch 8/25\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5392 - accuracy: 0.3366\n",
            "Epoch 00008: loss did not improve from 1.53809\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5393 - accuracy: 0.3365 - val_loss: 1.5192 - val_accuracy: 0.3022\n",
            "Epoch 9/25\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5373 - accuracy: 0.3354\n",
            "Epoch 00009: loss improved from 1.53809 to 1.53736, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f59beee5978>_Batch25_LR0.1_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5374 - accuracy: 0.3352 - val_loss: 1.5028 - val_accuracy: 0.3022\n",
            "Epoch 10/25\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5391 - accuracy: 0.3346\n",
            "Epoch 00010: loss did not improve from 1.53736\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5391 - accuracy: 0.3346 - val_loss: 1.4968 - val_accuracy: 0.3399\n",
            "Epoch 11/25\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5378 - accuracy: 0.3357\n",
            "Epoch 00011: loss did not improve from 1.53736\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5377 - accuracy: 0.3360 - val_loss: 1.4977 - val_accuracy: 0.3399\n",
            "Epoch 12/25\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5391 - accuracy: 0.3364\n",
            "Epoch 00012: loss did not improve from 1.53736\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5391 - accuracy: 0.3365 - val_loss: 1.5129 - val_accuracy: 0.3399\n",
            "Epoch 13/25\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5384 - accuracy: 0.3349\n",
            "Epoch 00013: loss did not improve from 1.53736\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5385 - accuracy: 0.3350 - val_loss: 1.4928 - val_accuracy: 0.3399\n",
            "Epoch 14/25\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5377 - accuracy: 0.3335\n",
            "Epoch 00014: loss did not improve from 1.53736\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5377 - accuracy: 0.3330 - val_loss: 1.4991 - val_accuracy: 0.3022\n",
            "Epoch 15/25\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5387 - accuracy: 0.3345\n",
            "Epoch 00015: loss did not improve from 1.53736\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5386 - accuracy: 0.3346 - val_loss: 1.5230 - val_accuracy: 0.3399\n",
            "Epoch 16/25\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5385 - accuracy: 0.3353\n",
            "Epoch 00016: loss did not improve from 1.53736\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5388 - accuracy: 0.3351 - val_loss: 1.5194 - val_accuracy: 0.3399\n",
            "Epoch 17/25\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5385 - accuracy: 0.3355\n",
            "Epoch 00017: loss did not improve from 1.53736\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5390 - accuracy: 0.3350 - val_loss: 1.5304 - val_accuracy: 0.3399\n",
            "Epoch 18/25\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5398 - accuracy: 0.3348\n",
            "Epoch 00018: loss did not improve from 1.53736\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5399 - accuracy: 0.3348 - val_loss: 1.4900 - val_accuracy: 0.3399\n",
            "Epoch 19/25\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5393 - accuracy: 0.3346\n",
            "Epoch 00019: loss did not improve from 1.53736\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5399 - accuracy: 0.3346 - val_loss: 1.4903 - val_accuracy: 0.3399\n",
            "Epoch 20/25\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5390 - accuracy: 0.3349\n",
            "Epoch 00020: loss did not improve from 1.53736\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5390 - accuracy: 0.3349 - val_loss: 1.5239 - val_accuracy: 0.3399\n",
            "Epoch 21/25\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5383 - accuracy: 0.3354\n",
            "Epoch 00021: loss did not improve from 1.53736\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5385 - accuracy: 0.3358 - val_loss: 1.5022 - val_accuracy: 0.3399\n",
            "Epoch 22/25\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5387 - accuracy: 0.3363\n",
            "Epoch 00022: loss did not improve from 1.53736\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5385 - accuracy: 0.3367 - val_loss: 1.4938 - val_accuracy: 0.3399\n",
            "Epoch 23/25\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5402 - accuracy: 0.3379\n",
            "Epoch 00023: loss did not improve from 1.53736\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5400 - accuracy: 0.3381 - val_loss: 1.5240 - val_accuracy: 0.3399\n",
            "Epoch 24/25\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5399 - accuracy: 0.3337\n",
            "Epoch 00024: loss did not improve from 1.53736\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5397 - accuracy: 0.3336 - val_loss: 1.4899 - val_accuracy: 0.3399\n",
            "Epoch 25/25\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5388 - accuracy: 0.3331\n",
            "Epoch 00025: loss did not improve from 1.53736\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5388 - accuracy: 0.3331 - val_loss: 1.5058 - val_accuracy: 0.3399\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/25\n",
            "  2/595 [..............................] - ETA: 34s - loss: 9.3191 - accuracy: 0.2000WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0168s vs `on_train_batch_end` time: 0.0999s). Check your callbacks.\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.6430 - accuracy: 0.3368\n",
            "Epoch 00001: loss improved from inf to 1.64303, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f59bed616d8>_Batch25_LR0.1_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.6430 - accuracy: 0.3368 - val_loss: 1.5229 - val_accuracy: 0.3399\n",
            "Epoch 2/25\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5355 - accuracy: 0.3358\n",
            "Epoch 00002: loss improved from 1.64303 to 1.53606, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f59bed616d8>_Batch25_LR0.1_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5361 - accuracy: 0.3355 - val_loss: 1.5037 - val_accuracy: 0.3399\n",
            "Epoch 3/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5376 - accuracy: 0.3331\n",
            "Epoch 00003: loss did not improve from 1.53606\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5375 - accuracy: 0.3332 - val_loss: 1.4957 - val_accuracy: 0.3399\n",
            "Epoch 4/25\n",
            "589/595 [============================>.] - ETA: 0s - loss: 1.5373 - accuracy: 0.3360\n",
            "Epoch 00004: loss did not improve from 1.53606\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5374 - accuracy: 0.3365 - val_loss: 1.5086 - val_accuracy: 0.3399\n",
            "Epoch 5/25\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5375 - accuracy: 0.3362\n",
            "Epoch 00005: loss did not improve from 1.53606\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5375 - accuracy: 0.3363 - val_loss: 1.4962 - val_accuracy: 0.3399\n",
            "Epoch 6/25\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5397 - accuracy: 0.3355\n",
            "Epoch 00006: loss did not improve from 1.53606\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5397 - accuracy: 0.3355 - val_loss: 1.5431 - val_accuracy: 0.3399\n",
            "Epoch 7/25\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5372 - accuracy: 0.3420\n",
            "Epoch 00007: loss did not improve from 1.53606\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5372 - accuracy: 0.3420 - val_loss: 1.4936 - val_accuracy: 0.3399\n",
            "Epoch 8/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5368 - accuracy: 0.3328\n",
            "Epoch 00008: loss did not improve from 1.53606\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5368 - accuracy: 0.3331 - val_loss: 1.4984 - val_accuracy: 0.3399\n",
            "Epoch 9/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5370 - accuracy: 0.3326\n",
            "Epoch 00009: loss did not improve from 1.53606\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5372 - accuracy: 0.3324 - val_loss: 1.4971 - val_accuracy: 0.3399\n",
            "Epoch 10/25\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5377 - accuracy: 0.3383\n",
            "Epoch 00010: loss did not improve from 1.53606\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5379 - accuracy: 0.3381 - val_loss: 1.5014 - val_accuracy: 0.3399\n",
            "Epoch 11/25\n",
            "589/595 [============================>.] - ETA: 0s - loss: 1.5373 - accuracy: 0.3362\n",
            "Epoch 00011: loss did not improve from 1.53606\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5371 - accuracy: 0.3364 - val_loss: 1.5107 - val_accuracy: 0.3399\n",
            "Epoch 12/25\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5362 - accuracy: 0.3387\n",
            "Epoch 00012: loss did not improve from 1.53606\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5361 - accuracy: 0.3389 - val_loss: 1.5404 - val_accuracy: 0.3399\n",
            "Epoch 13/25\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5357 - accuracy: 0.3388\n",
            "Epoch 00013: loss improved from 1.53606 to 1.53600, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f59bed616d8>_Batch25_LR0.1_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5360 - accuracy: 0.3385 - val_loss: 1.5036 - val_accuracy: 0.3399\n",
            "Epoch 14/25\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5370 - accuracy: 0.3368\n",
            "Epoch 00014: loss did not improve from 1.53600\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5371 - accuracy: 0.3369 - val_loss: 1.5017 - val_accuracy: 0.3399\n",
            "Epoch 15/25\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5364 - accuracy: 0.3370\n",
            "Epoch 00015: loss did not improve from 1.53600\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5365 - accuracy: 0.3368 - val_loss: 1.4927 - val_accuracy: 0.3399\n",
            "Epoch 16/25\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5391 - accuracy: 0.3318\n",
            "Epoch 00016: loss did not improve from 1.53600\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5396 - accuracy: 0.3315 - val_loss: 1.5038 - val_accuracy: 0.3399\n",
            "Epoch 17/25\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5377 - accuracy: 0.3361\n",
            "Epoch 00017: loss did not improve from 1.53600\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5375 - accuracy: 0.3365 - val_loss: 1.5100 - val_accuracy: 0.3399\n",
            "Epoch 18/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5371 - accuracy: 0.3326\n",
            "Epoch 00018: loss did not improve from 1.53600\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5374 - accuracy: 0.3326 - val_loss: 1.5012 - val_accuracy: 0.3399\n",
            "Epoch 19/25\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5364 - accuracy: 0.3367\n",
            "Epoch 00019: loss did not improve from 1.53600\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5364 - accuracy: 0.3367 - val_loss: 1.4994 - val_accuracy: 0.3022\n",
            "Epoch 20/25\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5381 - accuracy: 0.3343\n",
            "Epoch 00020: loss did not improve from 1.53600\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5381 - accuracy: 0.3344 - val_loss: 1.4956 - val_accuracy: 0.3399\n",
            "Epoch 21/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5366 - accuracy: 0.3376\n",
            "Epoch 00021: loss did not improve from 1.53600\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5368 - accuracy: 0.3378 - val_loss: 1.5114 - val_accuracy: 0.3399\n",
            "Epoch 22/25\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5379 - accuracy: 0.3362\n",
            "Epoch 00022: loss did not improve from 1.53600\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5378 - accuracy: 0.3363 - val_loss: 1.4975 - val_accuracy: 0.3399\n",
            "Epoch 23/25\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5374 - accuracy: 0.3362\n",
            "Epoch 00023: loss did not improve from 1.53600\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5374 - accuracy: 0.3362 - val_loss: 1.4947 - val_accuracy: 0.3399\n",
            "Epoch 24/25\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5363 - accuracy: 0.3410\n",
            "Epoch 00024: loss did not improve from 1.53600\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5367 - accuracy: 0.3406 - val_loss: 1.5083 - val_accuracy: 0.3399\n",
            "Epoch 25/25\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5376 - accuracy: 0.3354\n",
            "Epoch 00025: loss did not improve from 1.53600\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5375 - accuracy: 0.3353 - val_loss: 1.4928 - val_accuracy: 0.3399\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/25\n",
            "  2/595 [..............................] - ETA: 33s - loss: 3.6261 - accuracy: 0.0600   WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0144s vs `on_train_batch_end` time: 0.0973s). Check your callbacks.\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5532 - accuracy: 0.3406\n",
            "Epoch 00001: loss improved from inf to 1.55321, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59bf042630>_Batch25_LR0.1_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5532 - accuracy: 0.3406 - val_loss: 1.4941 - val_accuracy: 0.3399\n",
            "Epoch 2/25\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5320 - accuracy: 0.3419\n",
            "Epoch 00002: loss improved from 1.55321 to 1.53175, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59bf042630>_Batch25_LR0.1_Epochs25.hdf5\n",
            "595/595 [==============================] - 9s 14ms/step - loss: 1.5317 - accuracy: 0.3417 - val_loss: 1.4948 - val_accuracy: 0.3399\n",
            "Epoch 3/25\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5314 - accuracy: 0.3430\n",
            "Epoch 00003: loss improved from 1.53175 to 1.53146, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59bf042630>_Batch25_LR0.1_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5315 - accuracy: 0.3429 - val_loss: 1.4928 - val_accuracy: 0.3399\n",
            "Epoch 4/25\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5296 - accuracy: 0.3435\n",
            "Epoch 00004: loss improved from 1.53146 to 1.52946, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59bf042630>_Batch25_LR0.1_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5295 - accuracy: 0.3434 - val_loss: 1.5025 - val_accuracy: 0.3399\n",
            "Epoch 5/25\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5285 - accuracy: 0.3436\n",
            "Epoch 00005: loss improved from 1.52946 to 1.52846, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59bf042630>_Batch25_LR0.1_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5285 - accuracy: 0.3436 - val_loss: 1.5008 - val_accuracy: 0.3399\n",
            "Epoch 6/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5273 - accuracy: 0.3438\n",
            "Epoch 00006: loss improved from 1.52846 to 1.52747, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59bf042630>_Batch25_LR0.1_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5275 - accuracy: 0.3436 - val_loss: 1.4985 - val_accuracy: 0.3399\n",
            "Epoch 7/25\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5280 - accuracy: 0.3428\n",
            "Epoch 00007: loss improved from 1.52747 to 1.52710, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59bf042630>_Batch25_LR0.1_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5271 - accuracy: 0.3436 - val_loss: 1.4995 - val_accuracy: 0.3399\n",
            "Epoch 8/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5249 - accuracy: 0.3439\n",
            "Epoch 00008: loss improved from 1.52710 to 1.52520, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59bf042630>_Batch25_LR0.1_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5252 - accuracy: 0.3437 - val_loss: 1.5021 - val_accuracy: 0.3399\n",
            "Epoch 9/25\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5242 - accuracy: 0.3437\n",
            "Epoch 00009: loss improved from 1.52520 to 1.52397, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59bf042630>_Batch25_LR0.1_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5240 - accuracy: 0.3435 - val_loss: 1.4984 - val_accuracy: 0.3399\n",
            "Epoch 10/25\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5233 - accuracy: 0.3432\n",
            "Epoch 00010: loss improved from 1.52397 to 1.52304, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59bf042630>_Batch25_LR0.1_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5230 - accuracy: 0.3436 - val_loss: 1.5028 - val_accuracy: 0.3399\n",
            "Epoch 11/25\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5223 - accuracy: 0.3436\n",
            "Epoch 00011: loss improved from 1.52304 to 1.52224, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59bf042630>_Batch25_LR0.1_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5222 - accuracy: 0.3435 - val_loss: 1.4970 - val_accuracy: 0.3399\n",
            "Epoch 12/25\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5214 - accuracy: 0.3432\n",
            "Epoch 00012: loss improved from 1.52224 to 1.52139, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59bf042630>_Batch25_LR0.1_Epochs25.hdf5\n",
            "595/595 [==============================] - 9s 15ms/step - loss: 1.5214 - accuracy: 0.3432 - val_loss: 1.5031 - val_accuracy: 0.3399\n",
            "Epoch 13/25\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5191 - accuracy: 0.3440\n",
            "Epoch 00013: loss improved from 1.52139 to 1.51914, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59bf042630>_Batch25_LR0.1_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5191 - accuracy: 0.3436 - val_loss: 1.4992 - val_accuracy: 0.3399\n",
            "Epoch 14/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5184 - accuracy: 0.3431\n",
            "Epoch 00014: loss improved from 1.51914 to 1.51822, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59bf042630>_Batch25_LR0.1_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5182 - accuracy: 0.3432 - val_loss: 1.4970 - val_accuracy: 0.3399\n",
            "Epoch 15/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5184 - accuracy: 0.3427\n",
            "Epoch 00015: loss did not improve from 1.51822\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5185 - accuracy: 0.3429 - val_loss: 1.4963 - val_accuracy: 0.3399\n",
            "Epoch 16/25\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5157 - accuracy: 0.3436\n",
            "Epoch 00016: loss improved from 1.51822 to 1.51597, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59bf042630>_Batch25_LR0.1_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5160 - accuracy: 0.3434 - val_loss: 1.4996 - val_accuracy: 0.3399\n",
            "Epoch 17/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5161 - accuracy: 0.3435\n",
            "Epoch 00017: loss improved from 1.51597 to 1.51586, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59bf042630>_Batch25_LR0.1_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5159 - accuracy: 0.3436 - val_loss: 1.5035 - val_accuracy: 0.3399\n",
            "Epoch 18/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5164 - accuracy: 0.3436\n",
            "Epoch 00018: loss did not improve from 1.51586\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5167 - accuracy: 0.3432 - val_loss: 1.4981 - val_accuracy: 0.3399\n",
            "Epoch 19/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5156 - accuracy: 0.3439\n",
            "Epoch 00019: loss did not improve from 1.51586\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5159 - accuracy: 0.3436 - val_loss: 1.4948 - val_accuracy: 0.3262\n",
            "Epoch 20/25\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5148 - accuracy: 0.3444\n",
            "Epoch 00020: loss improved from 1.51586 to 1.51493, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59bf042630>_Batch25_LR0.1_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5149 - accuracy: 0.3444 - val_loss: 1.5132 - val_accuracy: 0.3410\n",
            "Epoch 21/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5143 - accuracy: 0.3437\n",
            "Epoch 00021: loss improved from 1.51493 to 1.51429, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59bf042630>_Batch25_LR0.1_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5143 - accuracy: 0.3437 - val_loss: 1.5013 - val_accuracy: 0.3399\n",
            "Epoch 22/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5138 - accuracy: 0.3447\n",
            "Epoch 00022: loss improved from 1.51429 to 1.51322, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59bf042630>_Batch25_LR0.1_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5132 - accuracy: 0.3451 - val_loss: 1.5113 - val_accuracy: 0.3402\n",
            "Epoch 23/25\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5127 - accuracy: 0.3459\n",
            "Epoch 00023: loss improved from 1.51322 to 1.51262, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59bf042630>_Batch25_LR0.1_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5126 - accuracy: 0.3461 - val_loss: 1.5067 - val_accuracy: 0.3399\n",
            "Epoch 24/25\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5126 - accuracy: 0.3453\n",
            "Epoch 00024: loss improved from 1.51262 to 1.51238, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59bf042630>_Batch25_LR0.1_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5124 - accuracy: 0.3455 - val_loss: 1.5047 - val_accuracy: 0.3385\n",
            "Epoch 25/25\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5120 - accuracy: 0.3444\n",
            "Epoch 00025: loss improved from 1.51238 to 1.51176, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59bf042630>_Batch25_LR0.1_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5118 - accuracy: 0.3444 - val_loss: 1.5084 - val_accuracy: 0.3410\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/25\n",
            "  2/595 [..............................] - ETA: 51s - loss: 14.8021 - accuracy: 0.1600WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0148s vs `on_train_batch_end` time: 0.1619s). Check your callbacks.\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.6659 - accuracy: 0.3361\n",
            "Epoch 00001: loss improved from inf to 1.66466, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f59c45e9fd0>_Batch25_LR0.1_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.6647 - accuracy: 0.3366 - val_loss: 1.4979 - val_accuracy: 0.3399\n",
            "Epoch 2/25\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5303 - accuracy: 0.3437\n",
            "Epoch 00002: loss improved from 1.66466 to 1.53024, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f59c45e9fd0>_Batch25_LR0.1_Epochs25.hdf5\n",
            "595/595 [==============================] - 9s 14ms/step - loss: 1.5302 - accuracy: 0.3436 - val_loss: 1.4979 - val_accuracy: 0.3399\n",
            "Epoch 3/25\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5308 - accuracy: 0.3396\n",
            "Epoch 00003: loss did not improve from 1.53024\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5309 - accuracy: 0.3395 - val_loss: 1.5025 - val_accuracy: 0.3399\n",
            "Epoch 4/25\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5315 - accuracy: 0.3407\n",
            "Epoch 00004: loss did not improve from 1.53024\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5316 - accuracy: 0.3408 - val_loss: 1.4961 - val_accuracy: 0.3399\n",
            "Epoch 5/25\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5309 - accuracy: 0.3401\n",
            "Epoch 00005: loss did not improve from 1.53024\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5307 - accuracy: 0.3404 - val_loss: 1.4961 - val_accuracy: 0.3399\n",
            "Epoch 6/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5313 - accuracy: 0.3434\n",
            "Epoch 00006: loss did not improve from 1.53024\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5312 - accuracy: 0.3436 - val_loss: 1.4991 - val_accuracy: 0.3399\n",
            "Epoch 7/25\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5309 - accuracy: 0.3436\n",
            "Epoch 00007: loss did not improve from 1.53024\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5309 - accuracy: 0.3436 - val_loss: 1.4947 - val_accuracy: 0.3399\n",
            "Epoch 8/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5312 - accuracy: 0.3439\n",
            "Epoch 00008: loss did not improve from 1.53024\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5311 - accuracy: 0.3436 - val_loss: 1.5021 - val_accuracy: 0.3399\n",
            "Epoch 9/25\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5319 - accuracy: 0.3423\n",
            "Epoch 00009: loss did not improve from 1.53024\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5317 - accuracy: 0.3422 - val_loss: 1.4939 - val_accuracy: 0.3399\n",
            "Epoch 10/25\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5324 - accuracy: 0.3436\n",
            "Epoch 00010: loss did not improve from 1.53024\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5324 - accuracy: 0.3436 - val_loss: 1.4992 - val_accuracy: 0.3399\n",
            "Epoch 11/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5306 - accuracy: 0.3435\n",
            "Epoch 00011: loss did not improve from 1.53024\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5307 - accuracy: 0.3436 - val_loss: 1.5000 - val_accuracy: 0.3399\n",
            "Epoch 12/25\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5319 - accuracy: 0.3423\n",
            "Epoch 00012: loss did not improve from 1.53024\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5319 - accuracy: 0.3427 - val_loss: 1.4903 - val_accuracy: 0.3399\n",
            "Epoch 13/25\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5309 - accuracy: 0.3426\n",
            "Epoch 00013: loss did not improve from 1.53024\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5314 - accuracy: 0.3424 - val_loss: 1.5094 - val_accuracy: 0.3399\n",
            "Epoch 14/25\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5320 - accuracy: 0.3433\n",
            "Epoch 00014: loss did not improve from 1.53024\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5319 - accuracy: 0.3436 - val_loss: 1.4959 - val_accuracy: 0.3399\n",
            "Epoch 15/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5322 - accuracy: 0.3422\n",
            "Epoch 00015: loss did not improve from 1.53024\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5320 - accuracy: 0.3422 - val_loss: 1.5034 - val_accuracy: 0.3399\n",
            "Epoch 16/25\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5321 - accuracy: 0.3426\n",
            "Epoch 00016: loss did not improve from 1.53024\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5317 - accuracy: 0.3428 - val_loss: 1.4961 - val_accuracy: 0.3399\n",
            "Epoch 17/25\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5315 - accuracy: 0.3438\n",
            "Epoch 00017: loss did not improve from 1.53024\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5316 - accuracy: 0.3436 - val_loss: 1.5029 - val_accuracy: 0.3399\n",
            "Epoch 18/25\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5317 - accuracy: 0.3421\n",
            "Epoch 00018: loss did not improve from 1.53024\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5315 - accuracy: 0.3424 - val_loss: 1.4906 - val_accuracy: 0.3399\n",
            "Epoch 19/25\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5315 - accuracy: 0.3428\n",
            "Epoch 00019: loss did not improve from 1.53024\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5316 - accuracy: 0.3424 - val_loss: 1.4917 - val_accuracy: 0.3399\n",
            "Epoch 20/25\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5312 - accuracy: 0.3430\n",
            "Epoch 00020: loss did not improve from 1.53024\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5313 - accuracy: 0.3430 - val_loss: 1.4960 - val_accuracy: 0.3399\n",
            "Epoch 21/25\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5320 - accuracy: 0.3373\n",
            "Epoch 00021: loss did not improve from 1.53024\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5319 - accuracy: 0.3375 - val_loss: 1.5046 - val_accuracy: 0.3399\n",
            "Epoch 22/25\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5317 - accuracy: 0.3393\n",
            "Epoch 00022: loss did not improve from 1.53024\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5317 - accuracy: 0.3397 - val_loss: 1.5141 - val_accuracy: 0.3399\n",
            "Epoch 23/25\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5317 - accuracy: 0.3436\n",
            "Epoch 00023: loss did not improve from 1.53024\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5316 - accuracy: 0.3436 - val_loss: 1.4998 - val_accuracy: 0.3399\n",
            "Epoch 24/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5311 - accuracy: 0.3417\n",
            "Epoch 00024: loss did not improve from 1.53024\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5309 - accuracy: 0.3418 - val_loss: 1.5043 - val_accuracy: 0.3399\n",
            "Epoch 25/25\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5315 - accuracy: 0.3433\n",
            "Epoch 00025: loss did not improve from 1.53024\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5313 - accuracy: 0.3436 - val_loss: 1.5071 - val_accuracy: 0.3399\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/25\n",
            "  2/595 [..............................] - ETA: 34s - loss: 2.0317 - accuracy: 0.2000WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0144s vs `on_train_batch_end` time: 0.1007s). Check your callbacks.\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5444 - accuracy: 0.3372\n",
            "Epoch 00001: loss improved from inf to 1.54445, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f59bebb3f60>_Batch25_LR0.1_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5445 - accuracy: 0.3372 - val_loss: 1.4944 - val_accuracy: 0.3399\n",
            "Epoch 2/25\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5341 - accuracy: 0.3412\n",
            "Epoch 00002: loss improved from 1.54445 to 1.53384, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f59bebb3f60>_Batch25_LR0.1_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5338 - accuracy: 0.3414 - val_loss: 1.4945 - val_accuracy: 0.3399\n",
            "Epoch 3/25\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5304 - accuracy: 0.3422\n",
            "Epoch 00003: loss improved from 1.53384 to 1.53029, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f59bebb3f60>_Batch25_LR0.1_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5303 - accuracy: 0.3423 - val_loss: 1.4987 - val_accuracy: 0.3399\n",
            "Epoch 4/25\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5280 - accuracy: 0.3436\n",
            "Epoch 00004: loss improved from 1.53029 to 1.52804, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f59bebb3f60>_Batch25_LR0.1_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5280 - accuracy: 0.3436 - val_loss: 1.5025 - val_accuracy: 0.3399\n",
            "Epoch 5/25\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5285 - accuracy: 0.3435\n",
            "Epoch 00005: loss did not improve from 1.52804\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5285 - accuracy: 0.3435 - val_loss: 1.4985 - val_accuracy: 0.3399\n",
            "Epoch 6/25\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5259 - accuracy: 0.3437\n",
            "Epoch 00006: loss improved from 1.52804 to 1.52648, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f59bebb3f60>_Batch25_LR0.1_Epochs25.hdf5\n",
            "595/595 [==============================] - 9s 15ms/step - loss: 1.5265 - accuracy: 0.3436 - val_loss: 1.5180 - val_accuracy: 0.3399\n",
            "Epoch 7/25\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5252 - accuracy: 0.3436\n",
            "Epoch 00007: loss improved from 1.52648 to 1.52508, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f59bebb3f60>_Batch25_LR0.1_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5251 - accuracy: 0.3436 - val_loss: 1.5060 - val_accuracy: 0.3399\n",
            "Epoch 8/25\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5244 - accuracy: 0.3435\n",
            "Epoch 00008: loss improved from 1.52508 to 1.52425, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f59bebb3f60>_Batch25_LR0.1_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5243 - accuracy: 0.3436 - val_loss: 1.4930 - val_accuracy: 0.3399\n",
            "Epoch 9/25\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5230 - accuracy: 0.3437\n",
            "Epoch 00009: loss improved from 1.52425 to 1.52300, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f59bebb3f60>_Batch25_LR0.1_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5230 - accuracy: 0.3436 - val_loss: 1.4994 - val_accuracy: 0.3399\n",
            "Epoch 10/25\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5208 - accuracy: 0.3431\n",
            "Epoch 00010: loss improved from 1.52300 to 1.52039, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f59bebb3f60>_Batch25_LR0.1_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5204 - accuracy: 0.3434 - val_loss: 1.4962 - val_accuracy: 0.3399\n",
            "Epoch 11/25\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5208 - accuracy: 0.3438\n",
            "Epoch 00011: loss did not improve from 1.52039\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5206 - accuracy: 0.3442 - val_loss: 1.4993 - val_accuracy: 0.3399\n",
            "Epoch 12/25\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5202 - accuracy: 0.3434\n",
            "Epoch 00012: loss improved from 1.52039 to 1.52011, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f59bebb3f60>_Batch25_LR0.1_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5201 - accuracy: 0.3435 - val_loss: 1.5054 - val_accuracy: 0.3399\n",
            "Epoch 13/25\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5193 - accuracy: 0.3434\n",
            "Epoch 00013: loss improved from 1.52011 to 1.51957, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f59bebb3f60>_Batch25_LR0.1_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5196 - accuracy: 0.3432 - val_loss: 1.5074 - val_accuracy: 0.3399\n",
            "Epoch 14/25\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5184 - accuracy: 0.3439\n",
            "Epoch 00014: loss improved from 1.51957 to 1.51878, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f59bebb3f60>_Batch25_LR0.1_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5188 - accuracy: 0.3440 - val_loss: 1.5065 - val_accuracy: 0.3399\n",
            "Epoch 15/25\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5180 - accuracy: 0.3433\n",
            "Epoch 00015: loss improved from 1.51878 to 1.51763, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f59bebb3f60>_Batch25_LR0.1_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5176 - accuracy: 0.3439 - val_loss: 1.5077 - val_accuracy: 0.3399\n",
            "Epoch 16/25\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5166 - accuracy: 0.3436\n",
            "Epoch 00016: loss improved from 1.51763 to 1.51656, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f59bebb3f60>_Batch25_LR0.1_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5166 - accuracy: 0.3439 - val_loss: 1.5037 - val_accuracy: 0.3399\n",
            "Epoch 17/25\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5146 - accuracy: 0.3444\n",
            "Epoch 00017: loss improved from 1.51656 to 1.51479, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f59bebb3f60>_Batch25_LR0.1_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5148 - accuracy: 0.3443 - val_loss: 1.5019 - val_accuracy: 0.3399\n",
            "Epoch 18/25\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5148 - accuracy: 0.3447\n",
            "Epoch 00018: loss improved from 1.51479 to 1.51468, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f59bebb3f60>_Batch25_LR0.1_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5147 - accuracy: 0.3448 - val_loss: 1.5070 - val_accuracy: 0.3399\n",
            "Epoch 19/25\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5148 - accuracy: 0.3456\n",
            "Epoch 00019: loss did not improve from 1.51468\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5147 - accuracy: 0.3455 - val_loss: 1.4981 - val_accuracy: 0.3399\n",
            "Epoch 20/25\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5139 - accuracy: 0.3437\n",
            "Epoch 00020: loss improved from 1.51468 to 1.51410, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f59bebb3f60>_Batch25_LR0.1_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5141 - accuracy: 0.3434 - val_loss: 1.5058 - val_accuracy: 0.3399\n",
            "Epoch 21/25\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5142 - accuracy: 0.3446\n",
            "Epoch 00021: loss improved from 1.51410 to 1.51384, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f59bebb3f60>_Batch25_LR0.1_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5138 - accuracy: 0.3447 - val_loss: 1.5191 - val_accuracy: 0.3348\n",
            "Epoch 22/25\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5117 - accuracy: 0.3433\n",
            "Epoch 00022: loss improved from 1.51384 to 1.51178, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f59bebb3f60>_Batch25_LR0.1_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5118 - accuracy: 0.3432 - val_loss: 1.5181 - val_accuracy: 0.3407\n",
            "Epoch 23/25\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5117 - accuracy: 0.3442\n",
            "Epoch 00023: loss did not improve from 1.51178\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5123 - accuracy: 0.3439 - val_loss: 1.5160 - val_accuracy: 0.3407\n",
            "Epoch 24/25\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5112 - accuracy: 0.3427\n",
            "Epoch 00024: loss improved from 1.51178 to 1.51093, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f59bebb3f60>_Batch25_LR0.1_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5109 - accuracy: 0.3432 - val_loss: 1.5018 - val_accuracy: 0.3399\n",
            "Epoch 25/25\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5110 - accuracy: 0.3419\n",
            "Epoch 00025: loss did not improve from 1.51093\n",
            "595/595 [==============================] - 7s 12ms/step - loss: 1.5110 - accuracy: 0.3419 - val_loss: 1.4985 - val_accuracy: 0.3399\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/50\n",
            "  2/595 [..............................] - ETA: 42s - loss: 2.3351 - accuracy: 0.0600WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0154s vs `on_train_batch_end` time: 0.1259s). Check your callbacks.\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.6065 - accuracy: 0.3098\n",
            "Epoch 00001: loss improved from inf to 1.60648, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59b97fbf28>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.6065 - accuracy: 0.3095 - val_loss: 1.5196 - val_accuracy: 0.3399\n",
            "Epoch 2/50\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5625 - accuracy: 0.3265\n",
            "Epoch 00002: loss improved from 1.60648 to 1.56251, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59b97fbf28>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5625 - accuracy: 0.3265 - val_loss: 1.5098 - val_accuracy: 0.3399\n",
            "Epoch 3/50\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5525 - accuracy: 0.3343\n",
            "Epoch 00003: loss improved from 1.56251 to 1.55234, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59b97fbf28>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5523 - accuracy: 0.3342 - val_loss: 1.5095 - val_accuracy: 0.3399\n",
            "Epoch 4/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5487 - accuracy: 0.3321\n",
            "Epoch 00004: loss improved from 1.55234 to 1.54854, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59b97fbf28>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5485 - accuracy: 0.3321 - val_loss: 1.5078 - val_accuracy: 0.3399\n",
            "Epoch 5/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5428 - accuracy: 0.3359\n",
            "Epoch 00005: loss improved from 1.54854 to 1.54251, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59b97fbf28>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5425 - accuracy: 0.3362 - val_loss: 1.5071 - val_accuracy: 0.3399\n",
            "Epoch 6/50\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5403 - accuracy: 0.3355\n",
            "Epoch 00006: loss improved from 1.54251 to 1.54046, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59b97fbf28>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5405 - accuracy: 0.3355 - val_loss: 1.5058 - val_accuracy: 0.3399\n",
            "Epoch 7/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5391 - accuracy: 0.3374\n",
            "Epoch 00007: loss improved from 1.54046 to 1.53896, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59b97fbf28>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5390 - accuracy: 0.3376 - val_loss: 1.5050 - val_accuracy: 0.3399\n",
            "Epoch 8/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5379 - accuracy: 0.3426\n",
            "Epoch 00008: loss improved from 1.53896 to 1.53789, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59b97fbf28>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5379 - accuracy: 0.3425 - val_loss: 1.5012 - val_accuracy: 0.3399\n",
            "Epoch 9/50\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5368 - accuracy: 0.3389\n",
            "Epoch 00009: loss improved from 1.53789 to 1.53665, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59b97fbf28>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5366 - accuracy: 0.3389 - val_loss: 1.5054 - val_accuracy: 0.3399\n",
            "Epoch 10/50\n",
            "589/595 [============================>.] - ETA: 0s - loss: 1.5375 - accuracy: 0.3357\n",
            "Epoch 00010: loss did not improve from 1.53665\n",
            "595/595 [==============================] - 7s 12ms/step - loss: 1.5369 - accuracy: 0.3362 - val_loss: 1.5060 - val_accuracy: 0.3399\n",
            "Epoch 11/50\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5350 - accuracy: 0.3386\n",
            "Epoch 00011: loss improved from 1.53665 to 1.53507, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59b97fbf28>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5351 - accuracy: 0.3385 - val_loss: 1.5057 - val_accuracy: 0.3399\n",
            "Epoch 12/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5320 - accuracy: 0.3431\n",
            "Epoch 00012: loss improved from 1.53507 to 1.53211, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59b97fbf28>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5321 - accuracy: 0.3430 - val_loss: 1.5056 - val_accuracy: 0.3399\n",
            "Epoch 13/50\n",
            "589/595 [============================>.] - ETA: 0s - loss: 1.5311 - accuracy: 0.3410\n",
            "Epoch 00013: loss improved from 1.53211 to 1.53190, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59b97fbf28>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5319 - accuracy: 0.3402 - val_loss: 1.5020 - val_accuracy: 0.3399\n",
            "Epoch 14/50\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5342 - accuracy: 0.3392\n",
            "Epoch 00014: loss did not improve from 1.53190\n",
            "595/595 [==============================] - 7s 12ms/step - loss: 1.5340 - accuracy: 0.3391 - val_loss: 1.5023 - val_accuracy: 0.3399\n",
            "Epoch 15/50\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5316 - accuracy: 0.3408\n",
            "Epoch 00015: loss improved from 1.53190 to 1.53089, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59b97fbf28>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5309 - accuracy: 0.3409 - val_loss: 1.4996 - val_accuracy: 0.3399\n",
            "Epoch 16/50\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5297 - accuracy: 0.3418\n",
            "Epoch 00016: loss improved from 1.53089 to 1.53003, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59b97fbf28>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5300 - accuracy: 0.3412 - val_loss: 1.5029 - val_accuracy: 0.3399\n",
            "Epoch 17/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5313 - accuracy: 0.3418\n",
            "Epoch 00017: loss did not improve from 1.53003\n",
            "595/595 [==============================] - 7s 13ms/step - loss: 1.5312 - accuracy: 0.3418 - val_loss: 1.5032 - val_accuracy: 0.3399\n",
            "Epoch 18/50\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5303 - accuracy: 0.3443\n",
            "Epoch 00018: loss did not improve from 1.53003\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5303 - accuracy: 0.3443 - val_loss: 1.5041 - val_accuracy: 0.3399\n",
            "Epoch 19/50\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5298 - accuracy: 0.3418\n",
            "Epoch 00019: loss improved from 1.53003 to 1.52972, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59b97fbf28>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5297 - accuracy: 0.3420 - val_loss: 1.4993 - val_accuracy: 0.3399\n",
            "Epoch 20/50\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5287 - accuracy: 0.3397\n",
            "Epoch 00020: loss improved from 1.52972 to 1.52872, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59b97fbf28>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5287 - accuracy: 0.3397 - val_loss: 1.5041 - val_accuracy: 0.3399\n",
            "Epoch 21/50\n",
            "589/595 [============================>.] - ETA: 0s - loss: 1.5303 - accuracy: 0.3444\n",
            "Epoch 00021: loss did not improve from 1.52872\n",
            "595/595 [==============================] - 7s 12ms/step - loss: 1.5300 - accuracy: 0.3442 - val_loss: 1.4988 - val_accuracy: 0.3399\n",
            "Epoch 22/50\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5288 - accuracy: 0.3429\n",
            "Epoch 00022: loss did not improve from 1.52872\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5288 - accuracy: 0.3430 - val_loss: 1.4982 - val_accuracy: 0.3399\n",
            "Epoch 23/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5276 - accuracy: 0.3426\n",
            "Epoch 00023: loss improved from 1.52872 to 1.52765, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59b97fbf28>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5277 - accuracy: 0.3424 - val_loss: 1.5030 - val_accuracy: 0.3399\n",
            "Epoch 24/50\n",
            "589/595 [============================>.] - ETA: 0s - loss: 1.5279 - accuracy: 0.3428\n",
            "Epoch 00024: loss did not improve from 1.52765\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5277 - accuracy: 0.3433 - val_loss: 1.5051 - val_accuracy: 0.3399\n",
            "Epoch 25/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5270 - accuracy: 0.3421\n",
            "Epoch 00025: loss improved from 1.52765 to 1.52694, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59b97fbf28>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5269 - accuracy: 0.3420 - val_loss: 1.5011 - val_accuracy: 0.3399\n",
            "Epoch 26/50\n",
            "589/595 [============================>.] - ETA: 0s - loss: 1.5272 - accuracy: 0.3429\n",
            "Epoch 00026: loss did not improve from 1.52694\n",
            "595/595 [==============================] - 7s 13ms/step - loss: 1.5273 - accuracy: 0.3431 - val_loss: 1.5014 - val_accuracy: 0.3399\n",
            "Epoch 27/50\n",
            "589/595 [============================>.] - ETA: 0s - loss: 1.5279 - accuracy: 0.3432\n",
            "Epoch 00027: loss did not improve from 1.52694\n",
            "595/595 [==============================] - 7s 12ms/step - loss: 1.5280 - accuracy: 0.3434 - val_loss: 1.5021 - val_accuracy: 0.3399\n",
            "Epoch 28/50\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5270 - accuracy: 0.3426\n",
            "Epoch 00028: loss did not improve from 1.52694\n",
            "595/595 [==============================] - 7s 12ms/step - loss: 1.5271 - accuracy: 0.3429 - val_loss: 1.5011 - val_accuracy: 0.3399\n",
            "Epoch 29/50\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5270 - accuracy: 0.3436\n",
            "Epoch 00029: loss improved from 1.52694 to 1.52684, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59b97fbf28>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5268 - accuracy: 0.3432 - val_loss: 1.4991 - val_accuracy: 0.3399\n",
            "Epoch 30/50\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5266 - accuracy: 0.3425\n",
            "Epoch 00030: loss did not improve from 1.52684\n",
            "595/595 [==============================] - 7s 13ms/step - loss: 1.5268 - accuracy: 0.3420 - val_loss: 1.4988 - val_accuracy: 0.3399\n",
            "Epoch 31/50\n",
            "589/595 [============================>.] - ETA: 0s - loss: 1.5278 - accuracy: 0.3429\n",
            "Epoch 00031: loss did not improve from 1.52684\n",
            "595/595 [==============================] - 7s 13ms/step - loss: 1.5274 - accuracy: 0.3432 - val_loss: 1.5006 - val_accuracy: 0.3399\n",
            "Epoch 32/50\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5273 - accuracy: 0.3425\n",
            "Epoch 00032: loss did not improve from 1.52684\n",
            "595/595 [==============================] - 7s 12ms/step - loss: 1.5276 - accuracy: 0.3428 - val_loss: 1.5044 - val_accuracy: 0.3399\n",
            "Epoch 33/50\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5244 - accuracy: 0.3437\n",
            "Epoch 00033: loss improved from 1.52684 to 1.52508, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59b97fbf28>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5251 - accuracy: 0.3437 - val_loss: 1.4996 - val_accuracy: 0.3399\n",
            "Epoch 34/50\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5272 - accuracy: 0.3422\n",
            "Epoch 00034: loss did not improve from 1.52508\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5274 - accuracy: 0.3420 - val_loss: 1.5001 - val_accuracy: 0.3399\n",
            "Epoch 35/50\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5261 - accuracy: 0.3426\n",
            "Epoch 00035: loss did not improve from 1.52508\n",
            "595/595 [==============================] - 7s 12ms/step - loss: 1.5266 - accuracy: 0.3425 - val_loss: 1.5043 - val_accuracy: 0.3399\n",
            "Epoch 36/50\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5258 - accuracy: 0.3434\n",
            "Epoch 00036: loss did not improve from 1.52508\n",
            "595/595 [==============================] - 7s 13ms/step - loss: 1.5258 - accuracy: 0.3434 - val_loss: 1.5010 - val_accuracy: 0.3399\n",
            "Epoch 37/50\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5246 - accuracy: 0.3442\n",
            "Epoch 00037: loss improved from 1.52508 to 1.52491, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59b97fbf28>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5249 - accuracy: 0.3437 - val_loss: 1.4982 - val_accuracy: 0.3399\n",
            "Epoch 38/50\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5248 - accuracy: 0.3418\n",
            "Epoch 00038: loss improved from 1.52491 to 1.52474, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59b97fbf28>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5247 - accuracy: 0.3417 - val_loss: 1.4975 - val_accuracy: 0.3399\n",
            "Epoch 39/50\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5234 - accuracy: 0.3438\n",
            "Epoch 00039: loss improved from 1.52474 to 1.52315, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59b97fbf28>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5231 - accuracy: 0.3440 - val_loss: 1.4962 - val_accuracy: 0.3399\n",
            "Epoch 40/50\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5248 - accuracy: 0.3428\n",
            "Epoch 00040: loss did not improve from 1.52315\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5247 - accuracy: 0.3427 - val_loss: 1.4970 - val_accuracy: 0.3399\n",
            "Epoch 41/50\n",
            "589/595 [============================>.] - ETA: 0s - loss: 1.5243 - accuracy: 0.3432\n",
            "Epoch 00041: loss did not improve from 1.52315\n",
            "595/595 [==============================] - 7s 12ms/step - loss: 1.5243 - accuracy: 0.3435 - val_loss: 1.4986 - val_accuracy: 0.3399\n",
            "Epoch 42/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5257 - accuracy: 0.3423\n",
            "Epoch 00042: loss did not improve from 1.52315\n",
            "595/595 [==============================] - 7s 12ms/step - loss: 1.5256 - accuracy: 0.3423 - val_loss: 1.5012 - val_accuracy: 0.3399\n",
            "Epoch 43/50\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5237 - accuracy: 0.3427\n",
            "Epoch 00043: loss did not improve from 1.52315\n",
            "595/595 [==============================] - 7s 12ms/step - loss: 1.5237 - accuracy: 0.3426 - val_loss: 1.5006 - val_accuracy: 0.3399\n",
            "Epoch 44/50\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5234 - accuracy: 0.3437\n",
            "Epoch 00044: loss did not improve from 1.52315\n",
            "595/595 [==============================] - 7s 12ms/step - loss: 1.5233 - accuracy: 0.3436 - val_loss: 1.5021 - val_accuracy: 0.3399\n",
            "Epoch 45/50\n",
            "589/595 [============================>.] - ETA: 0s - loss: 1.5238 - accuracy: 0.3434\n",
            "Epoch 00045: loss did not improve from 1.52315\n",
            "595/595 [==============================] - 7s 12ms/step - loss: 1.5235 - accuracy: 0.3439 - val_loss: 1.5009 - val_accuracy: 0.3399\n",
            "Epoch 46/50\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5232 - accuracy: 0.3449\n",
            "Epoch 00046: loss did not improve from 1.52315\n",
            "595/595 [==============================] - 7s 12ms/step - loss: 1.5233 - accuracy: 0.3449 - val_loss: 1.5000 - val_accuracy: 0.3399\n",
            "Epoch 47/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5229 - accuracy: 0.3438\n",
            "Epoch 00047: loss improved from 1.52315 to 1.52275, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59b97fbf28>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5228 - accuracy: 0.3439 - val_loss: 1.4996 - val_accuracy: 0.3399\n",
            "Epoch 48/50\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5220 - accuracy: 0.3438\n",
            "Epoch 00048: loss improved from 1.52275 to 1.52268, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59b97fbf28>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5227 - accuracy: 0.3436 - val_loss: 1.4985 - val_accuracy: 0.3399\n",
            "Epoch 49/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5223 - accuracy: 0.3432\n",
            "Epoch 00049: loss did not improve from 1.52268\n",
            "595/595 [==============================] - 7s 13ms/step - loss: 1.5228 - accuracy: 0.3430 - val_loss: 1.5006 - val_accuracy: 0.3399\n",
            "Epoch 50/50\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5221 - accuracy: 0.3433\n",
            "Epoch 00050: loss improved from 1.52268 to 1.52242, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59b97fbf28>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 10s 17ms/step - loss: 1.5224 - accuracy: 0.3432 - val_loss: 1.5030 - val_accuracy: 0.3399\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/50\n",
            "  2/595 [..............................] - ETA: 52s - loss: 2.1366 - accuracy: 0.1600WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0158s vs `on_train_batch_end` time: 0.1613s). Check your callbacks.\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5460 - accuracy: 0.3316\n",
            "Epoch 00001: loss improved from inf to 1.54612, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f59b9879470>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5461 - accuracy: 0.3313 - val_loss: 1.5033 - val_accuracy: 0.3399\n",
            "Epoch 2/50\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5286 - accuracy: 0.3405\n",
            "Epoch 00002: loss improved from 1.54612 to 1.52856, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f59b9879470>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5286 - accuracy: 0.3404 - val_loss: 1.4959 - val_accuracy: 0.3399\n",
            "Epoch 3/50\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5234 - accuracy: 0.3431\n",
            "Epoch 00003: loss improved from 1.52856 to 1.52350, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f59b9879470>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5235 - accuracy: 0.3432 - val_loss: 1.4909 - val_accuracy: 0.3399\n",
            "Epoch 4/50\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5203 - accuracy: 0.3426\n",
            "Epoch 00004: loss improved from 1.52350 to 1.52067, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f59b9879470>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5207 - accuracy: 0.3426 - val_loss: 1.4865 - val_accuracy: 0.3399\n",
            "Epoch 5/50\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5175 - accuracy: 0.3423\n",
            "Epoch 00005: loss improved from 1.52067 to 1.51755, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f59b9879470>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5176 - accuracy: 0.3423 - val_loss: 1.5161 - val_accuracy: 0.3372\n",
            "Epoch 6/50\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5139 - accuracy: 0.3458\n",
            "Epoch 00006: loss improved from 1.51755 to 1.51391, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f59b9879470>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5139 - accuracy: 0.3458 - val_loss: 1.4960 - val_accuracy: 0.3399\n",
            "Epoch 7/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5138 - accuracy: 0.3434\n",
            "Epoch 00007: loss improved from 1.51391 to 1.51385, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f59b9879470>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5139 - accuracy: 0.3434 - val_loss: 1.4899 - val_accuracy: 0.3372\n",
            "Epoch 8/50\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5102 - accuracy: 0.3466\n",
            "Epoch 00008: loss improved from 1.51385 to 1.51018, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f59b9879470>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5102 - accuracy: 0.3462 - val_loss: 1.4943 - val_accuracy: 0.3321\n",
            "Epoch 9/50\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5088 - accuracy: 0.3460\n",
            "Epoch 00009: loss improved from 1.51018 to 1.50911, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f59b9879470>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5091 - accuracy: 0.3460 - val_loss: 1.5073 - val_accuracy: 0.3348\n",
            "Epoch 10/50\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5083 - accuracy: 0.3461\n",
            "Epoch 00010: loss improved from 1.50911 to 1.50829, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f59b9879470>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5083 - accuracy: 0.3461 - val_loss: 1.4933 - val_accuracy: 0.3337\n",
            "Epoch 11/50\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5053 - accuracy: 0.3492\n",
            "Epoch 00011: loss improved from 1.50829 to 1.50524, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f59b9879470>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5052 - accuracy: 0.3491 - val_loss: 1.4981 - val_accuracy: 0.3138\n",
            "Epoch 12/50\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5022 - accuracy: 0.3454\n",
            "Epoch 00012: loss improved from 1.50524 to 1.50208, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f59b9879470>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5021 - accuracy: 0.3453 - val_loss: 1.5023 - val_accuracy: 0.3270\n",
            "Epoch 13/50\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5034 - accuracy: 0.3448\n",
            "Epoch 00013: loss did not improve from 1.50208\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5036 - accuracy: 0.3448 - val_loss: 1.5023 - val_accuracy: 0.3407\n",
            "Epoch 14/50\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5023 - accuracy: 0.3484\n",
            "Epoch 00014: loss did not improve from 1.50208\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5023 - accuracy: 0.3484 - val_loss: 1.5032 - val_accuracy: 0.3321\n",
            "Epoch 15/50\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5005 - accuracy: 0.3484\n",
            "Epoch 00015: loss improved from 1.50208 to 1.50048, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f59b9879470>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5005 - accuracy: 0.3484 - val_loss: 1.4884 - val_accuracy: 0.3305\n",
            "Epoch 16/50\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.4993 - accuracy: 0.3491\n",
            "Epoch 00016: loss improved from 1.50048 to 1.49936, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f59b9879470>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4994 - accuracy: 0.3487 - val_loss: 1.5012 - val_accuracy: 0.3122\n",
            "Epoch 17/50\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.4980 - accuracy: 0.3478\n",
            "Epoch 00017: loss improved from 1.49936 to 1.49815, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f59b9879470>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4982 - accuracy: 0.3477 - val_loss: 1.4997 - val_accuracy: 0.3256\n",
            "Epoch 18/50\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.4998 - accuracy: 0.3485\n",
            "Epoch 00018: loss did not improve from 1.49815\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4998 - accuracy: 0.3485 - val_loss: 1.5157 - val_accuracy: 0.3248\n",
            "Epoch 19/50\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.4945 - accuracy: 0.3569\n",
            "Epoch 00019: loss improved from 1.49815 to 1.49437, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f59b9879470>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.4944 - accuracy: 0.3569 - val_loss: 1.5051 - val_accuracy: 0.3307\n",
            "Epoch 20/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.4955 - accuracy: 0.3519\n",
            "Epoch 00020: loss did not improve from 1.49437\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4956 - accuracy: 0.3519 - val_loss: 1.5244 - val_accuracy: 0.3237\n",
            "Epoch 21/50\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.4950 - accuracy: 0.3540\n",
            "Epoch 00021: loss did not improve from 1.49437\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4952 - accuracy: 0.3543 - val_loss: 1.5356 - val_accuracy: 0.3353\n",
            "Epoch 22/50\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.4942 - accuracy: 0.3526\n",
            "Epoch 00022: loss improved from 1.49437 to 1.49422, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f59b9879470>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.4942 - accuracy: 0.3525 - val_loss: 1.5225 - val_accuracy: 0.3178\n",
            "Epoch 23/50\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.4904 - accuracy: 0.3538\n",
            "Epoch 00023: loss improved from 1.49422 to 1.49062, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f59b9879470>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4906 - accuracy: 0.3536 - val_loss: 1.5259 - val_accuracy: 0.3369\n",
            "Epoch 24/50\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.4913 - accuracy: 0.3539\n",
            "Epoch 00024: loss did not improve from 1.49062\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4910 - accuracy: 0.3543 - val_loss: 1.5472 - val_accuracy: 0.3127\n",
            "Epoch 25/50\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.4916 - accuracy: 0.3600\n",
            "Epoch 00025: loss did not improve from 1.49062\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4917 - accuracy: 0.3600 - val_loss: 1.5451 - val_accuracy: 0.3202\n",
            "Epoch 26/50\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.4902 - accuracy: 0.3572\n",
            "Epoch 00026: loss improved from 1.49062 to 1.49008, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f59b9879470>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.4901 - accuracy: 0.3574 - val_loss: 1.5259 - val_accuracy: 0.3227\n",
            "Epoch 27/50\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.4898 - accuracy: 0.3540\n",
            "Epoch 00027: loss improved from 1.49008 to 1.48953, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f59b9879470>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4895 - accuracy: 0.3545 - val_loss: 1.5468 - val_accuracy: 0.3229\n",
            "Epoch 28/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.4896 - accuracy: 0.3556\n",
            "Epoch 00028: loss did not improve from 1.48953\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4897 - accuracy: 0.3555 - val_loss: 1.5496 - val_accuracy: 0.3205\n",
            "Epoch 29/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.4889 - accuracy: 0.3593\n",
            "Epoch 00029: loss improved from 1.48953 to 1.48903, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f59b9879470>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.4890 - accuracy: 0.3591 - val_loss: 1.5435 - val_accuracy: 0.3450\n",
            "Epoch 30/50\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.4868 - accuracy: 0.3560\n",
            "Epoch 00030: loss improved from 1.48903 to 1.48654, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f59b9879470>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4865 - accuracy: 0.3559 - val_loss: 1.5485 - val_accuracy: 0.3248\n",
            "Epoch 31/50\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.4846 - accuracy: 0.3618\n",
            "Epoch 00031: loss improved from 1.48654 to 1.48472, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f59b9879470>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4847 - accuracy: 0.3615 - val_loss: 1.5656 - val_accuracy: 0.3399\n",
            "Epoch 32/50\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.4828 - accuracy: 0.3589\n",
            "Epoch 00032: loss improved from 1.48472 to 1.48311, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f59b9879470>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4831 - accuracy: 0.3588 - val_loss: 1.5578 - val_accuracy: 0.3315\n",
            "Epoch 33/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.4839 - accuracy: 0.3646\n",
            "Epoch 00033: loss did not improve from 1.48311\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4841 - accuracy: 0.3644 - val_loss: 1.5585 - val_accuracy: 0.3402\n",
            "Epoch 34/50\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.4831 - accuracy: 0.3621\n",
            "Epoch 00034: loss improved from 1.48311 to 1.48309, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f59b9879470>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.4831 - accuracy: 0.3621 - val_loss: 1.5644 - val_accuracy: 0.3380\n",
            "Epoch 35/50\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.4863 - accuracy: 0.3641\n",
            "Epoch 00035: loss did not improve from 1.48309\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4861 - accuracy: 0.3642 - val_loss: 1.5996 - val_accuracy: 0.3186\n",
            "Epoch 36/50\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.4834 - accuracy: 0.3628\n",
            "Epoch 00036: loss did not improve from 1.48309\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4841 - accuracy: 0.3626 - val_loss: 1.6068 - val_accuracy: 0.3219\n",
            "Epoch 37/50\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.4822 - accuracy: 0.3614\n",
            "Epoch 00037: loss improved from 1.48309 to 1.48163, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f59b9879470>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.4816 - accuracy: 0.3617 - val_loss: 1.5950 - val_accuracy: 0.3219\n",
            "Epoch 38/50\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.4813 - accuracy: 0.3644\n",
            "Epoch 00038: loss improved from 1.48163 to 1.48112, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f59b9879470>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4811 - accuracy: 0.3644 - val_loss: 1.6051 - val_accuracy: 0.3318\n",
            "Epoch 39/50\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.4818 - accuracy: 0.3610\n",
            "Epoch 00039: loss did not improve from 1.48112\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4817 - accuracy: 0.3611 - val_loss: 1.6593 - val_accuracy: 0.3130\n",
            "Epoch 40/50\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.4805 - accuracy: 0.3683\n",
            "Epoch 00040: loss improved from 1.48112 to 1.48046, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f59b9879470>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.4805 - accuracy: 0.3683 - val_loss: 1.6470 - val_accuracy: 0.3149\n",
            "Epoch 41/50\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.4799 - accuracy: 0.3651\n",
            "Epoch 00041: loss improved from 1.48046 to 1.48022, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f59b9879470>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4802 - accuracy: 0.3651 - val_loss: 1.6367 - val_accuracy: 0.3170\n",
            "Epoch 42/50\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.4770 - accuracy: 0.3632\n",
            "Epoch 00042: loss improved from 1.48022 to 1.47775, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f59b9879470>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4778 - accuracy: 0.3634 - val_loss: 1.6119 - val_accuracy: 0.3248\n",
            "Epoch 43/50\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.4770 - accuracy: 0.3607\n",
            "Epoch 00043: loss improved from 1.47775 to 1.47708, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f59b9879470>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4771 - accuracy: 0.3605 - val_loss: 1.6690 - val_accuracy: 0.3315\n",
            "Epoch 44/50\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.4766 - accuracy: 0.3664\n",
            "Epoch 00044: loss improved from 1.47708 to 1.47662, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f59b9879470>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4766 - accuracy: 0.3662 - val_loss: 1.6762 - val_accuracy: 0.3235\n",
            "Epoch 45/50\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.4753 - accuracy: 0.3686\n",
            "Epoch 00045: loss improved from 1.47662 to 1.47584, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f59b9879470>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4758 - accuracy: 0.3681 - val_loss: 1.6771 - val_accuracy: 0.3087\n",
            "Epoch 46/50\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.4750 - accuracy: 0.3685\n",
            "Epoch 00046: loss improved from 1.47584 to 1.47517, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f59b9879470>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4752 - accuracy: 0.3683 - val_loss: 1.7080 - val_accuracy: 0.3251\n",
            "Epoch 47/50\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.4763 - accuracy: 0.3665\n",
            "Epoch 00047: loss did not improve from 1.47517\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4763 - accuracy: 0.3665 - val_loss: 1.6730 - val_accuracy: 0.3235\n",
            "Epoch 48/50\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.4746 - accuracy: 0.3641\n",
            "Epoch 00048: loss improved from 1.47517 to 1.47514, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f59b9879470>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.4751 - accuracy: 0.3642 - val_loss: 1.7208 - val_accuracy: 0.3232\n",
            "Epoch 49/50\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.4778 - accuracy: 0.3703\n",
            "Epoch 00049: loss did not improve from 1.47514\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4778 - accuracy: 0.3703 - val_loss: 1.7109 - val_accuracy: 0.3127\n",
            "Epoch 50/50\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.4761 - accuracy: 0.3666\n",
            "Epoch 00050: loss did not improve from 1.47514\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4761 - accuracy: 0.3666 - val_loss: 1.7159 - val_accuracy: 0.3184\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/50\n",
            "  2/595 [..............................] - ETA: 34s - loss: 2.1142 - accuracy: 0.2200WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0160s vs `on_train_batch_end` time: 0.1006s). Check your callbacks.\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5489 - accuracy: 0.3312\n",
            "Epoch 00001: loss improved from inf to 1.54839, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f59c41d7fd0>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5484 - accuracy: 0.3314 - val_loss: 1.4996 - val_accuracy: 0.3399\n",
            "Epoch 2/50\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5272 - accuracy: 0.3434\n",
            "Epoch 00002: loss improved from 1.54839 to 1.52717, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f59c41d7fd0>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5272 - accuracy: 0.3434 - val_loss: 1.4991 - val_accuracy: 0.3399\n",
            "Epoch 3/50\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5214 - accuracy: 0.3435\n",
            "Epoch 00003: loss improved from 1.52717 to 1.52144, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f59c41d7fd0>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5214 - accuracy: 0.3435 - val_loss: 1.4975 - val_accuracy: 0.3372\n",
            "Epoch 4/50\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5188 - accuracy: 0.3401\n",
            "Epoch 00004: loss improved from 1.52144 to 1.51883, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f59c41d7fd0>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5188 - accuracy: 0.3401 - val_loss: 1.4923 - val_accuracy: 0.3372\n",
            "Epoch 5/50\n",
            "589/595 [============================>.] - ETA: 0s - loss: 1.5171 - accuracy: 0.3447\n",
            "Epoch 00005: loss improved from 1.51883 to 1.51661, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f59c41d7fd0>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5166 - accuracy: 0.3451 - val_loss: 1.4929 - val_accuracy: 0.3372\n",
            "Epoch 6/50\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5143 - accuracy: 0.3436\n",
            "Epoch 00006: loss improved from 1.51661 to 1.51436, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f59c41d7fd0>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5144 - accuracy: 0.3436 - val_loss: 1.5010 - val_accuracy: 0.3372\n",
            "Epoch 7/50\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5124 - accuracy: 0.3463\n",
            "Epoch 00007: loss improved from 1.51436 to 1.51254, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f59c41d7fd0>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5125 - accuracy: 0.3461 - val_loss: 1.4939 - val_accuracy: 0.3367\n",
            "Epoch 8/50\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5105 - accuracy: 0.3396\n",
            "Epoch 00008: loss improved from 1.51254 to 1.51046, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f59c41d7fd0>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5105 - accuracy: 0.3396 - val_loss: 1.4925 - val_accuracy: 0.3372\n",
            "Epoch 9/50\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5080 - accuracy: 0.3465\n",
            "Epoch 00009: loss improved from 1.51046 to 1.50846, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f59c41d7fd0>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5085 - accuracy: 0.3463 - val_loss: 1.4923 - val_accuracy: 0.3372\n",
            "Epoch 10/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5069 - accuracy: 0.3414\n",
            "Epoch 00010: loss improved from 1.50846 to 1.50677, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f59c41d7fd0>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5068 - accuracy: 0.3416 - val_loss: 1.4932 - val_accuracy: 0.3245\n",
            "Epoch 11/50\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5065 - accuracy: 0.3462\n",
            "Epoch 00011: loss improved from 1.50677 to 1.50629, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f59c41d7fd0>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5063 - accuracy: 0.3464 - val_loss: 1.4920 - val_accuracy: 0.3259\n",
            "Epoch 12/50\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5030 - accuracy: 0.3505\n",
            "Epoch 00012: loss improved from 1.50629 to 1.50314, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f59c41d7fd0>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5031 - accuracy: 0.3504 - val_loss: 1.4959 - val_accuracy: 0.3332\n",
            "Epoch 13/50\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5007 - accuracy: 0.3443\n",
            "Epoch 00013: loss improved from 1.50314 to 1.50113, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f59c41d7fd0>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5011 - accuracy: 0.3440 - val_loss: 1.5004 - val_accuracy: 0.3364\n",
            "Epoch 14/50\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.4992 - accuracy: 0.3470\n",
            "Epoch 00014: loss improved from 1.50113 to 1.49960, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f59c41d7fd0>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4996 - accuracy: 0.3468 - val_loss: 1.5030 - val_accuracy: 0.3358\n",
            "Epoch 15/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5011 - accuracy: 0.3430\n",
            "Epoch 00015: loss did not improve from 1.49960\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5015 - accuracy: 0.3429 - val_loss: 1.4969 - val_accuracy: 0.3297\n",
            "Epoch 16/50\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.4987 - accuracy: 0.3448\n",
            "Epoch 00016: loss improved from 1.49960 to 1.49812, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f59c41d7fd0>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.4981 - accuracy: 0.3448 - val_loss: 1.5037 - val_accuracy: 0.3385\n",
            "Epoch 17/50\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.4949 - accuracy: 0.3480\n",
            "Epoch 00017: loss improved from 1.49812 to 1.49487, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f59c41d7fd0>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4949 - accuracy: 0.3480 - val_loss: 1.5027 - val_accuracy: 0.3092\n",
            "Epoch 18/50\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.4927 - accuracy: 0.3526\n",
            "Epoch 00018: loss improved from 1.49487 to 1.49322, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f59c41d7fd0>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.4932 - accuracy: 0.3522 - val_loss: 1.4928 - val_accuracy: 0.3189\n",
            "Epoch 19/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.4925 - accuracy: 0.3500\n",
            "Epoch 00019: loss improved from 1.49322 to 1.49267, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f59c41d7fd0>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4927 - accuracy: 0.3497 - val_loss: 1.5023 - val_accuracy: 0.3270\n",
            "Epoch 20/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.4903 - accuracy: 0.3536\n",
            "Epoch 00020: loss improved from 1.49267 to 1.49038, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f59c41d7fd0>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4904 - accuracy: 0.3535 - val_loss: 1.4957 - val_accuracy: 0.3143\n",
            "Epoch 21/50\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.4893 - accuracy: 0.3513\n",
            "Epoch 00021: loss improved from 1.49038 to 1.48934, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f59c41d7fd0>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4893 - accuracy: 0.3513 - val_loss: 1.4833 - val_accuracy: 0.3302\n",
            "Epoch 22/50\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.4881 - accuracy: 0.3514\n",
            "Epoch 00022: loss improved from 1.48934 to 1.48806, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f59c41d7fd0>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4881 - accuracy: 0.3514 - val_loss: 1.4888 - val_accuracy: 0.3348\n",
            "Epoch 23/50\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.4865 - accuracy: 0.3543\n",
            "Epoch 00023: loss improved from 1.48806 to 1.48650, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f59c41d7fd0>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4865 - accuracy: 0.3543 - val_loss: 1.5094 - val_accuracy: 0.3108\n",
            "Epoch 24/50\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.4876 - accuracy: 0.3522\n",
            "Epoch 00024: loss did not improve from 1.48650\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4876 - accuracy: 0.3521 - val_loss: 1.5056 - val_accuracy: 0.3345\n",
            "Epoch 25/50\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.4864 - accuracy: 0.3555\n",
            "Epoch 00025: loss did not improve from 1.48650\n",
            "595/595 [==============================] - 7s 13ms/step - loss: 1.4868 - accuracy: 0.3554 - val_loss: 1.4891 - val_accuracy: 0.3393\n",
            "Epoch 26/50\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.4838 - accuracy: 0.3561\n",
            "Epoch 00026: loss improved from 1.48650 to 1.48367, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f59c41d7fd0>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.4837 - accuracy: 0.3566 - val_loss: 1.4946 - val_accuracy: 0.3089\n",
            "Epoch 27/50\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.4830 - accuracy: 0.3530\n",
            "Epoch 00027: loss improved from 1.48367 to 1.48297, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f59c41d7fd0>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4830 - accuracy: 0.3532 - val_loss: 1.5004 - val_accuracy: 0.3272\n",
            "Epoch 28/50\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.4812 - accuracy: 0.3550\n",
            "Epoch 00028: loss improved from 1.48297 to 1.48077, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f59c41d7fd0>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4808 - accuracy: 0.3549 - val_loss: 1.5266 - val_accuracy: 0.3221\n",
            "Epoch 29/50\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.4809 - accuracy: 0.3589\n",
            "Epoch 00029: loss improved from 1.48077 to 1.48072, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f59c41d7fd0>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4807 - accuracy: 0.3591 - val_loss: 1.5171 - val_accuracy: 0.3216\n",
            "Epoch 30/50\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.4800 - accuracy: 0.3616\n",
            "Epoch 00030: loss improved from 1.48072 to 1.47967, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f59c41d7fd0>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4797 - accuracy: 0.3616 - val_loss: 1.5120 - val_accuracy: 0.3391\n",
            "Epoch 31/50\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.4767 - accuracy: 0.3636\n",
            "Epoch 00031: loss improved from 1.47967 to 1.47647, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f59c41d7fd0>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4765 - accuracy: 0.3636 - val_loss: 1.5117 - val_accuracy: 0.3353\n",
            "Epoch 32/50\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.4758 - accuracy: 0.3671\n",
            "Epoch 00032: loss improved from 1.47647 to 1.47612, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f59c41d7fd0>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4761 - accuracy: 0.3668 - val_loss: 1.5309 - val_accuracy: 0.3157\n",
            "Epoch 33/50\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.4751 - accuracy: 0.3640\n",
            "Epoch 00033: loss improved from 1.47612 to 1.47511, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f59c41d7fd0>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4751 - accuracy: 0.3638 - val_loss: 1.5156 - val_accuracy: 0.3399\n",
            "Epoch 34/50\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.4754 - accuracy: 0.3634\n",
            "Epoch 00034: loss did not improve from 1.47511\n",
            "595/595 [==============================] - 7s 13ms/step - loss: 1.4759 - accuracy: 0.3634 - val_loss: 1.5284 - val_accuracy: 0.3235\n",
            "Epoch 35/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.4707 - accuracy: 0.3696\n",
            "Epoch 00035: loss improved from 1.47511 to 1.47077, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f59c41d7fd0>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.4708 - accuracy: 0.3696 - val_loss: 1.5433 - val_accuracy: 0.3229\n",
            "Epoch 36/50\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.4745 - accuracy: 0.3657\n",
            "Epoch 00036: loss did not improve from 1.47077\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4745 - accuracy: 0.3657 - val_loss: 1.5182 - val_accuracy: 0.3345\n",
            "Epoch 37/50\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.4733 - accuracy: 0.3620\n",
            "Epoch 00037: loss did not improve from 1.47077\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4731 - accuracy: 0.3622 - val_loss: 1.5358 - val_accuracy: 0.3216\n",
            "Epoch 38/50\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.4728 - accuracy: 0.3642\n",
            "Epoch 00038: loss did not improve from 1.47077\n",
            "595/595 [==============================] - 7s 13ms/step - loss: 1.4729 - accuracy: 0.3644 - val_loss: 1.5747 - val_accuracy: 0.3159\n",
            "Epoch 39/50\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.4717 - accuracy: 0.3657\n",
            "Epoch 00039: loss did not improve from 1.47077\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4717 - accuracy: 0.3657 - val_loss: 1.5523 - val_accuracy: 0.3264\n",
            "Epoch 40/50\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.4688 - accuracy: 0.3667\n",
            "Epoch 00040: loss improved from 1.47077 to 1.46867, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f59c41d7fd0>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.4687 - accuracy: 0.3667 - val_loss: 1.5319 - val_accuracy: 0.3385\n",
            "Epoch 41/50\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.4670 - accuracy: 0.3681\n",
            "Epoch 00041: loss improved from 1.46867 to 1.46697, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f59c41d7fd0>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4670 - accuracy: 0.3681 - val_loss: 1.5752 - val_accuracy: 0.3275\n",
            "Epoch 42/50\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.4677 - accuracy: 0.3696\n",
            "Epoch 00042: loss did not improve from 1.46697\n",
            "595/595 [==============================] - 7s 13ms/step - loss: 1.4678 - accuracy: 0.3693 - val_loss: 1.5681 - val_accuracy: 0.3469\n",
            "Epoch 43/50\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.4671 - accuracy: 0.3643\n",
            "Epoch 00043: loss did not improve from 1.46697\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4671 - accuracy: 0.3646 - val_loss: 1.5685 - val_accuracy: 0.3297\n",
            "Epoch 44/50\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.4643 - accuracy: 0.3661\n",
            "Epoch 00044: loss improved from 1.46697 to 1.46454, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f59c41d7fd0>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.4645 - accuracy: 0.3659 - val_loss: 1.5665 - val_accuracy: 0.3367\n",
            "Epoch 45/50\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.4648 - accuracy: 0.3704\n",
            "Epoch 00045: loss did not improve from 1.46454\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4648 - accuracy: 0.3700 - val_loss: 1.5553 - val_accuracy: 0.3393\n",
            "Epoch 46/50\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.4630 - accuracy: 0.3654\n",
            "Epoch 00046: loss improved from 1.46454 to 1.46255, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f59c41d7fd0>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.4626 - accuracy: 0.3657 - val_loss: 1.5682 - val_accuracy: 0.3213\n",
            "Epoch 47/50\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.4625 - accuracy: 0.3659\n",
            "Epoch 00047: loss did not improve from 1.46255\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4626 - accuracy: 0.3656 - val_loss: 1.5984 - val_accuracy: 0.3377\n",
            "Epoch 48/50\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.4617 - accuracy: 0.3690\n",
            "Epoch 00048: loss improved from 1.46255 to 1.46157, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f59c41d7fd0>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.4616 - accuracy: 0.3692 - val_loss: 1.6402 - val_accuracy: 0.3270\n",
            "Epoch 49/50\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.4582 - accuracy: 0.3743\n",
            "Epoch 00049: loss improved from 1.46157 to 1.45834, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f59c41d7fd0>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4583 - accuracy: 0.3743 - val_loss: 1.5950 - val_accuracy: 0.3375\n",
            "Epoch 50/50\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.4600 - accuracy: 0.3749\n",
            "Epoch 00050: loss did not improve from 1.45834\n",
            "595/595 [==============================] - 7s 13ms/step - loss: 1.4599 - accuracy: 0.3752 - val_loss: 1.5681 - val_accuracy: 0.3469\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/50\n",
            "  2/595 [..............................] - ETA: 31s - loss: 2.3347 - accuracy: 0.1200WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0151s vs `on_train_batch_end` time: 0.0912s). Check your callbacks.\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.6021 - accuracy: 0.3112\n",
            "Epoch 00001: loss improved from inf to 1.60236, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59b9872be0>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.6024 - accuracy: 0.3110 - val_loss: 1.5213 - val_accuracy: 0.3399\n",
            "Epoch 2/50\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5546 - accuracy: 0.3298\n",
            "Epoch 00002: loss improved from 1.60236 to 1.55455, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59b9872be0>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5545 - accuracy: 0.3297 - val_loss: 1.5087 - val_accuracy: 0.3399\n",
            "Epoch 3/50\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5539 - accuracy: 0.3283\n",
            "Epoch 00003: loss improved from 1.55455 to 1.55411, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59b9872be0>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5541 - accuracy: 0.3282 - val_loss: 1.5104 - val_accuracy: 0.3399\n",
            "Epoch 4/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5501 - accuracy: 0.3276\n",
            "Epoch 00004: loss improved from 1.55411 to 1.54999, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59b9872be0>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5500 - accuracy: 0.3276 - val_loss: 1.5069 - val_accuracy: 0.3399\n",
            "Epoch 5/50\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5471 - accuracy: 0.3255\n",
            "Epoch 00005: loss improved from 1.54999 to 1.54706, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59b9872be0>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5471 - accuracy: 0.3255 - val_loss: 1.5065 - val_accuracy: 0.3399\n",
            "Epoch 6/50\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5439 - accuracy: 0.3280\n",
            "Epoch 00006: loss improved from 1.54706 to 1.54387, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59b9872be0>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5439 - accuracy: 0.3277 - val_loss: 1.5065 - val_accuracy: 0.3399\n",
            "Epoch 7/50\n",
            "589/595 [============================>.] - ETA: 0s - loss: 1.5399 - accuracy: 0.3330\n",
            "Epoch 00007: loss improved from 1.54387 to 1.54005, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59b9872be0>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5400 - accuracy: 0.3325 - val_loss: 1.5049 - val_accuracy: 0.3399\n",
            "Epoch 8/50\n",
            "589/595 [============================>.] - ETA: 0s - loss: 1.5431 - accuracy: 0.3358\n",
            "Epoch 00008: loss did not improve from 1.54005\n",
            "595/595 [==============================] - 7s 13ms/step - loss: 1.5432 - accuracy: 0.3357 - val_loss: 1.5042 - val_accuracy: 0.3399\n",
            "Epoch 9/50\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5408 - accuracy: 0.3307\n",
            "Epoch 00009: loss did not improve from 1.54005\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5407 - accuracy: 0.3307 - val_loss: 1.5043 - val_accuracy: 0.3399\n",
            "Epoch 10/50\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5409 - accuracy: 0.3351\n",
            "Epoch 00010: loss did not improve from 1.54005\n",
            "595/595 [==============================] - 7s 12ms/step - loss: 1.5407 - accuracy: 0.3350 - val_loss: 1.5040 - val_accuracy: 0.3399\n",
            "Epoch 11/50\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5352 - accuracy: 0.3389\n",
            "Epoch 00011: loss improved from 1.54005 to 1.53548, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59b9872be0>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5355 - accuracy: 0.3385 - val_loss: 1.5036 - val_accuracy: 0.3399\n",
            "Epoch 12/50\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5358 - accuracy: 0.3374\n",
            "Epoch 00012: loss did not improve from 1.53548\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5361 - accuracy: 0.3370 - val_loss: 1.5042 - val_accuracy: 0.3399\n",
            "Epoch 13/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5358 - accuracy: 0.3363\n",
            "Epoch 00013: loss did not improve from 1.53548\n",
            "595/595 [==============================] - 7s 13ms/step - loss: 1.5358 - accuracy: 0.3363 - val_loss: 1.5036 - val_accuracy: 0.3399\n",
            "Epoch 14/50\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5356 - accuracy: 0.3385\n",
            "Epoch 00014: loss improved from 1.53548 to 1.53489, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59b9872be0>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5349 - accuracy: 0.3391 - val_loss: 1.5046 - val_accuracy: 0.3399\n",
            "Epoch 15/50\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5333 - accuracy: 0.3394\n",
            "Epoch 00015: loss improved from 1.53489 to 1.53339, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59b9872be0>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5334 - accuracy: 0.3395 - val_loss: 1.5042 - val_accuracy: 0.3399\n",
            "Epoch 16/50\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5339 - accuracy: 0.3346\n",
            "Epoch 00016: loss did not improve from 1.53339\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5339 - accuracy: 0.3346 - val_loss: 1.5036 - val_accuracy: 0.3399\n",
            "Epoch 17/50\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5356 - accuracy: 0.3394\n",
            "Epoch 00017: loss did not improve from 1.53339\n",
            "595/595 [==============================] - 7s 12ms/step - loss: 1.5357 - accuracy: 0.3392 - val_loss: 1.5040 - val_accuracy: 0.3399\n",
            "Epoch 18/50\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5341 - accuracy: 0.3347\n",
            "Epoch 00018: loss did not improve from 1.53339\n",
            "595/595 [==============================] - 7s 12ms/step - loss: 1.5341 - accuracy: 0.3348 - val_loss: 1.5035 - val_accuracy: 0.3399\n",
            "Epoch 19/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5329 - accuracy: 0.3395\n",
            "Epoch 00019: loss improved from 1.53339 to 1.53306, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59b9872be0>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5331 - accuracy: 0.3394 - val_loss: 1.5033 - val_accuracy: 0.3399\n",
            "Epoch 20/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5326 - accuracy: 0.3364\n",
            "Epoch 00020: loss improved from 1.53306 to 1.53253, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59b9872be0>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5325 - accuracy: 0.3364 - val_loss: 1.5032 - val_accuracy: 0.3399\n",
            "Epoch 21/50\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5326 - accuracy: 0.3389\n",
            "Epoch 00021: loss did not improve from 1.53253\n",
            "595/595 [==============================] - 7s 12ms/step - loss: 1.5328 - accuracy: 0.3388 - val_loss: 1.5030 - val_accuracy: 0.3399\n",
            "Epoch 22/50\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5315 - accuracy: 0.3381\n",
            "Epoch 00022: loss improved from 1.53253 to 1.53179, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59b9872be0>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5318 - accuracy: 0.3380 - val_loss: 1.5043 - val_accuracy: 0.3399\n",
            "Epoch 23/50\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5311 - accuracy: 0.3376\n",
            "Epoch 00023: loss improved from 1.53179 to 1.53145, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59b9872be0>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5315 - accuracy: 0.3377 - val_loss: 1.5030 - val_accuracy: 0.3399\n",
            "Epoch 24/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5312 - accuracy: 0.3387\n",
            "Epoch 00024: loss improved from 1.53145 to 1.53125, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59b9872be0>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5313 - accuracy: 0.3387 - val_loss: 1.5038 - val_accuracy: 0.3399\n",
            "Epoch 25/50\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5319 - accuracy: 0.3410\n",
            "Epoch 00025: loss did not improve from 1.53125\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5319 - accuracy: 0.3413 - val_loss: 1.5033 - val_accuracy: 0.3399\n",
            "Epoch 26/50\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5325 - accuracy: 0.3401\n",
            "Epoch 00026: loss did not improve from 1.53125\n",
            "595/595 [==============================] - 7s 13ms/step - loss: 1.5325 - accuracy: 0.3401 - val_loss: 1.5032 - val_accuracy: 0.3399\n",
            "Epoch 27/50\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5306 - accuracy: 0.3423\n",
            "Epoch 00027: loss improved from 1.53125 to 1.53047, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59b9872be0>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5305 - accuracy: 0.3423 - val_loss: 1.5033 - val_accuracy: 0.3399\n",
            "Epoch 28/50\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5298 - accuracy: 0.3420\n",
            "Epoch 00028: loss improved from 1.53047 to 1.52983, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59b9872be0>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5298 - accuracy: 0.3420 - val_loss: 1.5035 - val_accuracy: 0.3399\n",
            "Epoch 29/50\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5269 - accuracy: 0.3410\n",
            "Epoch 00029: loss improved from 1.52983 to 1.52705, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59b9872be0>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5271 - accuracy: 0.3411 - val_loss: 1.5023 - val_accuracy: 0.3399\n",
            "Epoch 30/50\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5293 - accuracy: 0.3418\n",
            "Epoch 00030: loss did not improve from 1.52705\n",
            "595/595 [==============================] - 7s 13ms/step - loss: 1.5293 - accuracy: 0.3418 - val_loss: 1.5026 - val_accuracy: 0.3399\n",
            "Epoch 31/50\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5297 - accuracy: 0.3398\n",
            "Epoch 00031: loss did not improve from 1.52705\n",
            "595/595 [==============================] - 7s 12ms/step - loss: 1.5295 - accuracy: 0.3402 - val_loss: 1.5033 - val_accuracy: 0.3399\n",
            "Epoch 32/50\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5292 - accuracy: 0.3431\n",
            "Epoch 00032: loss did not improve from 1.52705\n",
            "595/595 [==============================] - 7s 13ms/step - loss: 1.5288 - accuracy: 0.3432 - val_loss: 1.5029 - val_accuracy: 0.3399\n",
            "Epoch 33/50\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5287 - accuracy: 0.3434\n",
            "Epoch 00033: loss did not improve from 1.52705\n",
            "595/595 [==============================] - 7s 12ms/step - loss: 1.5285 - accuracy: 0.3432 - val_loss: 1.5023 - val_accuracy: 0.3399\n",
            "Epoch 34/50\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5272 - accuracy: 0.3427\n",
            "Epoch 00034: loss did not improve from 1.52705\n",
            "595/595 [==============================] - 7s 12ms/step - loss: 1.5272 - accuracy: 0.3424 - val_loss: 1.5025 - val_accuracy: 0.3399\n",
            "Epoch 35/50\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5280 - accuracy: 0.3401\n",
            "Epoch 00035: loss did not improve from 1.52705\n",
            "595/595 [==============================] - 7s 12ms/step - loss: 1.5284 - accuracy: 0.3400 - val_loss: 1.5022 - val_accuracy: 0.3399\n",
            "Epoch 36/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5302 - accuracy: 0.3397\n",
            "Epoch 00036: loss did not improve from 1.52705\n",
            "595/595 [==============================] - 7s 12ms/step - loss: 1.5301 - accuracy: 0.3396 - val_loss: 1.5025 - val_accuracy: 0.3399\n",
            "Epoch 37/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5285 - accuracy: 0.3422\n",
            "Epoch 00037: loss did not improve from 1.52705\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5285 - accuracy: 0.3421 - val_loss: 1.5020 - val_accuracy: 0.3399\n",
            "Epoch 38/50\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5280 - accuracy: 0.3402\n",
            "Epoch 00038: loss did not improve from 1.52705\n",
            "595/595 [==============================] - 7s 12ms/step - loss: 1.5276 - accuracy: 0.3405 - val_loss: 1.5015 - val_accuracy: 0.3399\n",
            "Epoch 39/50\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5276 - accuracy: 0.3431\n",
            "Epoch 00039: loss improved from 1.52705 to 1.52695, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59b9872be0>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5269 - accuracy: 0.3436 - val_loss: 1.5016 - val_accuracy: 0.3399\n",
            "Epoch 40/50\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5274 - accuracy: 0.3432\n",
            "Epoch 00040: loss did not improve from 1.52695\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5273 - accuracy: 0.3428 - val_loss: 1.5012 - val_accuracy: 0.3399\n",
            "Epoch 41/50\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5291 - accuracy: 0.3409\n",
            "Epoch 00041: loss did not improve from 1.52695\n",
            "595/595 [==============================] - 7s 13ms/step - loss: 1.5291 - accuracy: 0.3411 - val_loss: 1.5016 - val_accuracy: 0.3399\n",
            "Epoch 42/50\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5260 - accuracy: 0.3444\n",
            "Epoch 00042: loss improved from 1.52695 to 1.52564, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59b9872be0>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5256 - accuracy: 0.3449 - val_loss: 1.5019 - val_accuracy: 0.3399\n",
            "Epoch 43/50\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5266 - accuracy: 0.3411\n",
            "Epoch 00043: loss did not improve from 1.52564\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5269 - accuracy: 0.3410 - val_loss: 1.5016 - val_accuracy: 0.3399\n",
            "Epoch 44/50\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5261 - accuracy: 0.3432\n",
            "Epoch 00044: loss did not improve from 1.52564\n",
            "595/595 [==============================] - 7s 13ms/step - loss: 1.5259 - accuracy: 0.3432 - val_loss: 1.5015 - val_accuracy: 0.3399\n",
            "Epoch 45/50\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5254 - accuracy: 0.3432\n",
            "Epoch 00045: loss did not improve from 1.52564\n",
            "595/595 [==============================] - 7s 13ms/step - loss: 1.5259 - accuracy: 0.3426 - val_loss: 1.5016 - val_accuracy: 0.3399\n",
            "Epoch 46/50\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5272 - accuracy: 0.3396\n",
            "Epoch 00046: loss did not improve from 1.52564\n",
            "595/595 [==============================] - 7s 12ms/step - loss: 1.5270 - accuracy: 0.3399 - val_loss: 1.5017 - val_accuracy: 0.3399\n",
            "Epoch 47/50\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5263 - accuracy: 0.3411\n",
            "Epoch 00047: loss did not improve from 1.52564\n",
            "595/595 [==============================] - 7s 13ms/step - loss: 1.5265 - accuracy: 0.3410 - val_loss: 1.5016 - val_accuracy: 0.3399\n",
            "Epoch 48/50\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5267 - accuracy: 0.3412\n",
            "Epoch 00048: loss did not improve from 1.52564\n",
            "595/595 [==============================] - 7s 13ms/step - loss: 1.5260 - accuracy: 0.3418 - val_loss: 1.5014 - val_accuracy: 0.3399\n",
            "Epoch 49/50\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5263 - accuracy: 0.3438\n",
            "Epoch 00049: loss did not improve from 1.52564\n",
            "595/595 [==============================] - 7s 12ms/step - loss: 1.5262 - accuracy: 0.3436 - val_loss: 1.5012 - val_accuracy: 0.3399\n",
            "Epoch 50/50\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5254 - accuracy: 0.3403\n",
            "Epoch 00050: loss improved from 1.52564 to 1.52495, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59b9872be0>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5250 - accuracy: 0.3404 - val_loss: 1.5010 - val_accuracy: 0.3399\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/50\n",
            "  2/595 [..............................] - ETA: 33s - loss: 2.0763 - accuracy: 0.1400WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0143s vs `on_train_batch_end` time: 0.0976s). Check your callbacks.\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5553 - accuracy: 0.3291\n",
            "Epoch 00001: loss improved from inf to 1.55545, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f59b980be10>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5554 - accuracy: 0.3291 - val_loss: 1.5041 - val_accuracy: 0.3399\n",
            "Epoch 2/50\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5335 - accuracy: 0.3389\n",
            "Epoch 00002: loss improved from 1.55545 to 1.53351, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f59b980be10>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5335 - accuracy: 0.3389 - val_loss: 1.5014 - val_accuracy: 0.3399\n",
            "Epoch 3/50\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5284 - accuracy: 0.3379\n",
            "Epoch 00003: loss improved from 1.53351 to 1.52836, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f59b980be10>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5284 - accuracy: 0.3379 - val_loss: 1.5152 - val_accuracy: 0.3399\n",
            "Epoch 4/50\n",
            "589/595 [============================>.] - ETA: 0s - loss: 1.5258 - accuracy: 0.3400\n",
            "Epoch 00004: loss improved from 1.52836 to 1.52622, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f59b980be10>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5262 - accuracy: 0.3392 - val_loss: 1.5033 - val_accuracy: 0.3399\n",
            "Epoch 5/50\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5199 - accuracy: 0.3424\n",
            "Epoch 00005: loss improved from 1.52622 to 1.51986, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f59b980be10>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5199 - accuracy: 0.3424 - val_loss: 1.4914 - val_accuracy: 0.3399\n",
            "Epoch 6/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5199 - accuracy: 0.3426\n",
            "Epoch 00006: loss improved from 1.51986 to 1.51983, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f59b980be10>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5198 - accuracy: 0.3427 - val_loss: 1.5032 - val_accuracy: 0.3399\n",
            "Epoch 7/50\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5173 - accuracy: 0.3423\n",
            "Epoch 00007: loss improved from 1.51983 to 1.51749, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f59b980be10>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5175 - accuracy: 0.3425 - val_loss: 1.4980 - val_accuracy: 0.3399\n",
            "Epoch 8/50\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5161 - accuracy: 0.3434\n",
            "Epoch 00008: loss improved from 1.51749 to 1.51585, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f59b980be10>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5159 - accuracy: 0.3432 - val_loss: 1.4876 - val_accuracy: 0.3407\n",
            "Epoch 9/50\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5131 - accuracy: 0.3417\n",
            "Epoch 00009: loss improved from 1.51585 to 1.51286, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f59b980be10>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5129 - accuracy: 0.3418 - val_loss: 1.4944 - val_accuracy: 0.3372\n",
            "Epoch 10/50\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5123 - accuracy: 0.3444\n",
            "Epoch 00010: loss improved from 1.51286 to 1.51260, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f59b980be10>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5126 - accuracy: 0.3442 - val_loss: 1.4970 - val_accuracy: 0.3372\n",
            "Epoch 11/50\n",
            "589/595 [============================>.] - ETA: 0s - loss: 1.5111 - accuracy: 0.3473\n",
            "Epoch 00011: loss improved from 1.51260 to 1.51063, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f59b980be10>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5106 - accuracy: 0.3476 - val_loss: 1.4914 - val_accuracy: 0.3205\n",
            "Epoch 12/50\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5104 - accuracy: 0.3449\n",
            "Epoch 00012: loss improved from 1.51063 to 1.51050, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f59b980be10>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5105 - accuracy: 0.3449 - val_loss: 1.4974 - val_accuracy: 0.3372\n",
            "Epoch 13/50\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5096 - accuracy: 0.3428\n",
            "Epoch 00013: loss improved from 1.51050 to 1.50957, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f59b980be10>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5096 - accuracy: 0.3428 - val_loss: 1.4949 - val_accuracy: 0.3372\n",
            "Epoch 14/50\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5062 - accuracy: 0.3465\n",
            "Epoch 00014: loss improved from 1.50957 to 1.50615, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f59b980be10>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5061 - accuracy: 0.3464 - val_loss: 1.5026 - val_accuracy: 0.3372\n",
            "Epoch 15/50\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5055 - accuracy: 0.3471\n",
            "Epoch 00015: loss improved from 1.50615 to 1.50546, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f59b980be10>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5055 - accuracy: 0.3471 - val_loss: 1.4993 - val_accuracy: 0.3372\n",
            "Epoch 16/50\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5056 - accuracy: 0.3492\n",
            "Epoch 00016: loss did not improve from 1.50546\n",
            "595/595 [==============================] - 7s 13ms/step - loss: 1.5056 - accuracy: 0.3495 - val_loss: 1.4980 - val_accuracy: 0.3399\n",
            "Epoch 17/50\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5024 - accuracy: 0.3489\n",
            "Epoch 00017: loss improved from 1.50546 to 1.50244, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f59b980be10>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5024 - accuracy: 0.3489 - val_loss: 1.4937 - val_accuracy: 0.3367\n",
            "Epoch 18/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5023 - accuracy: 0.3465\n",
            "Epoch 00018: loss did not improve from 1.50244\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5026 - accuracy: 0.3464 - val_loss: 1.4954 - val_accuracy: 0.3205\n",
            "Epoch 19/50\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.4989 - accuracy: 0.3542\n",
            "Epoch 00019: loss improved from 1.50244 to 1.49865, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f59b980be10>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.4986 - accuracy: 0.3544 - val_loss: 1.5002 - val_accuracy: 0.3367\n",
            "Epoch 20/50\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.4982 - accuracy: 0.3518\n",
            "Epoch 00020: loss improved from 1.49865 to 1.49848, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f59b980be10>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4985 - accuracy: 0.3519 - val_loss: 1.4951 - val_accuracy: 0.3227\n",
            "Epoch 21/50\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.4991 - accuracy: 0.3511\n",
            "Epoch 00021: loss did not improve from 1.49848\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4988 - accuracy: 0.3510 - val_loss: 1.4979 - val_accuracy: 0.3143\n",
            "Epoch 22/50\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.4967 - accuracy: 0.3492\n",
            "Epoch 00022: loss improved from 1.49848 to 1.49667, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f59b980be10>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.4967 - accuracy: 0.3492 - val_loss: 1.4914 - val_accuracy: 0.3243\n",
            "Epoch 23/50\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.4951 - accuracy: 0.3516\n",
            "Epoch 00023: loss improved from 1.49667 to 1.49511, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f59b980be10>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4951 - accuracy: 0.3516 - val_loss: 1.4950 - val_accuracy: 0.3065\n",
            "Epoch 24/50\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.4959 - accuracy: 0.3535\n",
            "Epoch 00024: loss did not improve from 1.49511\n",
            "595/595 [==============================] - 7s 13ms/step - loss: 1.4961 - accuracy: 0.3535 - val_loss: 1.4951 - val_accuracy: 0.3369\n",
            "Epoch 25/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.4945 - accuracy: 0.3521\n",
            "Epoch 00025: loss improved from 1.49511 to 1.49430, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f59b980be10>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.4943 - accuracy: 0.3523 - val_loss: 1.4991 - val_accuracy: 0.3358\n",
            "Epoch 26/50\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.4938 - accuracy: 0.3506\n",
            "Epoch 00026: loss improved from 1.49430 to 1.49425, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f59b980be10>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4943 - accuracy: 0.3504 - val_loss: 1.4865 - val_accuracy: 0.3326\n",
            "Epoch 27/50\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.4939 - accuracy: 0.3527\n",
            "Epoch 00027: loss improved from 1.49425 to 1.49390, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f59b980be10>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.4939 - accuracy: 0.3527 - val_loss: 1.4908 - val_accuracy: 0.3213\n",
            "Epoch 28/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.4909 - accuracy: 0.3533\n",
            "Epoch 00028: loss improved from 1.49390 to 1.49083, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f59b980be10>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4908 - accuracy: 0.3532 - val_loss: 1.4918 - val_accuracy: 0.3135\n",
            "Epoch 29/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.4891 - accuracy: 0.3523\n",
            "Epoch 00029: loss improved from 1.49083 to 1.48911, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f59b980be10>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4891 - accuracy: 0.3522 - val_loss: 1.4934 - val_accuracy: 0.3175\n",
            "Epoch 30/50\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.4910 - accuracy: 0.3548\n",
            "Epoch 00030: loss did not improve from 1.48911\n",
            "595/595 [==============================] - 7s 13ms/step - loss: 1.4905 - accuracy: 0.3550 - val_loss: 1.5024 - val_accuracy: 0.3219\n",
            "Epoch 31/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.4887 - accuracy: 0.3515\n",
            "Epoch 00031: loss improved from 1.48911 to 1.48862, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f59b980be10>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.4886 - accuracy: 0.3515 - val_loss: 1.5028 - val_accuracy: 0.3165\n",
            "Epoch 32/50\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.4880 - accuracy: 0.3565\n",
            "Epoch 00032: loss improved from 1.48862 to 1.48799, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f59b980be10>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.4880 - accuracy: 0.3565 - val_loss: 1.4962 - val_accuracy: 0.3358\n",
            "Epoch 33/50\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.4857 - accuracy: 0.3543\n",
            "Epoch 00033: loss improved from 1.48799 to 1.48555, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f59b980be10>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4856 - accuracy: 0.3542 - val_loss: 1.4972 - val_accuracy: 0.3116\n",
            "Epoch 34/50\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.4866 - accuracy: 0.3557\n",
            "Epoch 00034: loss did not improve from 1.48555\n",
            "595/595 [==============================] - 7s 13ms/step - loss: 1.4864 - accuracy: 0.3560 - val_loss: 1.4973 - val_accuracy: 0.3326\n",
            "Epoch 35/50\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.4833 - accuracy: 0.3616\n",
            "Epoch 00035: loss improved from 1.48555 to 1.48334, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f59b980be10>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.4833 - accuracy: 0.3617 - val_loss: 1.4953 - val_accuracy: 0.3423\n",
            "Epoch 36/50\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.4840 - accuracy: 0.3608\n",
            "Epoch 00036: loss did not improve from 1.48334\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4839 - accuracy: 0.3613 - val_loss: 1.5000 - val_accuracy: 0.3189\n",
            "Epoch 37/50\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.4825 - accuracy: 0.3614\n",
            "Epoch 00037: loss improved from 1.48334 to 1.48232, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f59b980be10>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.4823 - accuracy: 0.3617 - val_loss: 1.5010 - val_accuracy: 0.3348\n",
            "Epoch 38/50\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.4834 - accuracy: 0.3639\n",
            "Epoch 00038: loss did not improve from 1.48232\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4836 - accuracy: 0.3639 - val_loss: 1.5014 - val_accuracy: 0.3291\n",
            "Epoch 39/50\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.4818 - accuracy: 0.3583\n",
            "Epoch 00039: loss improved from 1.48232 to 1.48190, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f59b980be10>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.4819 - accuracy: 0.3586 - val_loss: 1.4979 - val_accuracy: 0.3079\n",
            "Epoch 40/50\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.4813 - accuracy: 0.3637\n",
            "Epoch 00040: loss improved from 1.48190 to 1.48129, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f59b980be10>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4813 - accuracy: 0.3637 - val_loss: 1.5017 - val_accuracy: 0.3140\n",
            "Epoch 41/50\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.4789 - accuracy: 0.3597\n",
            "Epoch 00041: loss improved from 1.48129 to 1.47887, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f59b980be10>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.4789 - accuracy: 0.3597 - val_loss: 1.5018 - val_accuracy: 0.3259\n",
            "Epoch 42/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.4804 - accuracy: 0.3587\n",
            "Epoch 00042: loss did not improve from 1.47887\n",
            "595/595 [==============================] - 7s 13ms/step - loss: 1.4802 - accuracy: 0.3587 - val_loss: 1.4961 - val_accuracy: 0.3227\n",
            "Epoch 43/50\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.4788 - accuracy: 0.3599\n",
            "Epoch 00043: loss improved from 1.47887 to 1.47880, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f59b980be10>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.4788 - accuracy: 0.3600 - val_loss: 1.4985 - val_accuracy: 0.3221\n",
            "Epoch 44/50\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.4790 - accuracy: 0.3605\n",
            "Epoch 00044: loss did not improve from 1.47880\n",
            "595/595 [==============================] - 7s 12ms/step - loss: 1.4792 - accuracy: 0.3603 - val_loss: 1.5130 - val_accuracy: 0.3278\n",
            "Epoch 45/50\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.4783 - accuracy: 0.3635\n",
            "Epoch 00045: loss improved from 1.47880 to 1.47768, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f59b980be10>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.4777 - accuracy: 0.3638 - val_loss: 1.4963 - val_accuracy: 0.3310\n",
            "Epoch 46/50\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.4771 - accuracy: 0.3639\n",
            "Epoch 00046: loss improved from 1.47768 to 1.47717, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f59b980be10>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.4772 - accuracy: 0.3637 - val_loss: 1.4970 - val_accuracy: 0.3264\n",
            "Epoch 47/50\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.4787 - accuracy: 0.3628\n",
            "Epoch 00047: loss did not improve from 1.47717\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4781 - accuracy: 0.3634 - val_loss: 1.5040 - val_accuracy: 0.3213\n",
            "Epoch 48/50\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.4762 - accuracy: 0.3661\n",
            "Epoch 00048: loss improved from 1.47717 to 1.47640, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f59b980be10>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.4764 - accuracy: 0.3661 - val_loss: 1.4992 - val_accuracy: 0.3208\n",
            "Epoch 49/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.4754 - accuracy: 0.3651\n",
            "Epoch 00049: loss improved from 1.47640 to 1.47536, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f59b980be10>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4754 - accuracy: 0.3650 - val_loss: 1.5013 - val_accuracy: 0.3251\n",
            "Epoch 50/50\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.4726 - accuracy: 0.3676\n",
            "Epoch 00050: loss improved from 1.47536 to 1.47272, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f59b980be10>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4727 - accuracy: 0.3675 - val_loss: 1.4998 - val_accuracy: 0.3367\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/50\n",
            "  2/595 [..............................] - ETA: 33s - loss: 2.1722 - accuracy: 0.0400   WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0142s vs `on_train_batch_end` time: 0.0968s). Check your callbacks.\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.6596 - accuracy: 0.3032\n",
            "Epoch 00001: loss improved from inf to 1.65915, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f59b2f7e080>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.6591 - accuracy: 0.3035 - val_loss: 1.5447 - val_accuracy: 0.3399\n",
            "Epoch 2/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5574 - accuracy: 0.3436\n",
            "Epoch 00002: loss improved from 1.65915 to 1.55745, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f59b2f7e080>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5574 - accuracy: 0.3435 - val_loss: 1.5183 - val_accuracy: 0.3399\n",
            "Epoch 3/50\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5435 - accuracy: 0.3435\n",
            "Epoch 00003: loss improved from 1.55745 to 1.54326, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f59b2f7e080>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5433 - accuracy: 0.3437 - val_loss: 1.5096 - val_accuracy: 0.3399\n",
            "Epoch 4/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5368 - accuracy: 0.3437\n",
            "Epoch 00004: loss improved from 1.54326 to 1.53677, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f59b2f7e080>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5368 - accuracy: 0.3437 - val_loss: 1.5056 - val_accuracy: 0.3399\n",
            "Epoch 5/50\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5348 - accuracy: 0.3443\n",
            "Epoch 00005: loss improved from 1.53677 to 1.53525, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f59b2f7e080>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5352 - accuracy: 0.3438 - val_loss: 1.5030 - val_accuracy: 0.3399\n",
            "Epoch 6/50\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5325 - accuracy: 0.3437\n",
            "Epoch 00006: loss improved from 1.53525 to 1.53254, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f59b2f7e080>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5325 - accuracy: 0.3433 - val_loss: 1.5013 - val_accuracy: 0.3399\n",
            "Epoch 7/50\n",
            "589/595 [============================>.] - ETA: 0s - loss: 1.5307 - accuracy: 0.3439\n",
            "Epoch 00007: loss improved from 1.53254 to 1.53099, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f59b2f7e080>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5310 - accuracy: 0.3436 - val_loss: 1.5011 - val_accuracy: 0.3399\n",
            "Epoch 8/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5310 - accuracy: 0.3438\n",
            "Epoch 00008: loss did not improve from 1.53099\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5310 - accuracy: 0.3437 - val_loss: 1.5000 - val_accuracy: 0.3399\n",
            "Epoch 9/50\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5302 - accuracy: 0.3437\n",
            "Epoch 00009: loss improved from 1.53099 to 1.53016, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f59b2f7e080>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5302 - accuracy: 0.3436 - val_loss: 1.4995 - val_accuracy: 0.3399\n",
            "Epoch 10/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5298 - accuracy: 0.3436\n",
            "Epoch 00010: loss improved from 1.53016 to 1.52974, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f59b2f7e080>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5297 - accuracy: 0.3436 - val_loss: 1.4991 - val_accuracy: 0.3399\n",
            "Epoch 11/50\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5308 - accuracy: 0.3437\n",
            "Epoch 00011: loss did not improve from 1.52974\n",
            "595/595 [==============================] - 7s 13ms/step - loss: 1.5307 - accuracy: 0.3434 - val_loss: 1.4995 - val_accuracy: 0.3399\n",
            "Epoch 12/50\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5300 - accuracy: 0.3431\n",
            "Epoch 00012: loss did not improve from 1.52974\n",
            "595/595 [==============================] - 7s 13ms/step - loss: 1.5301 - accuracy: 0.3434 - val_loss: 1.4995 - val_accuracy: 0.3399\n",
            "Epoch 13/50\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5300 - accuracy: 0.3436\n",
            "Epoch 00013: loss did not improve from 1.52974\n",
            "595/595 [==============================] - 7s 12ms/step - loss: 1.5300 - accuracy: 0.3436 - val_loss: 1.4989 - val_accuracy: 0.3399\n",
            "Epoch 14/50\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5299 - accuracy: 0.3436\n",
            "Epoch 00014: loss improved from 1.52974 to 1.52948, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f59b2f7e080>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5295 - accuracy: 0.3440 - val_loss: 1.4983 - val_accuracy: 0.3399\n",
            "Epoch 15/50\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5290 - accuracy: 0.3439\n",
            "Epoch 00015: loss improved from 1.52948 to 1.52879, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f59b2f7e080>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5288 - accuracy: 0.3440 - val_loss: 1.4984 - val_accuracy: 0.3399\n",
            "Epoch 16/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5290 - accuracy: 0.3436\n",
            "Epoch 00016: loss did not improve from 1.52879\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5292 - accuracy: 0.3434 - val_loss: 1.4985 - val_accuracy: 0.3399\n",
            "Epoch 17/50\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5282 - accuracy: 0.3437\n",
            "Epoch 00017: loss improved from 1.52879 to 1.52853, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f59b2f7e080>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5285 - accuracy: 0.3435 - val_loss: 1.4985 - val_accuracy: 0.3399\n",
            "Epoch 18/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5290 - accuracy: 0.3438\n",
            "Epoch 00018: loss did not improve from 1.52853\n",
            "595/595 [==============================] - 7s 13ms/step - loss: 1.5293 - accuracy: 0.3436 - val_loss: 1.4980 - val_accuracy: 0.3399\n",
            "Epoch 19/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5290 - accuracy: 0.3436\n",
            "Epoch 00019: loss did not improve from 1.52853\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5289 - accuracy: 0.3435 - val_loss: 1.4983 - val_accuracy: 0.3399\n",
            "Epoch 20/50\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5285 - accuracy: 0.3437\n",
            "Epoch 00020: loss did not improve from 1.52853\n",
            "595/595 [==============================] - 7s 12ms/step - loss: 1.5286 - accuracy: 0.3437 - val_loss: 1.4985 - val_accuracy: 0.3399\n",
            "Epoch 21/50\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5292 - accuracy: 0.3436\n",
            "Epoch 00021: loss did not improve from 1.52853\n",
            "595/595 [==============================] - 7s 12ms/step - loss: 1.5294 - accuracy: 0.3432 - val_loss: 1.4985 - val_accuracy: 0.3399\n",
            "Epoch 22/50\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5300 - accuracy: 0.3435\n",
            "Epoch 00022: loss did not improve from 1.52853\n",
            "595/595 [==============================] - 7s 13ms/step - loss: 1.5300 - accuracy: 0.3433 - val_loss: 1.4987 - val_accuracy: 0.3399\n",
            "Epoch 23/50\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5278 - accuracy: 0.3438\n",
            "Epoch 00023: loss improved from 1.52853 to 1.52793, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f59b2f7e080>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5279 - accuracy: 0.3436 - val_loss: 1.4985 - val_accuracy: 0.3399\n",
            "Epoch 24/50\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5281 - accuracy: 0.3440\n",
            "Epoch 00024: loss did not improve from 1.52793\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5281 - accuracy: 0.3440 - val_loss: 1.4986 - val_accuracy: 0.3399\n",
            "Epoch 25/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5285 - accuracy: 0.3434\n",
            "Epoch 00025: loss did not improve from 1.52793\n",
            "595/595 [==============================] - 7s 12ms/step - loss: 1.5284 - accuracy: 0.3434 - val_loss: 1.4983 - val_accuracy: 0.3399\n",
            "Epoch 26/50\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5282 - accuracy: 0.3436\n",
            "Epoch 00026: loss did not improve from 1.52793\n",
            "595/595 [==============================] - 7s 12ms/step - loss: 1.5282 - accuracy: 0.3436 - val_loss: 1.4984 - val_accuracy: 0.3399\n",
            "Epoch 27/50\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5283 - accuracy: 0.3437\n",
            "Epoch 00027: loss did not improve from 1.52793\n",
            "595/595 [==============================] - 7s 12ms/step - loss: 1.5281 - accuracy: 0.3436 - val_loss: 1.4982 - val_accuracy: 0.3399\n",
            "Epoch 28/50\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5298 - accuracy: 0.3432\n",
            "Epoch 00028: loss did not improve from 1.52793\n",
            "595/595 [==============================] - 7s 12ms/step - loss: 1.5295 - accuracy: 0.3435 - val_loss: 1.4982 - val_accuracy: 0.3399\n",
            "Epoch 29/50\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5284 - accuracy: 0.3436\n",
            "Epoch 00029: loss did not improve from 1.52793\n",
            "595/595 [==============================] - 7s 12ms/step - loss: 1.5286 - accuracy: 0.3436 - val_loss: 1.4984 - val_accuracy: 0.3399\n",
            "Epoch 30/50\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5290 - accuracy: 0.3438\n",
            "Epoch 00030: loss did not improve from 1.52793\n",
            "595/595 [==============================] - 7s 12ms/step - loss: 1.5286 - accuracy: 0.3436 - val_loss: 1.4982 - val_accuracy: 0.3399\n",
            "Epoch 31/50\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5286 - accuracy: 0.3427\n",
            "Epoch 00031: loss did not improve from 1.52793\n",
            "595/595 [==============================] - 7s 12ms/step - loss: 1.5283 - accuracy: 0.3436 - val_loss: 1.4988 - val_accuracy: 0.3399\n",
            "Epoch 32/50\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5283 - accuracy: 0.3439\n",
            "Epoch 00032: loss did not improve from 1.52793\n",
            "595/595 [==============================] - 7s 13ms/step - loss: 1.5285 - accuracy: 0.3435 - val_loss: 1.4985 - val_accuracy: 0.3399\n",
            "Epoch 33/50\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5294 - accuracy: 0.3427\n",
            "Epoch 00033: loss did not improve from 1.52793\n",
            "595/595 [==============================] - 7s 12ms/step - loss: 1.5288 - accuracy: 0.3434 - val_loss: 1.4987 - val_accuracy: 0.3399\n",
            "Epoch 34/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5284 - accuracy: 0.3436\n",
            "Epoch 00034: loss did not improve from 1.52793\n",
            "595/595 [==============================] - 7s 13ms/step - loss: 1.5285 - accuracy: 0.3435 - val_loss: 1.4988 - val_accuracy: 0.3399\n",
            "Epoch 35/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5286 - accuracy: 0.3436\n",
            "Epoch 00035: loss did not improve from 1.52793\n",
            "595/595 [==============================] - 7s 12ms/step - loss: 1.5286 - accuracy: 0.3436 - val_loss: 1.4989 - val_accuracy: 0.3399\n",
            "Epoch 36/50\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5276 - accuracy: 0.3435\n",
            "Epoch 00036: loss improved from 1.52793 to 1.52740, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f59b2f7e080>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5274 - accuracy: 0.3437 - val_loss: 1.4987 - val_accuracy: 0.3399\n",
            "Epoch 37/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5273 - accuracy: 0.3434\n",
            "Epoch 00037: loss improved from 1.52740 to 1.52715, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f59b2f7e080>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5272 - accuracy: 0.3435 - val_loss: 1.4988 - val_accuracy: 0.3399\n",
            "Epoch 38/50\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5272 - accuracy: 0.3445\n",
            "Epoch 00038: loss did not improve from 1.52715\n",
            "595/595 [==============================] - 7s 12ms/step - loss: 1.5278 - accuracy: 0.3439 - val_loss: 1.4990 - val_accuracy: 0.3399\n",
            "Epoch 39/50\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5288 - accuracy: 0.3437\n",
            "Epoch 00039: loss did not improve from 1.52715\n",
            "595/595 [==============================] - 7s 12ms/step - loss: 1.5288 - accuracy: 0.3438 - val_loss: 1.4988 - val_accuracy: 0.3399\n",
            "Epoch 40/50\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5273 - accuracy: 0.3437\n",
            "Epoch 00040: loss did not improve from 1.52715\n",
            "595/595 [==============================] - 7s 12ms/step - loss: 1.5274 - accuracy: 0.3435 - val_loss: 1.4991 - val_accuracy: 0.3399\n",
            "Epoch 41/50\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5273 - accuracy: 0.3440\n",
            "Epoch 00041: loss did not improve from 1.52715\n",
            "595/595 [==============================] - 7s 12ms/step - loss: 1.5274 - accuracy: 0.3436 - val_loss: 1.4991 - val_accuracy: 0.3399\n",
            "Epoch 42/50\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5276 - accuracy: 0.3437\n",
            "Epoch 00042: loss did not improve from 1.52715\n",
            "595/595 [==============================] - 7s 12ms/step - loss: 1.5274 - accuracy: 0.3436 - val_loss: 1.4991 - val_accuracy: 0.3399\n",
            "Epoch 43/50\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5283 - accuracy: 0.3434\n",
            "Epoch 00043: loss did not improve from 1.52715\n",
            "595/595 [==============================] - 7s 12ms/step - loss: 1.5280 - accuracy: 0.3437 - val_loss: 1.4989 - val_accuracy: 0.3399\n",
            "Epoch 44/50\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5275 - accuracy: 0.3434\n",
            "Epoch 00044: loss did not improve from 1.52715\n",
            "595/595 [==============================] - 7s 13ms/step - loss: 1.5275 - accuracy: 0.3434 - val_loss: 1.4990 - val_accuracy: 0.3399\n",
            "Epoch 45/50\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5273 - accuracy: 0.3440\n",
            "Epoch 00045: loss did not improve from 1.52715\n",
            "595/595 [==============================] - 7s 13ms/step - loss: 1.5276 - accuracy: 0.3436 - val_loss: 1.4991 - val_accuracy: 0.3399\n",
            "Epoch 46/50\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5278 - accuracy: 0.3436\n",
            "Epoch 00046: loss did not improve from 1.52715\n",
            "595/595 [==============================] - 7s 12ms/step - loss: 1.5280 - accuracy: 0.3435 - val_loss: 1.4990 - val_accuracy: 0.3399\n",
            "Epoch 47/50\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5281 - accuracy: 0.3434\n",
            "Epoch 00047: loss did not improve from 1.52715\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5278 - accuracy: 0.3436 - val_loss: 1.4992 - val_accuracy: 0.3399\n",
            "Epoch 48/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5279 - accuracy: 0.3436\n",
            "Epoch 00048: loss did not improve from 1.52715\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5279 - accuracy: 0.3436 - val_loss: 1.4991 - val_accuracy: 0.3399\n",
            "Epoch 49/50\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5276 - accuracy: 0.3437\n",
            "Epoch 00049: loss did not improve from 1.52715\n",
            "595/595 [==============================] - 7s 12ms/step - loss: 1.5276 - accuracy: 0.3437 - val_loss: 1.4992 - val_accuracy: 0.3399\n",
            "Epoch 50/50\n",
            "589/595 [============================>.] - ETA: 0s - loss: 1.5268 - accuracy: 0.3440\n",
            "Epoch 00050: loss did not improve from 1.52715\n",
            "595/595 [==============================] - 7s 12ms/step - loss: 1.5273 - accuracy: 0.3436 - val_loss: 1.4991 - val_accuracy: 0.3399\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/50\n",
            "  2/595 [..............................] - ETA: 31s - loss: 2.1827 - accuracy: 0.1000WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0144s vs `on_train_batch_end` time: 0.0926s). Check your callbacks.\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5557 - accuracy: 0.3273\n",
            "Epoch 00001: loss improved from inf to 1.55562, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59b0bdc0b8>_Batch25_LR0.01_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5556 - accuracy: 0.3274 - val_loss: 1.5055 - val_accuracy: 0.3399\n",
            "Epoch 2/50\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5370 - accuracy: 0.3372\n",
            "Epoch 00002: loss improved from 1.55562 to 1.53693, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59b0bdc0b8>_Batch25_LR0.01_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5369 - accuracy: 0.3377 - val_loss: 1.5081 - val_accuracy: 0.3375\n",
            "Epoch 3/50\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5326 - accuracy: 0.3397\n",
            "Epoch 00003: loss improved from 1.53693 to 1.53259, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59b0bdc0b8>_Batch25_LR0.01_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5326 - accuracy: 0.3397 - val_loss: 1.5073 - val_accuracy: 0.3399\n",
            "Epoch 4/50\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5301 - accuracy: 0.3424\n",
            "Epoch 00004: loss improved from 1.53259 to 1.52969, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59b0bdc0b8>_Batch25_LR0.01_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5297 - accuracy: 0.3424 - val_loss: 1.5038 - val_accuracy: 0.3399\n",
            "Epoch 5/50\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5298 - accuracy: 0.3429\n",
            "Epoch 00005: loss improved from 1.52969 to 1.52939, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59b0bdc0b8>_Batch25_LR0.01_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5294 - accuracy: 0.3431 - val_loss: 1.5054 - val_accuracy: 0.3399\n",
            "Epoch 6/50\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5284 - accuracy: 0.3415\n",
            "Epoch 00006: loss improved from 1.52939 to 1.52830, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59b0bdc0b8>_Batch25_LR0.01_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5283 - accuracy: 0.3413 - val_loss: 1.5034 - val_accuracy: 0.3399\n",
            "Epoch 7/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5273 - accuracy: 0.3422\n",
            "Epoch 00007: loss improved from 1.52830 to 1.52718, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59b0bdc0b8>_Batch25_LR0.01_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5272 - accuracy: 0.3422 - val_loss: 1.5039 - val_accuracy: 0.3399\n",
            "Epoch 8/50\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5266 - accuracy: 0.3432\n",
            "Epoch 00008: loss improved from 1.52718 to 1.52615, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59b0bdc0b8>_Batch25_LR0.01_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5262 - accuracy: 0.3433 - val_loss: 1.4998 - val_accuracy: 0.3399\n",
            "Epoch 9/50\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5259 - accuracy: 0.3419\n",
            "Epoch 00009: loss improved from 1.52615 to 1.52535, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59b0bdc0b8>_Batch25_LR0.01_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5254 - accuracy: 0.3424 - val_loss: 1.4999 - val_accuracy: 0.3399\n",
            "Epoch 10/50\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5241 - accuracy: 0.3438\n",
            "Epoch 00010: loss improved from 1.52535 to 1.52465, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59b0bdc0b8>_Batch25_LR0.01_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5247 - accuracy: 0.3439 - val_loss: 1.5060 - val_accuracy: 0.3399\n",
            "Epoch 11/50\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5229 - accuracy: 0.3438\n",
            "Epoch 00011: loss improved from 1.52465 to 1.52328, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59b0bdc0b8>_Batch25_LR0.01_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5233 - accuracy: 0.3433 - val_loss: 1.4973 - val_accuracy: 0.3399\n",
            "Epoch 12/50\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5247 - accuracy: 0.3429\n",
            "Epoch 00012: loss did not improve from 1.52328\n",
            "595/595 [==============================] - 7s 12ms/step - loss: 1.5243 - accuracy: 0.3432 - val_loss: 1.4952 - val_accuracy: 0.3399\n",
            "Epoch 13/50\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5233 - accuracy: 0.3427\n",
            "Epoch 00013: loss improved from 1.52328 to 1.52327, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59b0bdc0b8>_Batch25_LR0.01_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5233 - accuracy: 0.3429 - val_loss: 1.5010 - val_accuracy: 0.3399\n",
            "Epoch 14/50\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5223 - accuracy: 0.3444\n",
            "Epoch 00014: loss improved from 1.52327 to 1.52237, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59b0bdc0b8>_Batch25_LR0.01_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5224 - accuracy: 0.3444 - val_loss: 1.4972 - val_accuracy: 0.3399\n",
            "Epoch 15/50\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5215 - accuracy: 0.3441\n",
            "Epoch 00015: loss improved from 1.52237 to 1.52176, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59b0bdc0b8>_Batch25_LR0.01_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5218 - accuracy: 0.3439 - val_loss: 1.4977 - val_accuracy: 0.3399\n",
            "Epoch 16/50\n",
            "589/595 [============================>.] - ETA: 0s - loss: 1.5216 - accuracy: 0.3443\n",
            "Epoch 00016: loss improved from 1.52176 to 1.52147, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59b0bdc0b8>_Batch25_LR0.01_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5215 - accuracy: 0.3439 - val_loss: 1.4912 - val_accuracy: 0.3369\n",
            "Epoch 17/50\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5215 - accuracy: 0.3429\n",
            "Epoch 00017: loss improved from 1.52147 to 1.52134, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59b0bdc0b8>_Batch25_LR0.01_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5213 - accuracy: 0.3428 - val_loss: 1.4945 - val_accuracy: 0.3399\n",
            "Epoch 18/50\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5203 - accuracy: 0.3422\n",
            "Epoch 00018: loss improved from 1.52134 to 1.52010, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59b0bdc0b8>_Batch25_LR0.01_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5201 - accuracy: 0.3424 - val_loss: 1.4996 - val_accuracy: 0.3399\n",
            "Epoch 19/50\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5197 - accuracy: 0.3429\n",
            "Epoch 00019: loss improved from 1.52010 to 1.51972, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59b0bdc0b8>_Batch25_LR0.01_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5197 - accuracy: 0.3429 - val_loss: 1.4925 - val_accuracy: 0.3399\n",
            "Epoch 20/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5208 - accuracy: 0.3427\n",
            "Epoch 00020: loss did not improve from 1.51972\n",
            "595/595 [==============================] - 7s 12ms/step - loss: 1.5207 - accuracy: 0.3426 - val_loss: 1.5184 - val_accuracy: 0.3399\n",
            "Epoch 21/50\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5184 - accuracy: 0.3430\n",
            "Epoch 00021: loss improved from 1.51972 to 1.51848, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59b0bdc0b8>_Batch25_LR0.01_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5185 - accuracy: 0.3434 - val_loss: 1.5268 - val_accuracy: 0.3399\n",
            "Epoch 22/50\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5204 - accuracy: 0.3429\n",
            "Epoch 00022: loss did not improve from 1.51848\n",
            "595/595 [==============================] - 7s 12ms/step - loss: 1.5198 - accuracy: 0.3433 - val_loss: 1.4964 - val_accuracy: 0.3399\n",
            "Epoch 23/50\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5192 - accuracy: 0.3428\n",
            "Epoch 00023: loss did not improve from 1.51848\n",
            "595/595 [==============================] - 7s 13ms/step - loss: 1.5188 - accuracy: 0.3432 - val_loss: 1.5109 - val_accuracy: 0.3399\n",
            "Epoch 24/50\n",
            "589/595 [============================>.] - ETA: 0s - loss: 1.5180 - accuracy: 0.3442\n",
            "Epoch 00024: loss improved from 1.51848 to 1.51811, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59b0bdc0b8>_Batch25_LR0.01_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5181 - accuracy: 0.3441 - val_loss: 1.5014 - val_accuracy: 0.3399\n",
            "Epoch 25/50\n",
            "589/595 [============================>.] - ETA: 0s - loss: 1.5170 - accuracy: 0.3432\n",
            "Epoch 00025: loss improved from 1.51811 to 1.51700, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59b0bdc0b8>_Batch25_LR0.01_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5170 - accuracy: 0.3430 - val_loss: 1.4958 - val_accuracy: 0.3399\n",
            "Epoch 26/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5170 - accuracy: 0.3428\n",
            "Epoch 00026: loss improved from 1.51700 to 1.51689, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59b0bdc0b8>_Batch25_LR0.01_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5169 - accuracy: 0.3428 - val_loss: 1.4952 - val_accuracy: 0.3399\n",
            "Epoch 27/50\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5143 - accuracy: 0.3433\n",
            "Epoch 00027: loss improved from 1.51689 to 1.51445, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59b0bdc0b8>_Batch25_LR0.01_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5144 - accuracy: 0.3432 - val_loss: 1.5125 - val_accuracy: 0.3399\n",
            "Epoch 28/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5167 - accuracy: 0.3424\n",
            "Epoch 00028: loss did not improve from 1.51445\n",
            "595/595 [==============================] - 7s 13ms/step - loss: 1.5169 - accuracy: 0.3424 - val_loss: 1.5033 - val_accuracy: 0.3399\n",
            "Epoch 29/50\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5160 - accuracy: 0.3436\n",
            "Epoch 00029: loss did not improve from 1.51445\n",
            "595/595 [==============================] - 7s 13ms/step - loss: 1.5158 - accuracy: 0.3434 - val_loss: 1.5016 - val_accuracy: 0.3399\n",
            "Epoch 30/50\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5159 - accuracy: 0.3429\n",
            "Epoch 00030: loss did not improve from 1.51445\n",
            "595/595 [==============================] - 7s 13ms/step - loss: 1.5157 - accuracy: 0.3431 - val_loss: 1.4935 - val_accuracy: 0.3399\n",
            "Epoch 31/50\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5144 - accuracy: 0.3415\n",
            "Epoch 00031: loss improved from 1.51445 to 1.51441, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59b0bdc0b8>_Batch25_LR0.01_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5144 - accuracy: 0.3415 - val_loss: 1.5011 - val_accuracy: 0.3399\n",
            "Epoch 32/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5143 - accuracy: 0.3418\n",
            "Epoch 00032: loss improved from 1.51441 to 1.51427, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59b0bdc0b8>_Batch25_LR0.01_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5143 - accuracy: 0.3418 - val_loss: 1.5067 - val_accuracy: 0.3399\n",
            "Epoch 33/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5144 - accuracy: 0.3447\n",
            "Epoch 00033: loss did not improve from 1.51427\n",
            "595/595 [==============================] - 7s 12ms/step - loss: 1.5144 - accuracy: 0.3447 - val_loss: 1.5019 - val_accuracy: 0.3399\n",
            "Epoch 34/50\n",
            "589/595 [============================>.] - ETA: 0s - loss: 1.5133 - accuracy: 0.3423\n",
            "Epoch 00034: loss improved from 1.51427 to 1.51376, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59b0bdc0b8>_Batch25_LR0.01_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5138 - accuracy: 0.3422 - val_loss: 1.4979 - val_accuracy: 0.3399\n",
            "Epoch 35/50\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5135 - accuracy: 0.3448\n",
            "Epoch 00035: loss improved from 1.51376 to 1.51330, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59b0bdc0b8>_Batch25_LR0.01_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5133 - accuracy: 0.3449 - val_loss: 1.4936 - val_accuracy: 0.3399\n",
            "Epoch 36/50\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5127 - accuracy: 0.3447\n",
            "Epoch 00036: loss improved from 1.51330 to 1.51267, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59b0bdc0b8>_Batch25_LR0.01_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5127 - accuracy: 0.3447 - val_loss: 1.4984 - val_accuracy: 0.3399\n",
            "Epoch 37/50\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5128 - accuracy: 0.3458\n",
            "Epoch 00037: loss improved from 1.51267 to 1.51266, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59b0bdc0b8>_Batch25_LR0.01_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5127 - accuracy: 0.3456 - val_loss: 1.4895 - val_accuracy: 0.3399\n",
            "Epoch 38/50\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5113 - accuracy: 0.3430\n",
            "Epoch 00038: loss improved from 1.51266 to 1.51157, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59b0bdc0b8>_Batch25_LR0.01_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5116 - accuracy: 0.3428 - val_loss: 1.4925 - val_accuracy: 0.3393\n",
            "Epoch 39/50\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5118 - accuracy: 0.3432\n",
            "Epoch 00039: loss did not improve from 1.51157\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5117 - accuracy: 0.3436 - val_loss: 1.5276 - val_accuracy: 0.3340\n",
            "Epoch 40/50\n",
            "589/595 [============================>.] - ETA: 0s - loss: 1.5109 - accuracy: 0.3451\n",
            "Epoch 00040: loss improved from 1.51157 to 1.51091, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59b0bdc0b8>_Batch25_LR0.01_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5109 - accuracy: 0.3450 - val_loss: 1.4986 - val_accuracy: 0.3399\n",
            "Epoch 41/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5118 - accuracy: 0.3463\n",
            "Epoch 00041: loss did not improve from 1.51091\n",
            "595/595 [==============================] - 7s 12ms/step - loss: 1.5117 - accuracy: 0.3464 - val_loss: 1.5011 - val_accuracy: 0.3399\n",
            "Epoch 42/50\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5109 - accuracy: 0.3439\n",
            "Epoch 00042: loss did not improve from 1.51091\n",
            "595/595 [==============================] - 7s 12ms/step - loss: 1.5110 - accuracy: 0.3437 - val_loss: 1.5008 - val_accuracy: 0.3372\n",
            "Epoch 43/50\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5107 - accuracy: 0.3448\n",
            "Epoch 00043: loss improved from 1.51091 to 1.51050, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59b0bdc0b8>_Batch25_LR0.01_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5105 - accuracy: 0.3449 - val_loss: 1.5099 - val_accuracy: 0.3399\n",
            "Epoch 44/50\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5113 - accuracy: 0.3439\n",
            "Epoch 00044: loss did not improve from 1.51050\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5113 - accuracy: 0.3439 - val_loss: 1.5022 - val_accuracy: 0.3372\n",
            "Epoch 45/50\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5101 - accuracy: 0.3443\n",
            "Epoch 00045: loss improved from 1.51050 to 1.51000, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59b0bdc0b8>_Batch25_LR0.01_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5100 - accuracy: 0.3443 - val_loss: 1.5027 - val_accuracy: 0.3372\n",
            "Epoch 46/50\n",
            "589/595 [============================>.] - ETA: 0s - loss: 1.5095 - accuracy: 0.3438\n",
            "Epoch 00046: loss improved from 1.51000 to 1.50932, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59b0bdc0b8>_Batch25_LR0.01_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5093 - accuracy: 0.3445 - val_loss: 1.5084 - val_accuracy: 0.3375\n",
            "Epoch 47/50\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5095 - accuracy: 0.3437\n",
            "Epoch 00047: loss did not improve from 1.50932\n",
            "595/595 [==============================] - 7s 12ms/step - loss: 1.5094 - accuracy: 0.3436 - val_loss: 1.4981 - val_accuracy: 0.3245\n",
            "Epoch 48/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5093 - accuracy: 0.3433\n",
            "Epoch 00048: loss did not improve from 1.50932\n",
            "595/595 [==============================] - 7s 13ms/step - loss: 1.5098 - accuracy: 0.3432 - val_loss: 1.5083 - val_accuracy: 0.3375\n",
            "Epoch 49/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5088 - accuracy: 0.3468\n",
            "Epoch 00049: loss improved from 1.50932 to 1.50881, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59b0bdc0b8>_Batch25_LR0.01_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5088 - accuracy: 0.3468 - val_loss: 1.5093 - val_accuracy: 0.3372\n",
            "Epoch 50/50\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5091 - accuracy: 0.3438\n",
            "Epoch 00050: loss did not improve from 1.50881\n",
            "595/595 [==============================] - 7s 12ms/step - loss: 1.5090 - accuracy: 0.3439 - val_loss: 1.4919 - val_accuracy: 0.3372\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/50\n",
            "  2/595 [..............................] - ETA: 42s - loss: 3.1488 - accuracy: 0.2200   WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0150s vs `on_train_batch_end` time: 0.1315s). Check your callbacks.\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5630 - accuracy: 0.3333\n",
            "Epoch 00001: loss improved from inf to 1.56282, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f59b0bce5c0>_Batch25_LR0.01_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5628 - accuracy: 0.3334 - val_loss: 1.5065 - val_accuracy: 0.3399\n",
            "Epoch 2/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5301 - accuracy: 0.3427\n",
            "Epoch 00002: loss improved from 1.56282 to 1.53018, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f59b0bce5c0>_Batch25_LR0.01_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5302 - accuracy: 0.3426 - val_loss: 1.4938 - val_accuracy: 0.3399\n",
            "Epoch 3/50\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5294 - accuracy: 0.3434\n",
            "Epoch 00003: loss improved from 1.53018 to 1.52923, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f59b0bce5c0>_Batch25_LR0.01_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5292 - accuracy: 0.3436 - val_loss: 1.4991 - val_accuracy: 0.3399\n",
            "Epoch 4/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5298 - accuracy: 0.3438\n",
            "Epoch 00004: loss did not improve from 1.52923\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5298 - accuracy: 0.3436 - val_loss: 1.4925 - val_accuracy: 0.3399\n",
            "Epoch 5/50\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5290 - accuracy: 0.3438\n",
            "Epoch 00005: loss did not improve from 1.52923\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5296 - accuracy: 0.3436 - val_loss: 1.4962 - val_accuracy: 0.3399\n",
            "Epoch 6/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5298 - accuracy: 0.3436\n",
            "Epoch 00006: loss did not improve from 1.52923\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5298 - accuracy: 0.3436 - val_loss: 1.4986 - val_accuracy: 0.3399\n",
            "Epoch 7/50\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5300 - accuracy: 0.3433\n",
            "Epoch 00007: loss did not improve from 1.52923\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5298 - accuracy: 0.3436 - val_loss: 1.4970 - val_accuracy: 0.3399\n",
            "Epoch 8/50\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5296 - accuracy: 0.3436\n",
            "Epoch 00008: loss did not improve from 1.52923\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5297 - accuracy: 0.3436 - val_loss: 1.5001 - val_accuracy: 0.3399\n",
            "Epoch 9/50\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5298 - accuracy: 0.3439\n",
            "Epoch 00009: loss did not improve from 1.52923\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5295 - accuracy: 0.3436 - val_loss: 1.4960 - val_accuracy: 0.3399\n",
            "Epoch 10/50\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5302 - accuracy: 0.3438\n",
            "Epoch 00010: loss did not improve from 1.52923\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5303 - accuracy: 0.3436 - val_loss: 1.4957 - val_accuracy: 0.3399\n",
            "Epoch 11/50\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5304 - accuracy: 0.3437\n",
            "Epoch 00011: loss did not improve from 1.52923\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5304 - accuracy: 0.3436 - val_loss: 1.4980 - val_accuracy: 0.3399\n",
            "Epoch 12/50\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5302 - accuracy: 0.3442\n",
            "Epoch 00012: loss did not improve from 1.52923\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5304 - accuracy: 0.3436 - val_loss: 1.4941 - val_accuracy: 0.3399\n",
            "Epoch 13/50\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5294 - accuracy: 0.3441\n",
            "Epoch 00013: loss did not improve from 1.52923\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5296 - accuracy: 0.3436 - val_loss: 1.4961 - val_accuracy: 0.3399\n",
            "Epoch 14/50\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5298 - accuracy: 0.3433\n",
            "Epoch 00014: loss did not improve from 1.52923\n",
            "595/595 [==============================] - 7s 13ms/step - loss: 1.5297 - accuracy: 0.3436 - val_loss: 1.4979 - val_accuracy: 0.3399\n",
            "Epoch 15/50\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5294 - accuracy: 0.3438\n",
            "Epoch 00015: loss did not improve from 1.52923\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5294 - accuracy: 0.3436 - val_loss: 1.4927 - val_accuracy: 0.3399\n",
            "Epoch 16/50\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5297 - accuracy: 0.3436\n",
            "Epoch 00016: loss did not improve from 1.52923\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5296 - accuracy: 0.3436 - val_loss: 1.4921 - val_accuracy: 0.3399\n",
            "Epoch 17/50\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5303 - accuracy: 0.3434\n",
            "Epoch 00017: loss did not improve from 1.52923\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5299 - accuracy: 0.3436 - val_loss: 1.4927 - val_accuracy: 0.3399\n",
            "Epoch 18/50\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5300 - accuracy: 0.3431\n",
            "Epoch 00018: loss did not improve from 1.52923\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5296 - accuracy: 0.3436 - val_loss: 1.4993 - val_accuracy: 0.3399\n",
            "Epoch 19/50\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5305 - accuracy: 0.3434\n",
            "Epoch 00019: loss did not improve from 1.52923\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5304 - accuracy: 0.3436 - val_loss: 1.4951 - val_accuracy: 0.3399\n",
            "Epoch 20/50\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5301 - accuracy: 0.3436\n",
            "Epoch 00020: loss did not improve from 1.52923\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5301 - accuracy: 0.3436 - val_loss: 1.4947 - val_accuracy: 0.3399\n",
            "Epoch 21/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5299 - accuracy: 0.3438\n",
            "Epoch 00021: loss did not improve from 1.52923\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5301 - accuracy: 0.3436 - val_loss: 1.4925 - val_accuracy: 0.3399\n",
            "Epoch 22/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5298 - accuracy: 0.3436\n",
            "Epoch 00022: loss did not improve from 1.52923\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5298 - accuracy: 0.3436 - val_loss: 1.4903 - val_accuracy: 0.3399\n",
            "Epoch 23/50\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5303 - accuracy: 0.3435\n",
            "Epoch 00023: loss did not improve from 1.52923\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5300 - accuracy: 0.3436 - val_loss: 1.4915 - val_accuracy: 0.3399\n",
            "Epoch 24/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5299 - accuracy: 0.3438\n",
            "Epoch 00024: loss did not improve from 1.52923\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5300 - accuracy: 0.3436 - val_loss: 1.4985 - val_accuracy: 0.3399\n",
            "Epoch 25/50\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5293 - accuracy: 0.3438\n",
            "Epoch 00025: loss did not improve from 1.52923\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5299 - accuracy: 0.3436 - val_loss: 1.4931 - val_accuracy: 0.3399\n",
            "Epoch 26/50\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5296 - accuracy: 0.3440\n",
            "Epoch 00026: loss did not improve from 1.52923\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5299 - accuracy: 0.3436 - val_loss: 1.4970 - val_accuracy: 0.3399\n",
            "Epoch 27/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5297 - accuracy: 0.3436\n",
            "Epoch 00027: loss did not improve from 1.52923\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5297 - accuracy: 0.3436 - val_loss: 1.4943 - val_accuracy: 0.3399\n",
            "Epoch 28/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5292 - accuracy: 0.3438\n",
            "Epoch 00028: loss did not improve from 1.52923\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5295 - accuracy: 0.3436 - val_loss: 1.4958 - val_accuracy: 0.3399\n",
            "Epoch 29/50\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5293 - accuracy: 0.3437\n",
            "Epoch 00029: loss did not improve from 1.52923\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5293 - accuracy: 0.3436 - val_loss: 1.4972 - val_accuracy: 0.3399\n",
            "Epoch 30/50\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5299 - accuracy: 0.3434\n",
            "Epoch 00030: loss did not improve from 1.52923\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5301 - accuracy: 0.3436 - val_loss: 1.4938 - val_accuracy: 0.3399\n",
            "Epoch 31/50\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5301 - accuracy: 0.3437\n",
            "Epoch 00031: loss did not improve from 1.52923\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5301 - accuracy: 0.3436 - val_loss: 1.4920 - val_accuracy: 0.3399\n",
            "Epoch 32/50\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5304 - accuracy: 0.3436\n",
            "Epoch 00032: loss did not improve from 1.52923\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5303 - accuracy: 0.3436 - val_loss: 1.4928 - val_accuracy: 0.3399\n",
            "Epoch 33/50\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5304 - accuracy: 0.3435\n",
            "Epoch 00033: loss did not improve from 1.52923\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5306 - accuracy: 0.3436 - val_loss: 1.4918 - val_accuracy: 0.3399\n",
            "Epoch 34/50\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5302 - accuracy: 0.3435\n",
            "Epoch 00034: loss did not improve from 1.52923\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5300 - accuracy: 0.3436 - val_loss: 1.4975 - val_accuracy: 0.3399\n",
            "Epoch 35/50\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5301 - accuracy: 0.3438\n",
            "Epoch 00035: loss did not improve from 1.52923\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5300 - accuracy: 0.3436 - val_loss: 1.4917 - val_accuracy: 0.3399\n",
            "Epoch 36/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5308 - accuracy: 0.3437\n",
            "Epoch 00036: loss did not improve from 1.52923\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5308 - accuracy: 0.3436 - val_loss: 1.4920 - val_accuracy: 0.3399\n",
            "Epoch 37/50\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5305 - accuracy: 0.3432\n",
            "Epoch 00037: loss did not improve from 1.52923\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5301 - accuracy: 0.3436 - val_loss: 1.4959 - val_accuracy: 0.3399\n",
            "Epoch 38/50\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5304 - accuracy: 0.3437\n",
            "Epoch 00038: loss did not improve from 1.52923\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5303 - accuracy: 0.3436 - val_loss: 1.4928 - val_accuracy: 0.3399\n",
            "Epoch 39/50\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5304 - accuracy: 0.3436\n",
            "Epoch 00039: loss did not improve from 1.52923\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5302 - accuracy: 0.3436 - val_loss: 1.4941 - val_accuracy: 0.3399\n",
            "Epoch 40/50\n",
            "589/595 [============================>.] - ETA: 0s - loss: 1.5302 - accuracy: 0.3435\n",
            "Epoch 00040: loss did not improve from 1.52923\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5299 - accuracy: 0.3436 - val_loss: 1.4980 - val_accuracy: 0.3399\n",
            "Epoch 41/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5302 - accuracy: 0.3436\n",
            "Epoch 00041: loss did not improve from 1.52923\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5302 - accuracy: 0.3436 - val_loss: 1.4994 - val_accuracy: 0.3399\n",
            "Epoch 42/50\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5299 - accuracy: 0.3431\n",
            "Epoch 00042: loss did not improve from 1.52923\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5299 - accuracy: 0.3436 - val_loss: 1.5012 - val_accuracy: 0.3399\n",
            "Epoch 43/50\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5302 - accuracy: 0.3436\n",
            "Epoch 00043: loss did not improve from 1.52923\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5302 - accuracy: 0.3436 - val_loss: 1.4931 - val_accuracy: 0.3399\n",
            "Epoch 44/50\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5298 - accuracy: 0.3436\n",
            "Epoch 00044: loss did not improve from 1.52923\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5297 - accuracy: 0.3436 - val_loss: 1.4945 - val_accuracy: 0.3399\n",
            "Epoch 45/50\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5296 - accuracy: 0.3439\n",
            "Epoch 00045: loss did not improve from 1.52923\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5298 - accuracy: 0.3436 - val_loss: 1.4929 - val_accuracy: 0.3399\n",
            "Epoch 46/50\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5299 - accuracy: 0.3436\n",
            "Epoch 00046: loss did not improve from 1.52923\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5299 - accuracy: 0.3436 - val_loss: 1.4917 - val_accuracy: 0.3399\n",
            "Epoch 47/50\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5293 - accuracy: 0.3439\n",
            "Epoch 00047: loss did not improve from 1.52923\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5297 - accuracy: 0.3436 - val_loss: 1.4967 - val_accuracy: 0.3399\n",
            "Epoch 48/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5295 - accuracy: 0.3438\n",
            "Epoch 00048: loss did not improve from 1.52923\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5296 - accuracy: 0.3436 - val_loss: 1.4945 - val_accuracy: 0.3399\n",
            "Epoch 49/50\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5293 - accuracy: 0.3439\n",
            "Epoch 00049: loss did not improve from 1.52923\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5300 - accuracy: 0.3436 - val_loss: 1.4967 - val_accuracy: 0.3399\n",
            "Epoch 50/50\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5298 - accuracy: 0.3437\n",
            "Epoch 00050: loss did not improve from 1.52923\n",
            "595/595 [==============================] - 7s 13ms/step - loss: 1.5299 - accuracy: 0.3436 - val_loss: 1.4948 - val_accuracy: 0.3399\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/50\n",
            "  2/595 [..............................] - ETA: 39s - loss: 1.9916 - accuracy: 0.2000WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0142s vs `on_train_batch_end` time: 0.1169s). Check your callbacks.\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5508 - accuracy: 0.3316\n",
            "Epoch 00001: loss improved from inf to 1.55038, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f59b0a1cf60>_Batch25_LR0.01_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5504 - accuracy: 0.3317 - val_loss: 1.4961 - val_accuracy: 0.3399\n",
            "Epoch 2/50\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5343 - accuracy: 0.3438\n",
            "Epoch 00002: loss improved from 1.55038 to 1.53427, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f59b0a1cf60>_Batch25_LR0.01_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5343 - accuracy: 0.3438 - val_loss: 1.4989 - val_accuracy: 0.3399\n",
            "Epoch 3/50\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5289 - accuracy: 0.3436\n",
            "Epoch 00003: loss improved from 1.53427 to 1.52891, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f59b0a1cf60>_Batch25_LR0.01_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5289 - accuracy: 0.3436 - val_loss: 1.4961 - val_accuracy: 0.3399\n",
            "Epoch 4/50\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5287 - accuracy: 0.3441\n",
            "Epoch 00004: loss improved from 1.52891 to 1.52884, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f59b0a1cf60>_Batch25_LR0.01_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5288 - accuracy: 0.3436 - val_loss: 1.5011 - val_accuracy: 0.3399\n",
            "Epoch 5/50\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5290 - accuracy: 0.3436\n",
            "Epoch 00005: loss did not improve from 1.52884\n",
            "595/595 [==============================] - 7s 13ms/step - loss: 1.5290 - accuracy: 0.3436 - val_loss: 1.4964 - val_accuracy: 0.3399\n",
            "Epoch 6/50\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5292 - accuracy: 0.3438\n",
            "Epoch 00006: loss did not improve from 1.52884\n",
            "595/595 [==============================] - 7s 12ms/step - loss: 1.5292 - accuracy: 0.3436 - val_loss: 1.4989 - val_accuracy: 0.3399\n",
            "Epoch 7/50\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5288 - accuracy: 0.3436\n",
            "Epoch 00007: loss improved from 1.52884 to 1.52880, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f59b0a1cf60>_Batch25_LR0.01_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5288 - accuracy: 0.3436 - val_loss: 1.5025 - val_accuracy: 0.3399\n",
            "Epoch 8/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5289 - accuracy: 0.3437\n",
            "Epoch 00008: loss did not improve from 1.52880\n",
            "595/595 [==============================] - 7s 13ms/step - loss: 1.5291 - accuracy: 0.3436 - val_loss: 1.4910 - val_accuracy: 0.3399\n",
            "Epoch 9/50\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5286 - accuracy: 0.3435\n",
            "Epoch 00009: loss did not improve from 1.52880\n",
            "595/595 [==============================] - 7s 13ms/step - loss: 1.5290 - accuracy: 0.3436 - val_loss: 1.4977 - val_accuracy: 0.3399\n",
            "Epoch 10/50\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5291 - accuracy: 0.3437\n",
            "Epoch 00010: loss did not improve from 1.52880\n",
            "595/595 [==============================] - 7s 13ms/step - loss: 1.5289 - accuracy: 0.3436 - val_loss: 1.4922 - val_accuracy: 0.3399\n",
            "Epoch 11/50\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5292 - accuracy: 0.3436\n",
            "Epoch 00011: loss did not improve from 1.52880\n",
            "595/595 [==============================] - 7s 12ms/step - loss: 1.5292 - accuracy: 0.3436 - val_loss: 1.4986 - val_accuracy: 0.3399\n",
            "Epoch 12/50\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5293 - accuracy: 0.3437\n",
            "Epoch 00012: loss did not improve from 1.52880\n",
            "595/595 [==============================] - 7s 12ms/step - loss: 1.5291 - accuracy: 0.3436 - val_loss: 1.4996 - val_accuracy: 0.3399\n",
            "Epoch 13/50\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5291 - accuracy: 0.3437\n",
            "Epoch 00013: loss did not improve from 1.52880\n",
            "595/595 [==============================] - 7s 12ms/step - loss: 1.5290 - accuracy: 0.3436 - val_loss: 1.4966 - val_accuracy: 0.3399\n",
            "Epoch 14/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5293 - accuracy: 0.3434\n",
            "Epoch 00014: loss did not improve from 1.52880\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5291 - accuracy: 0.3436 - val_loss: 1.4958 - val_accuracy: 0.3399\n",
            "Epoch 15/50\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5289 - accuracy: 0.3435\n",
            "Epoch 00015: loss did not improve from 1.52880\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5288 - accuracy: 0.3436 - val_loss: 1.4971 - val_accuracy: 0.3399\n",
            "Epoch 16/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5291 - accuracy: 0.3436\n",
            "Epoch 00016: loss did not improve from 1.52880\n",
            "595/595 [==============================] - 7s 13ms/step - loss: 1.5290 - accuracy: 0.3436 - val_loss: 1.4943 - val_accuracy: 0.3399\n",
            "Epoch 17/50\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5289 - accuracy: 0.3441\n",
            "Epoch 00017: loss did not improve from 1.52880\n",
            "595/595 [==============================] - 7s 13ms/step - loss: 1.5289 - accuracy: 0.3436 - val_loss: 1.4955 - val_accuracy: 0.3399\n",
            "Epoch 18/50\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5292 - accuracy: 0.3436\n",
            "Epoch 00018: loss did not improve from 1.52880\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5290 - accuracy: 0.3436 - val_loss: 1.4960 - val_accuracy: 0.3399\n",
            "Epoch 19/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5291 - accuracy: 0.3435\n",
            "Epoch 00019: loss did not improve from 1.52880\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5290 - accuracy: 0.3436 - val_loss: 1.4981 - val_accuracy: 0.3399\n",
            "Epoch 20/50\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5292 - accuracy: 0.3436\n",
            "Epoch 00020: loss did not improve from 1.52880\n",
            "595/595 [==============================] - 7s 13ms/step - loss: 1.5290 - accuracy: 0.3436 - val_loss: 1.4983 - val_accuracy: 0.3399\n",
            "Epoch 21/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5293 - accuracy: 0.3436\n",
            "Epoch 00021: loss did not improve from 1.52880\n",
            "595/595 [==============================] - 7s 12ms/step - loss: 1.5293 - accuracy: 0.3436 - val_loss: 1.5002 - val_accuracy: 0.3399\n",
            "Epoch 22/50\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5289 - accuracy: 0.3436\n",
            "Epoch 00022: loss did not improve from 1.52880\n",
            "595/595 [==============================] - 7s 12ms/step - loss: 1.5289 - accuracy: 0.3436 - val_loss: 1.4922 - val_accuracy: 0.3399\n",
            "Epoch 23/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5291 - accuracy: 0.3437\n",
            "Epoch 00023: loss did not improve from 1.52880\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5290 - accuracy: 0.3436 - val_loss: 1.4981 - val_accuracy: 0.3399\n",
            "Epoch 24/50\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5288 - accuracy: 0.3439\n",
            "Epoch 00024: loss did not improve from 1.52880\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5290 - accuracy: 0.3436 - val_loss: 1.4967 - val_accuracy: 0.3399\n",
            "Epoch 25/50\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5286 - accuracy: 0.3438\n",
            "Epoch 00025: loss improved from 1.52880 to 1.52876, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f59b0a1cf60>_Batch25_LR0.01_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5288 - accuracy: 0.3436 - val_loss: 1.5009 - val_accuracy: 0.3399\n",
            "Epoch 26/50\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5295 - accuracy: 0.3436\n",
            "Epoch 00026: loss did not improve from 1.52876\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5293 - accuracy: 0.3436 - val_loss: 1.4980 - val_accuracy: 0.3399\n",
            "Epoch 27/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5291 - accuracy: 0.3437\n",
            "Epoch 00027: loss did not improve from 1.52876\n",
            "595/595 [==============================] - 7s 13ms/step - loss: 1.5292 - accuracy: 0.3436 - val_loss: 1.4943 - val_accuracy: 0.3399\n",
            "Epoch 28/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5290 - accuracy: 0.3435\n",
            "Epoch 00028: loss did not improve from 1.52876\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5289 - accuracy: 0.3436 - val_loss: 1.4981 - val_accuracy: 0.3399\n",
            "Epoch 29/50\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5278 - accuracy: 0.3438\n",
            "Epoch 00029: loss improved from 1.52876 to 1.52829, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f59b0a1cf60>_Batch25_LR0.01_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5283 - accuracy: 0.3436 - val_loss: 1.5012 - val_accuracy: 0.3399\n",
            "Epoch 30/50\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5290 - accuracy: 0.3440\n",
            "Epoch 00030: loss did not improve from 1.52829\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5294 - accuracy: 0.3436 - val_loss: 1.4978 - val_accuracy: 0.3399\n",
            "Epoch 31/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5287 - accuracy: 0.3434\n",
            "Epoch 00031: loss did not improve from 1.52829\n",
            "595/595 [==============================] - 7s 13ms/step - loss: 1.5285 - accuracy: 0.3436 - val_loss: 1.4966 - val_accuracy: 0.3399\n",
            "Epoch 32/50\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5291 - accuracy: 0.3437\n",
            "Epoch 00032: loss did not improve from 1.52829\n",
            "595/595 [==============================] - 7s 12ms/step - loss: 1.5290 - accuracy: 0.3436 - val_loss: 1.5004 - val_accuracy: 0.3399\n",
            "Epoch 33/50\n",
            "589/595 [============================>.] - ETA: 0s - loss: 1.5294 - accuracy: 0.3436\n",
            "Epoch 00033: loss did not improve from 1.52829\n",
            "595/595 [==============================] - 7s 12ms/step - loss: 1.5291 - accuracy: 0.3436 - val_loss: 1.4977 - val_accuracy: 0.3399\n",
            "Epoch 34/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5293 - accuracy: 0.3436\n",
            "Epoch 00034: loss did not improve from 1.52829\n",
            "595/595 [==============================] - 7s 12ms/step - loss: 1.5291 - accuracy: 0.3436 - val_loss: 1.4964 - val_accuracy: 0.3399\n",
            "Epoch 35/50\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5293 - accuracy: 0.3436\n",
            "Epoch 00035: loss did not improve from 1.52829\n",
            "595/595 [==============================] - 7s 12ms/step - loss: 1.5293 - accuracy: 0.3436 - val_loss: 1.4951 - val_accuracy: 0.3399\n",
            "Epoch 36/50\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5285 - accuracy: 0.3444\n",
            "Epoch 00036: loss did not improve from 1.52829\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5290 - accuracy: 0.3436 - val_loss: 1.4942 - val_accuracy: 0.3399\n",
            "Epoch 37/50\n",
            "589/595 [============================>.] - ETA: 0s - loss: 1.5298 - accuracy: 0.3429\n",
            "Epoch 00037: loss did not improve from 1.52829\n",
            "595/595 [==============================] - 7s 12ms/step - loss: 1.5288 - accuracy: 0.3436 - val_loss: 1.5000 - val_accuracy: 0.3399\n",
            "Epoch 38/50\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5291 - accuracy: 0.3438\n",
            "Epoch 00038: loss did not improve from 1.52829\n",
            "595/595 [==============================] - 7s 12ms/step - loss: 1.5290 - accuracy: 0.3436 - val_loss: 1.4989 - val_accuracy: 0.3399\n",
            "Epoch 39/50\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5291 - accuracy: 0.3437\n",
            "Epoch 00039: loss did not improve from 1.52829\n",
            "595/595 [==============================] - 7s 12ms/step - loss: 1.5291 - accuracy: 0.3436 - val_loss: 1.4964 - val_accuracy: 0.3399\n",
            "Epoch 40/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5289 - accuracy: 0.3434\n",
            "Epoch 00040: loss did not improve from 1.52829\n",
            "595/595 [==============================] - 7s 13ms/step - loss: 1.5287 - accuracy: 0.3436 - val_loss: 1.4915 - val_accuracy: 0.3399\n",
            "Epoch 41/50\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5294 - accuracy: 0.3432\n",
            "Epoch 00041: loss did not improve from 1.52829\n",
            "595/595 [==============================] - 7s 13ms/step - loss: 1.5291 - accuracy: 0.3436 - val_loss: 1.4953 - val_accuracy: 0.3399\n",
            "Epoch 42/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5290 - accuracy: 0.3434\n",
            "Epoch 00042: loss did not improve from 1.52829\n",
            "595/595 [==============================] - 7s 13ms/step - loss: 1.5289 - accuracy: 0.3436 - val_loss: 1.4994 - val_accuracy: 0.3399\n",
            "Epoch 43/50\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5291 - accuracy: 0.3436\n",
            "Epoch 00043: loss did not improve from 1.52829\n",
            "595/595 [==============================] - 7s 12ms/step - loss: 1.5291 - accuracy: 0.3436 - val_loss: 1.4933 - val_accuracy: 0.3399\n",
            "Epoch 44/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5286 - accuracy: 0.3435\n",
            "Epoch 00044: loss did not improve from 1.52829\n",
            "595/595 [==============================] - 7s 13ms/step - loss: 1.5285 - accuracy: 0.3436 - val_loss: 1.4920 - val_accuracy: 0.3399\n",
            "Epoch 45/50\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5293 - accuracy: 0.3433\n",
            "Epoch 00045: loss did not improve from 1.52829\n",
            "595/595 [==============================] - 7s 12ms/step - loss: 1.5290 - accuracy: 0.3436 - val_loss: 1.5013 - val_accuracy: 0.3399\n",
            "Epoch 46/50\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5292 - accuracy: 0.3437\n",
            "Epoch 00046: loss did not improve from 1.52829\n",
            "595/595 [==============================] - 7s 12ms/step - loss: 1.5288 - accuracy: 0.3436 - val_loss: 1.4958 - val_accuracy: 0.3399\n",
            "Epoch 47/50\n",
            "589/595 [============================>.] - ETA: 0s - loss: 1.5295 - accuracy: 0.3432\n",
            "Epoch 00047: loss did not improve from 1.52829\n",
            "595/595 [==============================] - 7s 13ms/step - loss: 1.5290 - accuracy: 0.3436 - val_loss: 1.4961 - val_accuracy: 0.3399\n",
            "Epoch 48/50\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5288 - accuracy: 0.3439\n",
            "Epoch 00048: loss did not improve from 1.52829\n",
            "595/595 [==============================] - 7s 12ms/step - loss: 1.5290 - accuracy: 0.3436 - val_loss: 1.4963 - val_accuracy: 0.3399\n",
            "Epoch 49/50\n",
            "589/595 [============================>.] - ETA: 0s - loss: 1.5292 - accuracy: 0.3432\n",
            "Epoch 00049: loss did not improve from 1.52829\n",
            "595/595 [==============================] - 7s 12ms/step - loss: 1.5291 - accuracy: 0.3436 - val_loss: 1.4929 - val_accuracy: 0.3399\n",
            "Epoch 50/50\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5294 - accuracy: 0.3435\n",
            "Epoch 00050: loss did not improve from 1.52829\n",
            "595/595 [==============================] - 7s 12ms/step - loss: 1.5292 - accuracy: 0.3436 - val_loss: 1.4950 - val_accuracy: 0.3399\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/50\n",
            "  2/595 [..............................] - ETA: 36s - loss: 2.0207 - accuracy: 0.1600WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0135s vs `on_train_batch_end` time: 0.1105s). Check your callbacks.\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5496 - accuracy: 0.3290\n",
            "Epoch 00001: loss improved from inf to 1.55009, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59b0a265c0>_Batch25_LR0.01_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5501 - accuracy: 0.3284 - val_loss: 1.5087 - val_accuracy: 0.3399\n",
            "Epoch 2/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5323 - accuracy: 0.3405\n",
            "Epoch 00002: loss improved from 1.55009 to 1.53219, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59b0a265c0>_Batch25_LR0.01_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5322 - accuracy: 0.3405 - val_loss: 1.4982 - val_accuracy: 0.3399\n",
            "Epoch 3/50\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5279 - accuracy: 0.3443\n",
            "Epoch 00003: loss improved from 1.53219 to 1.52812, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59b0a265c0>_Batch25_LR0.01_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5281 - accuracy: 0.3443 - val_loss: 1.5020 - val_accuracy: 0.3399\n",
            "Epoch 4/50\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5245 - accuracy: 0.3429\n",
            "Epoch 00004: loss improved from 1.52812 to 1.52459, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59b0a265c0>_Batch25_LR0.01_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5246 - accuracy: 0.3429 - val_loss: 1.4988 - val_accuracy: 0.3399\n",
            "Epoch 5/50\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5230 - accuracy: 0.3443\n",
            "Epoch 00005: loss improved from 1.52459 to 1.52275, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59b0a265c0>_Batch25_LR0.01_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5228 - accuracy: 0.3442 - val_loss: 1.4977 - val_accuracy: 0.3399\n",
            "Epoch 6/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5240 - accuracy: 0.3432\n",
            "Epoch 00006: loss did not improve from 1.52275\n",
            "595/595 [==============================] - 7s 13ms/step - loss: 1.5240 - accuracy: 0.3431 - val_loss: 1.5002 - val_accuracy: 0.3399\n",
            "Epoch 7/50\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5237 - accuracy: 0.3427\n",
            "Epoch 00007: loss did not improve from 1.52275\n",
            "595/595 [==============================] - 7s 12ms/step - loss: 1.5234 - accuracy: 0.3430 - val_loss: 1.5044 - val_accuracy: 0.3399\n",
            "Epoch 8/50\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5201 - accuracy: 0.3441\n",
            "Epoch 00008: loss improved from 1.52275 to 1.52077, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59b0a265c0>_Batch25_LR0.01_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5208 - accuracy: 0.3438 - val_loss: 1.5031 - val_accuracy: 0.3399\n",
            "Epoch 9/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5207 - accuracy: 0.3435\n",
            "Epoch 00009: loss improved from 1.52077 to 1.52043, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59b0a265c0>_Batch25_LR0.01_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5204 - accuracy: 0.3437 - val_loss: 1.4988 - val_accuracy: 0.3399\n",
            "Epoch 10/50\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5195 - accuracy: 0.3438\n",
            "Epoch 00010: loss improved from 1.52043 to 1.51951, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59b0a265c0>_Batch25_LR0.01_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5195 - accuracy: 0.3439 - val_loss: 1.5025 - val_accuracy: 0.3399\n",
            "Epoch 11/50\n",
            "288/595 [=============>................] - ETA: 2s - loss: 1.5143 - accuracy: 0.3432"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8lTHN_5ZpzC",
        "outputId": "f7f916b7-daa2-43bc-bb9e-fd19fd5f3de2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import json\n",
        "\n",
        "# as requested in comment\n",
        "with open('result_training.txt', 'w') as file:\n",
        "     file.write(json.dumps(Tabres)) # use `json.loads` to do the reverse"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fUVybHIT4aA8"
      },
      "source": [
        "Loss vs accuracy\n",
        "\n",
        "https://kharshit.github.io/blog/2018/12/07/loss-vs-accuracy\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fxXLslzA4V8j"
      },
      "source": [
        "https://kharshit.github.io/blog/2018/12/07/loss-vs-accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fo3lfsYbZpcB"
      },
      "source": [
        "####Improve the Model with GAN - NOT FUNCTIONAL SO FAR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Qltq67Ua9ac"
      },
      "source": [
        "https://keras.io/guides/customizing_what_happens_in_fit/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d9lf5VWAKZ2m"
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "\n",
        "# Create the discriminator\n",
        "discriminator = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=(28, 28, 1)),\n",
        "        layers.Conv2D(64, (3, 3), strides=(2, 2), padding=\"same\"),\n",
        "        layers.LeakyReLU(alpha=0.2),\n",
        "        layers.Conv2D(128, (3, 3), strides=(2, 2), padding=\"same\"),\n",
        "        layers.LeakyReLU(alpha=0.2),\n",
        "        layers.GlobalMaxPooling2D(),\n",
        "        layers.Dense(1),\n",
        "    ],\n",
        "    name=\"discriminator\",\n",
        ")\n",
        "\n",
        "# Create the generator\n",
        "latent_dim = 128\n",
        "generator = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=(latent_dim,)),\n",
        "        # We want to generate 128 coefficients to reshape into a 7x7x128 map\n",
        "        layers.Dense(7 * 7 * 128),\n",
        "        layers.LeakyReLU(alpha=0.2),\n",
        "        layers.Reshape((7, 7, 128)),\n",
        "        layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding=\"same\"),\n",
        "        layers.LeakyReLU(alpha=0.2),\n",
        "        layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding=\"same\"),\n",
        "        layers.LeakyReLU(alpha=0.2),\n",
        "        layers.Conv2D(1, (7, 7), padding=\"same\", activation=\"sigmoid\"),\n",
        "    ],\n",
        "    name=\"generator\",\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R4wpRPC5bTua"
      },
      "source": [
        "class GAN(keras.Model):\n",
        "    def __init__(self, discriminator, generator, latent_dim):\n",
        "        super(GAN, self).__init__()\n",
        "        self.discriminator = discriminator\n",
        "        self.generator = generator\n",
        "        self.latent_dim = latent_dim\n",
        "\n",
        "    def compile(self, d_optimizer, g_optimizer, loss_fn):\n",
        "        super(GAN, self).compile()\n",
        "        self.d_optimizer = d_optimizer\n",
        "        self.g_optimizer = g_optimizer\n",
        "        self.loss_fn = loss_fn\n",
        "\n",
        "    def train_step(self, real_images):\n",
        "        if isinstance(real_images, tuple):\n",
        "            real_images = real_images[0]\n",
        "        # Sample random points in the latent space\n",
        "        batch_size = tf.shape(real_images)[0]\n",
        "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
        "\n",
        "        # Decode them to fake images\n",
        "        generated_images = self.generator(random_latent_vectors)\n",
        "\n",
        "        # Combine them with real images\n",
        "        combined_images = tf.concat([generated_images, real_images], axis=0)\n",
        "\n",
        "        # Assemble labels discriminating real from fake images\n",
        "        labels = tf.concat(\n",
        "            [tf.ones((batch_size, 1)), tf.zeros((batch_size, 1))], axis=0\n",
        "        )\n",
        "        # Add random noise to the labels - important trick!\n",
        "        labels += 0.05 * tf.random.uniform(tf.shape(labels))\n",
        "\n",
        "        # Train the discriminator\n",
        "        with tf.GradientTape() as tape:\n",
        "            predictions = self.discriminator(combined_images)\n",
        "            d_loss = self.loss_fn(labels, predictions)\n",
        "        grads = tape.gradient(d_loss, self.discriminator.trainable_weights)\n",
        "        self.d_optimizer.apply_gradients(\n",
        "            zip(grads, self.discriminator.trainable_weights)\n",
        "        )\n",
        "\n",
        "        # Sample random points in the latent space\n",
        "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
        "\n",
        "        # Assemble labels that say \"all real images\"\n",
        "        misleading_labels = tf.zeros((batch_size, 1))\n",
        "\n",
        "        # Train the generator (note that we should *not* update the weights\n",
        "        # of the discriminator)!\n",
        "        with tf.GradientTape() as tape:\n",
        "            predictions = self.discriminator(self.generator(random_latent_vectors))\n",
        "            g_loss = self.loss_fn(misleading_labels, predictions)\n",
        "        grads = tape.gradient(g_loss, self.generator.trainable_weights)\n",
        "        self.g_optimizer.apply_gradients(zip(grads, self.generator.trainable_weights))\n",
        "        return {\"d_loss\": d_loss, \"g_loss\": g_loss}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vOtZ0dD7bYhp"
      },
      "source": [
        "# Prepare the dataset. We use both the training & test MNIST digits.\n",
        "batch_size = 64\n",
        "(x_train, _), (x_test, _) = keras.datasets.mnist.load_data()\n",
        "all_digits = np.concatenate([x_train, x_test])\n",
        "all_digits = all_digits.astype(\"float32\") / 255.0\n",
        "all_digits = np.reshape(all_digits, (-1, 28, 28, 1))\n",
        "dataset = tf.data.Dataset.from_tensor_slices(all_digits)\n",
        "dataset = dataset.shuffle(buffer_size=1024).batch(batch_size)\n",
        "\n",
        "gan = GAN(discriminator=discriminator, generator=generator, latent_dim=latent_dim)\n",
        "gan.compile(\n",
        "    d_optimizer=keras.optimizers.Adam(learning_rate=0.0003),\n",
        "    g_optimizer=keras.optimizers.Adam(learning_rate=0.0003),\n",
        "    loss_fn=keras.losses.BinaryCrossentropy(from_logits=True),\n",
        ")\n",
        "\n",
        "# To limit execution time, we only train on 100 batches. You can train on\n",
        "# the entire dataset. You will need about 20 epochs to get nice results.\n",
        "gan.fit(dataset.take(100), epochs=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cez5uqWb4SSc"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oyRJzUx_5DSF"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R2_xo8psY5Iy"
      },
      "source": [
        "##Step 3: Evaluate the VGGsp500 model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PXXUYNbwZ4TX"
      },
      "source": [
        "This part will evaluate the model with the testing dataset that we generated in first step. We show the accuracy, the confusion matrix and the classification report"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mUSUr5CdwPPz"
      },
      "source": [
        "To improve learning after playing with all the parameters \n",
        "\n",
        "- get more dataset on stock and indice\n",
        "\n",
        "- work on vgg untrained \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eKbQ6tBAhlw8",
        "outputId": "84b52850-8f5a-4e5d-eeb5-0cc8628b0cf6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        }
      },
      "source": [
        "print(\"name of the best model for each set of parameters\")\n",
        "bestmodel=\"best_model\"+vggsp500loss+\"_\"+vggsp500optimizer_name+\"_Batch\"+str(batch_size)+\"_LR\"+str(initial_learning_rate)+\".hdf5\"\n",
        "print(bestmodel)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "name of the best model for each set of parameters\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-379eac6dc040>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"name of the best model for each set of parameters\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mbestmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"best_model\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mvggsp500loss\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"_\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mvggsp500optimizer_name\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"_Batch\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"_LR\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitial_learning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\".hdf5\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbestmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'vggsp500loss' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23kG1lJE5KqF",
        "outputId": "7a92151c-ae13-4338-e07c-a1b8a5387089",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "source": [
        "%cd /content/drive/My Drive/A_transfertTFMVggSP500\n",
        "%cd model \n",
        "%cp best_modelcategorical_crossentropy_adam_Batch100_LR0.1_0.99.hdf5 /content/DL_Tools_For_Finance/model/\n",
        "%ls -l"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/A_transfertTFMVggSP500\n",
            "/content/drive/My Drive/A_transfertTFMVggSP500/model\n",
            "cp: cannot stat 'best_modelcategorical_crossentropy_adam_Batch100_LR0.1_0.99.hdf5': No such file or directory\n",
            "total 465803\n",
            "-rw------- 1 root root 59726904 Sep  5 06:04  best_modelcategorical_crossentropy_Adagrad_Batch32_LR0.01_0.98.hdf5\n",
            "-rw------- 1 root root 59456824 Sep  1 00:22 'best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59b9654fd0>_Batch25_LR0.001_Epochs100vggforsp500.h5'\n",
            "-rw------- 1 root root 59726928 Sep  1 00:35 'best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f59b9808a20>_Batch25_LR0.001_Epochs100.hdf5'\n",
            "-rw------- 1 root root 59726928 Sep  1 00:35 'best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f59b9808a20>_Batch25_LR0.001_Epochs100vggforsp500.h5'\n",
            "-rw------- 1 root root 59725496 Sep  1 00:44 'best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f599f76e400>_Batch25_LR0.001_Epochs100.hdf5'\n",
            "-rw------- 1 root root 59726920 Aug 31 08:06  final_modelcategorical_crossentropy_adam_32.h5\n",
            "-rw------- 1 root root 59161736 Sep  5 06:10  initial_weights.h5\n",
            "-rw------- 1 root root 59726904 Sep  5 06:04  vggforsp500.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HAQnQZoR6rD6",
        "outputId": "bd4d4adc-5751-4c3d-81a0-e3489531edda",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd /content/DL_Tools_For_Finance/\n",
        "trained_model_path='/content/DL_Tools_For_Finance/model/final_modelcategorical_crossentropy_adam_32.h5'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/DL_Tools_For_Finance\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yxMUW3tCMVBM",
        "outputId": "31913564-b148-4977-e387-9e10ea68b556",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 598
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from keras.utils import np_utils\n",
        "from keras.models import load_model\n",
        "from keras import backend as K\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "'''\n",
        "Here we have a trained model model/vggforsp500.h5 and datas for testing \n",
        "datas/X_test_image.csv\n",
        "datas/Y_test_StateClass_image.csv\n",
        "datas/Y_test_FutPredict_image.csv\n",
        "\n",
        "'''\n",
        "\n",
        "##\n",
        "'''\n",
        "UTILITY FUNCTIONS\n",
        "to put in another file\n",
        "'''\n",
        "\n",
        "def change_X_df__nparray_image(df_X_train_image_flattened ):\n",
        "  '''\n",
        "  setup_input_NN_image returns a dataframe of flaten image for x train and xtest\n",
        "  then this function will change each date into a nparray list of images with 32, 32, 3 size \n",
        "  '''\n",
        "  X_train_image=df_X_train_image_flattened\n",
        "  nb_train=len(X_train_image.index)\n",
        "  \n",
        "  x_train=np.zeros((nb_train,32,32,3))\n",
        "  for i in range(nb_train):\n",
        "    tmp=np.array(X_train_image.iloc[i])\n",
        "    tmp=tmp.reshape(32,32,3)\n",
        "    x_train[i]=tmp\n",
        "  return x_train\n",
        "##\n",
        "\n",
        "\n",
        "\n",
        "#recuperation of testing datas and organising it \n",
        "X_test_image=pd.read_csv('datas/X_test_image.csv')\n",
        "Y_test_StateClass_image=pd.read_csv('datas/Y_test_StateClass_image.csv')\n",
        "Y_test_FutPredict_image=pd.read_csv('datas/Y_test_FutPredict_image.csv')\n",
        "\n",
        "#setting up the index to Date\n",
        "X_test_image=X_test_image.set_index(\"Date\")\n",
        "Y_test_StateClass_image=Y_test_StateClass_image.set_index(\"Date\")\n",
        "Y_test_FutPredict_image=Y_test_FutPredict_image.set_index(\"Date\")\n",
        "\n",
        "#modify dataset to np array for input to NN\n",
        "x_test=change_X_df__nparray_image(X_test_image)\n",
        "y_test_state=np.array(Y_test_StateClass_image)\n",
        "y_test_value=np.array(Y_test_FutPredict_image)\n",
        "\n",
        "##Setting up xtest and ytest\n",
        "#Here we focus on predicting the future state Y_train_StateClass_image\n",
        "nb_test=len(X_test_image.index)\n",
        "x_test=np.zeros((nb_test,32,32,3))\n",
        "for i in range(nb_test):\n",
        "  tmp=np.array(X_test_image.iloc[i])\n",
        "  tmp=tmp.reshape(32,32,3)\n",
        "  x_test[i]=tmp\n",
        "\n",
        "y_test=np.array(Y_test_StateClass_image)\n",
        "#y_test=np.array(Y_test_FutPredict_image)\n",
        "\n",
        "#In our example we need to y into categorical as it has 6 categories\n",
        "nb_classes=6\n",
        "y_test_m = np_utils.to_categorical(y_test, nb_classes)\n",
        "############\n",
        "#recuperation of model\n",
        "vggsp500model = load_model(trained_model_path)\n",
        "\n",
        "#Evaluate the model on the test data\n",
        "score  = vggsp500model.evaluate(x_test, y_test_m)\n",
        "\n",
        "\n",
        "Y_pred = vggsp500model.predict(x_test)\n",
        "y_pred = np.argmax(Y_pred, axis=1)\n",
        "y= np.argmax(y_test_m,axis=1)\n",
        "\n",
        "\n",
        "print('Confusion Matrix')\n",
        "\n",
        "target_state = ['SS', 'SN', 'N','NB','BB','Error']\n",
        "\n",
        "def statetostring(x):\n",
        "  return target_state[int(x)]\n",
        "\n",
        "sY_pred=[statetostring(i) for i in y_pred]\n",
        "sY_real=[statetostring(i) for i in y]\n",
        "\n",
        "#matrice  de confusion\n",
        "mat=confusion_matrix(sY_real, sY_pred, normalize='true', labels=target_state)\n",
        "df_confmat=pd.DataFrame(mat,index=target_state, columns=target_state)\n",
        "\n",
        "#matrice  de confusion\n",
        "mat2=confusion_matrix(sY_real, sY_pred,  labels=target_state)\n",
        "df_confmat2=pd.DataFrame(mat2,index=target_state, columns=target_state)\n",
        "\n",
        "#Accuracy on test data\n",
        "print('Accuracy on the Test Images: ', score[1])\n",
        "#matrice  de confusion\n",
        "print(df_confmat)\n",
        "\n",
        "#matrice  de confusion\n",
        "print(df_confmat2)\n",
        "\n",
        "# Classification report\n",
        "print('classification report')\n",
        "print(classification_report(sY_real, sY_pred, target_names=target_state))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "146/146 [==============================] - 1s 5ms/step - loss: 1.4815 - accuracy: 0.3833\n",
            "Confusion Matrix\n",
            "Accuracy on the Test Images:  0.3833225667476654\n",
            "             SS        SN         N   NB        BB  Error\n",
            "SS     0.051780  0.000000  0.800971  0.0  0.147249    0.0\n",
            "SN     0.013834  0.023715  0.806324  0.0  0.156126    0.0\n",
            "N      0.007975  0.006135  0.712270  0.0  0.273620    0.0\n",
            "NB     0.007496  0.000000  0.659670  0.0  0.332834    0.0\n",
            "BB     0.004136  0.000000  0.521092  0.0  0.474773    0.0\n",
            "Error  0.000000  0.000000  0.454545  0.0  0.545455    0.0\n",
            "       SS  SN     N  NB   BB  Error\n",
            "SS     32   0   495   0   91      0\n",
            "SN      7  12   408   0   79      0\n",
            "N      13  10  1161   0  446      0\n",
            "NB      5   0   440   0  222      0\n",
            "BB      5   0   630   0  574      0\n",
            "Error   0   0     5   0    6      0\n",
            "classification report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          SS       0.40      0.47      0.44      1209\n",
            "          SN       0.00      0.00      0.00        11\n",
            "           N       0.37      0.71      0.49      1630\n",
            "          NB       0.00      0.00      0.00       667\n",
            "          BB       0.55      0.02      0.05       506\n",
            "       Error       0.52      0.05      0.09       618\n",
            "\n",
            "    accuracy                           0.38      4641\n",
            "   macro avg       0.31      0.21      0.18      4641\n",
            "weighted avg       0.36      0.38      0.30      4641\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TIz78gePZY76"
      },
      "source": [
        "##Step 4: Guess future market state from random image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ulkwESoxZm1z"
      },
      "source": [
        "Take an image of an historical graph from a market webpage like investing.com and save it to the ImageM/ folder with name image1.PNG or you can change the value of image_path to the link you need.\n",
        "\n",
        "This execution tell us which market state in the future is the best representative."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvqRijItZML8",
        "outputId": "c5063777-565a-44f7-82c8-2a53cb84637b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from keras.utils import np_utils\n",
        "from keras.models import load_model\n",
        "from keras import backend as K\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "#path for trained model\n",
        "trained_model_path='model/vggforsp500.h5'\n",
        "\n",
        "#path for the image taken by the user\n",
        "#image_path='ImageM/image1.PNG'\n",
        "image_path =input(\"Enter the path of the image to check next state:\\n\")\n",
        "\n",
        "#Load the image and resize it to 32x32 and taking off the transparency\n",
        "load_img_rz = np.array(Image.open(image_path).resize((32,32)))\n",
        "#Image.fromarray(load_img_rz).save('/content/drive/My Drive/_sample_data/ImageM/image1.PNG')\n",
        "image=load_img_rz[:,:,:3]/255\n",
        "print(\"After resizing:\",image.shape)\n",
        "\n",
        "#petite astuce pour ne pas avoir d erreur avec les types list, tensors,  nparray et dataframe\n",
        "doubleimage=np.array([image,image])\n",
        "############\n",
        "#recuperation of the model\n",
        "vggsp500model = load_model(trained_model_path)\n",
        "Y_pred = vggsp500model.predict(doubleimage)\n",
        "y_pred = np.argmax(Y_pred, axis=1)\n",
        "\n",
        "target_state = ['SS', 'SN', 'N','NB','BB','Error']\n",
        "df_result=pd.DataFrame((Y_pred))\n",
        "\n",
        "df_result.columns=target_state\n",
        "df_result.index=[image_path, image_path+'1']\n",
        "print (\"for \",image_path, \"the best result is \", target_state[int(y_pred[0])] )\n",
        "\n",
        "df_result"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter the path of the image to check next state:\n",
            "/content/DL_Tools_For_Finance/ImageM/image2.PNG\n",
            "After resizing: (32, 32, 3)\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3286689ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "for  /content/DL_Tools_For_Finance/ImageM/image2.PNG the best result is  SS\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SS</th>\n",
              "      <th>SN</th>\n",
              "      <th>N</th>\n",
              "      <th>NB</th>\n",
              "      <th>BB</th>\n",
              "      <th>Error</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>/content/DL_Tools_For_Finance/ImageM/image2.PNG</th>\n",
              "      <td>0.31159</td>\n",
              "      <td>0.119561</td>\n",
              "      <td>0.263224</td>\n",
              "      <td>0.073631</td>\n",
              "      <td>0.231359</td>\n",
              "      <td>0.000636</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>/content/DL_Tools_For_Finance/ImageM/image2.PNG1</th>\n",
              "      <td>0.31159</td>\n",
              "      <td>0.119561</td>\n",
              "      <td>0.263224</td>\n",
              "      <td>0.073631</td>\n",
              "      <td>0.231359</td>\n",
              "      <td>0.000636</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                       SS  ...     Error\n",
              "/content/DL_Tools_For_Finance/ImageM/image2.PNG   0.31159  ...  0.000636\n",
              "/content/DL_Tools_For_Finance/ImageM/image2.PNG1  0.31159  ...  0.000636\n",
              "\n",
              "[2 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBOG00tVbHS7",
        "outputId": "686ec072-2661-4b03-c1a8-d4ea42ed5233",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(image)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f007032f1d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gXmOXke1hlip"
      },
      "source": [
        "Give the results for all the PNG file of a directory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z0aDBnGTh6yi",
        "outputId": "2a0aa2d4-3708-496b-9b3a-ecfcab9b7387",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 662
        }
      },
      "source": [
        "import os\n",
        "\n",
        "path = '/content/DL_Tools_For_Finance/ImageM/'\n",
        "\n",
        "#files = os.listdir(path)\n",
        "#l_file=[]\n",
        "#for f in files:\n",
        "#    l_file.append(f)\n",
        "\n",
        "l_file=glob.glob('**/*.PNG', recursive=True)\n",
        "l_image_input_NN=[]\n",
        "\n",
        "for x_image in l_file:  \n",
        "  #Load the image and resize it to 32x32 and taking off the transparency\n",
        "  load_img_rz = np.array(Image.open(x_image).resize((32,32)))\n",
        "\n",
        "  #Image.fromarray(load_img_rz).save('/content/drive/My Drive/_sample_data/ImageM/image1.PNG')\n",
        "  image=load_img_rz[:,:,:3]/255\n",
        "  print(\"After resizing:\",image.shape)\n",
        "\n",
        "  l_image_input_NN.append(image)\n",
        "\n",
        "############\n",
        "#recuperation of the model\n",
        "vggsp500model = load_model(trained_model_path)\n",
        "Y_pred = vggsp500model.predict(np.array(l_image_input_NN))\n",
        "y_pred = np.argmax(Y_pred, axis=1)\n",
        "\n",
        "target_state = ['SS', 'SN', 'N','NB','BB','Error']\n",
        "df_result=pd.DataFrame((Y_pred))\n",
        "\n",
        "df_result.columns=target_state\n",
        "df_result.index=l_file\n",
        "\n",
        "df_decision=pd.DataFrame([target_state[i] for i in  y_pred],index=l_file, columns=['Decision'])\n",
        "df_result=pd.concat([df_result,df_decision],axis=1)\n",
        "(df_result)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "After resizing: (32, 32, 3)\n",
            "After resizing: (32, 32, 3)\n",
            "After resizing: (32, 32, 3)\n",
            "After resizing: (32, 32, 3)\n",
            "After resizing: (32, 32, 3)\n",
            "After resizing: (32, 32, 3)\n",
            "After resizing: (32, 32, 3)\n",
            "After resizing: (32, 32, 3)\n",
            "After resizing: (32, 32, 3)\n",
            "After resizing: (32, 32, 3)\n",
            "After resizing: (32, 32, 3)\n",
            "After resizing: (32, 32, 3)\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f32888d3488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SS</th>\n",
              "      <th>SN</th>\n",
              "      <th>N</th>\n",
              "      <th>NB</th>\n",
              "      <th>BB</th>\n",
              "      <th>Error</th>\n",
              "      <th>Decision</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>ImageM/image3.PNG</th>\n",
              "      <td>0.301182</td>\n",
              "      <td>0.121881</td>\n",
              "      <td>0.264708</td>\n",
              "      <td>0.073682</td>\n",
              "      <td>0.237916</td>\n",
              "      <td>0.000632</td>\n",
              "      <td>SS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ImageM/image2.PNG</th>\n",
              "      <td>0.311591</td>\n",
              "      <td>0.119561</td>\n",
              "      <td>0.263224</td>\n",
              "      <td>0.073630</td>\n",
              "      <td>0.231358</td>\n",
              "      <td>0.000636</td>\n",
              "      <td>SS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ImageM/image1.PNG</th>\n",
              "      <td>0.209848</td>\n",
              "      <td>0.190190</td>\n",
              "      <td>0.379863</td>\n",
              "      <td>0.045567</td>\n",
              "      <td>0.174114</td>\n",
              "      <td>0.000418</td>\n",
              "      <td>N</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ImageM/image4.PNG</th>\n",
              "      <td>0.342570</td>\n",
              "      <td>0.142008</td>\n",
              "      <td>0.243726</td>\n",
              "      <td>0.072087</td>\n",
              "      <td>0.198942</td>\n",
              "      <td>0.000667</td>\n",
              "      <td>SS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ImageM/image5.PNG</th>\n",
              "      <td>0.194147</td>\n",
              "      <td>0.321485</td>\n",
              "      <td>0.290173</td>\n",
              "      <td>0.048638</td>\n",
              "      <td>0.144945</td>\n",
              "      <td>0.000611</td>\n",
              "      <td>SN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ImageM/graphsp500tocrop.PNG</th>\n",
              "      <td>0.001264</td>\n",
              "      <td>0.057363</td>\n",
              "      <td>0.833274</td>\n",
              "      <td>0.032646</td>\n",
              "      <td>0.075410</td>\n",
              "      <td>0.000044</td>\n",
              "      <td>N</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ImageM/ImageM/image3.PNG</th>\n",
              "      <td>0.301182</td>\n",
              "      <td>0.121881</td>\n",
              "      <td>0.264708</td>\n",
              "      <td>0.073682</td>\n",
              "      <td>0.237916</td>\n",
              "      <td>0.000632</td>\n",
              "      <td>SS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ImageM/ImageM/image2.PNG</th>\n",
              "      <td>0.311591</td>\n",
              "      <td>0.119561</td>\n",
              "      <td>0.263224</td>\n",
              "      <td>0.073630</td>\n",
              "      <td>0.231358</td>\n",
              "      <td>0.000636</td>\n",
              "      <td>SS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ImageM/ImageM/image1.PNG</th>\n",
              "      <td>0.209848</td>\n",
              "      <td>0.190190</td>\n",
              "      <td>0.379863</td>\n",
              "      <td>0.045567</td>\n",
              "      <td>0.174114</td>\n",
              "      <td>0.000418</td>\n",
              "      <td>N</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ImageM/ImageM/image4.PNG</th>\n",
              "      <td>0.342570</td>\n",
              "      <td>0.142008</td>\n",
              "      <td>0.243726</td>\n",
              "      <td>0.072087</td>\n",
              "      <td>0.198942</td>\n",
              "      <td>0.000667</td>\n",
              "      <td>SS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ImageM/ImageM/image5.PNG</th>\n",
              "      <td>0.194147</td>\n",
              "      <td>0.321485</td>\n",
              "      <td>0.290173</td>\n",
              "      <td>0.048638</td>\n",
              "      <td>0.144945</td>\n",
              "      <td>0.000611</td>\n",
              "      <td>SN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ImageM/ImageM/graphsp500tocrop.PNG</th>\n",
              "      <td>0.001264</td>\n",
              "      <td>0.057363</td>\n",
              "      <td>0.833274</td>\n",
              "      <td>0.032646</td>\n",
              "      <td>0.075410</td>\n",
              "      <td>0.000044</td>\n",
              "      <td>N</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                          SS        SN  ...     Error  Decision\n",
              "ImageM/image3.PNG                   0.301182  0.121881  ...  0.000632        SS\n",
              "ImageM/image2.PNG                   0.311591  0.119561  ...  0.000636        SS\n",
              "ImageM/image1.PNG                   0.209848  0.190190  ...  0.000418         N\n",
              "ImageM/image4.PNG                   0.342570  0.142008  ...  0.000667        SS\n",
              "ImageM/image5.PNG                   0.194147  0.321485  ...  0.000611        SN\n",
              "ImageM/graphsp500tocrop.PNG         0.001264  0.057363  ...  0.000044         N\n",
              "ImageM/ImageM/image3.PNG            0.301182  0.121881  ...  0.000632        SS\n",
              "ImageM/ImageM/image2.PNG            0.311591  0.119561  ...  0.000636        SS\n",
              "ImageM/ImageM/image1.PNG            0.209848  0.190190  ...  0.000418         N\n",
              "ImageM/ImageM/image4.PNG            0.342570  0.142008  ...  0.000667        SS\n",
              "ImageM/ImageM/image5.PNG            0.194147  0.321485  ...  0.000611        SN\n",
              "ImageM/ImageM/graphsp500tocrop.PNG  0.001264  0.057363  ...  0.000044         N\n",
              "\n",
              "[12 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8Rqf47ewbmk",
        "outputId": "539f26c0-046f-495b-b3f6-b7e630e6ba9c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter the path of the image to check next state:/content/DL_Tools_For_Finance/ImageM/image2.PNG\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QeXi5PdYxJ3r",
        "outputId": "40bc8e51-f752-4868-d0a1-372f17cb57d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "direction"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/DL_Tools_For_Finance/ImageM/image2.PNG'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uE2TBYhJxQK7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}