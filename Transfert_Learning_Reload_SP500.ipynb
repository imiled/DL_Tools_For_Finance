{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transfert_Learning_Vgg16forSP500.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/imiled/DL_Tools_For_Finance/blob/master/Transfert_Learning_Reload_SP500.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QGkfWRfEIyvy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "66b54387-b8ba-4c1d-d461-ca5011e92580"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SmqFDg5Dxk7m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b663c387-80f5-44b2-da72-281b28bdaef4"
      },
      "source": [
        "%pwd"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J597ZlrUNtzb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ce30630a-0ce9-4444-e2e4-bdd38ddc911d"
      },
      "source": [
        "%ls"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mDL_Tools_For_Finance\u001b[0m/  \u001b[01;34mdrive\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cAHcIW__zC2D",
        "colab_type": "text"
      },
      "source": [
        "Downloading the project from github"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dWRUvmdLI64s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "15e99794-75cb-4a8b-ec67-65212fad6529"
      },
      "source": [
        "!git clone https://github.com/imiled/DL_Tools_For_Finance.git\n",
        "#!git clone https://korakot:$password@github.com/korakot/myrepo\n",
        "\n",
        " "
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'DL_Tools_For_Finance'...\n",
            "remote: Enumerating objects: 887, done.\u001b[K\n",
            "remote: Total 887 (delta 0), reused 0 (delta 0), pack-reused 887\u001b[K\n",
            "Receiving objects: 100% (887/887), 206.84 MiB | 32.93 MiB/s, done.\n",
            "Resolving deltas: 100% (491/491), done.\n",
            "Checking out files: 100% (59/59), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1LgIdJgy1U3_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "a5308861-4c23-4bcc-e72a-d41461ca95cc"
      },
      "source": [
        "%cd /content/DL_Tools_For_Finance  \n",
        "!git init\n",
        "!git status\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/DL_Tools_For_Finance\n",
            "Reinitialized existing Git repository in /content/DL_Tools_For_Finance/.git/\n",
            "On branch master\n",
            "Your branch is up to date with 'origin/master'.\n",
            "\n",
            "nothing to commit, working tree clean\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QDgwDAvbxhHX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git log"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n8y-NAfI2Bpp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls > hello.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1se_dxs2DyU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "409c88d5-763e-4a5e-9488-5a01cf257a6a"
      },
      "source": [
        "!cat hello.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "datas\n",
            "hello.txt\n",
            "ImageM\n",
            "LICENSE\n",
            "MainNotebook\n",
            "MANIFEST.in\n",
            "model\n",
            "Notebooks\n",
            "README.md\n",
            "requirements.txt\n",
            "setup.cfg\n",
            "setup.py\n",
            "step1_generate_dataset_IndexImage.py\n",
            "step2_loadingtrainingdatas_vgg_transfert_modelandtraining.py\n",
            "step3_evaluate_vggsp500_model.py\n",
            "step4_guess_future_marketstate_from_image.py\n",
            "tests\n",
            "TFM Imiled 2019-2020_Deep Learning application to Finance.docx\n",
            "trainer\n",
            "Transfert_Learning_Vgg16forSP500.ipynb\n",
            "versioneer.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_dnJgtZMHHv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "outputId": "8b32395b-b120-4dd2-a534-14042eb32c74"
      },
      "source": [
        "%cd /content/DL_Tools_For_Finance  \n",
        "!git add .\n",
        "!ls > hello.txt\n",
        "!git add hello.txt\n",
        "!git commit -m \"reorganisation of files\"\n",
        "!git push origin master          # push to github\n",
        "\n",
        "!git config user.email 'miledismael@gmail.com'\n",
        "!git config user.name 'imiled'\n",
        "\n",
        "username=input(\"what is you github username?\\n\")\n",
        "from getpass import getpass\n",
        "password = getpass('Password:')\n",
        "!git remote add origin https://$username:$password@github.com/$username/reponame.git\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/DL_Tools_For_Finance\n",
            "\n",
            "*** Please tell me who you are.\n",
            "\n",
            "Run\n",
            "\n",
            "  git config --global user.email \"you@example.com\"\n",
            "  git config --global user.name \"Your Name\"\n",
            "\n",
            "to set your account's default identity.\n",
            "Omit --global to set the identity only in this repository.\n",
            "\n",
            "fatal: unable to auto-detect email address (got 'root@4544a85cfe70.(none)')\n",
            "fatal: could not read Username for 'https://github.com': No such device or address\n",
            "what is you github username?\n",
            "imiled\n",
            "Password:··········\n",
            "fatal: remote origin already exists.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nr7TjeHXy80v",
        "colab_type": "text"
      },
      "source": [
        "Saving dataset from drive to local"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3TiNDoAbMJx2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "2461143e-2974-4951-d714-b6fd52a07124"
      },
      "source": [
        "%cd /content/drive/My Drive/A_transfertTFMVggSP500\n",
        "%cp DatasetVggSP500.zip /content/DL_Tools_For_Finance/datas\n",
        "%cd /content/DL_Tools_For_Finance/datas\n",
        "!unzip DatasetVggSP500.zip"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/A_transfertTFMVggSP500\n",
            "/content/DL_Tools_For_Finance/datas\n",
            "Archive:  DatasetVggSP500.zip\n",
            "replace X_test_image.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n",
            "  inflating: X_test_image.csv        \n",
            "  inflating: X_train_image.csv       \n",
            "  inflating: Y_test_FutPredict_image.csv  \n",
            "  inflating: Y_test_StateClass_image.csv  \n",
            "  inflating: Y_train_FutPredict_image.csv  \n",
            "  inflating: Y_train_StateClass_image.csv  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mq_ZXp4zzQ7l",
        "colab_type": "text"
      },
      "source": [
        "Saving latest model from drive to local"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iSxPytYKNjKH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "outputId": "be7754fe-5473-4898-a83b-df7e6c673fe3"
      },
      "source": [
        "%cd /content/drive/My Drive/A_transfertTFMVggSP500 \n",
        "%cp model/final_modelcategorical_crossentropy_adam_32.h5 /content/DL_Tools_For_Finance/model\n",
        "%cp vggforsp500.h5 /content/DL_Tools_For_Finance/model"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: '/content/drive/My Drive/A_transfertTFMVggSP500'\n",
            "/content/DL_Tools_For_Finance/datas\n",
            "cp: cannot stat 'model/final_modelcategorical_crossentropy_adam_32.h5': No such file or directory\n",
            "cp: cannot stat 'vggforsp500.h5': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VehZVTphSljL",
        "colab_type": "text"
      },
      "source": [
        "###Requirement instalation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EEpibDu_Ovpv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "012e3b3e-34e2-42ab-98e9-2f711adb2e34"
      },
      "source": [
        "%cd /content/DL_Tools_For_Finance\n",
        "!pip3 install -r requirements.txt  "
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/DL_Tools_For_Finance\n",
            "Collecting tensorflow==1.15\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3f/98/5a99af92fb911d7a88a0005ad55005f35b4c1ba8d75fba02df726cd936e6/tensorflow-1.15.0-cp36-cp36m-manylinux2010_x86_64.whl (412.3MB)\n",
            "\u001b[K     |████████████████████████████████| 412.3MB 40kB/s \n",
            "\u001b[?25hCollecting Keras==2.3.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ad/fd/6bfe87920d7f4fd475acd28500a42482b6b84479832bdc0fe9e589a60ceb/Keras-2.3.1-py2.py3-none-any.whl (377kB)\n",
            "\u001b[K     |████████████████████████████████| 378kB 40.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 8)) (1.0.5)\n",
            "Collecting numpy>=1.19.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/63/97/af8a92864a04bfa48f1b5c9b1f8bf2ccb2847f24530026f26dd223de4ca0/numpy-1.19.2-cp36-cp36m-manylinux2010_x86_64.whl (14.5MB)\n",
            "\u001b[K     |████████████████████████████████| 14.5MB 306kB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 10)) (0.22.2.post1)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 11)) (0.16.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 12)) (1.4.1)\n",
            "Requirement already satisfied: pandas_datareader in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 13)) (0.8.1)\n",
            "Collecting yfinance\n",
            "  Downloading https://files.pythonhosted.org/packages/c2/31/8b374a12b90def92a4e27d0fc595fc43635f395984e36a075244d98bd265/yfinance-0.1.54.tar.gz\n",
            "Collecting tensorflow-estimator==1.15.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/62/2ee9cd74c9fa2fa450877847ba560b260f5d0fb70ee0595203082dafcc9d/tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503kB)\n",
            "\u001b[K     |████████████████████████████████| 512kB 41.3MB/s \n",
            "\u001b[?25hCollecting keras-applications>=1.0.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 5.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15->-r requirements.txt (line 2)) (1.32.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15->-r requirements.txt (line 2)) (0.2.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15->-r requirements.txt (line 2)) (1.1.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15->-r requirements.txt (line 2)) (0.8.1)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15->-r requirements.txt (line 2)) (3.12.4)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15->-r requirements.txt (line 2)) (1.1.2)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15->-r requirements.txt (line 2)) (1.15.0)\n",
            "Collecting tensorboard<1.16.0,>=1.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/e9/d3d747a97f7188f48aa5eda486907f3b345cd409f0a0850468ba867db246/tensorboard-1.15.0-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 37.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15->-r requirements.txt (line 2)) (0.35.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15->-r requirements.txt (line 2)) (3.3.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15->-r requirements.txt (line 2)) (0.10.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15->-r requirements.txt (line 2)) (1.12.1)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras==2.3.1->-r requirements.txt (line 3)) (3.13)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras==2.3.1->-r requirements.txt (line 3)) (2.10.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->-r requirements.txt (line 8)) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas->-r requirements.txt (line 8)) (2.8.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->-r requirements.txt (line 10)) (0.16.0)\n",
            "Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->-r requirements.txt (line 11)) (7.0.0)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->-r requirements.txt (line 11)) (2.5)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->-r requirements.txt (line 11)) (3.2.2)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->-r requirements.txt (line 11)) (1.1.1)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->-r requirements.txt (line 11)) (2.4.1)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.6/dist-packages (from pandas_datareader->-r requirements.txt (line 13)) (4.2.6)\n",
            "Requirement already satisfied: requests>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from pandas_datareader->-r requirements.txt (line 13)) (2.23.0)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from yfinance->-r requirements.txt (line 16)) (0.0.9)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==1.15->-r requirements.txt (line 2)) (50.3.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15->-r requirements.txt (line 2)) (3.2.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15->-r requirements.txt (line 2)) (1.0.1)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.0->scikit-image->-r requirements.txt (line 11)) (4.4.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->-r requirements.txt (line 11)) (1.2.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->-r requirements.txt (line 11)) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->-r requirements.txt (line 11)) (0.10.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.3.0->pandas_datareader->-r requirements.txt (line 13)) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.3.0->pandas_datareader->-r requirements.txt (line 13)) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.3.0->pandas_datareader->-r requirements.txt (line 13)) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.3.0->pandas_datareader->-r requirements.txt (line 13)) (1.24.3)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15->-r requirements.txt (line 2)) (1.7.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15->-r requirements.txt (line 2)) (3.1.0)\n",
            "Building wheels for collected packages: yfinance, gast\n",
            "  Building wheel for yfinance (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for yfinance: filename=yfinance-0.1.54-py2.py3-none-any.whl size=22409 sha256=e2a56ff349c9c464c7aa1ffb980f9a2483f06cbae68a4fbb12811fd107cf8785\n",
            "  Stored in directory: /root/.cache/pip/wheels/f9/e3/5b/ec24dd2984b12d61e0abf26289746c2436a0e7844f26f2515c\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-cp36-none-any.whl size=7542 sha256=ce66f235e486db0252bf9e3f1eaa8d1720a3e492a54953896c0f1cb82424e524\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
            "Successfully built yfinance gast\n",
            "\u001b[31mERROR: tensorflow-probability 0.11.0 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tensorflow-estimator, numpy, keras-applications, tensorboard, gast, tensorflow, Keras, yfinance\n",
            "  Found existing installation: tensorflow-estimator 2.3.0\n",
            "    Uninstalling tensorflow-estimator-2.3.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.3.0\n",
            "  Found existing installation: numpy 1.18.5\n",
            "    Uninstalling numpy-1.18.5:\n",
            "      Successfully uninstalled numpy-1.18.5\n",
            "  Found existing installation: tensorboard 2.3.0\n",
            "    Uninstalling tensorboard-2.3.0:\n",
            "      Successfully uninstalled tensorboard-2.3.0\n",
            "  Found existing installation: gast 0.3.3\n",
            "    Uninstalling gast-0.3.3:\n",
            "      Successfully uninstalled gast-0.3.3\n",
            "  Found existing installation: tensorflow 2.3.0\n",
            "    Uninstalling tensorflow-2.3.0:\n",
            "      Successfully uninstalled tensorflow-2.3.0\n",
            "  Found existing installation: Keras 2.4.3\n",
            "    Uninstalling Keras-2.4.3:\n",
            "      Successfully uninstalled Keras-2.4.3\n",
            "Successfully installed Keras-2.3.1 gast-0.2.2 keras-applications-1.0.8 numpy-1.19.2 tensorboard-1.15.0 tensorflow-1.15.0 tensorflow-estimator-1.15.1 yfinance-0.1.54\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "gast",
                  "keras",
                  "numpy",
                  "tensorboard",
                  "tensorflow"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dTwxPiI4zLz3",
        "colab_type": "text"
      },
      "source": [
        "##Part with all steps through python command##"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_SEuIXmtTG26",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "35fef0a0-efce-4166-8dd0-77856a90d251"
      },
      "source": [
        "%cd /content/DL_Tools_For_Finance\n",
        "!python3 step1_generate_dataset_IndexImage.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: '/content/DL_Tools_For_Finance'\n",
            "/content\n",
            "python3: can't open file 'step1_generate_dataset_IndexImage.py': [Errno 2] No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jKbZEi02Ti5r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "fd6b1d56-610a-4156-cc40-48381fc4c2b7"
      },
      "source": [
        "%cd /content/DL_Tools_For_Finance\n",
        "!python3 step2_loadingtrainingdatas_vgg_transfert_modelandtraining.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/DL_Tools_For_Finance\n",
            "2020-08-31 14:00:07.536779: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-08-31 14:00:23.283485: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1\n",
            "2020-08-31 14:00:23.354418: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-31 14:00:23.355305: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\n",
            "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.73GiB deviceMemoryBandwidth: 298.08GiB/s\n",
            "2020-08-31 14:00:23.355378: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-08-31 14:00:23.618262: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
            "2020-08-31 14:00:23.772071: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
            "2020-08-31 14:00:23.799494: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
            "2020-08-31 14:00:24.091903: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-08-31 14:00:24.121391: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-08-31 14:00:24.631937: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-08-31 14:00:24.632162: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-31 14:00:24.632916: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-31 14:00:24.633516: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\n",
            "2020-08-31 14:00:24.633867: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX512F\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2020-08-31 14:00:24.655218: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2000125000 Hz\n",
            "2020-08-31 14:00:24.655444: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1b70f40 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-08-31 14:00:24.655479: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2020-08-31 14:00:24.794351: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-31 14:00:24.795101: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1b70d80 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2020-08-31 14:00:24.795132: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "2020-08-31 14:00:24.796328: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-31 14:00:24.796900: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\n",
            "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.73GiB deviceMemoryBandwidth: 298.08GiB/s\n",
            "2020-08-31 14:00:24.796955: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-08-31 14:00:24.796995: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
            "2020-08-31 14:00:24.797016: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
            "2020-08-31 14:00:24.797040: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
            "2020-08-31 14:00:24.797060: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-08-31 14:00:24.797078: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-08-31 14:00:24.797098: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-08-31 14:00:24.797174: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-31 14:00:24.797845: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-31 14:00:24.798390: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\n",
            "2020-08-31 14:00:24.804305: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-08-31 14:00:28.654055: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-08-31 14:00:28.654111: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 \n",
            "2020-08-31 14:00:28.654124: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N \n",
            "2020-08-31 14:00:28.661735: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-31 14:00:28.662361: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-31 14:00:28.662893: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2020-08-31 14:00:28.662938: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13962 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 1s 0us/step\n",
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 32, 32, 64)        1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 32, 32, 64)        36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 16, 16, 128)       73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 16, 16, 128)       147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 8, 8, 256)         295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 8, 8, 256)         590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 8, 8, 256)         590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 4, 4, 256)         0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 4, 4, 512)         1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 2, 2, 512)         0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 1, 1, 512)         0         \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 0\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/50\n",
            "2020-08-31 14:00:30.921687: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
            "2020-08-31 14:00:32.390571: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
            "149/149 [==============================] - ETA: 0s - loss: 2.0473 - accuracy: 0.3377\n",
            "Epoch 00001: loss improved from inf to 2.04734, saving model to model/best_modelcategorical_crossentropy_adam_Batch100_LR0.1_0.99.hdf5\n",
            "149/149 [==============================] - 3s 21ms/step - loss: 2.0473 - accuracy: 0.3377 - val_loss: 1.4949 - val_accuracy: 0.3399\n",
            "Epoch 2/50\n",
            "145/149 [============================>.] - ETA: 0s - loss: 1.5323 - accuracy: 0.3433\n",
            "Epoch 00002: loss improved from 2.04734 to 1.53141, saving model to model/best_modelcategorical_crossentropy_adam_Batch100_LR0.1_0.99.hdf5\n",
            "149/149 [==============================] - 3s 17ms/step - loss: 1.5314 - accuracy: 0.3436 - val_loss: 1.4906 - val_accuracy: 0.3399\n",
            "Epoch 3/50\n",
            "149/149 [==============================] - ETA: 0s - loss: 1.5308 - accuracy: 0.3436\n",
            "Epoch 00003: loss improved from 1.53141 to 1.53084, saving model to model/best_modelcategorical_crossentropy_adam_Batch100_LR0.1_0.99.hdf5\n",
            "149/149 [==============================] - 3s 17ms/step - loss: 1.5308 - accuracy: 0.3436 - val_loss: 1.4926 - val_accuracy: 0.3399\n",
            "Epoch 4/50\n",
            "149/149 [==============================] - ETA: 0s - loss: 1.5320 - accuracy: 0.3436\n",
            "Epoch 00004: loss did not improve from 1.53084\n",
            "149/149 [==============================] - 2s 16ms/step - loss: 1.5320 - accuracy: 0.3436 - val_loss: 1.4935 - val_accuracy: 0.3399\n",
            "Epoch 5/50\n",
            "145/149 [============================>.] - ETA: 0s - loss: 1.5321 - accuracy: 0.3389\n",
            "Epoch 00005: loss did not improve from 1.53084\n",
            "149/149 [==============================] - 2s 16ms/step - loss: 1.5314 - accuracy: 0.3394 - val_loss: 1.5005 - val_accuracy: 0.3399\n",
            "Epoch 6/50\n",
            "145/149 [============================>.] - ETA: 0s - loss: 1.5315 - accuracy: 0.3385\n",
            "Epoch 00006: loss did not improve from 1.53084\n",
            "149/149 [==============================] - 2s 16ms/step - loss: 1.5321 - accuracy: 0.3381 - val_loss: 1.5235 - val_accuracy: 0.3399\n",
            "Epoch 7/50\n",
            "149/149 [==============================] - ETA: 0s - loss: 1.5318 - accuracy: 0.3414\n",
            "Epoch 00007: loss did not improve from 1.53084\n",
            "149/149 [==============================] - 2s 16ms/step - loss: 1.5318 - accuracy: 0.3414 - val_loss: 1.5054 - val_accuracy: 0.3399\n",
            "Epoch 8/50\n",
            "149/149 [==============================] - ETA: 0s - loss: 1.5345 - accuracy: 0.3360\n",
            "Epoch 00008: loss did not improve from 1.53084\n",
            "149/149 [==============================] - 2s 17ms/step - loss: 1.5345 - accuracy: 0.3360 - val_loss: 1.4982 - val_accuracy: 0.3399\n",
            "Epoch 9/50\n",
            "145/149 [============================>.] - ETA: 0s - loss: 1.5337 - accuracy: 0.3428\n",
            "Epoch 00009: loss did not improve from 1.53084\n",
            "149/149 [==============================] - 2s 17ms/step - loss: 1.5329 - accuracy: 0.3436 - val_loss: 1.5099 - val_accuracy: 0.3399\n",
            "Epoch 10/50\n",
            "149/149 [==============================] - ETA: 0s - loss: 1.5336 - accuracy: 0.3358\n",
            "Epoch 00010: loss did not improve from 1.53084\n",
            "149/149 [==============================] - 2s 16ms/step - loss: 1.5336 - accuracy: 0.3358 - val_loss: 1.4912 - val_accuracy: 0.3399\n",
            "Epoch 11/50\n",
            "145/149 [============================>.] - ETA: 0s - loss: 1.5348 - accuracy: 0.3426\n",
            "Epoch 00011: loss did not improve from 1.53084\n",
            "149/149 [==============================] - 2s 16ms/step - loss: 1.5333 - accuracy: 0.3436 - val_loss: 1.4965 - val_accuracy: 0.3399\n",
            "Epoch 12/50\n",
            "145/149 [============================>.] - ETA: 0s - loss: 1.5330 - accuracy: 0.3417\n",
            "Epoch 00012: loss did not improve from 1.53084\n",
            "149/149 [==============================] - 2s 16ms/step - loss: 1.5326 - accuracy: 0.3422 - val_loss: 1.5040 - val_accuracy: 0.3399\n",
            "Epoch 13/50\n",
            "145/149 [============================>.] - ETA: 0s - loss: 1.5341 - accuracy: 0.3383\n",
            "Epoch 00013: loss did not improve from 1.53084\n",
            "149/149 [==============================] - 2s 16ms/step - loss: 1.5341 - accuracy: 0.3381 - val_loss: 1.4915 - val_accuracy: 0.3399\n",
            "Epoch 14/50\n",
            "145/149 [============================>.] - ETA: 0s - loss: 1.5342 - accuracy: 0.3352\n",
            "Epoch 00014: loss did not improve from 1.53084\n",
            "149/149 [==============================] - 2s 16ms/step - loss: 1.5330 - accuracy: 0.3366 - val_loss: 1.5078 - val_accuracy: 0.3399\n",
            "Epoch 15/50\n",
            "149/149 [==============================] - ETA: 0s - loss: 1.5326 - accuracy: 0.3412\n",
            "Epoch 00015: loss did not improve from 1.53084\n",
            "149/149 [==============================] - 2s 16ms/step - loss: 1.5326 - accuracy: 0.3412 - val_loss: 1.5212 - val_accuracy: 0.3399\n",
            "Epoch 16/50\n",
            "149/149 [==============================] - ETA: 0s - loss: 1.5344 - accuracy: 0.3402\n",
            "Epoch 00016: loss did not improve from 1.53084\n",
            "149/149 [==============================] - 2s 16ms/step - loss: 1.5344 - accuracy: 0.3402 - val_loss: 1.5016 - val_accuracy: 0.3399\n",
            "Epoch 17/50\n",
            "149/149 [==============================] - ETA: 0s - loss: 1.5320 - accuracy: 0.3436\n",
            "Epoch 00017: loss did not improve from 1.53084\n",
            "149/149 [==============================] - 2s 17ms/step - loss: 1.5320 - accuracy: 0.3436 - val_loss: 1.4908 - val_accuracy: 0.3399\n",
            "Epoch 18/50\n",
            "145/149 [============================>.] - ETA: 0s - loss: 1.5335 - accuracy: 0.3357\n",
            "Epoch 00018: loss did not improve from 1.53084\n",
            "149/149 [==============================] - 2s 16ms/step - loss: 1.5332 - accuracy: 0.3360 - val_loss: 1.5041 - val_accuracy: 0.3399\n",
            "Epoch 19/50\n",
            "149/149 [==============================] - ETA: 0s - loss: 1.5333 - accuracy: 0.3388\n",
            "Epoch 00019: loss did not improve from 1.53084\n",
            "149/149 [==============================] - 2s 16ms/step - loss: 1.5333 - accuracy: 0.3388 - val_loss: 1.4987 - val_accuracy: 0.3399\n",
            "Epoch 20/50\n",
            "145/149 [============================>.] - ETA: 0s - loss: 1.5306 - accuracy: 0.3443\n",
            "Epoch 00020: loss improved from 1.53084 to 1.53068, saving model to model/best_modelcategorical_crossentropy_adam_Batch100_LR0.1_0.99.hdf5\n",
            "149/149 [==============================] - 3s 17ms/step - loss: 1.5307 - accuracy: 0.3436 - val_loss: 1.4947 - val_accuracy: 0.3399\n",
            "Epoch 21/50\n",
            "149/149 [==============================] - ETA: 0s - loss: 1.5315 - accuracy: 0.3436\n",
            "Epoch 00021: loss did not improve from 1.53068\n",
            "149/149 [==============================] - 3s 17ms/step - loss: 1.5315 - accuracy: 0.3436 - val_loss: 1.4899 - val_accuracy: 0.3399\n",
            "Epoch 22/50\n",
            "145/149 [============================>.] - ETA: 0s - loss: 1.5312 - accuracy: 0.3430\n",
            "Epoch 00022: loss did not improve from 1.53068\n",
            "149/149 [==============================] - 2s 17ms/step - loss: 1.5323 - accuracy: 0.3421 - val_loss: 1.5026 - val_accuracy: 0.3399\n",
            "Epoch 23/50\n",
            "145/149 [============================>.] - ETA: 0s - loss: 1.5311 - accuracy: 0.3438\n",
            "Epoch 00023: loss did not improve from 1.53068\n",
            "149/149 [==============================] - 2s 17ms/step - loss: 1.5313 - accuracy: 0.3436 - val_loss: 1.5046 - val_accuracy: 0.3399\n",
            "Epoch 24/50\n",
            "149/149 [==============================] - ETA: 0s - loss: 1.5319 - accuracy: 0.3413\n",
            "Epoch 00024: loss did not improve from 1.53068\n",
            "149/149 [==============================] - 2s 17ms/step - loss: 1.5319 - accuracy: 0.3413 - val_loss: 1.5038 - val_accuracy: 0.3399\n",
            "Epoch 25/50\n",
            "145/149 [============================>.] - ETA: 0s - loss: 1.5322 - accuracy: 0.3435\n",
            "Epoch 00025: loss did not improve from 1.53068\n",
            "149/149 [==============================] - 2s 17ms/step - loss: 1.5322 - accuracy: 0.3436 - val_loss: 1.5049 - val_accuracy: 0.3399\n",
            "Epoch 26/50\n",
            "149/149 [==============================] - ETA: 0s - loss: 1.5319 - accuracy: 0.3436\n",
            "Epoch 00026: loss did not improve from 1.53068\n",
            "149/149 [==============================] - 2s 17ms/step - loss: 1.5319 - accuracy: 0.3436 - val_loss: 1.4944 - val_accuracy: 0.3399\n",
            "Epoch 27/50\n",
            "149/149 [==============================] - ETA: 0s - loss: 1.5332 - accuracy: 0.3436\n",
            "Epoch 00027: loss did not improve from 1.53068\n",
            "149/149 [==============================] - 2s 17ms/step - loss: 1.5332 - accuracy: 0.3436 - val_loss: 1.5045 - val_accuracy: 0.3399\n",
            "Epoch 28/50\n",
            "145/149 [============================>.] - ETA: 0s - loss: 1.5328 - accuracy: 0.3399\n",
            "Epoch 00028: loss did not improve from 1.53068\n",
            "149/149 [==============================] - 2s 17ms/step - loss: 1.5326 - accuracy: 0.3402 - val_loss: 1.4924 - val_accuracy: 0.3399\n",
            "Epoch 29/50\n",
            "149/149 [==============================] - ETA: 0s - loss: 1.5317 - accuracy: 0.3436\n",
            "Epoch 00029: loss did not improve from 1.53068\n",
            "149/149 [==============================] - 2s 17ms/step - loss: 1.5317 - accuracy: 0.3436 - val_loss: 1.4979 - val_accuracy: 0.3399\n",
            "Epoch 30/50\n",
            "145/149 [============================>.] - ETA: 0s - loss: 1.5314 - accuracy: 0.3441\n",
            "Epoch 00030: loss did not improve from 1.53068\n",
            "149/149 [==============================] - 2s 17ms/step - loss: 1.5317 - accuracy: 0.3436 - val_loss: 1.4978 - val_accuracy: 0.3399\n",
            "Epoch 31/50\n",
            "149/149 [==============================] - ETA: 0s - loss: 1.5328 - accuracy: 0.3383\n",
            "Epoch 00031: loss did not improve from 1.53068\n",
            "149/149 [==============================] - 2s 17ms/step - loss: 1.5328 - accuracy: 0.3383 - val_loss: 1.5141 - val_accuracy: 0.3399\n",
            "Epoch 32/50\n",
            "149/149 [==============================] - ETA: 0s - loss: 1.5315 - accuracy: 0.3410\n",
            "Epoch 00032: loss did not improve from 1.53068\n",
            "149/149 [==============================] - 2s 17ms/step - loss: 1.5315 - accuracy: 0.3410 - val_loss: 1.4968 - val_accuracy: 0.3399\n",
            "Epoch 33/50\n",
            "149/149 [==============================] - ETA: 0s - loss: 1.5342 - accuracy: 0.3372\n",
            "Epoch 00033: loss did not improve from 1.53068\n",
            "149/149 [==============================] - 2s 17ms/step - loss: 1.5342 - accuracy: 0.3372 - val_loss: 1.4964 - val_accuracy: 0.3399\n",
            "Epoch 34/50\n",
            "149/149 [==============================] - ETA: 0s - loss: 1.5337 - accuracy: 0.3420\n",
            "Epoch 00034: loss did not improve from 1.53068\n",
            "149/149 [==============================] - 3s 17ms/step - loss: 1.5337 - accuracy: 0.3420 - val_loss: 1.4939 - val_accuracy: 0.3399\n",
            "Epoch 35/50\n",
            "149/149 [==============================] - ETA: 0s - loss: 1.5328 - accuracy: 0.3436\n",
            "Epoch 00035: loss did not improve from 1.53068\n",
            "149/149 [==============================] - 2s 17ms/step - loss: 1.5328 - accuracy: 0.3436 - val_loss: 1.4953 - val_accuracy: 0.3399\n",
            "Epoch 36/50\n",
            "145/149 [============================>.] - ETA: 0s - loss: 1.5336 - accuracy: 0.3441\n",
            "Epoch 00036: loss did not improve from 1.53068\n",
            "149/149 [==============================] - 3s 17ms/step - loss: 1.5341 - accuracy: 0.3436 - val_loss: 1.5010 - val_accuracy: 0.3399\n",
            "Epoch 37/50\n",
            "149/149 [==============================] - ETA: 0s - loss: 1.5328 - accuracy: 0.3399\n",
            "Epoch 00037: loss did not improve from 1.53068\n",
            "149/149 [==============================] - 3s 17ms/step - loss: 1.5328 - accuracy: 0.3399 - val_loss: 1.4952 - val_accuracy: 0.3399\n",
            "Epoch 38/50\n",
            "149/149 [==============================] - ETA: 0s - loss: 1.5319 - accuracy: 0.3415\n",
            "Epoch 00038: loss did not improve from 1.53068\n",
            "149/149 [==============================] - 2s 17ms/step - loss: 1.5319 - accuracy: 0.3415 - val_loss: 1.5012 - val_accuracy: 0.3399\n",
            "Epoch 39/50\n",
            "149/149 [==============================] - ETA: 0s - loss: 1.5335 - accuracy: 0.3417\n",
            "Epoch 00039: loss did not improve from 1.53068\n",
            "149/149 [==============================] - 3s 17ms/step - loss: 1.5335 - accuracy: 0.3417 - val_loss: 1.4931 - val_accuracy: 0.3399\n",
            "Epoch 40/50\n",
            "149/149 [==============================] - ETA: 0s - loss: 1.5328 - accuracy: 0.3427\n",
            "Epoch 00040: loss did not improve from 1.53068\n",
            "149/149 [==============================] - 3s 17ms/step - loss: 1.5328 - accuracy: 0.3427 - val_loss: 1.5152 - val_accuracy: 0.3399\n",
            "Epoch 41/50\n",
            "149/149 [==============================] - ETA: 0s - loss: 1.5332 - accuracy: 0.3414\n",
            "Epoch 00041: loss did not improve from 1.53068\n",
            "149/149 [==============================] - 3s 17ms/step - loss: 1.5332 - accuracy: 0.3414 - val_loss: 1.4931 - val_accuracy: 0.3399\n",
            "Epoch 42/50\n",
            "149/149 [==============================] - ETA: 0s - loss: 1.5312 - accuracy: 0.3436\n",
            "Epoch 00042: loss did not improve from 1.53068\n",
            "149/149 [==============================] - 3s 17ms/step - loss: 1.5312 - accuracy: 0.3436 - val_loss: 1.5019 - val_accuracy: 0.3399\n",
            "Epoch 43/50\n",
            "149/149 [==============================] - ETA: 0s - loss: 1.5320 - accuracy: 0.3397\n",
            "Epoch 00043: loss did not improve from 1.53068\n",
            "149/149 [==============================] - 3s 17ms/step - loss: 1.5320 - accuracy: 0.3397 - val_loss: 1.5109 - val_accuracy: 0.3399\n",
            "Epoch 44/50\n",
            "149/149 [==============================] - ETA: 0s - loss: 1.5329 - accuracy: 0.3436\n",
            "Epoch 00044: loss did not improve from 1.53068\n",
            "149/149 [==============================] - 3s 17ms/step - loss: 1.5329 - accuracy: 0.3436 - val_loss: 1.5056 - val_accuracy: 0.3399\n",
            "Epoch 45/50\n",
            "149/149 [==============================] - ETA: 0s - loss: 1.5321 - accuracy: 0.3436\n",
            "Epoch 00045: loss did not improve from 1.53068\n",
            "149/149 [==============================] - 3s 17ms/step - loss: 1.5321 - accuracy: 0.3436 - val_loss: 1.5010 - val_accuracy: 0.3399\n",
            "Epoch 46/50\n",
            "149/149 [==============================] - ETA: 0s - loss: 1.5316 - accuracy: 0.3409\n",
            "Epoch 00046: loss did not improve from 1.53068\n",
            "149/149 [==============================] - 3s 17ms/step - loss: 1.5316 - accuracy: 0.3409 - val_loss: 1.4912 - val_accuracy: 0.3399\n",
            "Epoch 47/50\n",
            "149/149 [==============================] - ETA: 0s - loss: 1.5313 - accuracy: 0.3436\n",
            "Epoch 00047: loss did not improve from 1.53068\n",
            "149/149 [==============================] - 3s 17ms/step - loss: 1.5313 - accuracy: 0.3436 - val_loss: 1.4899 - val_accuracy: 0.3399\n",
            "Epoch 48/50\n",
            "145/149 [============================>.] - ETA: 0s - loss: 1.5329 - accuracy: 0.3438\n",
            "Epoch 00048: loss did not improve from 1.53068\n",
            "149/149 [==============================] - 3s 17ms/step - loss: 1.5331 - accuracy: 0.3436 - val_loss: 1.5025 - val_accuracy: 0.3399\n",
            "Epoch 49/50\n",
            "145/149 [============================>.] - ETA: 0s - loss: 1.5322 - accuracy: 0.3412\n",
            "Epoch 00049: loss did not improve from 1.53068\n",
            "149/149 [==============================] - 3s 17ms/step - loss: 1.5326 - accuracy: 0.3408 - val_loss: 1.5109 - val_accuracy: 0.3399\n",
            "Epoch 50/50\n",
            "149/149 [==============================] - ETA: 0s - loss: 1.5326 - accuracy: 0.3436\n",
            "Epoch 00050: loss did not improve from 1.53068\n",
            "149/149 [==============================] - 3s 17ms/step - loss: 1.5326 - accuracy: 0.3436 - val_loss: 1.4915 - val_accuracy: 0.3399\n",
            "Traceback (most recent call last):\n",
            "  File \"step2_loadingtrainingdatas_vgg_transfert_modelandtraining.py\", line 160, in <module>\n",
            "    transfer_model.save(\"model/\"+datetime.now().strftime(\"%Y%m%d-%H%M%S\")+\"vggforsp500.h5\")\n",
            "NameError: name 'datetime' is not defined\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CjSc-KxlVc0L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b639276e-8b87-4388-99ea-a75aba35a86f"
      },
      "source": [
        "%cd /content/DL_Tools_For_Finance\n",
        "!python3 step3_evaluate_vggsp500_model.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/DL_Tools_For_Finance\n",
            "2020-08-31 14:02:47.233647: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-08-31 14:02:51.669914: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1\n",
            "2020-08-31 14:02:51.704030: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-31 14:02:51.704632: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\n",
            "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.73GiB deviceMemoryBandwidth: 298.08GiB/s\n",
            "2020-08-31 14:02:51.704688: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-08-31 14:02:51.706171: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
            "2020-08-31 14:02:51.707708: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
            "2020-08-31 14:02:51.708035: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
            "2020-08-31 14:02:51.709428: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-08-31 14:02:51.710185: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-08-31 14:02:51.713048: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-08-31 14:02:51.713172: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-31 14:02:51.713766: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-31 14:02:51.714261: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\n",
            "2020-08-31 14:02:51.714718: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX512F\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2020-08-31 14:02:51.719389: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2000125000 Hz\n",
            "2020-08-31 14:02:51.719605: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x28f6bc0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-08-31 14:02:51.719633: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2020-08-31 14:02:51.807725: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-31 14:02:51.808365: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x28f6a00 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2020-08-31 14:02:51.808401: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "2020-08-31 14:02:51.808620: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-31 14:02:51.809133: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\n",
            "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.73GiB deviceMemoryBandwidth: 298.08GiB/s\n",
            "2020-08-31 14:02:51.809188: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-08-31 14:02:51.809222: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
            "2020-08-31 14:02:51.809244: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
            "2020-08-31 14:02:51.809264: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
            "2020-08-31 14:02:51.809287: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-08-31 14:02:51.809306: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-08-31 14:02:51.809326: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-08-31 14:02:51.809405: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-31 14:02:51.810022: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-31 14:02:51.810533: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\n",
            "2020-08-31 14:02:51.810597: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-08-31 14:02:52.339278: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-08-31 14:02:52.339335: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 \n",
            "2020-08-31 14:02:52.339348: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N \n",
            "2020-08-31 14:02:52.339561: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-31 14:02:52.340218: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-31 14:02:52.340755: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2020-08-31 14:02:52.340796: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13962 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "2020-08-31 14:02:52.849852: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
            "2020-08-31 14:02:53.190922: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
            "146/146 [==============================] - 1s 9ms/step - loss: 2.0681 - accuracy: 0.2512\n",
            "Confusion Matrix\n",
            "Accuracy on the Test Images:  0.25123897194862366\n",
            "             SS  ...  Error\n",
            "SS     0.152104  ...    0.0\n",
            "SN     0.175889  ...    0.0\n",
            "N      0.157669  ...    0.0\n",
            "NB     0.157421  ...    0.0\n",
            "BB     0.150538  ...    0.0\n",
            "Error  0.000000  ...    0.0\n",
            "\n",
            "[6 rows x 6 columns]\n",
            "classification report\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          SS       0.26      0.47      0.33      1209\n",
            "          SN       0.00      0.00      0.00        11\n",
            "           N       0.36      0.26      0.30      1630\n",
            "          NB       0.14      0.10      0.12       667\n",
            "          BB       0.52      0.02      0.05       506\n",
            "       Error       0.13      0.15      0.14       618\n",
            "\n",
            "    accuracy                           0.25      4641\n",
            "   macro avg       0.23      0.17      0.16      4641\n",
            "weighted avg       0.29      0.25      0.23      4641\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MfSMBNcGxMF2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 988
        },
        "outputId": "c3008cb3-6bfe-4259-ce16-c9adcf367400"
      },
      "source": [
        "%cd /content/DL_Tools_For_Finance\n",
        "!python3 step4_guess_future_marketstate_from_image.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/DL_Tools_For_Finance\n",
            "2020-08-31 14:03:08.385690: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "After resizing: (32, 32, 3)\n",
            "2020-08-31 14:03:09.535186: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1\n",
            "2020-08-31 14:03:09.574599: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-31 14:03:09.575181: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\n",
            "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.73GiB deviceMemoryBandwidth: 298.08GiB/s\n",
            "2020-08-31 14:03:09.575244: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-08-31 14:03:09.576673: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
            "2020-08-31 14:03:09.585531: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
            "2020-08-31 14:03:09.585899: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
            "2020-08-31 14:03:09.591997: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-08-31 14:03:09.592918: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-08-31 14:03:09.602832: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-08-31 14:03:09.602955: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-31 14:03:09.603582: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-31 14:03:09.604090: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\n",
            "2020-08-31 14:03:09.604397: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX512F\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2020-08-31 14:03:09.610479: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2000125000 Hz\n",
            "2020-08-31 14:03:09.610705: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1354bc0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-08-31 14:03:09.610739: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2020-08-31 14:03:09.722558: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-31 14:03:09.723230: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1354d80 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2020-08-31 14:03:09.723264: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "2020-08-31 14:03:09.723464: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-31 14:03:09.724073: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\n",
            "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.73GiB deviceMemoryBandwidth: 298.08GiB/s\n",
            "2020-08-31 14:03:09.724132: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-08-31 14:03:09.724172: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
            "2020-08-31 14:03:09.724199: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
            "2020-08-31 14:03:09.724224: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
            "2020-08-31 14:03:09.724253: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-08-31 14:03:09.724275: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-08-31 14:03:09.724305: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-08-31 14:03:09.724386: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-31 14:03:09.725011: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-31 14:03:09.725535: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\n",
            "2020-08-31 14:03:09.725602: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-08-31 14:03:10.322458: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-08-31 14:03:10.322529: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 \n",
            "2020-08-31 14:03:10.322543: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N \n",
            "2020-08-31 14:03:10.322768: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-31 14:03:10.323702: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-31 14:03:10.324428: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2020-08-31 14:03:10.324484: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13962 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "2020-08-31 14:03:10.764422: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
            "2020-08-31 14:03:11.077927: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
            "for  ImageM/image1.PNG the best result is  N\n",
            "                          SS  ...     Error\n",
            "ImageM/image1.PNG   0.209848  ...  0.000418\n",
            "ImageM/image1.PNG1  0.209848  ...  0.000418\n",
            "\n",
            "[2 rows x 6 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1n0vJA_lL-Xv",
        "colab_type": "text"
      },
      "source": [
        "##Step 1 : Generate Dataset of the Image and the Future maket state"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7jbsgi1Qa6Rg",
        "colab_type": "text"
      },
      "source": [
        "In this part we are generating the training and testing dataset.\n",
        "First we download the historical prices of the sp500 from 1927 to 31 July 2020 and built the image of 15 days historical graph also we get the 5 days future price evolution of the sp500. \n",
        "From the future price evolution, we calculate a future state which can be splitted in 6 classes :\n",
        "\n",
        "Sell-Sell | Sell- Neutral | Neutral | Neutral -Buy | Buy -Buy (and the Error class)\n",
        "\n",
        "The objective is to get the following files which represent a dataframe in the data/ repertory:\n",
        "\n",
        "X_train_image.csv , X_test_image.csv a 3072 column time serie dataframe  of the image (32 x 32 x3) of the sp500 closing price \n",
        "\n",
        "Y_test_StateClass.csv, Y_train_StateClass.csv a 1 column time serie dataframe of the future state value betwwen -1 to 4\n",
        "\n",
        "We generate also the following files but we won´t use it in this project - more fore RNN & price prediction - Y_test_FutPredict.csv Y_train_FutPredict.csv\n",
        "\n",
        "the testing and training time serie dataset are shuffled by the date of reference with a split number of 0.8\n",
        "\n",
        "Please note that: \n",
        "1. We can increase the dataset taking into account the evolution very liquid stocks or other indices as long as we have very high the liquidity and number of participants \n",
        "2. The calculation of the dataset can take more than 6 hours of calulation as the code is not optimized so far, we can quickly implement parallel computing and rapid image setup instead of using matplotlib library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_7hN1p8cJY_3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "2063d9cc-a343-42c4-c7ce-a32615d6eb30"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import bs4 as bs\n",
        "import requests\n",
        "import yfinance as yf\n",
        "import fix_yahoo_finance as yf\n",
        "import datetime\n",
        "import io\n",
        "import cv2\n",
        "import skimage\n",
        "import datetime\n",
        "from PIL import Image\n",
        "from pandas_datareader import data as pdr\n",
        "from skimage import measure\n",
        "from skimage.measure import block_reduce\n",
        "from datetime import datetime\n",
        "\n",
        "'''\n",
        "Functions to be used for data generation \n",
        "'''\n",
        "\n",
        "def get_img_from_fig(fig, dpi=180):\n",
        "   # get_img_from_fig is function which returns an image as numpy array from figure\n",
        "    buf = io.BytesIO()\n",
        "    fig.savefig(buf, format=\"png\", dpi=dpi)\n",
        "    buf.seek(0)\n",
        "    img_arr = np.frombuffer(buf.getvalue(), dtype=np.uint8)\n",
        "    buf.close()\n",
        "    img = cv2.imdecode(img_arr, 1)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    return img\n",
        "\n",
        "def build_image(stockindex, idate=10, pastlag=10, futlag=3,nb_dates=1000):\n",
        "  # Build image from a table stockindex price list \n",
        "  #return a (32,32,3) np.array representing the image in color\n",
        "  #ising idate as a starting point\n",
        "  #paslag futlag number of days to consider for translate\n",
        "  sp500close=stockindex\n",
        "  nb_days=nb_dates\n",
        "\n",
        "  x_datas=[]\n",
        "  x_datas=np.zeros((32,32,3))\n",
        "  i=idate\n",
        "  \n",
        "  fig=plt.figure()\n",
        "  ax=fig.add_subplot(111)\n",
        "  ax.plot(sp500close[(i-pastlag):i])\n",
        "  plot_img_np = get_img_from_fig(fig)\n",
        "  x_tmp= skimage.measure.block_reduce(plot_img_np[90:620,140:970], (18,28,1), np.mean)\n",
        "  (x_datas[1:-1])[:,1:-1][:]=x_tmp\n",
        "  fig.clear()\n",
        "  plt.close(fig)\n",
        "    \n",
        "  x_datas=x_datas/255\n",
        "  return x_datas\n",
        "\n",
        "  \n",
        "'''\n",
        "MAIN FUNCTION OF CLASSIFICATION \n",
        "build y state y fut \n",
        "and x  \n",
        "'''\n",
        "def class_shortterm_returnfut(x, yfut, indexforpast,tpastlag):\n",
        "  '''\n",
        "  #this function is use to classifiy the future state based on the position of future value with the past range \n",
        "  #Put the value from the 2 boxes (max min) or (open close) on the time range  and check if it is within\n",
        "  #go down go up or exit the box\n",
        "  #the fucntion return 5 state depending on the future value position on the boxes and one state for error cases\n",
        "  '''\n",
        "\n",
        "  xpast_min=np.min(x[(indexforpast-tpastlag):indexforpast])\n",
        "  xpast_max=np.max(x[(indexforpast-tpastlag):indexforpast])\n",
        "  x_open=x[int(indexforpast-tpastlag)]\n",
        "  x_close=x[indexforpast]\n",
        "  \n",
        "  if (yfut < xpast_min ): return 0\n",
        "  elif  (yfut < min(x_open,x_close)): return 1\n",
        "  elif  (yfut < max(x_open,x_close)): return 2\n",
        "  elif  (yfut < xpast_max): return 3\n",
        "  elif  (yfut > xpast_max): return 4\n",
        "  else  : return -1\n",
        "\n",
        "def main_class_shortterm_returnfut(iterable):\n",
        "  return class_shortterm_returnfut(sp500close, iterable, pastlag,futlag)\n",
        "\n",
        "def normalise_df_image(xdf):\n",
        "  #normalisation to 0,1 range of the equity index\n",
        "  df_tmp=xdf\n",
        "  maxval=np.max(df_tmp)\n",
        "  df_tmp=df_tmp/maxval\n",
        "  return df_tmp, maxval\n",
        "\n",
        "def build_image(stockindex, idate=10, pastlag=10, futlag=3):\n",
        "  #another version of returning image from a data frame index\n",
        "  #using the pastlag as range for the graph\n",
        "  #ising idate as a starting point\n",
        "  #return a (32,32,3) np array\n",
        "\n",
        "  #number of days to consider for translate\n",
        "  sp500close=stockindex\n",
        "  x_datas=[]\n",
        "  x_datas=np.zeros((32,32,3))\n",
        "  i=idate\n",
        "  \n",
        "  fig=plt.figure()\n",
        "  ax=fig.add_subplot(111)\n",
        "  ax.plot(sp500close[(i-pastlag):i])\n",
        "  plot_img_np = get_img_from_fig(fig)\n",
        "  x_tmp= skimage.measure.block_reduce(plot_img_np[90:620,140:970], (18,28,1), np.mean)\n",
        "  (x_datas[1:-1])[:,1:-1][:]=x_tmp\n",
        "  fig.clear()\n",
        "  plt.close(fig)\n",
        "    \n",
        "  x_datas=x_datas/255\n",
        "  return x_datas\n",
        "\n",
        "def build_image_df(xdf, past_step,fut_step) :\n",
        "  '''\n",
        "  returning a dictionary of time series dataframes to be used in setup_input_NN_image so a to generate \n",
        "  Input X Result Y_StateClass, Y_FutPredict\n",
        "  pastlag as range for the graph\n",
        "  fut _step the future value lag in time to predict or to check the financial state of the market \n",
        "  #times series to get information from the stock index value\n",
        "  'stock_value':the time serie of the index normalised on the whole period\n",
        "  'moving_average':  time serie of the rolling moving average value of the index for past step image\n",
        "  \"max\": time serie of the rolling max  value of the index for past step image\n",
        "  \"min\": time serie of the rolling  min value of the index for past step image\n",
        "  'volatility':  time serie of the rolling  vol value of the index for past step image\n",
        "          \n",
        "  'df_x_image': is a time series of flattened (1, ) calculed from images (32, 32, 3) list \n",
        "  #I had to flatten it because panda does not create table with this format\n",
        "  'market_state': future markket state to be predicted time lag is futlag\n",
        "  'future_value': future value of stock price to predict  time lag is futlag\n",
        "  'future_volatility':  time serie of the future volatility of the index time lag is futlag\n",
        "  '''\n",
        "\n",
        "  df_stockvaluecorrected=xdf\n",
        "  df_stockvaluecorrected, _ = normalise_df_image(df_stockvaluecorrected)\n",
        "  df_pctchge = df_stockvaluecorrected.pct_change(periods=past_step)\n",
        "  df_movave = df_stockvaluecorrected.rolling(window=past_step).mean()\n",
        "  df_volaty = np.sqrt(252)*df_pctchge.rolling(window=past_step).std()\n",
        "  df_max =df_stockvaluecorrected.rolling(window=past_step).max()\n",
        "  df_min =df_stockvaluecorrected.rolling(window=past_step).min()\n",
        "  df_Fut_value =df_stockvaluecorrected.shift(periods=-fut_step)\n",
        "  df_Fut_value.name='future_value'\n",
        "  df_Fut_volaty =df_volaty.shift(periods=-fut_step)\n",
        "  \n",
        "  df_market_state=pd.DataFrame(index=df_stockvaluecorrected.index,columns=['market_state'],dtype=np.float64)\n",
        "  \n",
        "  tmpimage=build_image(df_stockvaluecorrected,past_step+1,pastlag=past_step,futlag=fut_step)\n",
        "  flatten_image=np.reshape(tmpimage,(1,-1))\n",
        "  colname_d_x_image_flattened = ['Image Col'+str(j) for j in range(flatten_image.shape[1])]\n",
        "\n",
        "  np_x_image=np.zeros((len(df_stockvaluecorrected.index),flatten_image.shape[1]))\n",
        "  \n",
        "  for i in range(len(df_stockvaluecorrected.index)):\n",
        "        yfut=df_Fut_value.iloc[i]\n",
        "        df_market_state.iloc[i]=class_shortterm_returnfut(df_stockvaluecorrected,yfut, i,tpastlag=past_step)\n",
        "        print(\"loop 1 market state :\", \"step \",i,\"market state fut\", df_market_state.iloc[i],\" future value\",df_Fut_value.iloc[i] )\n",
        "  df_market_state.index=df_Fut_value.index\n",
        "\n",
        "  fig=plt.figure()\n",
        "  '''\n",
        "  for i in range(len(df_stockvaluecorrected.index)):\n",
        "        try:\n",
        "          tmpimage=build_image_optimfig(fig, df_stockvaluecorrected,i,pastlag=past_step,futlag=fut_step)\n",
        "          np_x_image[i,:]=np.reshape(tmpimage,(1,-1))\n",
        "          print(\"loop 2 image :\", \"step \",i,\"market state fut\", df_market_state.iloc[i],\" future value\",df_Fut_value.iloc[i] )\n",
        "        except:\n",
        "           print(\"error at index\", i)\n",
        "  '''           \n",
        "  \n",
        "  def build_image_optimfig_simplified(i_index):\n",
        "    return build_image_optimfig(fig, df_stockvaluecorrected,i_index,pastlag=past_step,futlag=fut_step)\n",
        "\n",
        "  def quick_build_image_from_index(indexstart, index_end, np_x_image):\n",
        "        if (indexstart==index_end):\n",
        "            tmpimage=build_image_optimfig_simplified(indexstart)\n",
        "            np_x_image[indexstart,:]=np.reshape(tmpimage,(1,-1))\n",
        "            print(\"loop 2 image :\", \"step \",indexstart)\n",
        "        else :\n",
        "            i_split=indexstart+(index_end-indexstart)//2\n",
        "            quick_build_image_from_index(indexstart, i_split,np_x_image)\n",
        "            quick_build_image_from_index(i_split+1, index_end,np_x_image)\n",
        "\n",
        "  quick_build_image_from_index(0, len(df_stockvaluecorrected.index)-1, np_x_image)\n",
        "\n",
        "  df_x_image=pd.DataFrame(data=np_x_image,columns=colname_d_x_image_flattened, index=df_stockvaluecorrected.index)\n",
        "  fig.clear\n",
        "  plt.close(fig)\n",
        "\n",
        "\n",
        "  df_data= {\n",
        "          'stock_value': df_stockvaluecorrected, \n",
        "          'moving_average': df_movave, \n",
        "          \"max\": df_max, \n",
        "          \"min\": df_max,\n",
        "          'volatility': df_volaty,\n",
        "          'future_volatility': df_Fut_volaty,\n",
        "          \n",
        "          'df_x_image':df_x_image,\n",
        "          'market_state':df_market_state,\n",
        "          'future_value': df_Fut_value,\n",
        "\n",
        "          }\n",
        "\n",
        "  return df_data\n",
        "\n",
        "def build_image_clean(stockindex_ohlcv, ret_image_size=(32,32,3), idate=10, pastlag=32):\n",
        "  '''\n",
        "  TO BE COMPLETED\n",
        "  NOT USED NOW\n",
        "  \n",
        "  change one date into an array (32,32,3)\n",
        "  Each absciss pixel is one day\n",
        "  in ordinate the min value of ohlc shall be 0 (volume is tabled on the third image) \n",
        "  in ordinate the max value of ohlc shall be  (volume is tabled on the third image) \n",
        "  1st image: 32 x32\n",
        "    based on each day we place the open and close point\n",
        "    in ordinate int (255 * price /max ohlc)\n",
        "    with value of  255 for close and 127 for open\n",
        "  2nd image: 32 x32\n",
        "    based on each day we place the high low point \n",
        "    in ordinate int (255 * price /max ohlc)\n",
        "    with 64 for high and 32 for low\n",
        "  3rd image: 32 x32\n",
        "    each column value is a equal to int 255* volume of day / volume max period)\n",
        "  '''\n",
        "  #number of days to consider for translate\n",
        "  tsindexstock=stockindex_ohlcv.iloc[(idate-pastlag):idate]\n",
        "  valmax=np.max(np.array(tsindexstock[tsindexstock.columns[:-1]]))\n",
        "  valmin=np.min(np.array(tsindexstock[tsindexstock.columns[:-1]]))\n",
        "  vol=tsindexstock[tsindexstock.columns[-1]]\n",
        "  \n",
        "  x_datas=np.zeros(ret_image_size)\n",
        "  \n",
        "  return x_datas\n",
        "  \n",
        "def setup_input_NN_image(xdf, past_step=25,fut_step=5, split=0.8):\n",
        "  '''\n",
        "  this function the time serie of the index price \n",
        "  and generate the random dataset with split value from the whole time serie\n",
        "  X is a time serie of the flattened 32, 32 ,3 image list\n",
        "  Y_StateClass is a time serie of future state to predict with a classification made with class_shortterm_returnfut\n",
        "  Y_FutPredict is the time serie of stocke index shifted in time to be predicted\n",
        "  we randomize the dates and retun 2 set of dataframes\n",
        "  '''\n",
        "  xdf_data=build_image_df(xdf,past_step,fut_step)\n",
        "  \n",
        "  tmp_data=pd.concat([xdf_data['market_state'],xdf_data['future_value'],xdf_data['df_x_image']],axis=1)\n",
        "  tmp_data=tmp_data.dropna()\n",
        "\n",
        "  Y_StateClass= tmp_data['market_state']\n",
        "  Y_FutPredict= tmp_data['future_value']  \n",
        "  X=tmp_data.drop(columns=['market_state','future_value'])\n",
        "\n",
        "  nb_dates=len(Y_StateClass.index)\n",
        "  rng = np.random.default_rng()\n",
        "  list_shuffle = np.arange(nb_dates)\n",
        "  rng.shuffle(list_shuffle)\n",
        "  split_index=int(split*nb_dates)\n",
        "    \n",
        "  train_split=list_shuffle[:split_index]\n",
        "  test_split=list_shuffle[(split_index+1):]\n",
        "\n",
        "  X_train=(X.iloc[train_split])\n",
        "  Y_train_StateClass=(Y_StateClass.iloc[train_split])\n",
        "  Y_train_FutPredict=(Y_FutPredict.iloc[train_split])\n",
        "\n",
        "  X_test=(X.iloc[test_split])\n",
        "  Y_test_StateClass=(Y_StateClass.iloc[test_split])\n",
        "  Y_test_FutPredict=(Y_FutPredict.iloc[test_split])\n",
        "\n",
        "  return (X_train, Y_train_StateClass, Y_train_FutPredict), (X_test, Y_test_StateClass, Y_test_FutPredict)\n",
        "\n",
        "def change_X_df__nparray_image(df_X_train_image_flattened ):\n",
        "  '''\n",
        "  setup_input_NN_image returns a dataframe of flaten image for x train and xtest\n",
        "  then this function will change each date into a nparray list of images with 32, 32, 3 size \n",
        "  '''\n",
        "  X_train_image=df_X_train_image_flattened\n",
        "  nb_train=len(X_train_image.index)\n",
        "  \n",
        "  x_train=np.zeros((nb_train,32,32,3))\n",
        "  for i in range(nb_train):\n",
        "    tmp=np.array(X_train_image.iloc[i])\n",
        "    tmp=tmp.reshape(32,32,3)\n",
        "    x_train[i]=tmp\n",
        "  return x_train\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas_datareader/compat/__init__.py:7: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  from pandas.util.testing import assert_frame_equal\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0mY5OLZIymc_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def build_image_optimfig(fig, stockindex, idate=10, pastlag=10, futlag=3):\n",
        "  '''\n",
        "  #version of returning image from a data frame index\n",
        "  #using the pastlag as range for the graph\n",
        "  #ising idate as a starting point\n",
        "  #return a (32,32,3) np array\n",
        "  #this one is optimisng the use of ram \n",
        "  '''\n",
        "\n",
        "  #number of days to consider for translate\n",
        "  sp500close=stockindex\n",
        "  x_datas=[]\n",
        "  x_datas=np.zeros((255,255,3))\n",
        "  i=idate\n",
        "  \n",
        "  plt.plot(sp500close[(i-pastlag):i])\n",
        "  plot_img_np = get_img_from_fig(fig)\n",
        "  #x_tmp= skimage.measure.block_reduce(plot_img_np[90:620,140:970], (18,28,1), np.mean)\n",
        "  x_tmp= skimage.measure.block_reduce(plot_img_np[90:620,140:970], (2,3,1), np.mean)\n",
        "  (x_datas[:])[:,:][:]=(x_tmp[5:-5])[:,11:-11][:]\n",
        "    \n",
        "  x_datas=x_datas/255\n",
        "  return x_datas     \n"
      ],
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zcNAYR-zbLoS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "469e2502-1049-425f-9fcf-73fd45c84fd9"
      },
      "source": [
        " fig=plt.figure()\n",
        "x_image_test=build_image_optimfig(fig, testsp500, idate=10, pastlag=10, futlag=3)\n",
        "x_image_test.shape"
      ],
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(255, 255, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 138
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CPITIKnfapXp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a7c9b892-a33b-4e61-97f8-44b620b3bca0"
      },
      "source": [
        ""
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(32, 32, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OyzAFCoi0hFD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f40d43a6-f5fb-476d-bf6d-68366b2a86c7"
      },
      "source": [
        "#https://www.machinelearningplus.com/python/parallel-processing-python/\n",
        "import multiprocessing as mp\n",
        "print(\"Number of processors: \", mp.cpu_count())"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of processors:  2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZLYbyEmwBwF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "56840eed-1a7a-4a37-bac0-1c295c8d5738"
      },
      "source": [
        "\n",
        "'''\n",
        "COMMAND NOW FOR THE DATSET GENERATION\n",
        "'''\n",
        "\n",
        "#Recuperation from yahoo of sp500 large history\n",
        "start = datetime(1920,1,1)\n",
        "end = datetime(2020,7,31)\n",
        "yf.pdr_override() # <== that's all it takes :-)\n",
        "sp500 = pdr.get_data_yahoo('^GSPC', \n",
        "                           start,\n",
        "                             end)\n",
        "\n",
        "#generate the dataset it can take 6 - 8 hours\n",
        "#Need to be optimzed with more time\n",
        "testsp500=(sp500['Close'])[21002:]\n"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[*********************100%***********************]  1 of 1 downloaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gj6vLE8IbxV1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(X_train_image, Y_train_StateClass_image, Y_train_FutPredict_image) , (X_test_image, Y_test_StateClass_image, Y_test_FutPredict_image) = setup_input_NN_image(testsp500)\n",
        "\n",
        "#copy the datafrae dataset in csv format to be used after\n",
        "#dateTimeObj = datetime.now()\n",
        "#timeStr = dateTimeObj.strftime(\"%Y_%m_%d_%H_%M_%S_%f\")\n",
        "\n",
        "X_train_image.to_csv('datas/X_train_image4.csv')\n",
        "Y_train_StateClass_image.to_csv('datas/Y_train_StateClass_image4.csv')\n",
        "Y_train_FutPredict_image.to_csv('datas/Y_train_FutPredict_image4.csv')\n",
        "\n",
        "X_test_image.to_csv('datas/X_test_image4.csv')\n",
        "Y_test_StateClass_image.to_csv('datas/Y_test_StateClass_image4.csv')\n",
        "Y_test_FutPredict_image.to_csv('datas/Y_test_FutPredict_image4.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V_QcOSjqMHSy",
        "colab_type": "text"
      },
      "source": [
        "##Step 2: Loading training datas with vgg16 transfert model and training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R98_pBo02L2-",
        "colab_type": "text"
      },
      "source": [
        "####List of model utilisation of main example resnet \n",
        "https://towardsdatascience.com/understanding-and-coding-a-resnet-in-keras-446d7ff84d33"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fI7gHLdU15Bb",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "![1_NdCntZms6S2pBmQ3j_wyuw.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1R3sN7G1IWIK",
        "colab_type": "text"
      },
      "source": [
        "####Loading and Cleaning Training Datas "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MTfVYoKBaQzZ",
        "colab_type": "text"
      },
      "source": [
        "This part is for loading the training dataset as it is better to generate it once for all in step 1 because of it time consuming process.\n",
        "\n",
        "This part also configure back the X_train datas from dataframe based on columns to a (32,32,3) np. array for the input of the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zqU-LK4JTEOM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f4e7a4e8-e4fb-4dfd-f387-93a58ee1b1f2"
      },
      "source": [
        "%pwd"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/My Drive/A_transfertTFMresnetSP500'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jp0_855PpN3S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2ddcc167-0b3e-42db-b7a2-d34496a2fc31"
      },
      "source": [
        "%cd /content/DL_Tools_For_Finance\n",
        "\n",
        "import numpy as np\n",
        "import pylab as plt\n",
        "import pandas as pd\n",
        "\n",
        "from keras.datasets import cifar10\n",
        "from keras.utils import np_utils\n",
        "from keras.models import Sequential\n",
        "from keras import optimizers\n",
        "from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
        "from keras.layers import Dropout, Flatten, GlobalAveragePooling2D\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "'''\n",
        "UTILITY FUNCTIONS\n",
        "'''\n",
        "\n",
        "def change_X_df__nparray_image(df_X_train_image_flattened ):\n",
        "  '''\n",
        "  setup_input_NN_image returns a dataframe of flaten image for x train and xtest\n",
        "  then this function will change each date into a nparray list of images with 32, 32, 3 size \n",
        "  '''\n",
        "  X_train_image=df_X_train_image_flattened\n",
        "  nb_train=len(X_train_image.index)\n",
        "  \n",
        "  x_train=np.zeros((nb_train,32,32,3))\n",
        "  for i in range(nb_train):\n",
        "    tmp=np.array(X_train_image.iloc[i])\n",
        "    tmp=tmp.reshape(32,32,3)\n",
        "    x_train[i]=tmp\n",
        "  return x_train\n",
        "\n",
        "'''\n",
        "MAIN EXECUTIONS\n",
        "'''\n",
        "#recuperation of datas \n",
        "X_train_image=pd.read_csv('datas/X_train_image.csv')\n",
        "Y_train_StateClass_image=pd.read_csv('datas/Y_train_StateClass_image.csv')\n",
        "Y_train_FutPredict_image=pd.read_csv('datas/Y_train_FutPredict_image.csv')\n",
        "\n",
        "\n",
        "#setting up the index to Date\n",
        "X_train_image=X_train_image.set_index(\"Date\")\n",
        "Y_train_StateClass_image=Y_train_StateClass_image.set_index(\"Date\")\n",
        "Y_train_FutPredict_image=Y_train_FutPredict_image.set_index(\"Date\")\n",
        "\n",
        "#modify dataset to np array for input to NN\n",
        "x_train=change_X_df__nparray_image(X_train_image)\n",
        "y_train_state=np.array(Y_train_StateClass_image)\n",
        "y_train_value=np.array(Y_train_FutPredict_image)\n",
        "\n",
        "##Setting up xtrain and ytrain\n",
        "#Here we focus on predicting the future state Y_train_StateClass_image\n",
        "nb_train=len(X_train_image.index)\n",
        "x_train=np.zeros((nb_train,32,32,3))\n",
        "for i in range(nb_train):\n",
        "  tmp=np.array(X_train_image.iloc[i])\n",
        "  tmp=tmp.reshape(32,32,3)\n",
        "  x_train[i]=tmp\n",
        "  \n",
        "y_train=np.array(Y_train_StateClass_image)\n",
        "#y_train=np.array(Y_train_FutPredict_image)\n",
        "\n",
        "nb_train=len(X_train_image.index)\n",
        "x_train=np.zeros((nb_train,32,32,3))\n",
        "for i in range(nb_train):\n",
        "  tmp=np.array(X_train_image.iloc[i])\n",
        "  tmp=tmp.reshape(32,32,3)\n",
        "  x_train[i]=tmp\n",
        "\n",
        "y_train=np.array(Y_train_StateClass_image)\n",
        "#y_train=np.array(Y_train_FutPredict_image)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/DL_Tools_For_Finance\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OiGYdJFX-aEC",
        "colab_type": "text"
      },
      "source": [
        "Now we check the datas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fwiNBaTN-Ufq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "4cd5a6af-6f2b-422a-e535-0cad1bddf1ca"
      },
      "source": [
        "print(\"number of train datas\",len(y_train))\n",
        "print(\"number of dates actual\",len(y_train))\n",
        "print(\"shape of y and x train\", y_train.shape, \" and \", x_train.shape)\n",
        "print(\"min value of datas\", np.min(y_train), \", max value of datas\",np.max(y_train))"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of train datas 18580\n",
            "number of dates actual 18580\n",
            "shape of y and x train (18580, 1)  and  (18580, 32, 32, 3)\n",
            "min value of datas -1.0 , max value of datas 4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ewhz7vXwxzf4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "f8cd89cc-224e-4acc-970c-43bb39bdaa7c"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig2 = plt.figure(figsize=(10, 6))\n",
        "x_datas=x_train[np.random.randint(low=10,high=1000,size=8)]\n",
        "for i in range(0,8,1):\n",
        "    img = x_datas[i][:-1][:-1]\n",
        "    fig2.add_subplot(2, 4, i+1)\n",
        "    plt.imshow(img)\n",
        "\n",
        "\n",
        "print('Shape of each image in the training data: ', x_datas.shape[:])"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of each image in the training data:  (8, 32, 32, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x432 with 8 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6Z8846EWC3F",
        "colab_type": "text"
      },
      "source": [
        "####Build up and training of the NN model "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tbRtrFYtaDI5",
        "colab_type": "text"
      },
      "source": [
        "In this part we suppose that we have the training dataset taken from step 2. We use a Transfert model for vgg16 and some other layers. we use for this example a categorical_crossentropy loss and rmsprop optimizer. This part can be fined tuned for each financial index or stock index (layers, optimmizer, metrics, dropout) but in this case we introduced a simplier case. We train and save the model, please refer to XX to see the convergence of the model.\n",
        "\n",
        "We have 14.7M parameters and 66k trainable parametres. the size of training input is 571M only for the image not including rolling volatility, moving average etc\n",
        "\n",
        "NB: If you have an error on size of input of the ytrain you have to reload the input executing  step 2 once again"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gTHxq8RVg-vE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pylab as plt\n",
        "import pandas as pd\n",
        "\n",
        "from keras.utils import np_utils\n",
        "from keras.models import Sequential, Model\n",
        "from keras import optimizers\n",
        "from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
        "from keras.layers import Dropout, Flatten, GlobalAveragePooling2D\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras import applications\n",
        "\n",
        "from datetime import datetime\n",
        "from packaging import version\n",
        "import tensorboard\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-aVAzmKU9t8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "99551224-3b1a-4400-b57d-a59a533cc0fd"
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(18580, 32, 32, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-2BAtxzmPpe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "c7a15e80-ae42-4855-ba7e-06618763406a"
      },
      "source": [
        "'''\n",
        "PARAMETERS to change so as to improve the training\n",
        "'''\n",
        "\n",
        "#We can modify batch size and epochs to adjust improve the training\n",
        "batch_size=64\n",
        "epochs=5\n",
        "sp500_learning_rate=0.001\n",
        "\n",
        "#Use of exponential decay for learning rate\n",
        "#https://keras.io/api/optimizers/learning_rate_schedules/exponential_decay/\n",
        "\n",
        "lr_schedule = sp500_learning_rate  #or lr_scheduleExp\n",
        "\n",
        "sp500_decay_rate=0.90\n",
        "\n",
        "\n",
        "lr_scheduleExp = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "    sp500_learning_rate,\n",
        "    decay_steps=100,\n",
        "    decay_rate=vggsp500_decay_rate,\n",
        "    staircase=True)\n",
        "\n",
        "##https://keras.io/api/losses/\n",
        "sp500loss='categorical_crossentropy'                                 \n",
        "\n",
        "##https://keras.io/api/optimizers/\n",
        "sp500optimizer_name='Adam'\n",
        "sp500optimizer=keras.optimizers.Adam(learning_rate=lr_schedule)  \n",
        "\n",
        "##https://keras.io/api/metrics/\n",
        "sp500metrics=['accuracy']                                           \n",
        "\n",
        "\n",
        "\n",
        "'''\n",
        "model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=lr_schedule),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(data, labels, epochs=5)\n",
        "'''"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\nmodel.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=lr_schedule),\\n              loss='sparse_categorical_crossentropy',\\n              metrics=['accuracy'])\\n\\nmodel.fit(data, labels, epochs=5)\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7cRVj5gY5R3E",
        "colab_type": "text"
      },
      "source": [
        "###Version with resnet\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vw_E83udAoLa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "87dda025-7131-4d02-af71-a715eb0054a3"
      },
      "source": [
        "transfer_model.summary()"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_20 (InputLayer)           [(None, 32, 32, 3)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)       (None, 38, 38, 3)    0           input_20[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv1_conv (Conv2D)             (None, 16, 16, 64)   9472        conv1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1_bn (BatchNormalization)   (None, 16, 16, 64)   256         conv1_conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1_relu (Activation)         (None, 16, 16, 64)   0           conv1_bn[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pad (ZeroPadding2D)       (None, 18, 18, 64)   0           conv1_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pool (MaxPooling2D)       (None, 8, 8, 64)     0           pool1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_conv (Conv2D)    (None, 8, 8, 64)     4160        pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_relu (Activation (None, 8, 8, 64)     0           conv2_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_relu (Activation (None, 8, 8, 64)     0           conv2_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_conv (Conv2D)    (None, 8, 8, 256)    16640       pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_add (Add)          (None, 8, 8, 256)    0           conv2_block1_0_bn[0][0]          \n",
            "                                                                 conv2_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_out (Activation)   (None, 8, 8, 256)    0           conv2_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_relu (Activation (None, 8, 8, 64)     0           conv2_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_relu (Activation (None, 8, 8, 64)     0           conv2_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_add (Add)          (None, 8, 8, 256)    0           conv2_block1_out[0][0]           \n",
            "                                                                 conv2_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_out (Activation)   (None, 8, 8, 256)    0           conv2_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_relu (Activation (None, 8, 8, 64)     0           conv2_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_relu (Activation (None, 8, 8, 64)     0           conv2_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_add (Add)          (None, 8, 8, 256)    0           conv2_block2_out[0][0]           \n",
            "                                                                 conv2_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_out (Activation)   (None, 8, 8, 256)    0           conv2_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_conv (Conv2D)    (None, 4, 4, 128)    32896       conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_relu (Activation (None, 4, 4, 128)    0           conv3_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_relu (Activation (None, 4, 4, 128)    0           conv3_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_conv (Conv2D)    (None, 4, 4, 512)    131584      conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_add (Add)          (None, 4, 4, 512)    0           conv3_block1_0_bn[0][0]          \n",
            "                                                                 conv3_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_out (Activation)   (None, 4, 4, 512)    0           conv3_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_relu (Activation (None, 4, 4, 128)    0           conv3_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_relu (Activation (None, 4, 4, 128)    0           conv3_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_add (Add)          (None, 4, 4, 512)    0           conv3_block1_out[0][0]           \n",
            "                                                                 conv3_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_out (Activation)   (None, 4, 4, 512)    0           conv3_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_relu (Activation (None, 4, 4, 128)    0           conv3_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_relu (Activation (None, 4, 4, 128)    0           conv3_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_add (Add)          (None, 4, 4, 512)    0           conv3_block2_out[0][0]           \n",
            "                                                                 conv3_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_out (Activation)   (None, 4, 4, 512)    0           conv3_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_relu (Activation (None, 4, 4, 128)    0           conv3_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_relu (Activation (None, 4, 4, 128)    0           conv3_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_add (Add)          (None, 4, 4, 512)    0           conv3_block3_out[0][0]           \n",
            "                                                                 conv3_block4_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_out (Activation)   (None, 4, 4, 512)    0           conv3_block4_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_conv (Conv2D)    (None, 2, 2, 256)    131328      conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_relu (Activation (None, 2, 2, 256)    0           conv4_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_relu (Activation (None, 2, 2, 256)    0           conv4_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_conv (Conv2D)    (None, 2, 2, 1024)   525312      conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_0_bn[0][0]          \n",
            "                                                                 conv4_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_out (Activation)   (None, 2, 2, 1024)   0           conv4_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_relu (Activation (None, 2, 2, 256)    0           conv4_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_relu (Activation (None, 2, 2, 256)    0           conv4_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_out[0][0]           \n",
            "                                                                 conv4_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_out (Activation)   (None, 2, 2, 1024)   0           conv4_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_relu (Activation (None, 2, 2, 256)    0           conv4_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_relu (Activation (None, 2, 2, 256)    0           conv4_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_add (Add)          (None, 2, 2, 1024)   0           conv4_block2_out[0][0]           \n",
            "                                                                 conv4_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_out (Activation)   (None, 2, 2, 1024)   0           conv4_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_relu (Activation (None, 2, 2, 256)    0           conv4_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_relu (Activation (None, 2, 2, 256)    0           conv4_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_add (Add)          (None, 2, 2, 1024)   0           conv4_block3_out[0][0]           \n",
            "                                                                 conv4_block4_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_out (Activation)   (None, 2, 2, 1024)   0           conv4_block4_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_relu (Activation (None, 2, 2, 256)    0           conv4_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_relu (Activation (None, 2, 2, 256)    0           conv4_block5_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block5_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block5_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_add (Add)          (None, 2, 2, 1024)   0           conv4_block4_out[0][0]           \n",
            "                                                                 conv4_block5_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_out (Activation)   (None, 2, 2, 1024)   0           conv4_block5_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block5_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_relu (Activation (None, 2, 2, 256)    0           conv4_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_relu (Activation (None, 2, 2, 256)    0           conv4_block6_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block6_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block6_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_add (Add)          (None, 2, 2, 1024)   0           conv4_block5_out[0][0]           \n",
            "                                                                 conv4_block6_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_out (Activation)   (None, 2, 2, 1024)   0           conv4_block6_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_conv (Conv2D)    (None, 1, 1, 512)    524800      conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_relu (Activation (None, 1, 1, 512)    0           conv5_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_relu (Activation (None, 1, 1, 512)    0           conv5_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_conv (Conv2D)    (None, 1, 1, 2048)   2099200     conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_0_bn[0][0]          \n",
            "                                                                 conv5_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_out (Activation)   (None, 1, 1, 2048)   0           conv5_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_relu (Activation (None, 1, 1, 512)    0           conv5_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_relu (Activation (None, 1, 1, 512)    0           conv5_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_out[0][0]           \n",
            "                                                                 conv5_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_out (Activation)   (None, 1, 1, 2048)   0           conv5_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_relu (Activation (None, 1, 1, 512)    0           conv5_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_relu (Activation (None, 1, 1, 512)    0           conv5_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_add (Add)          (None, 1, 1, 2048)   0           conv5_block2_out[0][0]           \n",
            "                                                                 conv5_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_out (Activation)   (None, 1, 1, 2048)   0           conv5_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_3 (Glo (None, 2048)         0           conv5_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dropout_19 (Dropout)            (None, 2048)         0           global_average_pooling2d_3[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "dense_34 (Dense)                (None, 6)            12294       dropout_19[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 23,600,006\n",
            "Trainable params: 23,546,886\n",
            "Non-trainable params: 53,120\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9dBDC-Pb5Vi1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b5d106d2-d402-451c-8778-dd79eca040a2"
      },
      "source": [
        "%cd /content/drive/My Drive/A_transfertTFMresnetSP500\n",
        "\n",
        "'''\n",
        "PART 3 Resnet TRAINING AND SAVING\n",
        "we suppose that we have loaded xtrain and ytrain\n",
        "This part is based on the Design of the NN\n",
        "Her we find the  quite usefull\n",
        "'''\n",
        "\n",
        "#Importing the resnet model\n",
        "from keras.applications.resnet import ResNet50, preprocess_input\n",
        "\n",
        "#In our example we need to y into categorical as it has 6 categories\n",
        "nb_classes=6\n",
        "y_train = np_utils.to_categorical(y_train, nb_classes)\n",
        "\n",
        "\n",
        "#Loading the resnet16 model with pre-trained ImageNet weights\n",
        "resnet_model = ResNet50(weights=None, include_top=False, input_shape=(32, 32, 3))\n",
        "resnet_model.trainable = False # remove if you want to retrain resnet weights\n",
        "\n",
        "resnet_model.summary()\n",
        "\n",
        "\n",
        "##Transfert model from resnet\n",
        "transfer_model = Sequential()\n",
        "transfer_model.add(resnet_model)\n",
        "transfer_model.add(Flatten())\n",
        "transfer_model.add(Dense(128, activation='relu'))\n",
        "transfer_model.add(Dropout(0.7))\n",
        "transfer_model.add(Dense(6, activation='softmax'))\n",
        "\n",
        "\n",
        "#Transfert model 2\n",
        "img_height,img_width=32,32\n",
        "num_classes=6\n",
        "base_model = applications.resnet50.ResNet50(weights= None, include_top=False, input_shape= (img_height,img_width,3))\n",
        "\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dropout(0.7)(x)\n",
        "predictions = Dense(num_classes, activation= 'softmax')(x)\n",
        "transfer_model = Model(inputs = base_model.input, outputs = predictions)\n",
        "\n",
        "###compilation model\n",
        "\n",
        "transfer_model.compile(loss=sp500loss, optimizer=sp500optimizer,\n",
        "              metrics=sp500metrics)\n",
        "\n",
        "#Save initial weight to reinitialize it after when we trying to find the best set of parameters\n",
        "transfer_model.save_weights('model/initial_weights.h5')\n",
        "#model.load_weights('my_model_weights.h5'\n",
        "\n",
        "##Saving the best model for each parameters\n",
        "checkpoint = ModelCheckpoint(\"model/best_model\"+sp500loss+\"_\"+sp500optimizer_name+\"_Batch\"+\\\n",
        "                             str(batch_size)+\"_LR\"+str(sp500_learning_rate)+\"_\"+str(sp500_decay_rate)+\".hdf5\", \\\n",
        "                                monitor='loss', verbose=1, \\\n",
        "                                save_best_only=True, mode='auto', period=1)\n",
        "\n",
        "# Load the TensorBoard notebook extension.\n",
        "%load_ext tensorboard\n",
        "#!rm -rf ./logs/ \n",
        "\n",
        " # Define the Keras TensorBoard callback.\n",
        "logdir=\"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir, histogram_freq=1)\n",
        "\n",
        "##Fitting the model on the train data and labels.\n",
        "#reinitialise xtrain, ytrain to avoid change of type from np.array to tensor by keras\n",
        "m_x_train=x_train\n",
        "m_y_train=y_train\n",
        "\n",
        "history = transfer_model.fit(m_x_train, m_y_train, \\\n",
        "                              batch_size=batch_size, epochs=epochs, \\\n",
        "                              validation_split=0.2, verbose=1, shuffle=True, \\\n",
        "                              callbacks=[checkpoint, tensorboard_callback])\n",
        "\n",
        "# Saving themodel\n",
        "transfer_model.save('model/resnetforsp500.h5')\n",
        "\n",
        "#Display the graph of the model\n",
        "tf.keras.utils.plot_model(transfer_model)\n",
        "\n",
        "##Display summary of neural network\n",
        "transfer_model.summary()"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/A_transfertTFMresnetSP500\n",
            "Model: \"resnet50\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_21 (InputLayer)           [(None, 32, 32, 3)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)       (None, 38, 38, 3)    0           input_21[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv1_conv (Conv2D)             (None, 16, 16, 64)   9472        conv1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1_bn (BatchNormalization)   (None, 16, 16, 64)   256         conv1_conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1_relu (Activation)         (None, 16, 16, 64)   0           conv1_bn[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pad (ZeroPadding2D)       (None, 18, 18, 64)   0           conv1_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pool (MaxPooling2D)       (None, 8, 8, 64)     0           pool1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_conv (Conv2D)    (None, 8, 8, 64)     4160        pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_relu (Activation (None, 8, 8, 64)     0           conv2_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_relu (Activation (None, 8, 8, 64)     0           conv2_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_conv (Conv2D)    (None, 8, 8, 256)    16640       pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_add (Add)          (None, 8, 8, 256)    0           conv2_block1_0_bn[0][0]          \n",
            "                                                                 conv2_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_out (Activation)   (None, 8, 8, 256)    0           conv2_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_relu (Activation (None, 8, 8, 64)     0           conv2_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_relu (Activation (None, 8, 8, 64)     0           conv2_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_add (Add)          (None, 8, 8, 256)    0           conv2_block1_out[0][0]           \n",
            "                                                                 conv2_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_out (Activation)   (None, 8, 8, 256)    0           conv2_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_relu (Activation (None, 8, 8, 64)     0           conv2_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_relu (Activation (None, 8, 8, 64)     0           conv2_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_add (Add)          (None, 8, 8, 256)    0           conv2_block2_out[0][0]           \n",
            "                                                                 conv2_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_out (Activation)   (None, 8, 8, 256)    0           conv2_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_conv (Conv2D)    (None, 4, 4, 128)    32896       conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_relu (Activation (None, 4, 4, 128)    0           conv3_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_relu (Activation (None, 4, 4, 128)    0           conv3_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_conv (Conv2D)    (None, 4, 4, 512)    131584      conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_add (Add)          (None, 4, 4, 512)    0           conv3_block1_0_bn[0][0]          \n",
            "                                                                 conv3_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_out (Activation)   (None, 4, 4, 512)    0           conv3_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_relu (Activation (None, 4, 4, 128)    0           conv3_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_relu (Activation (None, 4, 4, 128)    0           conv3_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_add (Add)          (None, 4, 4, 512)    0           conv3_block1_out[0][0]           \n",
            "                                                                 conv3_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_out (Activation)   (None, 4, 4, 512)    0           conv3_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_relu (Activation (None, 4, 4, 128)    0           conv3_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_relu (Activation (None, 4, 4, 128)    0           conv3_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_add (Add)          (None, 4, 4, 512)    0           conv3_block2_out[0][0]           \n",
            "                                                                 conv3_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_out (Activation)   (None, 4, 4, 512)    0           conv3_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_relu (Activation (None, 4, 4, 128)    0           conv3_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_relu (Activation (None, 4, 4, 128)    0           conv3_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_add (Add)          (None, 4, 4, 512)    0           conv3_block3_out[0][0]           \n",
            "                                                                 conv3_block4_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_out (Activation)   (None, 4, 4, 512)    0           conv3_block4_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_conv (Conv2D)    (None, 2, 2, 256)    131328      conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_relu (Activation (None, 2, 2, 256)    0           conv4_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_relu (Activation (None, 2, 2, 256)    0           conv4_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_conv (Conv2D)    (None, 2, 2, 1024)   525312      conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_0_bn[0][0]          \n",
            "                                                                 conv4_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_out (Activation)   (None, 2, 2, 1024)   0           conv4_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_relu (Activation (None, 2, 2, 256)    0           conv4_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_relu (Activation (None, 2, 2, 256)    0           conv4_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_out[0][0]           \n",
            "                                                                 conv4_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_out (Activation)   (None, 2, 2, 1024)   0           conv4_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_relu (Activation (None, 2, 2, 256)    0           conv4_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_relu (Activation (None, 2, 2, 256)    0           conv4_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_add (Add)          (None, 2, 2, 1024)   0           conv4_block2_out[0][0]           \n",
            "                                                                 conv4_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_out (Activation)   (None, 2, 2, 1024)   0           conv4_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_relu (Activation (None, 2, 2, 256)    0           conv4_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_relu (Activation (None, 2, 2, 256)    0           conv4_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_add (Add)          (None, 2, 2, 1024)   0           conv4_block3_out[0][0]           \n",
            "                                                                 conv4_block4_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_out (Activation)   (None, 2, 2, 1024)   0           conv4_block4_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_relu (Activation (None, 2, 2, 256)    0           conv4_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_relu (Activation (None, 2, 2, 256)    0           conv4_block5_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block5_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block5_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_add (Add)          (None, 2, 2, 1024)   0           conv4_block4_out[0][0]           \n",
            "                                                                 conv4_block5_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_out (Activation)   (None, 2, 2, 1024)   0           conv4_block5_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block5_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_relu (Activation (None, 2, 2, 256)    0           conv4_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_relu (Activation (None, 2, 2, 256)    0           conv4_block6_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block6_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block6_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_add (Add)          (None, 2, 2, 1024)   0           conv4_block5_out[0][0]           \n",
            "                                                                 conv4_block6_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_out (Activation)   (None, 2, 2, 1024)   0           conv4_block6_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_conv (Conv2D)    (None, 1, 1, 512)    524800      conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_relu (Activation (None, 1, 1, 512)    0           conv5_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_relu (Activation (None, 1, 1, 512)    0           conv5_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_conv (Conv2D)    (None, 1, 1, 2048)   2099200     conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_0_bn[0][0]          \n",
            "                                                                 conv5_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_out (Activation)   (None, 1, 1, 2048)   0           conv5_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_relu (Activation (None, 1, 1, 512)    0           conv5_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_relu (Activation (None, 1, 1, 512)    0           conv5_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_out[0][0]           \n",
            "                                                                 conv5_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_out (Activation)   (None, 1, 1, 2048)   0           conv5_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_relu (Activation (None, 1, 1, 512)    0           conv5_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_relu (Activation (None, 1, 1, 512)    0           conv5_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_add (Add)          (None, 1, 1, 2048)   0           conv5_block2_out[0][0]           \n",
            "                                                                 conv5_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_out (Activation)   (None, 1, 1, 2048)   0           conv5_block3_add[0][0]           \n",
            "==================================================================================================\n",
            "Total params: 23,587,712\n",
            "Trainable params: 0\n",
            "Non-trainable params: 23,587,712\n",
            "__________________________________________________________________________________________________\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "The tensorboard extension is already loaded. To reload it, use:\n",
            "  %reload_ext tensorboard\n",
            "Epoch 1/5\n",
            "233/233 [==============================] - ETA: 0s - loss: 3.1298 - accuracy: 0.2633\n",
            "Epoch 00001: loss improved from inf to 3.12980, saving model to model/best_modelcategorical_crossentropy_Adam_Batch64_LR0.001_0.9.hdf5\n",
            "233/233 [==============================] - 1057s 5s/step - loss: 3.1298 - accuracy: 0.2633 - val_loss: 2.8547 - val_accuracy: 0.3022\n",
            "Epoch 2/5\n",
            "233/233 [==============================] - ETA: 0s - loss: 2.1033 - accuracy: 0.3033\n",
            "Epoch 00002: loss improved from 3.12980 to 2.10330, saving model to model/best_modelcategorical_crossentropy_Adam_Batch64_LR0.001_0.9.hdf5\n",
            "233/233 [==============================] - 1060s 5s/step - loss: 2.1033 - accuracy: 0.3033 - val_loss: 2.0254 - val_accuracy: 0.3399\n",
            "Epoch 3/5\n",
            "233/233 [==============================] - ETA: 0s - loss: 2.0591 - accuracy: 0.3144\n",
            "Epoch 00003: loss improved from 2.10330 to 2.05908, saving model to model/best_modelcategorical_crossentropy_Adam_Batch64_LR0.001_0.9.hdf5\n",
            "233/233 [==============================] - 1058s 5s/step - loss: 2.0591 - accuracy: 0.3144 - val_loss: 2.0103 - val_accuracy: 0.2896\n",
            "Epoch 4/5\n",
            "233/233 [==============================] - ETA: 0s - loss: 1.9791 - accuracy: 0.3219\n",
            "Epoch 00004: loss improved from 2.05908 to 1.97908, saving model to model/best_modelcategorical_crossentropy_Adam_Batch64_LR0.001_0.9.hdf5\n",
            "233/233 [==============================] - 1050s 5s/step - loss: 1.9791 - accuracy: 0.3219 - val_loss: 2.3768 - val_accuracy: 0.3385\n",
            "Epoch 5/5\n",
            "233/233 [==============================] - ETA: 0s - loss: 1.9411 - accuracy: 0.3229\n",
            "Epoch 00005: loss improved from 1.97908 to 1.94115, saving model to model/best_modelcategorical_crossentropy_Adam_Batch64_LR0.001_0.9.hdf5\n",
            "233/233 [==============================] - 1044s 4s/step - loss: 1.9411 - accuracy: 0.3229 - val_loss: 1.5205 - val_accuracy: 0.3022\n",
            "Model: \"functional_5\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_22 (InputLayer)           [(None, 32, 32, 3)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)       (None, 38, 38, 3)    0           input_22[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv1_conv (Conv2D)             (None, 16, 16, 64)   9472        conv1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1_bn (BatchNormalization)   (None, 16, 16, 64)   256         conv1_conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1_relu (Activation)         (None, 16, 16, 64)   0           conv1_bn[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pad (ZeroPadding2D)       (None, 18, 18, 64)   0           conv1_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pool (MaxPooling2D)       (None, 8, 8, 64)     0           pool1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_conv (Conv2D)    (None, 8, 8, 64)     4160        pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_relu (Activation (None, 8, 8, 64)     0           conv2_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_relu (Activation (None, 8, 8, 64)     0           conv2_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_conv (Conv2D)    (None, 8, 8, 256)    16640       pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_add (Add)          (None, 8, 8, 256)    0           conv2_block1_0_bn[0][0]          \n",
            "                                                                 conv2_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_out (Activation)   (None, 8, 8, 256)    0           conv2_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_relu (Activation (None, 8, 8, 64)     0           conv2_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_relu (Activation (None, 8, 8, 64)     0           conv2_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_add (Add)          (None, 8, 8, 256)    0           conv2_block1_out[0][0]           \n",
            "                                                                 conv2_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_out (Activation)   (None, 8, 8, 256)    0           conv2_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_relu (Activation (None, 8, 8, 64)     0           conv2_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_relu (Activation (None, 8, 8, 64)     0           conv2_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_add (Add)          (None, 8, 8, 256)    0           conv2_block2_out[0][0]           \n",
            "                                                                 conv2_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_out (Activation)   (None, 8, 8, 256)    0           conv2_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_conv (Conv2D)    (None, 4, 4, 128)    32896       conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_relu (Activation (None, 4, 4, 128)    0           conv3_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_relu (Activation (None, 4, 4, 128)    0           conv3_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_conv (Conv2D)    (None, 4, 4, 512)    131584      conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_add (Add)          (None, 4, 4, 512)    0           conv3_block1_0_bn[0][0]          \n",
            "                                                                 conv3_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_out (Activation)   (None, 4, 4, 512)    0           conv3_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_relu (Activation (None, 4, 4, 128)    0           conv3_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_relu (Activation (None, 4, 4, 128)    0           conv3_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_add (Add)          (None, 4, 4, 512)    0           conv3_block1_out[0][0]           \n",
            "                                                                 conv3_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_out (Activation)   (None, 4, 4, 512)    0           conv3_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_relu (Activation (None, 4, 4, 128)    0           conv3_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_relu (Activation (None, 4, 4, 128)    0           conv3_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_add (Add)          (None, 4, 4, 512)    0           conv3_block2_out[0][0]           \n",
            "                                                                 conv3_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_out (Activation)   (None, 4, 4, 512)    0           conv3_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_relu (Activation (None, 4, 4, 128)    0           conv3_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_relu (Activation (None, 4, 4, 128)    0           conv3_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_add (Add)          (None, 4, 4, 512)    0           conv3_block3_out[0][0]           \n",
            "                                                                 conv3_block4_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_out (Activation)   (None, 4, 4, 512)    0           conv3_block4_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_conv (Conv2D)    (None, 2, 2, 256)    131328      conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_relu (Activation (None, 2, 2, 256)    0           conv4_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_relu (Activation (None, 2, 2, 256)    0           conv4_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_conv (Conv2D)    (None, 2, 2, 1024)   525312      conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_0_bn[0][0]          \n",
            "                                                                 conv4_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_out (Activation)   (None, 2, 2, 1024)   0           conv4_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_relu (Activation (None, 2, 2, 256)    0           conv4_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_relu (Activation (None, 2, 2, 256)    0           conv4_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_out[0][0]           \n",
            "                                                                 conv4_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_out (Activation)   (None, 2, 2, 1024)   0           conv4_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_relu (Activation (None, 2, 2, 256)    0           conv4_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_relu (Activation (None, 2, 2, 256)    0           conv4_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_add (Add)          (None, 2, 2, 1024)   0           conv4_block2_out[0][0]           \n",
            "                                                                 conv4_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_out (Activation)   (None, 2, 2, 1024)   0           conv4_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_relu (Activation (None, 2, 2, 256)    0           conv4_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_relu (Activation (None, 2, 2, 256)    0           conv4_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_add (Add)          (None, 2, 2, 1024)   0           conv4_block3_out[0][0]           \n",
            "                                                                 conv4_block4_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_out (Activation)   (None, 2, 2, 1024)   0           conv4_block4_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_relu (Activation (None, 2, 2, 256)    0           conv4_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_relu (Activation (None, 2, 2, 256)    0           conv4_block5_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block5_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block5_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_add (Add)          (None, 2, 2, 1024)   0           conv4_block4_out[0][0]           \n",
            "                                                                 conv4_block5_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_out (Activation)   (None, 2, 2, 1024)   0           conv4_block5_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block5_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_relu (Activation (None, 2, 2, 256)    0           conv4_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_relu (Activation (None, 2, 2, 256)    0           conv4_block6_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block6_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block6_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_add (Add)          (None, 2, 2, 1024)   0           conv4_block5_out[0][0]           \n",
            "                                                                 conv4_block6_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_out (Activation)   (None, 2, 2, 1024)   0           conv4_block6_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_conv (Conv2D)    (None, 1, 1, 512)    524800      conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_relu (Activation (None, 1, 1, 512)    0           conv5_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_relu (Activation (None, 1, 1, 512)    0           conv5_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_conv (Conv2D)    (None, 1, 1, 2048)   2099200     conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_0_bn[0][0]          \n",
            "                                                                 conv5_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_out (Activation)   (None, 1, 1, 2048)   0           conv5_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_relu (Activation (None, 1, 1, 512)    0           conv5_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_relu (Activation (None, 1, 1, 512)    0           conv5_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_out[0][0]           \n",
            "                                                                 conv5_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_out (Activation)   (None, 1, 1, 2048)   0           conv5_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_relu (Activation (None, 1, 1, 512)    0           conv5_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_relu (Activation (None, 1, 1, 512)    0           conv5_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_add (Add)          (None, 1, 1, 2048)   0           conv5_block2_out[0][0]           \n",
            "                                                                 conv5_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_out (Activation)   (None, 1, 1, 2048)   0           conv5_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_4 (Glo (None, 2048)         0           conv5_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dropout_21 (Dropout)            (None, 2048)         0           global_average_pooling2d_4[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "dense_37 (Dense)                (None, 6)            12294       dropout_21[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 23,600,006\n",
            "Trainable params: 23,546,886\n",
            "Non-trainable params: 53,120\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wa7aDNZGWE6h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b9acec98-2994-4cff-b751-7d7643dc8d0d"
      },
      "source": [
        "%pwd"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/My Drive/A_transfertTFMresnetSP500'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sqRbJ1lTWRD7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "cce77f57-a0b0-49da-8b6f-1ae87b0bf723"
      },
      "source": [
        "ls -l model/"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 837925\n",
            "-rw------- 1 root root  97839904 Sep 19 14:40 best_modelcategorical_crossentropy_Adam_Batch32_LR0.0001_0.98.hdf5\n",
            "-rw------- 1 root root  97839896 Sep 19 13:15 best_modelcategorical_crossentropy_Adam_Batch32_LR0.01_0.98.hdf5\n",
            "-rw------- 1 root root 283765328 Sep 19 17:08 best_modelcategorical_crossentropy_Adam_Batch64_LR0.001_0.9.hdf5\n",
            "-rw------- 1 root root  94822472 Sep 19 15:40 initial_weights.h5\n",
            "-rw------- 1 root root 283765328 Sep 19 17:08 resnetforsp500.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uhuotgb6WcNZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cp model/best_modelcategorical_crossentropy_Adam_Batch64_LR0.001_0.9.hdf5 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "weqAP7PdW1On",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transfer_model.save('model/initial_weights.h5')"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H6eFmzP24-vc",
        "colab_type": "text"
      },
      "source": [
        "###Version with vgg16"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQNbUuu_ofxC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9930dc87-6f44-4727-a4fa-892dbc144628"
      },
      "source": [
        "%cd /content/drive/My Drive/A_transfertTFMVggSP500\n",
        "\n",
        "'''\n",
        "PART 3 VGGSP500 TRAINING AND SAVING\n",
        "we suppose that we have loaded xtrain and ytrain\n",
        "This part is based on the Design of the NN\n",
        "Her we find the Vgg16 quite usefull\n",
        "'''\n",
        "\n",
        "#Importing the VGG16 model\n",
        "from keras.applications.vgg16 import VGG16, preprocess_input\n",
        "from keras.applications.resnet import ResNet50\n",
        "\n",
        "#In our example we need to y into categorical as it has 6 categories\n",
        "nb_classes=6\n",
        "y_train = np_utils.to_categorical(y_train, nb_classes)\n",
        "\n",
        "\n",
        "#Loading the VGG16 model with pre-trained ImageNet weights\n",
        "vgg_model = VGG16(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n",
        "vgg_model.trainable = False # remove if you want to retrain vgg weights\n",
        "\n",
        "vgg_model.summary()\n",
        "\n",
        "\n",
        "##Transfert model from vgg\n",
        "transfer_model = Sequential()\n",
        "transfer_model.add(vgg_model)\n",
        "transfer_model.add(Flatten())\n",
        "transfer_model.add(Dense(128, activation='relu'))\n",
        "transfer_model.add(Dropout(0.2))\n",
        "transfer_model.add(Dense(6, activation='softmax'))\n",
        "\n",
        "\n",
        "\n",
        "transfer_model.compile(loss=vggsp500loss, optimizer=vggsp500optimizer,\n",
        "              metrics=vggsp500metrics)\n",
        "\n",
        "#Save initial weight to reinitialize it after when we trying to find the best set of parameters\n",
        "transfer_model.save_weights('model/initial_weights.h5')\n",
        "#model.load_weights('my_model_weights.h5'\n",
        "\n",
        "##Saving the best model for each parameters\n",
        "checkpoint = ModelCheckpoint(\"model/best_model\"+vggsp500loss+\"_\"+vggsp500optimizer_name+\"_Batch\"+\\\n",
        "                             str(batch_size)+\"_LR\"+str(vggsp500_learning_rate)+\"_\"+str(vggsp500_decay_rate)+\".hdf5\", \\\n",
        "                                monitor='loss', verbose=1, \\\n",
        "                                save_best_only=True, mode='auto', period=1)\n",
        "\n",
        "# Load the TensorBoard notebook extension.\n",
        "%load_ext tensorboard\n",
        "#!rm -rf ./logs/ \n",
        "\n",
        " # Define the Keras TensorBoard callback.\n",
        "logdir=\"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir, histogram_freq=1)\n",
        "\n",
        "##Fitting the model on the train data and labels.\n",
        "#reinitialise xtrain, ytrain to avoid change of type from np.array to tensor by keras\n",
        "m_x_train=x_train\n",
        "m_y_train=y_train\n",
        "\n",
        "history = transfer_model.fit(m_x_train, m_y_train, \\\n",
        "                              batch_size=batch_size, epochs=epochs, \\\n",
        "                              validation_split=0.2, verbose=1, shuffle=True, \\\n",
        "                              callbacks=[checkpoint, tensorboard_callback])\n",
        "\n",
        "# Saving themodel\n",
        "transfer_model.save('model/vggforsp500.h5')\n",
        "\n",
        "#Display the graph of the model\n",
        "tf.keras.utils.plot_model(transfer_model)\n",
        "\n",
        "##Display summary of neural network\n",
        "transfer_model.summary()\n",
        "\n",
        "#Display Tensorboard\n",
        "%tensorboard --logdir logs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/A_transfertTFMVggSP500\n",
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 32, 32, 64)        1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 32, 32, 64)        36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 16, 16, 128)       73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 16, 16, 128)       147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 8, 8, 256)         295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 8, 8, 256)         590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 8, 8, 256)         590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 4, 4, 256)         0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 4, 4, 512)         1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 2, 2, 512)         0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 1, 1, 512)         0         \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 0\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "The tensorboard extension is already loaded. To reload it, use:\n",
            "  %reload_ext tensorboard\n",
            "Epoch 1/3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-f479dc028c0d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0mm_y_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransfer_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm_x_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm_y_train\u001b[0m\u001b[0;34m,\u001b[0m                               \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m                               \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m                               \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensorboard_callback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;31m# Saving themodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    821\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    824\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    695\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    696\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 697\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    698\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2853\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2854\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2855\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2856\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3212\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3213\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3214\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3215\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3073\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3074\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3075\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3076\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3077\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    598\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    601\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    971\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    972\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 973\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    974\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    975\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:806 train_function  *\n        return step_function(self, iterator)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:796 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:789 run_step  **\n        outputs = model.train_step(data)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:749 train_step\n        y, y_pred, sample_weight, regularization_losses=self.losses)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/compile_utils.py:204 __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/losses.py:149 __call__\n        losses = ag_call(y_true, y_pred)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/losses.py:253 call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/losses.py:1535 categorical_crossentropy\n        return K.categorical_crossentropy(y_true, y_pred, from_logits=from_logits)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py:4687 categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/tensor_shape.py:1134 assert_is_compatible_with\n        raise ValueError(\"Shapes %s and %s are incompatible\" % (self, other))\n\n    ValueError: Shapes (None, 6, 6) and (None, 6) are incompatible\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FiDWq98sOAb-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%load_ext tensorboard"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pJfc1EgdOIn8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#here you have with the logs in drive link where you can launch tensorboard and see the training process\n",
        "%cd /content/drive/My Drive/A_transfertTFMVggSP500\n",
        "%tensorboard --logdir logs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n4hYLydW_XH2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history.history['loss']\n",
        "history.history"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SgkpclptyV7A",
        "colab_type": "text"
      },
      "source": [
        "**IN CASE OF ERROR OF SHAPE OF INPUT**\n",
        "\n",
        "please note that if some error in shape of the input you have to execute the loading datas once again\n",
        "there is a update of type between tensor and np.array of y_train and x_train\n",
        "\n",
        "Go back to\n",
        "\n",
        "Step 2: Loading training datas with vgg16 transfert model and training\n",
        "\n",
        "Loading and Cleaning Training Datas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IuzuOOsaLAsO",
        "colab_type": "text"
      },
      "source": [
        "####Search of the best parameters for training and evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQD_FVuIK--C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "450c342a-0c91-41ed-c32a-a902c34f04bd"
      },
      "source": [
        "%cd /content/drive/My Drive/A_transfertTFMVggSP500\n",
        "# Load the TensorBoard notebook extension.\n",
        "%reload_ext tensorboard\n",
        "!rm -rf ./logs/ \n",
        "\n",
        "#We can modify batch size and epochs to adjust improve the training\n",
        "l_batch_size=[25,50,100]\n",
        "l_epochs=[25,50,100]\n",
        "l_learning_rate=[0.001,0.01,0.1]\n",
        "l_optimizer_name=[keras.optimizers.SGD, keras.optimizers.RMSprop, keras.optimizers.Adam, keras.optimizers.Adagrad, keras.optimizers.Adamax, keras.optimizers.Ftrl]\n",
        "\n",
        "Tabres={}\n",
        "\n",
        "for x_batch_size in l_batch_size :\n",
        "  for  x_epochs in l_epochs:\n",
        "    for x_learning_rate in l_learning_rate:\n",
        "      for x_optimizer_name in l_optimizer_name :\n",
        "        batch_size= x_batch_size\n",
        "        epochs= x_epochs\n",
        "        lr_schedule =  x_learning_rate\n",
        "        \n",
        "        ##https://keras.io/api/losses/\n",
        "        vggsp500loss='categorical_crossentropy'                             \n",
        "\n",
        "        ##https://keras.io/api/optimizers/\n",
        "        vggsp500optimizer_name=x_optimizer_name(learning_rate=x_learning_rate)\n",
        "        \n",
        "        ##https://keras.io/api/metrics/\n",
        "        vggsp500metrics=['accuracy']                                           \n",
        "        \n",
        "        \n",
        "        ##ACTUALISATION OF THE MODEL AND BY EACH SET OF PARAMETERS\n",
        "        \n",
        "        #First we initialize weight for each set of param see abpve where we had saved it\n",
        "        transfer_model.load_weights('model/initial_weights.h5')\n",
        "        transfer_model.compile(loss=vggsp500loss, optimizer=vggsp500optimizer_name,\n",
        "                      metrics=vggsp500metrics)\n",
        "\n",
        "        ##Saving the best model for each parameters\n",
        "        nameof_intermediarymodel=\"best_model\"+vggsp500loss+\"_\"+str(vggsp500optimizer_name)+\"_Batch\"+\\\n",
        "                                    str(batch_size)+\"_LR\"+str(x_learning_rate)+\"_Epochs\"+str(epochs)\n",
        "        checkpoint = ModelCheckpoint('model/'+nameof_intermediarymodel+\".hdf5\", \\\n",
        "                                        monitor='loss', verbose=1, \\\n",
        "                                        save_best_only=True, mode='auto', period=1)\n",
        "\n",
        "        \n",
        "        # Define the Keras TensorBoard callback.\n",
        "        logdir=\"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "        tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir, histogram_freq=1)\n",
        "\n",
        "        ##Fitting the model on the train data and labels.\n",
        "        m_x_train=x_train\n",
        "        m_y_train=y_train\n",
        "\n",
        "        history = transfer_model.fit(m_x_train, m_y_train, \\\n",
        "                                      batch_size=batch_size, epochs=epochs, \\\n",
        "                                      validation_split=0.2, verbose=1, shuffle=True, \\\n",
        "                                      callbacks=[checkpoint,tensorboard_callback])\n",
        "        # Saving themodel\n",
        "        transfer_model.save('model/'+nameof_intermediarymodel+'vggforsp500'+'.h5')\n",
        "        Tabres.update({nameof_intermediarymodel:history.history})\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/A_transfertTFMVggSP500\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/25\n",
            "  2/595 [..............................] - ETA: 34s - loss: 2.4315 - accuracy: 0.0400WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0145s vs `on_train_batch_end` time: 0.1003s). Check your callbacks.\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.6045 - accuracy: 0.3101\n",
            "Epoch 00001: loss improved from inf to 1.60393, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f5b6204e8d0>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.6039 - accuracy: 0.3110 - val_loss: 1.5135 - val_accuracy: 0.3399\n",
            "Epoch 2/25\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5611 - accuracy: 0.3199\n",
            "Epoch 00002: loss improved from 1.60393 to 1.56054, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f5b6204e8d0>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5605 - accuracy: 0.3201 - val_loss: 1.5102 - val_accuracy: 0.3399\n",
            "Epoch 3/25\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5548 - accuracy: 0.3293\n",
            "Epoch 00003: loss improved from 1.56054 to 1.55448, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f5b6204e8d0>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5545 - accuracy: 0.3294 - val_loss: 1.5035 - val_accuracy: 0.3399\n",
            "Epoch 4/25\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5459 - accuracy: 0.3327\n",
            "Epoch 00004: loss improved from 1.55448 to 1.54585, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f5b6204e8d0>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5459 - accuracy: 0.3326 - val_loss: 1.5065 - val_accuracy: 0.3399\n",
            "Epoch 5/25\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5430 - accuracy: 0.3321\n",
            "Epoch 00005: loss improved from 1.54585 to 1.54320, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f5b6204e8d0>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5432 - accuracy: 0.3318 - val_loss: 1.5075 - val_accuracy: 0.3399\n",
            "Epoch 6/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5411 - accuracy: 0.3384\n",
            "Epoch 00006: loss improved from 1.54320 to 1.54099, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f5b6204e8d0>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5410 - accuracy: 0.3387 - val_loss: 1.5053 - val_accuracy: 0.3399\n",
            "Epoch 7/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5378 - accuracy: 0.3389\n",
            "Epoch 00007: loss improved from 1.54099 to 1.53811, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f5b6204e8d0>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5381 - accuracy: 0.3387 - val_loss: 1.5027 - val_accuracy: 0.3399\n",
            "Epoch 8/25\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5351 - accuracy: 0.3378\n",
            "Epoch 00008: loss improved from 1.53811 to 1.53514, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f5b6204e8d0>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5351 - accuracy: 0.3379 - val_loss: 1.5048 - val_accuracy: 0.3399\n",
            "Epoch 9/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5381 - accuracy: 0.3386\n",
            "Epoch 00009: loss did not improve from 1.53514\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5382 - accuracy: 0.3388 - val_loss: 1.5061 - val_accuracy: 0.3399\n",
            "Epoch 10/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5370 - accuracy: 0.3422\n",
            "Epoch 00010: loss did not improve from 1.53514\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5366 - accuracy: 0.3422 - val_loss: 1.5034 - val_accuracy: 0.3399\n",
            "Epoch 11/25\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5342 - accuracy: 0.3403\n",
            "Epoch 00011: loss improved from 1.53514 to 1.53396, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f5b6204e8d0>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5340 - accuracy: 0.3404 - val_loss: 1.5014 - val_accuracy: 0.3399\n",
            "Epoch 12/25\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5354 - accuracy: 0.3381\n",
            "Epoch 00012: loss did not improve from 1.53396\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5354 - accuracy: 0.3381 - val_loss: 1.5010 - val_accuracy: 0.3399\n",
            "Epoch 13/25\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5326 - accuracy: 0.3406\n",
            "Epoch 00013: loss improved from 1.53396 to 1.53260, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f5b6204e8d0>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5326 - accuracy: 0.3406 - val_loss: 1.5043 - val_accuracy: 0.3399\n",
            "Epoch 14/25\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5333 - accuracy: 0.3436\n",
            "Epoch 00014: loss did not improve from 1.53260\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5329 - accuracy: 0.3442 - val_loss: 1.5033 - val_accuracy: 0.3399\n",
            "Epoch 15/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5314 - accuracy: 0.3414\n",
            "Epoch 00015: loss improved from 1.53260 to 1.53111, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f5b6204e8d0>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5311 - accuracy: 0.3417 - val_loss: 1.5036 - val_accuracy: 0.3399\n",
            "Epoch 16/25\n",
            "589/595 [============================>.] - ETA: 0s - loss: 1.5308 - accuracy: 0.3419\n",
            "Epoch 00016: loss improved from 1.53111 to 1.53053, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f5b6204e8d0>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5305 - accuracy: 0.3425 - val_loss: 1.5035 - val_accuracy: 0.3399\n",
            "Epoch 17/25\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5306 - accuracy: 0.3430\n",
            "Epoch 00017: loss did not improve from 1.53053\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5306 - accuracy: 0.3430 - val_loss: 1.5025 - val_accuracy: 0.3399\n",
            "Epoch 18/25\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5305 - accuracy: 0.3426\n",
            "Epoch 00018: loss did not improve from 1.53053\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5305 - accuracy: 0.3426 - val_loss: 1.5024 - val_accuracy: 0.3399\n",
            "Epoch 19/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5305 - accuracy: 0.3420\n",
            "Epoch 00019: loss improved from 1.53053 to 1.53039, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f5b6204e8d0>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5304 - accuracy: 0.3421 - val_loss: 1.5016 - val_accuracy: 0.3399\n",
            "Epoch 20/25\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5282 - accuracy: 0.3417\n",
            "Epoch 00020: loss improved from 1.53039 to 1.52811, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f5b6204e8d0>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5281 - accuracy: 0.3420 - val_loss: 1.5025 - val_accuracy: 0.3399\n",
            "Epoch 21/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5292 - accuracy: 0.3424\n",
            "Epoch 00021: loss did not improve from 1.52811\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5293 - accuracy: 0.3422 - val_loss: 1.5011 - val_accuracy: 0.3399\n",
            "Epoch 22/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5287 - accuracy: 0.3414\n",
            "Epoch 00022: loss did not improve from 1.52811\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5283 - accuracy: 0.3416 - val_loss: 1.5029 - val_accuracy: 0.3399\n",
            "Epoch 23/25\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5282 - accuracy: 0.3419\n",
            "Epoch 00023: loss did not improve from 1.52811\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5282 - accuracy: 0.3419 - val_loss: 1.4992 - val_accuracy: 0.3399\n",
            "Epoch 24/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5283 - accuracy: 0.3428\n",
            "Epoch 00024: loss did not improve from 1.52811\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5281 - accuracy: 0.3428 - val_loss: 1.4994 - val_accuracy: 0.3399\n",
            "Epoch 25/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5271 - accuracy: 0.3417\n",
            "Epoch 00025: loss improved from 1.52811 to 1.52711, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f5b6204e8d0>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5271 - accuracy: 0.3418 - val_loss: 1.4991 - val_accuracy: 0.3399\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/25\n",
            "  2/595 [..............................] - ETA: 39s - loss: 2.0196 - accuracy: 0.0800WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0155s vs `on_train_batch_end` time: 0.1178s). Check your callbacks.\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5473 - accuracy: 0.3327\n",
            "Epoch 00001: loss improved from inf to 1.54702, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f59cc45efd0>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5470 - accuracy: 0.3329 - val_loss: 1.5068 - val_accuracy: 0.3399\n",
            "Epoch 2/25\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5284 - accuracy: 0.3414\n",
            "Epoch 00002: loss improved from 1.54702 to 1.52771, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f59cc45efd0>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5277 - accuracy: 0.3420 - val_loss: 1.4969 - val_accuracy: 0.3399\n",
            "Epoch 3/25\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5241 - accuracy: 0.3425\n",
            "Epoch 00003: loss improved from 1.52771 to 1.52421, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f59cc45efd0>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5242 - accuracy: 0.3423 - val_loss: 1.5041 - val_accuracy: 0.3399\n",
            "Epoch 4/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5199 - accuracy: 0.3434\n",
            "Epoch 00004: loss improved from 1.52421 to 1.52004, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f59cc45efd0>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5200 - accuracy: 0.3435 - val_loss: 1.4919 - val_accuracy: 0.3442\n",
            "Epoch 5/25\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5180 - accuracy: 0.3408\n",
            "Epoch 00005: loss improved from 1.52004 to 1.51803, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f59cc45efd0>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5180 - accuracy: 0.3408 - val_loss: 1.4974 - val_accuracy: 0.3358\n",
            "Epoch 6/25\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5138 - accuracy: 0.3458\n",
            "Epoch 00006: loss improved from 1.51803 to 1.51346, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f59cc45efd0>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5135 - accuracy: 0.3451 - val_loss: 1.4893 - val_accuracy: 0.3415\n",
            "Epoch 7/25\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5116 - accuracy: 0.3461\n",
            "Epoch 00007: loss improved from 1.51346 to 1.51201, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f59cc45efd0>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5120 - accuracy: 0.3457 - val_loss: 1.4988 - val_accuracy: 0.3286\n",
            "Epoch 8/25\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5121 - accuracy: 0.3473\n",
            "Epoch 00008: loss improved from 1.51201 to 1.51195, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f59cc45efd0>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5120 - accuracy: 0.3475 - val_loss: 1.5162 - val_accuracy: 0.3372\n",
            "Epoch 9/25\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5079 - accuracy: 0.3443\n",
            "Epoch 00009: loss improved from 1.51195 to 1.50823, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f59cc45efd0>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5082 - accuracy: 0.3443 - val_loss: 1.5151 - val_accuracy: 0.3224\n",
            "Epoch 10/25\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5068 - accuracy: 0.3448\n",
            "Epoch 00010: loss improved from 1.50823 to 1.50675, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f59cc45efd0>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5068 - accuracy: 0.3448 - val_loss: 1.5074 - val_accuracy: 0.3243\n",
            "Epoch 11/25\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5046 - accuracy: 0.3450\n",
            "Epoch 00011: loss improved from 1.50675 to 1.50467, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f59cc45efd0>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5047 - accuracy: 0.3451 - val_loss: 1.5108 - val_accuracy: 0.3229\n",
            "Epoch 12/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5039 - accuracy: 0.3482\n",
            "Epoch 00012: loss improved from 1.50467 to 1.50432, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f59cc45efd0>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5043 - accuracy: 0.3480 - val_loss: 1.4885 - val_accuracy: 0.3202\n",
            "Epoch 13/25\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5011 - accuracy: 0.3495\n",
            "Epoch 00013: loss improved from 1.50432 to 1.50177, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f59cc45efd0>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5018 - accuracy: 0.3493 - val_loss: 1.4918 - val_accuracy: 0.3294\n",
            "Epoch 14/25\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5013 - accuracy: 0.3525\n",
            "Epoch 00014: loss improved from 1.50177 to 1.50128, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f59cc45efd0>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5013 - accuracy: 0.3525 - val_loss: 1.5210 - val_accuracy: 0.3221\n",
            "Epoch 15/25\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.4995 - accuracy: 0.3475\n",
            "Epoch 00015: loss improved from 1.50128 to 1.49957, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f59cc45efd0>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.4996 - accuracy: 0.3473 - val_loss: 1.4979 - val_accuracy: 0.3200\n",
            "Epoch 16/25\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.4982 - accuracy: 0.3465\n",
            "Epoch 00016: loss improved from 1.49957 to 1.49825, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f59cc45efd0>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4982 - accuracy: 0.3465 - val_loss: 1.4987 - val_accuracy: 0.3305\n",
            "Epoch 17/25\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.4980 - accuracy: 0.3498\n",
            "Epoch 00017: loss improved from 1.49825 to 1.49805, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f59cc45efd0>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4980 - accuracy: 0.3498 - val_loss: 1.5270 - val_accuracy: 0.3251\n",
            "Epoch 18/25\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.4963 - accuracy: 0.3502\n",
            "Epoch 00018: loss improved from 1.49805 to 1.49669, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f59cc45efd0>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4967 - accuracy: 0.3495 - val_loss: 1.5085 - val_accuracy: 0.3272\n",
            "Epoch 19/25\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.4960 - accuracy: 0.3529\n",
            "Epoch 00019: loss improved from 1.49669 to 1.49595, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f59cc45efd0>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4960 - accuracy: 0.3529 - val_loss: 1.5233 - val_accuracy: 0.3369\n",
            "Epoch 20/25\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.4945 - accuracy: 0.3533\n",
            "Epoch 00020: loss improved from 1.49595 to 1.49452, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f59cc45efd0>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.4945 - accuracy: 0.3533 - val_loss: 1.5195 - val_accuracy: 0.3267\n",
            "Epoch 21/25\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.4946 - accuracy: 0.3554\n",
            "Epoch 00021: loss improved from 1.49452 to 1.49425, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f59cc45efd0>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4942 - accuracy: 0.3559 - val_loss: 1.5107 - val_accuracy: 0.3173\n",
            "Epoch 22/25\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.4921 - accuracy: 0.3575\n",
            "Epoch 00022: loss improved from 1.49425 to 1.49210, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f59cc45efd0>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4921 - accuracy: 0.3574 - val_loss: 1.5283 - val_accuracy: 0.3375\n",
            "Epoch 23/25\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.4911 - accuracy: 0.3549\n",
            "Epoch 00023: loss improved from 1.49210 to 1.49081, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f59cc45efd0>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.4908 - accuracy: 0.3552 - val_loss: 1.5110 - val_accuracy: 0.3393\n",
            "Epoch 24/25\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.4900 - accuracy: 0.3575\n",
            "Epoch 00024: loss improved from 1.49081 to 1.48945, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f59cc45efd0>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4894 - accuracy: 0.3578 - val_loss: 1.5388 - val_accuracy: 0.3122\n",
            "Epoch 25/25\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.4890 - accuracy: 0.3592\n",
            "Epoch 00025: loss improved from 1.48945 to 1.48899, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f59cc45efd0>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.4890 - accuracy: 0.3591 - val_loss: 1.5243 - val_accuracy: 0.3253\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/25\n",
            "  2/595 [..............................] - ETA: 34s - loss: 2.1772 - accuracy: 0.0800WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0163s vs `on_train_batch_end` time: 0.0981s). Check your callbacks.\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5496 - accuracy: 0.3283\n",
            "Epoch 00001: loss improved from inf to 1.54961, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f5b61ded208>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5496 - accuracy: 0.3283 - val_loss: 1.5036 - val_accuracy: 0.3399\n",
            "Epoch 2/25\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5277 - accuracy: 0.3429\n",
            "Epoch 00002: loss improved from 1.54961 to 1.52753, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f5b61ded208>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5275 - accuracy: 0.3429 - val_loss: 1.4948 - val_accuracy: 0.3399\n",
            "Epoch 3/25\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5233 - accuracy: 0.3418\n",
            "Epoch 00003: loss improved from 1.52753 to 1.52306, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f5b61ded208>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5231 - accuracy: 0.3420 - val_loss: 1.4904 - val_accuracy: 0.3224\n",
            "Epoch 4/25\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5196 - accuracy: 0.3423\n",
            "Epoch 00004: loss improved from 1.52306 to 1.51946, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f5b61ded208>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5195 - accuracy: 0.3424 - val_loss: 1.4875 - val_accuracy: 0.3372\n",
            "Epoch 5/25\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5168 - accuracy: 0.3432\n",
            "Epoch 00005: loss improved from 1.51946 to 1.51672, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f5b61ded208>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5167 - accuracy: 0.3432 - val_loss: 1.5036 - val_accuracy: 0.3372\n",
            "Epoch 6/25\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5151 - accuracy: 0.3447\n",
            "Epoch 00006: loss improved from 1.51672 to 1.51510, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f5b61ded208>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5151 - accuracy: 0.3447 - val_loss: 1.4885 - val_accuracy: 0.3372\n",
            "Epoch 7/25\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5128 - accuracy: 0.3461\n",
            "Epoch 00007: loss improved from 1.51510 to 1.51256, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f5b61ded208>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5126 - accuracy: 0.3463 - val_loss: 1.5083 - val_accuracy: 0.3361\n",
            "Epoch 8/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5114 - accuracy: 0.3440\n",
            "Epoch 00008: loss improved from 1.51256 to 1.51128, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f5b61ded208>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5113 - accuracy: 0.3439 - val_loss: 1.5006 - val_accuracy: 0.3348\n",
            "Epoch 9/25\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5086 - accuracy: 0.3468\n",
            "Epoch 00009: loss improved from 1.51128 to 1.50812, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f5b61ded208>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5081 - accuracy: 0.3469 - val_loss: 1.4871 - val_accuracy: 0.3302\n",
            "Epoch 10/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5065 - accuracy: 0.3476\n",
            "Epoch 00010: loss improved from 1.50812 to 1.50689, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f5b61ded208>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5069 - accuracy: 0.3473 - val_loss: 1.4937 - val_accuracy: 0.3369\n",
            "Epoch 11/25\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5041 - accuracy: 0.3462\n",
            "Epoch 00011: loss improved from 1.50689 to 1.50414, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f5b61ded208>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5041 - accuracy: 0.3462 - val_loss: 1.4974 - val_accuracy: 0.3345\n",
            "Epoch 12/25\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5026 - accuracy: 0.3454\n",
            "Epoch 00012: loss improved from 1.50414 to 1.50225, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f5b61ded208>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5023 - accuracy: 0.3457 - val_loss: 1.4946 - val_accuracy: 0.3219\n",
            "Epoch 13/25\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5018 - accuracy: 0.3485\n",
            "Epoch 00013: loss improved from 1.50225 to 1.50216, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f5b61ded208>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5022 - accuracy: 0.3481 - val_loss: 1.4966 - val_accuracy: 0.3294\n",
            "Epoch 14/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.4981 - accuracy: 0.3499\n",
            "Epoch 00014: loss improved from 1.50216 to 1.49781, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f5b61ded208>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4978 - accuracy: 0.3500 - val_loss: 1.5049 - val_accuracy: 0.3124\n",
            "Epoch 15/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.4988 - accuracy: 0.3509\n",
            "Epoch 00015: loss did not improve from 1.49781\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4990 - accuracy: 0.3507 - val_loss: 1.5013 - val_accuracy: 0.3200\n",
            "Epoch 16/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.4970 - accuracy: 0.3486\n",
            "Epoch 00016: loss improved from 1.49781 to 1.49698, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f5b61ded208>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.4970 - accuracy: 0.3484 - val_loss: 1.4958 - val_accuracy: 0.3294\n",
            "Epoch 17/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.4939 - accuracy: 0.3497\n",
            "Epoch 00017: loss improved from 1.49698 to 1.49405, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f5b61ded208>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4941 - accuracy: 0.3496 - val_loss: 1.5069 - val_accuracy: 0.3087\n",
            "Epoch 18/25\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.4930 - accuracy: 0.3517\n",
            "Epoch 00018: loss improved from 1.49405 to 1.49286, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f5b61ded208>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.4929 - accuracy: 0.3519 - val_loss: 1.4970 - val_accuracy: 0.3291\n",
            "Epoch 19/25\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.4932 - accuracy: 0.3467\n",
            "Epoch 00019: loss did not improve from 1.49286\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4931 - accuracy: 0.3466 - val_loss: 1.4949 - val_accuracy: 0.3130\n",
            "Epoch 20/25\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.4915 - accuracy: 0.3534\n",
            "Epoch 00020: loss improved from 1.49286 to 1.49150, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f5b61ded208>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.4915 - accuracy: 0.3534 - val_loss: 1.5029 - val_accuracy: 0.3081\n",
            "Epoch 21/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.4885 - accuracy: 0.3549\n",
            "Epoch 00021: loss improved from 1.49150 to 1.48841, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f5b61ded208>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4884 - accuracy: 0.3549 - val_loss: 1.5132 - val_accuracy: 0.3130\n",
            "Epoch 22/25\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.4871 - accuracy: 0.3521\n",
            "Epoch 00022: loss improved from 1.48841 to 1.48767, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f5b61ded208>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4877 - accuracy: 0.3516 - val_loss: 1.4946 - val_accuracy: 0.3315\n",
            "Epoch 23/25\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.4849 - accuracy: 0.3528\n",
            "Epoch 00023: loss improved from 1.48767 to 1.48474, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f5b61ded208>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.4847 - accuracy: 0.3528 - val_loss: 1.5146 - val_accuracy: 0.3221\n",
            "Epoch 24/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.4834 - accuracy: 0.3567\n",
            "Epoch 00024: loss improved from 1.48474 to 1.48375, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f5b61ded208>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4837 - accuracy: 0.3569 - val_loss: 1.5243 - val_accuracy: 0.3122\n",
            "Epoch 25/25\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.4833 - accuracy: 0.3565\n",
            "Epoch 00025: loss improved from 1.48375 to 1.48263, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f5b61ded208>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4826 - accuracy: 0.3568 - val_loss: 1.5092 - val_accuracy: 0.3399\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/25\n",
            "  2/595 [..............................] - ETA: 37s - loss: 2.1424 - accuracy: 0.1400WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0170s vs `on_train_batch_end` time: 0.1080s). Check your callbacks.\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5985 - accuracy: 0.3146\n",
            "Epoch 00001: loss improved from inf to 1.59869, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59d1b66c50>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5987 - accuracy: 0.3144 - val_loss: 1.5194 - val_accuracy: 0.3399\n",
            "Epoch 2/25\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5618 - accuracy: 0.3284\n",
            "Epoch 00002: loss improved from 1.59869 to 1.56176, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59d1b66c50>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 9s 15ms/step - loss: 1.5618 - accuracy: 0.3284 - val_loss: 1.5115 - val_accuracy: 0.3399\n",
            "Epoch 3/25\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5547 - accuracy: 0.3271\n",
            "Epoch 00003: loss improved from 1.56176 to 1.55475, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59d1b66c50>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5548 - accuracy: 0.3272 - val_loss: 1.5069 - val_accuracy: 0.3399\n",
            "Epoch 4/25\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5489 - accuracy: 0.3295\n",
            "Epoch 00004: loss improved from 1.55475 to 1.54948, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59d1b66c50>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5495 - accuracy: 0.3291 - val_loss: 1.5093 - val_accuracy: 0.3399\n",
            "Epoch 5/25\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5484 - accuracy: 0.3290\n",
            "Epoch 00005: loss improved from 1.54948 to 1.54797, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59d1b66c50>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5480 - accuracy: 0.3295 - val_loss: 1.5071 - val_accuracy: 0.3399\n",
            "Epoch 6/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5460 - accuracy: 0.3311\n",
            "Epoch 00006: loss improved from 1.54797 to 1.54594, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59d1b66c50>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5459 - accuracy: 0.3311 - val_loss: 1.5058 - val_accuracy: 0.3399\n",
            "Epoch 7/25\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5434 - accuracy: 0.3353\n",
            "Epoch 00007: loss improved from 1.54594 to 1.54391, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59d1b66c50>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5439 - accuracy: 0.3349 - val_loss: 1.5040 - val_accuracy: 0.3399\n",
            "Epoch 8/25\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5402 - accuracy: 0.3349\n",
            "Epoch 00008: loss improved from 1.54391 to 1.54047, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59d1b66c50>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5405 - accuracy: 0.3346 - val_loss: 1.5042 - val_accuracy: 0.3399\n",
            "Epoch 9/25\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5377 - accuracy: 0.3320\n",
            "Epoch 00009: loss improved from 1.54047 to 1.53778, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59d1b66c50>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5378 - accuracy: 0.3321 - val_loss: 1.5055 - val_accuracy: 0.3399\n",
            "Epoch 10/25\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5346 - accuracy: 0.3371\n",
            "Epoch 00010: loss improved from 1.53778 to 1.53518, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59d1b66c50>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5352 - accuracy: 0.3367 - val_loss: 1.5045 - val_accuracy: 0.3399\n",
            "Epoch 11/25\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5357 - accuracy: 0.3319\n",
            "Epoch 00011: loss did not improve from 1.53518\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5357 - accuracy: 0.3319 - val_loss: 1.5063 - val_accuracy: 0.3399\n",
            "Epoch 12/25\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5368 - accuracy: 0.3347\n",
            "Epoch 00012: loss did not improve from 1.53518\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5367 - accuracy: 0.3347 - val_loss: 1.5044 - val_accuracy: 0.3399\n",
            "Epoch 13/25\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5375 - accuracy: 0.3338\n",
            "Epoch 00013: loss did not improve from 1.53518\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5377 - accuracy: 0.3339 - val_loss: 1.5049 - val_accuracy: 0.3399\n",
            "Epoch 14/25\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5358 - accuracy: 0.3367\n",
            "Epoch 00014: loss did not improve from 1.53518\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5357 - accuracy: 0.3369 - val_loss: 1.5035 - val_accuracy: 0.3399\n",
            "Epoch 15/25\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5363 - accuracy: 0.3365\n",
            "Epoch 00015: loss did not improve from 1.53518\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5357 - accuracy: 0.3371 - val_loss: 1.5039 - val_accuracy: 0.3399\n",
            "Epoch 16/25\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5348 - accuracy: 0.3356\n",
            "Epoch 00016: loss improved from 1.53518 to 1.53487, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59d1b66c50>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5349 - accuracy: 0.3355 - val_loss: 1.5029 - val_accuracy: 0.3399\n",
            "Epoch 17/25\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5344 - accuracy: 0.3354\n",
            "Epoch 00017: loss improved from 1.53487 to 1.53424, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59d1b66c50>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5342 - accuracy: 0.3356 - val_loss: 1.5028 - val_accuracy: 0.3399\n",
            "Epoch 18/25\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5347 - accuracy: 0.3370\n",
            "Epoch 00018: loss did not improve from 1.53424\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5347 - accuracy: 0.3369 - val_loss: 1.5032 - val_accuracy: 0.3399\n",
            "Epoch 19/25\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5332 - accuracy: 0.3408\n",
            "Epoch 00019: loss improved from 1.53424 to 1.53361, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59d1b66c50>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5336 - accuracy: 0.3405 - val_loss: 1.5025 - val_accuracy: 0.3399\n",
            "Epoch 20/25\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5320 - accuracy: 0.3413\n",
            "Epoch 00020: loss improved from 1.53361 to 1.53176, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59d1b66c50>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5318 - accuracy: 0.3415 - val_loss: 1.5033 - val_accuracy: 0.3399\n",
            "Epoch 21/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5315 - accuracy: 0.3372\n",
            "Epoch 00021: loss improved from 1.53176 to 1.53164, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59d1b66c50>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5316 - accuracy: 0.3371 - val_loss: 1.5039 - val_accuracy: 0.3399\n",
            "Epoch 22/25\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5318 - accuracy: 0.3401\n",
            "Epoch 00022: loss did not improve from 1.53164\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5320 - accuracy: 0.3403 - val_loss: 1.5035 - val_accuracy: 0.3399\n",
            "Epoch 23/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5325 - accuracy: 0.3372\n",
            "Epoch 00023: loss did not improve from 1.53164\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5327 - accuracy: 0.3370 - val_loss: 1.5038 - val_accuracy: 0.3399\n",
            "Epoch 24/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5291 - accuracy: 0.3414\n",
            "Epoch 00024: loss improved from 1.53164 to 1.52933, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59d1b66c50>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5293 - accuracy: 0.3410 - val_loss: 1.5028 - val_accuracy: 0.3399\n",
            "Epoch 25/25\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5315 - accuracy: 0.3377\n",
            "Epoch 00025: loss did not improve from 1.52933\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5317 - accuracy: 0.3380 - val_loss: 1.5038 - val_accuracy: 0.3399\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/25\n",
            "  2/595 [..............................] - ETA: 35s - loss: 2.2563 - accuracy: 0.1000WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0149s vs `on_train_batch_end` time: 0.1030s). Check your callbacks.\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5564 - accuracy: 0.3263\n",
            "Epoch 00001: loss improved from inf to 1.55637, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f59c909e1d0>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5564 - accuracy: 0.3263 - val_loss: 1.5220 - val_accuracy: 0.3399\n",
            "Epoch 2/25\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5350 - accuracy: 0.3360\n",
            "Epoch 00002: loss improved from 1.55637 to 1.53484, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f59c909e1d0>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5348 - accuracy: 0.3358 - val_loss: 1.4980 - val_accuracy: 0.3399\n",
            "Epoch 3/25\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5294 - accuracy: 0.3424\n",
            "Epoch 00003: loss improved from 1.53484 to 1.52974, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f59c909e1d0>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5297 - accuracy: 0.3421 - val_loss: 1.4993 - val_accuracy: 0.3399\n",
            "Epoch 4/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5241 - accuracy: 0.3391\n",
            "Epoch 00004: loss improved from 1.52974 to 1.52419, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f59c909e1d0>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5242 - accuracy: 0.3391 - val_loss: 1.5081 - val_accuracy: 0.3399\n",
            "Epoch 5/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5219 - accuracy: 0.3428\n",
            "Epoch 00005: loss improved from 1.52419 to 1.52203, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f59c909e1d0>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5220 - accuracy: 0.3426 - val_loss: 1.4936 - val_accuracy: 0.3399\n",
            "Epoch 6/25\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5191 - accuracy: 0.3419\n",
            "Epoch 00006: loss improved from 1.52203 to 1.51928, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f59c909e1d0>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5193 - accuracy: 0.3418 - val_loss: 1.4924 - val_accuracy: 0.3399\n",
            "Epoch 7/25\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5171 - accuracy: 0.3422\n",
            "Epoch 00007: loss improved from 1.51928 to 1.51689, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f59c909e1d0>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5169 - accuracy: 0.3423 - val_loss: 1.4939 - val_accuracy: 0.3399\n",
            "Epoch 8/25\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5163 - accuracy: 0.3422\n",
            "Epoch 00008: loss improved from 1.51689 to 1.51610, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f59c909e1d0>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5161 - accuracy: 0.3422 - val_loss: 1.4942 - val_accuracy: 0.3372\n",
            "Epoch 9/25\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5140 - accuracy: 0.3438\n",
            "Epoch 00009: loss improved from 1.51610 to 1.51376, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f59c909e1d0>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5138 - accuracy: 0.3437 - val_loss: 1.4962 - val_accuracy: 0.3372\n",
            "Epoch 10/25\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5101 - accuracy: 0.3447\n",
            "Epoch 00010: loss improved from 1.51376 to 1.51026, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f59c909e1d0>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5103 - accuracy: 0.3445 - val_loss: 1.4937 - val_accuracy: 0.3380\n",
            "Epoch 11/25\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5095 - accuracy: 0.3437\n",
            "Epoch 00011: loss improved from 1.51026 to 1.50954, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f59c909e1d0>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5095 - accuracy: 0.3437 - val_loss: 1.4921 - val_accuracy: 0.3385\n",
            "Epoch 12/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5082 - accuracy: 0.3401\n",
            "Epoch 00012: loss improved from 1.50954 to 1.50815, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f59c909e1d0>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5081 - accuracy: 0.3402 - val_loss: 1.5015 - val_accuracy: 0.3375\n",
            "Epoch 13/25\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5081 - accuracy: 0.3456\n",
            "Epoch 00013: loss improved from 1.50815 to 1.50805, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f59c909e1d0>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5081 - accuracy: 0.3457 - val_loss: 1.4902 - val_accuracy: 0.3364\n",
            "Epoch 14/25\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5045 - accuracy: 0.3453\n",
            "Epoch 00014: loss improved from 1.50805 to 1.50479, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f59c909e1d0>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5048 - accuracy: 0.3457 - val_loss: 1.4946 - val_accuracy: 0.3356\n",
            "Epoch 15/25\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5048 - accuracy: 0.3452\n",
            "Epoch 00015: loss did not improve from 1.50479\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5049 - accuracy: 0.3452 - val_loss: 1.4905 - val_accuracy: 0.3361\n",
            "Epoch 16/25\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5027 - accuracy: 0.3489\n",
            "Epoch 00016: loss improved from 1.50479 to 1.50248, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f59c909e1d0>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 9s 14ms/step - loss: 1.5025 - accuracy: 0.3484 - val_loss: 1.4910 - val_accuracy: 0.3227\n",
            "Epoch 17/25\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5026 - accuracy: 0.3457\n",
            "Epoch 00017: loss did not improve from 1.50248\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5027 - accuracy: 0.3458 - val_loss: 1.4920 - val_accuracy: 0.3358\n",
            "Epoch 18/25\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5007 - accuracy: 0.3466\n",
            "Epoch 00018: loss improved from 1.50248 to 1.50078, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f59c909e1d0>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 9s 15ms/step - loss: 1.5008 - accuracy: 0.3465 - val_loss: 1.4932 - val_accuracy: 0.3237\n",
            "Epoch 19/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5007 - accuracy: 0.3476\n",
            "Epoch 00019: loss improved from 1.50078 to 1.50071, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f59c909e1d0>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5007 - accuracy: 0.3472 - val_loss: 1.4969 - val_accuracy: 0.3353\n",
            "Epoch 20/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.4983 - accuracy: 0.3464\n",
            "Epoch 00020: loss improved from 1.50071 to 1.49821, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f59c909e1d0>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4982 - accuracy: 0.3469 - val_loss: 1.5061 - val_accuracy: 0.3367\n",
            "Epoch 21/25\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.4974 - accuracy: 0.3492\n",
            "Epoch 00021: loss improved from 1.49821 to 1.49756, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f59c909e1d0>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4976 - accuracy: 0.3494 - val_loss: 1.4918 - val_accuracy: 0.3410\n",
            "Epoch 22/25\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.4949 - accuracy: 0.3558\n",
            "Epoch 00022: loss improved from 1.49756 to 1.49498, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f59c909e1d0>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4950 - accuracy: 0.3557 - val_loss: 1.4959 - val_accuracy: 0.3375\n",
            "Epoch 23/25\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.4952 - accuracy: 0.3508\n",
            "Epoch 00023: loss did not improve from 1.49498\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4954 - accuracy: 0.3505 - val_loss: 1.4967 - val_accuracy: 0.3356\n",
            "Epoch 24/25\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.4957 - accuracy: 0.3497\n",
            "Epoch 00024: loss did not improve from 1.49498\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4956 - accuracy: 0.3499 - val_loss: 1.4963 - val_accuracy: 0.3377\n",
            "Epoch 25/25\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.4926 - accuracy: 0.3525\n",
            "Epoch 00025: loss improved from 1.49498 to 1.49258, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f59c909e1d0>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.4926 - accuracy: 0.3526 - val_loss: 1.4902 - val_accuracy: 0.3283\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/25\n",
            "  2/595 [..............................] - ETA: 33s - loss: 2.1209 - accuracy: 0.0800WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0158s vs `on_train_batch_end` time: 0.0965s). Check your callbacks.\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.6698 - accuracy: 0.3214\n",
            "Epoch 00001: loss improved from inf to 1.66937, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f59c8cb1e80>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.6694 - accuracy: 0.3216 - val_loss: 1.5491 - val_accuracy: 0.3399\n",
            "Epoch 2/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5571 - accuracy: 0.3437\n",
            "Epoch 00002: loss improved from 1.66937 to 1.55727, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f59c8cb1e80>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5573 - accuracy: 0.3436 - val_loss: 1.5178 - val_accuracy: 0.3399\n",
            "Epoch 3/25\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5417 - accuracy: 0.3437\n",
            "Epoch 00003: loss improved from 1.55727 to 1.54183, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f59c8cb1e80>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5418 - accuracy: 0.3436 - val_loss: 1.5095 - val_accuracy: 0.3399\n",
            "Epoch 4/25\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5361 - accuracy: 0.3436\n",
            "Epoch 00004: loss improved from 1.54183 to 1.53613, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f59c8cb1e80>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5361 - accuracy: 0.3436 - val_loss: 1.5045 - val_accuracy: 0.3399\n",
            "Epoch 5/25\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5332 - accuracy: 0.3438\n",
            "Epoch 00005: loss improved from 1.53613 to 1.53350, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f59c8cb1e80>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5335 - accuracy: 0.3436 - val_loss: 1.5022 - val_accuracy: 0.3399\n",
            "Epoch 6/25\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5329 - accuracy: 0.3436\n",
            "Epoch 00006: loss improved from 1.53350 to 1.53267, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f59c8cb1e80>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5327 - accuracy: 0.3436 - val_loss: 1.5012 - val_accuracy: 0.3399\n",
            "Epoch 7/25\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5309 - accuracy: 0.3436\n",
            "Epoch 00007: loss improved from 1.53267 to 1.53082, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f59c8cb1e80>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5308 - accuracy: 0.3436 - val_loss: 1.4997 - val_accuracy: 0.3399\n",
            "Epoch 8/25\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5305 - accuracy: 0.3437\n",
            "Epoch 00008: loss improved from 1.53082 to 1.53056, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f59c8cb1e80>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5306 - accuracy: 0.3436 - val_loss: 1.4995 - val_accuracy: 0.3399\n",
            "Epoch 9/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5303 - accuracy: 0.3432\n",
            "Epoch 00009: loss improved from 1.53056 to 1.52996, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f59c8cb1e80>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5300 - accuracy: 0.3436 - val_loss: 1.4995 - val_accuracy: 0.3399\n",
            "Epoch 10/25\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5296 - accuracy: 0.3436\n",
            "Epoch 00010: loss improved from 1.52996 to 1.52963, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f59c8cb1e80>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5296 - accuracy: 0.3436 - val_loss: 1.4984 - val_accuracy: 0.3399\n",
            "Epoch 11/25\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5298 - accuracy: 0.3438\n",
            "Epoch 00011: loss did not improve from 1.52963\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5297 - accuracy: 0.3436 - val_loss: 1.4986 - val_accuracy: 0.3399\n",
            "Epoch 12/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5284 - accuracy: 0.3436\n",
            "Epoch 00012: loss improved from 1.52963 to 1.52869, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f59c8cb1e80>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5287 - accuracy: 0.3436 - val_loss: 1.4984 - val_accuracy: 0.3399\n",
            "Epoch 13/25\n",
            "589/595 [============================>.] - ETA: 0s - loss: 1.5289 - accuracy: 0.3438\n",
            "Epoch 00013: loss did not improve from 1.52869\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5289 - accuracy: 0.3436 - val_loss: 1.4982 - val_accuracy: 0.3399\n",
            "Epoch 14/25\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5291 - accuracy: 0.3441\n",
            "Epoch 00014: loss did not improve from 1.52869\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5294 - accuracy: 0.3436 - val_loss: 1.4981 - val_accuracy: 0.3399\n",
            "Epoch 15/25\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5292 - accuracy: 0.3434\n",
            "Epoch 00015: loss did not improve from 1.52869\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5291 - accuracy: 0.3436 - val_loss: 1.4987 - val_accuracy: 0.3399\n",
            "Epoch 16/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5290 - accuracy: 0.3437\n",
            "Epoch 00016: loss did not improve from 1.52869\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5291 - accuracy: 0.3436 - val_loss: 1.4984 - val_accuracy: 0.3399\n",
            "Epoch 17/25\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5290 - accuracy: 0.3436\n",
            "Epoch 00017: loss did not improve from 1.52869\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5290 - accuracy: 0.3436 - val_loss: 1.4980 - val_accuracy: 0.3399\n",
            "Epoch 18/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5293 - accuracy: 0.3434\n",
            "Epoch 00018: loss did not improve from 1.52869\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5292 - accuracy: 0.3436 - val_loss: 1.4981 - val_accuracy: 0.3399\n",
            "Epoch 19/25\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5284 - accuracy: 0.3436\n",
            "Epoch 00019: loss improved from 1.52869 to 1.52842, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f59c8cb1e80>_Batch25_LR0.001_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5284 - accuracy: 0.3436 - val_loss: 1.4979 - val_accuracy: 0.3399\n",
            "Epoch 20/25\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5287 - accuracy: 0.3438\n",
            "Epoch 00020: loss did not improve from 1.52842\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5285 - accuracy: 0.3437 - val_loss: 1.4980 - val_accuracy: 0.3399\n",
            "Epoch 21/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5288 - accuracy: 0.3436\n",
            "Epoch 00021: loss did not improve from 1.52842\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5287 - accuracy: 0.3436 - val_loss: 1.4978 - val_accuracy: 0.3399\n",
            "Epoch 22/25\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5292 - accuracy: 0.3433\n",
            "Epoch 00022: loss did not improve from 1.52842\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5291 - accuracy: 0.3436 - val_loss: 1.4980 - val_accuracy: 0.3399\n",
            "Epoch 23/25\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5290 - accuracy: 0.3436\n",
            "Epoch 00023: loss did not improve from 1.52842\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5291 - accuracy: 0.3436 - val_loss: 1.4981 - val_accuracy: 0.3399\n",
            "Epoch 24/25\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5285 - accuracy: 0.3436\n",
            "Epoch 00024: loss did not improve from 1.52842\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5285 - accuracy: 0.3436 - val_loss: 1.4979 - val_accuracy: 0.3399\n",
            "Epoch 25/25\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5289 - accuracy: 0.3436\n",
            "Epoch 00025: loss did not improve from 1.52842\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5287 - accuracy: 0.3436 - val_loss: 1.4977 - val_accuracy: 0.3399\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/25\n",
            "  2/595 [..............................] - ETA: 40s - loss: 2.1576 - accuracy: 0.0600WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0153s vs `on_train_batch_end` time: 0.1207s). Check your callbacks.\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5562 - accuracy: 0.3308\n",
            "Epoch 00001: loss improved from inf to 1.55579, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59c8dc0f60>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5558 - accuracy: 0.3309 - val_loss: 1.4990 - val_accuracy: 0.3399\n",
            "Epoch 2/25\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5389 - accuracy: 0.3372\n",
            "Epoch 00002: loss improved from 1.55579 to 1.53883, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59c8dc0f60>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5388 - accuracy: 0.3374 - val_loss: 1.5072 - val_accuracy: 0.3399\n",
            "Epoch 3/25\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5325 - accuracy: 0.3380\n",
            "Epoch 00003: loss improved from 1.53883 to 1.53253, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59c8dc0f60>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5325 - accuracy: 0.3380 - val_loss: 1.5163 - val_accuracy: 0.3399\n",
            "Epoch 4/25\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5314 - accuracy: 0.3427\n",
            "Epoch 00004: loss improved from 1.53253 to 1.53152, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59c8dc0f60>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5315 - accuracy: 0.3425 - val_loss: 1.5035 - val_accuracy: 0.3399\n",
            "Epoch 5/25\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5286 - accuracy: 0.3412\n",
            "Epoch 00005: loss improved from 1.53152 to 1.52848, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59c8dc0f60>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 9s 15ms/step - loss: 1.5285 - accuracy: 0.3415 - val_loss: 1.5018 - val_accuracy: 0.3399\n",
            "Epoch 6/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5268 - accuracy: 0.3419\n",
            "Epoch 00006: loss improved from 1.52848 to 1.52661, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59c8dc0f60>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5266 - accuracy: 0.3420 - val_loss: 1.4989 - val_accuracy: 0.3399\n",
            "Epoch 7/25\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5255 - accuracy: 0.3433\n",
            "Epoch 00007: loss improved from 1.52661 to 1.52547, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59c8dc0f60>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5255 - accuracy: 0.3433 - val_loss: 1.5056 - val_accuracy: 0.3399\n",
            "Epoch 8/25\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5247 - accuracy: 0.3436\n",
            "Epoch 00008: loss improved from 1.52547 to 1.52494, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59c8dc0f60>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5249 - accuracy: 0.3434 - val_loss: 1.5007 - val_accuracy: 0.3399\n",
            "Epoch 9/25\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5257 - accuracy: 0.3439\n",
            "Epoch 00009: loss did not improve from 1.52494\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5254 - accuracy: 0.3444 - val_loss: 1.5045 - val_accuracy: 0.3399\n",
            "Epoch 10/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5248 - accuracy: 0.3420\n",
            "Epoch 00010: loss improved from 1.52494 to 1.52479, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59c8dc0f60>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5248 - accuracy: 0.3418 - val_loss: 1.4934 - val_accuracy: 0.3396\n",
            "Epoch 11/25\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5240 - accuracy: 0.3430\n",
            "Epoch 00011: loss improved from 1.52479 to 1.52407, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59c8dc0f60>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5241 - accuracy: 0.3428 - val_loss: 1.5073 - val_accuracy: 0.3399\n",
            "Epoch 12/25\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5242 - accuracy: 0.3437\n",
            "Epoch 00012: loss improved from 1.52407 to 1.52375, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59c8dc0f60>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5238 - accuracy: 0.3440 - val_loss: 1.5033 - val_accuracy: 0.3399\n",
            "Epoch 13/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5226 - accuracy: 0.3438\n",
            "Epoch 00013: loss improved from 1.52375 to 1.52267, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59c8dc0f60>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5227 - accuracy: 0.3434 - val_loss: 1.4944 - val_accuracy: 0.3399\n",
            "Epoch 14/25\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5216 - accuracy: 0.3436\n",
            "Epoch 00014: loss improved from 1.52267 to 1.52157, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59c8dc0f60>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5216 - accuracy: 0.3436 - val_loss: 1.4969 - val_accuracy: 0.3399\n",
            "Epoch 15/25\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5215 - accuracy: 0.3424\n",
            "Epoch 00015: loss did not improve from 1.52157\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5217 - accuracy: 0.3422 - val_loss: 1.5020 - val_accuracy: 0.3399\n",
            "Epoch 16/25\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5214 - accuracy: 0.3443\n",
            "Epoch 00016: loss did not improve from 1.52157\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5217 - accuracy: 0.3442 - val_loss: 1.4994 - val_accuracy: 0.3399\n",
            "Epoch 17/25\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5212 - accuracy: 0.3424\n",
            "Epoch 00017: loss improved from 1.52157 to 1.52112, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59c8dc0f60>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5211 - accuracy: 0.3424 - val_loss: 1.4951 - val_accuracy: 0.3399\n",
            "Epoch 18/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5206 - accuracy: 0.3428\n",
            "Epoch 00018: loss improved from 1.52112 to 1.52049, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59c8dc0f60>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5205 - accuracy: 0.3429 - val_loss: 1.4941 - val_accuracy: 0.3399\n",
            "Epoch 19/25\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5202 - accuracy: 0.3428\n",
            "Epoch 00019: loss improved from 1.52049 to 1.52019, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59c8dc0f60>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5202 - accuracy: 0.3428 - val_loss: 1.5056 - val_accuracy: 0.3399\n",
            "Epoch 20/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5191 - accuracy: 0.3427\n",
            "Epoch 00020: loss improved from 1.52019 to 1.51922, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59c8dc0f60>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5192 - accuracy: 0.3430 - val_loss: 1.5182 - val_accuracy: 0.3399\n",
            "Epoch 21/25\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5188 - accuracy: 0.3432\n",
            "Epoch 00021: loss improved from 1.51922 to 1.51883, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59c8dc0f60>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5188 - accuracy: 0.3432 - val_loss: 1.4992 - val_accuracy: 0.3399\n",
            "Epoch 22/25\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5177 - accuracy: 0.3433\n",
            "Epoch 00022: loss improved from 1.51883 to 1.51818, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59c8dc0f60>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5182 - accuracy: 0.3432 - val_loss: 1.5033 - val_accuracy: 0.3399\n",
            "Epoch 23/25\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5161 - accuracy: 0.3443\n",
            "Epoch 00023: loss improved from 1.51818 to 1.51637, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59c8dc0f60>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5164 - accuracy: 0.3447 - val_loss: 1.5086 - val_accuracy: 0.3399\n",
            "Epoch 24/25\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5167 - accuracy: 0.3447\n",
            "Epoch 00024: loss did not improve from 1.51637\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5168 - accuracy: 0.3446 - val_loss: 1.4969 - val_accuracy: 0.3399\n",
            "Epoch 25/25\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5174 - accuracy: 0.3442\n",
            "Epoch 00025: loss did not improve from 1.51637\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5173 - accuracy: 0.3443 - val_loss: 1.5104 - val_accuracy: 0.3399\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/25\n",
            "  2/595 [..............................] - ETA: 50s - loss: 3.5273 - accuracy: 0.2000WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0208s vs `on_train_batch_end` time: 0.1441s). Check your callbacks.\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5615 - accuracy: 0.3328\n",
            "Epoch 00001: loss improved from inf to 1.56149, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f59c8aa62e8>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 9s 14ms/step - loss: 1.5615 - accuracy: 0.3328 - val_loss: 1.5115 - val_accuracy: 0.3399\n",
            "Epoch 2/25\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5301 - accuracy: 0.3432\n",
            "Epoch 00002: loss improved from 1.56149 to 1.52966, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f59c8aa62e8>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 9s 14ms/step - loss: 1.5297 - accuracy: 0.3436 - val_loss: 1.4937 - val_accuracy: 0.3399\n",
            "Epoch 3/25\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5294 - accuracy: 0.3435\n",
            "Epoch 00003: loss improved from 1.52966 to 1.52937, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f59c8aa62e8>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5294 - accuracy: 0.3436 - val_loss: 1.4940 - val_accuracy: 0.3399\n",
            "Epoch 4/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5294 - accuracy: 0.3441\n",
            "Epoch 00004: loss did not improve from 1.52937\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5295 - accuracy: 0.3436 - val_loss: 1.4967 - val_accuracy: 0.3399\n",
            "Epoch 5/25\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5297 - accuracy: 0.3436\n",
            "Epoch 00005: loss did not improve from 1.52937\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5295 - accuracy: 0.3436 - val_loss: 1.4932 - val_accuracy: 0.3399\n",
            "Epoch 6/25\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5296 - accuracy: 0.3437\n",
            "Epoch 00006: loss did not improve from 1.52937\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5297 - accuracy: 0.3436 - val_loss: 1.4963 - val_accuracy: 0.3399\n",
            "Epoch 7/25\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5295 - accuracy: 0.3439\n",
            "Epoch 00007: loss did not improve from 1.52937\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5295 - accuracy: 0.3436 - val_loss: 1.4966 - val_accuracy: 0.3399\n",
            "Epoch 8/25\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5300 - accuracy: 0.3431\n",
            "Epoch 00008: loss did not improve from 1.52937\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5298 - accuracy: 0.3436 - val_loss: 1.4957 - val_accuracy: 0.3399\n",
            "Epoch 9/25\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5299 - accuracy: 0.3436\n",
            "Epoch 00009: loss did not improve from 1.52937\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5297 - accuracy: 0.3436 - val_loss: 1.4959 - val_accuracy: 0.3399\n",
            "Epoch 10/25\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5302 - accuracy: 0.3436\n",
            "Epoch 00010: loss did not improve from 1.52937\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5302 - accuracy: 0.3436 - val_loss: 1.4923 - val_accuracy: 0.3399\n",
            "Epoch 11/25\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5304 - accuracy: 0.3436\n",
            "Epoch 00011: loss did not improve from 1.52937\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5305 - accuracy: 0.3436 - val_loss: 1.4912 - val_accuracy: 0.3399\n",
            "Epoch 12/25\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5307 - accuracy: 0.3435\n",
            "Epoch 00012: loss did not improve from 1.52937\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5306 - accuracy: 0.3436 - val_loss: 1.4987 - val_accuracy: 0.3399\n",
            "Epoch 13/25\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5302 - accuracy: 0.3436\n",
            "Epoch 00013: loss did not improve from 1.52937\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5302 - accuracy: 0.3436 - val_loss: 1.4929 - val_accuracy: 0.3399\n",
            "Epoch 14/25\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5303 - accuracy: 0.3438\n",
            "Epoch 00014: loss did not improve from 1.52937\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5302 - accuracy: 0.3436 - val_loss: 1.4968 - val_accuracy: 0.3399\n",
            "Epoch 15/25\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5299 - accuracy: 0.3436\n",
            "Epoch 00015: loss did not improve from 1.52937\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5299 - accuracy: 0.3436 - val_loss: 1.4945 - val_accuracy: 0.3399\n",
            "Epoch 16/25\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5303 - accuracy: 0.3436\n",
            "Epoch 00016: loss did not improve from 1.52937\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5303 - accuracy: 0.3436 - val_loss: 1.4920 - val_accuracy: 0.3399\n",
            "Epoch 17/25\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5296 - accuracy: 0.3439\n",
            "Epoch 00017: loss did not improve from 1.52937\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5299 - accuracy: 0.3436 - val_loss: 1.4910 - val_accuracy: 0.3399\n",
            "Epoch 18/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5309 - accuracy: 0.3438\n",
            "Epoch 00018: loss did not improve from 1.52937\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5310 - accuracy: 0.3436 - val_loss: 1.4943 - val_accuracy: 0.3399\n",
            "Epoch 19/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5307 - accuracy: 0.3431\n",
            "Epoch 00019: loss did not improve from 1.52937\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5303 - accuracy: 0.3436 - val_loss: 1.4973 - val_accuracy: 0.3399\n",
            "Epoch 20/25\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5301 - accuracy: 0.3438\n",
            "Epoch 00020: loss did not improve from 1.52937\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5301 - accuracy: 0.3436 - val_loss: 1.4909 - val_accuracy: 0.3399\n",
            "Epoch 21/25\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5302 - accuracy: 0.3439\n",
            "Epoch 00021: loss did not improve from 1.52937\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5301 - accuracy: 0.3436 - val_loss: 1.4938 - val_accuracy: 0.3399\n",
            "Epoch 22/25\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5303 - accuracy: 0.3432\n",
            "Epoch 00022: loss did not improve from 1.52937\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5298 - accuracy: 0.3436 - val_loss: 1.4922 - val_accuracy: 0.3399\n",
            "Epoch 23/25\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5295 - accuracy: 0.3436\n",
            "Epoch 00023: loss did not improve from 1.52937\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5295 - accuracy: 0.3436 - val_loss: 1.4925 - val_accuracy: 0.3399\n",
            "Epoch 24/25\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5305 - accuracy: 0.3432\n",
            "Epoch 00024: loss did not improve from 1.52937\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5303 - accuracy: 0.3436 - val_loss: 1.4978 - val_accuracy: 0.3399\n",
            "Epoch 25/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5299 - accuracy: 0.3436\n",
            "Epoch 00025: loss did not improve from 1.52937\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5297 - accuracy: 0.3436 - val_loss: 1.4975 - val_accuracy: 0.3399\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/25\n",
            "  2/595 [..............................] - ETA: 33s - loss: 1.9792 - accuracy: 0.2200WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0152s vs `on_train_batch_end` time: 0.1007s). Check your callbacks.\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5536 - accuracy: 0.3335\n",
            "Epoch 00001: loss improved from inf to 1.55335, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f59c8bc5828>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5533 - accuracy: 0.3338 - val_loss: 1.4947 - val_accuracy: 0.3323\n",
            "Epoch 2/25\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5327 - accuracy: 0.3410\n",
            "Epoch 00002: loss improved from 1.55335 to 1.53266, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f59c8bc5828>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5327 - accuracy: 0.3411 - val_loss: 1.5036 - val_accuracy: 0.3399\n",
            "Epoch 3/25\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5295 - accuracy: 0.3437\n",
            "Epoch 00003: loss improved from 1.53266 to 1.52941, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f59c8bc5828>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5294 - accuracy: 0.3436 - val_loss: 1.4982 - val_accuracy: 0.3399\n",
            "Epoch 4/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5288 - accuracy: 0.3439\n",
            "Epoch 00004: loss improved from 1.52941 to 1.52909, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f59c8bc5828>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5291 - accuracy: 0.3436 - val_loss: 1.4991 - val_accuracy: 0.3399\n",
            "Epoch 5/25\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5289 - accuracy: 0.3434\n",
            "Epoch 00005: loss improved from 1.52909 to 1.52907, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f59c8bc5828>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5291 - accuracy: 0.3436 - val_loss: 1.4947 - val_accuracy: 0.3399\n",
            "Epoch 6/25\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5291 - accuracy: 0.3436\n",
            "Epoch 00006: loss did not improve from 1.52907\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5291 - accuracy: 0.3436 - val_loss: 1.4954 - val_accuracy: 0.3399\n",
            "Epoch 7/25\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5288 - accuracy: 0.3436\n",
            "Epoch 00007: loss improved from 1.52907 to 1.52881, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f59c8bc5828>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5288 - accuracy: 0.3436 - val_loss: 1.4999 - val_accuracy: 0.3399\n",
            "Epoch 8/25\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5288 - accuracy: 0.3437\n",
            "Epoch 00008: loss did not improve from 1.52881\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5289 - accuracy: 0.3436 - val_loss: 1.4978 - val_accuracy: 0.3399\n",
            "Epoch 9/25\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5293 - accuracy: 0.3436\n",
            "Epoch 00009: loss did not improve from 1.52881\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5292 - accuracy: 0.3436 - val_loss: 1.5000 - val_accuracy: 0.3399\n",
            "Epoch 10/25\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5291 - accuracy: 0.3436\n",
            "Epoch 00010: loss did not improve from 1.52881\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5291 - accuracy: 0.3436 - val_loss: 1.4912 - val_accuracy: 0.3399\n",
            "Epoch 11/25\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5289 - accuracy: 0.3436\n",
            "Epoch 00011: loss did not improve from 1.52881\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5289 - accuracy: 0.3436 - val_loss: 1.4949 - val_accuracy: 0.3399\n",
            "Epoch 12/25\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5291 - accuracy: 0.3432\n",
            "Epoch 00012: loss did not improve from 1.52881\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5290 - accuracy: 0.3436 - val_loss: 1.4972 - val_accuracy: 0.3399\n",
            "Epoch 13/25\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5291 - accuracy: 0.3434\n",
            "Epoch 00013: loss did not improve from 1.52881\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5290 - accuracy: 0.3436 - val_loss: 1.4924 - val_accuracy: 0.3399\n",
            "Epoch 14/25\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5294 - accuracy: 0.3435\n",
            "Epoch 00014: loss did not improve from 1.52881\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5293 - accuracy: 0.3436 - val_loss: 1.4974 - val_accuracy: 0.3399\n",
            "Epoch 15/25\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5289 - accuracy: 0.3438\n",
            "Epoch 00015: loss did not improve from 1.52881\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5288 - accuracy: 0.3436 - val_loss: 1.5003 - val_accuracy: 0.3399\n",
            "Epoch 16/25\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5285 - accuracy: 0.3440\n",
            "Epoch 00016: loss improved from 1.52881 to 1.52861, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f59c8bc5828>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5286 - accuracy: 0.3436 - val_loss: 1.4977 - val_accuracy: 0.3399\n",
            "Epoch 17/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5289 - accuracy: 0.3435\n",
            "Epoch 00017: loss did not improve from 1.52861\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5292 - accuracy: 0.3436 - val_loss: 1.4991 - val_accuracy: 0.3399\n",
            "Epoch 18/25\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5294 - accuracy: 0.3436\n",
            "Epoch 00018: loss did not improve from 1.52861\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5293 - accuracy: 0.3436 - val_loss: 1.4997 - val_accuracy: 0.3399\n",
            "Epoch 19/25\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5286 - accuracy: 0.3438\n",
            "Epoch 00019: loss did not improve from 1.52861\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5289 - accuracy: 0.3436 - val_loss: 1.4967 - val_accuracy: 0.3399\n",
            "Epoch 20/25\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5289 - accuracy: 0.3437\n",
            "Epoch 00020: loss did not improve from 1.52861\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5291 - accuracy: 0.3436 - val_loss: 1.5008 - val_accuracy: 0.3399\n",
            "Epoch 21/25\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5289 - accuracy: 0.3438\n",
            "Epoch 00021: loss did not improve from 1.52861\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5290 - accuracy: 0.3436 - val_loss: 1.4944 - val_accuracy: 0.3399\n",
            "Epoch 22/25\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5288 - accuracy: 0.3437\n",
            "Epoch 00022: loss did not improve from 1.52861\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5289 - accuracy: 0.3436 - val_loss: 1.4968 - val_accuracy: 0.3399\n",
            "Epoch 23/25\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5291 - accuracy: 0.3436\n",
            "Epoch 00023: loss did not improve from 1.52861\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5289 - accuracy: 0.3436 - val_loss: 1.4975 - val_accuracy: 0.3399\n",
            "Epoch 24/25\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5289 - accuracy: 0.3436\n",
            "Epoch 00024: loss did not improve from 1.52861\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5289 - accuracy: 0.3436 - val_loss: 1.4962 - val_accuracy: 0.3399\n",
            "Epoch 25/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5288 - accuracy: 0.3440\n",
            "Epoch 00025: loss did not improve from 1.52861\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5287 - accuracy: 0.3436 - val_loss: 1.4947 - val_accuracy: 0.3399\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/25\n",
            "  2/595 [..............................] - ETA: 34s - loss: 2.0010 - accuracy: 0.1400WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0165s vs `on_train_batch_end` time: 0.0975s). Check your callbacks.\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5469 - accuracy: 0.3292\n",
            "Epoch 00001: loss improved from inf to 1.54695, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59c8ff0e80>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5469 - accuracy: 0.3292 - val_loss: 1.5165 - val_accuracy: 0.3399\n",
            "Epoch 2/25\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5330 - accuracy: 0.3392\n",
            "Epoch 00002: loss improved from 1.54695 to 1.53307, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59c8ff0e80>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5331 - accuracy: 0.3391 - val_loss: 1.5040 - val_accuracy: 0.3399\n",
            "Epoch 3/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5280 - accuracy: 0.3436\n",
            "Epoch 00003: loss improved from 1.53307 to 1.52826, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59c8ff0e80>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5283 - accuracy: 0.3430 - val_loss: 1.5046 - val_accuracy: 0.3399\n",
            "Epoch 4/25\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5257 - accuracy: 0.3422\n",
            "Epoch 00004: loss improved from 1.52826 to 1.52569, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59c8ff0e80>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5257 - accuracy: 0.3422 - val_loss: 1.5107 - val_accuracy: 0.3399\n",
            "Epoch 5/25\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5236 - accuracy: 0.3441\n",
            "Epoch 00005: loss improved from 1.52569 to 1.52361, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59c8ff0e80>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5236 - accuracy: 0.3441 - val_loss: 1.4989 - val_accuracy: 0.3399\n",
            "Epoch 6/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5225 - accuracy: 0.3432\n",
            "Epoch 00006: loss improved from 1.52361 to 1.52262, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59c8ff0e80>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5226 - accuracy: 0.3433 - val_loss: 1.5001 - val_accuracy: 0.3399\n",
            "Epoch 7/25\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5218 - accuracy: 0.3446\n",
            "Epoch 00007: loss improved from 1.52262 to 1.52158, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59c8ff0e80>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5216 - accuracy: 0.3443 - val_loss: 1.4977 - val_accuracy: 0.3399\n",
            "Epoch 8/25\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5198 - accuracy: 0.3424\n",
            "Epoch 00008: loss improved from 1.52158 to 1.51971, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59c8ff0e80>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5197 - accuracy: 0.3428 - val_loss: 1.5040 - val_accuracy: 0.3399\n",
            "Epoch 9/25\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5189 - accuracy: 0.3431\n",
            "Epoch 00009: loss improved from 1.51971 to 1.51921, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59c8ff0e80>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5192 - accuracy: 0.3434 - val_loss: 1.4987 - val_accuracy: 0.3399\n",
            "Epoch 10/25\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5179 - accuracy: 0.3433\n",
            "Epoch 00010: loss improved from 1.51921 to 1.51790, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59c8ff0e80>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5179 - accuracy: 0.3433 - val_loss: 1.4942 - val_accuracy: 0.3399\n",
            "Epoch 11/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5169 - accuracy: 0.3432\n",
            "Epoch 00011: loss improved from 1.51790 to 1.51679, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59c8ff0e80>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5168 - accuracy: 0.3434 - val_loss: 1.4967 - val_accuracy: 0.3399\n",
            "Epoch 12/25\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5161 - accuracy: 0.3459\n",
            "Epoch 00012: loss improved from 1.51679 to 1.51613, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59c8ff0e80>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5161 - accuracy: 0.3459 - val_loss: 1.4969 - val_accuracy: 0.3399\n",
            "Epoch 13/25\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5153 - accuracy: 0.3431\n",
            "Epoch 00013: loss improved from 1.51613 to 1.51543, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59c8ff0e80>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5154 - accuracy: 0.3430 - val_loss: 1.4968 - val_accuracy: 0.3399\n",
            "Epoch 14/25\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5139 - accuracy: 0.3450\n",
            "Epoch 00014: loss improved from 1.51543 to 1.51426, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59c8ff0e80>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5143 - accuracy: 0.3448 - val_loss: 1.4954 - val_accuracy: 0.3399\n",
            "Epoch 15/25\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5142 - accuracy: 0.3452\n",
            "Epoch 00015: loss did not improve from 1.51426\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5143 - accuracy: 0.3451 - val_loss: 1.4909 - val_accuracy: 0.3399\n",
            "Epoch 16/25\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5143 - accuracy: 0.3444\n",
            "Epoch 00016: loss improved from 1.51426 to 1.51413, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59c8ff0e80>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5141 - accuracy: 0.3443 - val_loss: 1.4950 - val_accuracy: 0.3399\n",
            "Epoch 17/25\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5128 - accuracy: 0.3468\n",
            "Epoch 00017: loss improved from 1.51413 to 1.51348, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59c8ff0e80>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5135 - accuracy: 0.3463 - val_loss: 1.4960 - val_accuracy: 0.3396\n",
            "Epoch 18/25\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5123 - accuracy: 0.3435\n",
            "Epoch 00018: loss improved from 1.51348 to 1.51233, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59c8ff0e80>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5123 - accuracy: 0.3435 - val_loss: 1.4957 - val_accuracy: 0.3399\n",
            "Epoch 19/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5118 - accuracy: 0.3470\n",
            "Epoch 00019: loss improved from 1.51233 to 1.51209, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59c8ff0e80>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5121 - accuracy: 0.3469 - val_loss: 1.4970 - val_accuracy: 0.3361\n",
            "Epoch 20/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5123 - accuracy: 0.3465\n",
            "Epoch 00020: loss did not improve from 1.51209\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5122 - accuracy: 0.3466 - val_loss: 1.4968 - val_accuracy: 0.3399\n",
            "Epoch 21/25\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5118 - accuracy: 0.3465\n",
            "Epoch 00021: loss improved from 1.51209 to 1.51166, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59c8ff0e80>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5117 - accuracy: 0.3469 - val_loss: 1.4954 - val_accuracy: 0.3399\n",
            "Epoch 22/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5104 - accuracy: 0.3455\n",
            "Epoch 00022: loss improved from 1.51166 to 1.51054, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59c8ff0e80>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5105 - accuracy: 0.3456 - val_loss: 1.4963 - val_accuracy: 0.3372\n",
            "Epoch 23/25\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5105 - accuracy: 0.3460\n",
            "Epoch 00023: loss did not improve from 1.51054\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5107 - accuracy: 0.3459 - val_loss: 1.4945 - val_accuracy: 0.3348\n",
            "Epoch 24/25\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5088 - accuracy: 0.3446\n",
            "Epoch 00024: loss improved from 1.51054 to 1.50878, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59c8ff0e80>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5088 - accuracy: 0.3447 - val_loss: 1.4971 - val_accuracy: 0.3369\n",
            "Epoch 25/25\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5100 - accuracy: 0.3434\n",
            "Epoch 00025: loss did not improve from 1.50878\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5100 - accuracy: 0.3434 - val_loss: 1.4946 - val_accuracy: 0.3358\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/25\n",
            "  2/595 [..............................] - ETA: 43s - loss: 2.1160 - accuracy: 0.2600WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0177s vs `on_train_batch_end` time: 0.1277s). Check your callbacks.\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5451 - accuracy: 0.3324\n",
            "Epoch 00001: loss improved from inf to 1.54523, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f59c8bcde48>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 9s 14ms/step - loss: 1.5452 - accuracy: 0.3324 - val_loss: 1.5013 - val_accuracy: 0.3399\n",
            "Epoch 2/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5313 - accuracy: 0.3397\n",
            "Epoch 00002: loss improved from 1.54523 to 1.53107, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f59c8bcde48>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5311 - accuracy: 0.3400 - val_loss: 1.4999 - val_accuracy: 0.3399\n",
            "Epoch 3/25\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5271 - accuracy: 0.3432\n",
            "Epoch 00003: loss improved from 1.53107 to 1.52712, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f59c8bcde48>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5271 - accuracy: 0.3432 - val_loss: 1.4883 - val_accuracy: 0.3399\n",
            "Epoch 4/25\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5238 - accuracy: 0.3425\n",
            "Epoch 00004: loss improved from 1.52712 to 1.52378, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f59c8bcde48>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5238 - accuracy: 0.3425 - val_loss: 1.4862 - val_accuracy: 0.3372\n",
            "Epoch 5/25\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5213 - accuracy: 0.3443\n",
            "Epoch 00005: loss improved from 1.52378 to 1.52140, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f59c8bcde48>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5214 - accuracy: 0.3441 - val_loss: 1.4954 - val_accuracy: 0.3372\n",
            "Epoch 6/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5191 - accuracy: 0.3420\n",
            "Epoch 00006: loss improved from 1.52140 to 1.51938, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f59c8bcde48>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5194 - accuracy: 0.3418 - val_loss: 1.4909 - val_accuracy: 0.3372\n",
            "Epoch 7/25\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5154 - accuracy: 0.3408\n",
            "Epoch 00007: loss improved from 1.51938 to 1.51537, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f59c8bcde48>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5154 - accuracy: 0.3408 - val_loss: 1.4971 - val_accuracy: 0.3380\n",
            "Epoch 8/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5163 - accuracy: 0.3457\n",
            "Epoch 00008: loss did not improve from 1.51537\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5169 - accuracy: 0.3457 - val_loss: 1.5035 - val_accuracy: 0.3380\n",
            "Epoch 9/25\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5146 - accuracy: 0.3439\n",
            "Epoch 00009: loss improved from 1.51537 to 1.51445, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f59c8bcde48>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5144 - accuracy: 0.3443 - val_loss: 1.5064 - val_accuracy: 0.3396\n",
            "Epoch 10/25\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5111 - accuracy: 0.3425\n",
            "Epoch 00010: loss improved from 1.51445 to 1.51114, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f59c8bcde48>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5111 - accuracy: 0.3427 - val_loss: 1.5258 - val_accuracy: 0.3334\n",
            "Epoch 11/25\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5105 - accuracy: 0.3425\n",
            "Epoch 00011: loss improved from 1.51114 to 1.51018, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f59c8bcde48>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5102 - accuracy: 0.3428 - val_loss: 1.4969 - val_accuracy: 0.3219\n",
            "Epoch 12/25\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5077 - accuracy: 0.3461\n",
            "Epoch 00012: loss improved from 1.51018 to 1.50776, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f59c8bcde48>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5078 - accuracy: 0.3461 - val_loss: 1.4837 - val_accuracy: 0.3399\n",
            "Epoch 13/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5055 - accuracy: 0.3414\n",
            "Epoch 00013: loss improved from 1.50776 to 1.50534, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f59c8bcde48>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5053 - accuracy: 0.3412 - val_loss: 1.4943 - val_accuracy: 0.3186\n",
            "Epoch 14/25\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5063 - accuracy: 0.3429\n",
            "Epoch 00014: loss did not improve from 1.50534\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5060 - accuracy: 0.3428 - val_loss: 1.4863 - val_accuracy: 0.3259\n",
            "Epoch 15/25\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5054 - accuracy: 0.3469\n",
            "Epoch 00015: loss did not improve from 1.50534\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5059 - accuracy: 0.3471 - val_loss: 1.4820 - val_accuracy: 0.3332\n",
            "Epoch 16/25\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5019 - accuracy: 0.3453\n",
            "Epoch 00016: loss improved from 1.50534 to 1.50112, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f59c8bcde48>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5011 - accuracy: 0.3459 - val_loss: 1.4956 - val_accuracy: 0.3332\n",
            "Epoch 17/25\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5033 - accuracy: 0.3467\n",
            "Epoch 00017: loss did not improve from 1.50112\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5033 - accuracy: 0.3467 - val_loss: 1.4913 - val_accuracy: 0.3393\n",
            "Epoch 18/25\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.4995 - accuracy: 0.3488\n",
            "Epoch 00018: loss improved from 1.50112 to 1.49953, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f59c8bcde48>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.4995 - accuracy: 0.3488 - val_loss: 1.4847 - val_accuracy: 0.3307\n",
            "Epoch 19/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.4992 - accuracy: 0.3455\n",
            "Epoch 00019: loss did not improve from 1.49953\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4996 - accuracy: 0.3453 - val_loss: 1.4983 - val_accuracy: 0.3057\n",
            "Epoch 20/25\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.4983 - accuracy: 0.3489\n",
            "Epoch 00020: loss improved from 1.49953 to 1.49826, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f59c8bcde48>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.4983 - accuracy: 0.3488 - val_loss: 1.4890 - val_accuracy: 0.3280\n",
            "Epoch 21/25\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.4995 - accuracy: 0.3503\n",
            "Epoch 00021: loss did not improve from 1.49826\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4990 - accuracy: 0.3504 - val_loss: 1.4883 - val_accuracy: 0.3280\n",
            "Epoch 22/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.4998 - accuracy: 0.3504\n",
            "Epoch 00022: loss did not improve from 1.49826\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4998 - accuracy: 0.3504 - val_loss: 1.4912 - val_accuracy: 0.3272\n",
            "Epoch 23/25\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.4991 - accuracy: 0.3470\n",
            "Epoch 00023: loss did not improve from 1.49826\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4993 - accuracy: 0.3469 - val_loss: 1.4950 - val_accuracy: 0.3114\n",
            "Epoch 24/25\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.4965 - accuracy: 0.3500\n",
            "Epoch 00024: loss improved from 1.49826 to 1.49655, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f59c8bcde48>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.4965 - accuracy: 0.3500 - val_loss: 1.4787 - val_accuracy: 0.3272\n",
            "Epoch 25/25\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.4977 - accuracy: 0.3492\n",
            "Epoch 00025: loss did not improve from 1.49655\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4978 - accuracy: 0.3492 - val_loss: 1.5022 - val_accuracy: 0.3253\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/25\n",
            "  2/595 [..............................] - ETA: 44s - loss: 2.1071 - accuracy: 0.1400WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0151s vs `on_train_batch_end` time: 0.1349s). Check your callbacks.\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5449 - accuracy: 0.3418\n",
            "Epoch 00001: loss improved from inf to 1.54494, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f59c45e9fd0>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5449 - accuracy: 0.3418 - val_loss: 1.4955 - val_accuracy: 0.3399\n",
            "Epoch 2/25\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5317 - accuracy: 0.3436\n",
            "Epoch 00002: loss improved from 1.54494 to 1.53172, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f59c45e9fd0>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5317 - accuracy: 0.3436 - val_loss: 1.4993 - val_accuracy: 0.3399\n",
            "Epoch 3/25\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5292 - accuracy: 0.3438\n",
            "Epoch 00003: loss improved from 1.53172 to 1.52936, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f59c45e9fd0>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5294 - accuracy: 0.3436 - val_loss: 1.5000 - val_accuracy: 0.3399\n",
            "Epoch 4/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5290 - accuracy: 0.3432\n",
            "Epoch 00004: loss improved from 1.52936 to 1.52877, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f59c45e9fd0>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5288 - accuracy: 0.3436 - val_loss: 1.4933 - val_accuracy: 0.3399\n",
            "Epoch 5/25\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5294 - accuracy: 0.3435\n",
            "Epoch 00005: loss did not improve from 1.52877\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5296 - accuracy: 0.3436 - val_loss: 1.4981 - val_accuracy: 0.3399\n",
            "Epoch 6/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5287 - accuracy: 0.3438\n",
            "Epoch 00006: loss improved from 1.52877 to 1.52867, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f59c45e9fd0>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 9s 14ms/step - loss: 1.5287 - accuracy: 0.3436 - val_loss: 1.4990 - val_accuracy: 0.3399\n",
            "Epoch 7/25\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5292 - accuracy: 0.3435\n",
            "Epoch 00007: loss did not improve from 1.52867\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5287 - accuracy: 0.3436 - val_loss: 1.4936 - val_accuracy: 0.3399\n",
            "Epoch 8/25\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5287 - accuracy: 0.3436\n",
            "Epoch 00008: loss did not improve from 1.52867\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5287 - accuracy: 0.3436 - val_loss: 1.5011 - val_accuracy: 0.3399\n",
            "Epoch 9/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5286 - accuracy: 0.3434\n",
            "Epoch 00009: loss improved from 1.52867 to 1.52862, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f59c45e9fd0>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5286 - accuracy: 0.3436 - val_loss: 1.5033 - val_accuracy: 0.3399\n",
            "Epoch 10/25\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5274 - accuracy: 0.3436\n",
            "Epoch 00010: loss improved from 1.52862 to 1.52737, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f59c45e9fd0>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5274 - accuracy: 0.3436 - val_loss: 1.5012 - val_accuracy: 0.3399\n",
            "Epoch 11/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5278 - accuracy: 0.3436\n",
            "Epoch 00011: loss did not improve from 1.52737\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5276 - accuracy: 0.3436 - val_loss: 1.4964 - val_accuracy: 0.3399\n",
            "Epoch 12/25\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5262 - accuracy: 0.3437\n",
            "Epoch 00012: loss improved from 1.52737 to 1.52624, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f59c45e9fd0>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5262 - accuracy: 0.3436 - val_loss: 1.4975 - val_accuracy: 0.3399\n",
            "Epoch 13/25\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5259 - accuracy: 0.3437\n",
            "Epoch 00013: loss improved from 1.52624 to 1.52591, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f59c45e9fd0>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5259 - accuracy: 0.3436 - val_loss: 1.5051 - val_accuracy: 0.3399\n",
            "Epoch 14/25\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5253 - accuracy: 0.3434\n",
            "Epoch 00014: loss improved from 1.52591 to 1.52517, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f59c45e9fd0>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5252 - accuracy: 0.3436 - val_loss: 1.4986 - val_accuracy: 0.3399\n",
            "Epoch 15/25\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5258 - accuracy: 0.3429\n",
            "Epoch 00015: loss did not improve from 1.52517\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5252 - accuracy: 0.3436 - val_loss: 1.4991 - val_accuracy: 0.3399\n",
            "Epoch 16/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5249 - accuracy: 0.3436\n",
            "Epoch 00016: loss improved from 1.52517 to 1.52484, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f59c45e9fd0>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5248 - accuracy: 0.3436 - val_loss: 1.4971 - val_accuracy: 0.3399\n",
            "Epoch 17/25\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5242 - accuracy: 0.3440\n",
            "Epoch 00017: loss improved from 1.52484 to 1.52430, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f59c45e9fd0>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5243 - accuracy: 0.3439 - val_loss: 1.5003 - val_accuracy: 0.3399\n",
            "Epoch 18/25\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5237 - accuracy: 0.3437\n",
            "Epoch 00018: loss improved from 1.52430 to 1.52390, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f59c45e9fd0>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5239 - accuracy: 0.3434 - val_loss: 1.5019 - val_accuracy: 0.3399\n",
            "Epoch 19/25\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5235 - accuracy: 0.3436\n",
            "Epoch 00019: loss improved from 1.52390 to 1.52346, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f59c45e9fd0>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5235 - accuracy: 0.3435 - val_loss: 1.5084 - val_accuracy: 0.3399\n",
            "Epoch 20/25\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5232 - accuracy: 0.3433\n",
            "Epoch 00020: loss improved from 1.52346 to 1.52335, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f59c45e9fd0>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5233 - accuracy: 0.3436 - val_loss: 1.5022 - val_accuracy: 0.3399\n",
            "Epoch 21/25\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5231 - accuracy: 0.3435\n",
            "Epoch 00021: loss improved from 1.52335 to 1.52314, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f59c45e9fd0>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5231 - accuracy: 0.3437 - val_loss: 1.5025 - val_accuracy: 0.3399\n",
            "Epoch 22/25\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5234 - accuracy: 0.3435\n",
            "Epoch 00022: loss improved from 1.52314 to 1.52314, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f59c45e9fd0>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5231 - accuracy: 0.3436 - val_loss: 1.5015 - val_accuracy: 0.3399\n",
            "Epoch 23/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5216 - accuracy: 0.3439\n",
            "Epoch 00023: loss improved from 1.52314 to 1.52189, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f59c45e9fd0>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5219 - accuracy: 0.3436 - val_loss: 1.5018 - val_accuracy: 0.3399\n",
            "Epoch 24/25\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5214 - accuracy: 0.3433\n",
            "Epoch 00024: loss improved from 1.52189 to 1.52137, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f59c45e9fd0>_Batch25_LR0.01_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5214 - accuracy: 0.3433 - val_loss: 1.4987 - val_accuracy: 0.3399\n",
            "Epoch 25/25\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5217 - accuracy: 0.3437\n",
            "Epoch 00025: loss did not improve from 1.52137\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5219 - accuracy: 0.3434 - val_loss: 1.4994 - val_accuracy: 0.3399\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/25\n",
            "  2/595 [..............................] - ETA: 32s - loss: 2.4005 - accuracy: 0.1800WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0155s vs `on_train_batch_end` time: 0.0944s). Check your callbacks.\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5523 - accuracy: 0.3327\n",
            "Epoch 00001: loss improved from inf to 1.55214, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59c422fa58>_Batch25_LR0.1_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5521 - accuracy: 0.3328 - val_loss: 1.4925 - val_accuracy: 0.3399\n",
            "Epoch 2/25\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5367 - accuracy: 0.3376\n",
            "Epoch 00002: loss improved from 1.55214 to 1.53694, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59c422fa58>_Batch25_LR0.1_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5369 - accuracy: 0.3373 - val_loss: 1.5014 - val_accuracy: 0.3399\n",
            "Epoch 3/25\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5341 - accuracy: 0.3391\n",
            "Epoch 00003: loss improved from 1.53694 to 1.53411, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59c422fa58>_Batch25_LR0.1_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5341 - accuracy: 0.3391 - val_loss: 1.5084 - val_accuracy: 0.3399\n",
            "Epoch 4/25\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5334 - accuracy: 0.3396\n",
            "Epoch 00004: loss improved from 1.53411 to 1.53265, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59c422fa58>_Batch25_LR0.1_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5327 - accuracy: 0.3397 - val_loss: 1.4998 - val_accuracy: 0.3022\n",
            "Epoch 5/25\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5321 - accuracy: 0.3426\n",
            "Epoch 00005: loss improved from 1.53265 to 1.53207, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59c422fa58>_Batch25_LR0.1_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5321 - accuracy: 0.3423 - val_loss: 1.4992 - val_accuracy: 0.3399\n",
            "Epoch 6/25\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5302 - accuracy: 0.3426\n",
            "Epoch 00006: loss improved from 1.53207 to 1.53019, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59c422fa58>_Batch25_LR0.1_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5302 - accuracy: 0.3428 - val_loss: 1.5037 - val_accuracy: 0.3399\n",
            "Epoch 7/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5271 - accuracy: 0.3424\n",
            "Epoch 00007: loss improved from 1.53019 to 1.52725, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59c422fa58>_Batch25_LR0.1_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5273 - accuracy: 0.3421 - val_loss: 1.5022 - val_accuracy: 0.3399\n",
            "Epoch 8/25\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5264 - accuracy: 0.3433\n",
            "Epoch 00008: loss improved from 1.52725 to 1.52629, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59c422fa58>_Batch25_LR0.1_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5263 - accuracy: 0.3431 - val_loss: 1.4939 - val_accuracy: 0.3399\n",
            "Epoch 9/25\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5257 - accuracy: 0.3422\n",
            "Epoch 00009: loss improved from 1.52629 to 1.52526, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59c422fa58>_Batch25_LR0.1_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5253 - accuracy: 0.3426 - val_loss: 1.4927 - val_accuracy: 0.3399\n",
            "Epoch 10/25\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5230 - accuracy: 0.3430\n",
            "Epoch 00010: loss improved from 1.52526 to 1.52312, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59c422fa58>_Batch25_LR0.1_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5231 - accuracy: 0.3428 - val_loss: 1.4917 - val_accuracy: 0.3399\n",
            "Epoch 11/25\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5228 - accuracy: 0.3435\n",
            "Epoch 00011: loss improved from 1.52312 to 1.52273, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59c422fa58>_Batch25_LR0.1_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5227 - accuracy: 0.3434 - val_loss: 1.5113 - val_accuracy: 0.3375\n",
            "Epoch 12/25\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5224 - accuracy: 0.3436\n",
            "Epoch 00012: loss improved from 1.52273 to 1.52245, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59c422fa58>_Batch25_LR0.1_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5225 - accuracy: 0.3438 - val_loss: 1.4849 - val_accuracy: 0.3372\n",
            "Epoch 13/25\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5213 - accuracy: 0.3436\n",
            "Epoch 00013: loss improved from 1.52245 to 1.52138, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59c422fa58>_Batch25_LR0.1_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5214 - accuracy: 0.3436 - val_loss: 1.4899 - val_accuracy: 0.3399\n",
            "Epoch 14/25\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5225 - accuracy: 0.3437\n",
            "Epoch 00014: loss did not improve from 1.52138\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5225 - accuracy: 0.3438 - val_loss: 1.5007 - val_accuracy: 0.3372\n",
            "Epoch 15/25\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5214 - accuracy: 0.3436\n",
            "Epoch 00015: loss improved from 1.52138 to 1.52136, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59c422fa58>_Batch25_LR0.1_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5214 - accuracy: 0.3436 - val_loss: 1.4860 - val_accuracy: 0.3372\n",
            "Epoch 16/25\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5194 - accuracy: 0.3440\n",
            "Epoch 00016: loss improved from 1.52136 to 1.51948, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59c422fa58>_Batch25_LR0.1_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5195 - accuracy: 0.3439 - val_loss: 1.4967 - val_accuracy: 0.3391\n",
            "Epoch 17/25\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5200 - accuracy: 0.3429\n",
            "Epoch 00017: loss did not improve from 1.51948\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5202 - accuracy: 0.3430 - val_loss: 1.5008 - val_accuracy: 0.3372\n",
            "Epoch 18/25\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5203 - accuracy: 0.3435\n",
            "Epoch 00018: loss did not improve from 1.51948\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5198 - accuracy: 0.3441 - val_loss: 1.4962 - val_accuracy: 0.3399\n",
            "Epoch 19/25\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5209 - accuracy: 0.3438\n",
            "Epoch 00019: loss did not improve from 1.51948\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5206 - accuracy: 0.3438 - val_loss: 1.4920 - val_accuracy: 0.3399\n",
            "Epoch 20/25\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5191 - accuracy: 0.3434\n",
            "Epoch 00020: loss improved from 1.51948 to 1.51934, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59c422fa58>_Batch25_LR0.1_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5193 - accuracy: 0.3434 - val_loss: 1.5000 - val_accuracy: 0.3372\n",
            "Epoch 21/25\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5197 - accuracy: 0.3425\n",
            "Epoch 00021: loss did not improve from 1.51934\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5196 - accuracy: 0.3430 - val_loss: 1.5052 - val_accuracy: 0.3240\n",
            "Epoch 22/25\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5190 - accuracy: 0.3434\n",
            "Epoch 00022: loss improved from 1.51934 to 1.51900, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59c422fa58>_Batch25_LR0.1_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5190 - accuracy: 0.3436 - val_loss: 1.5070 - val_accuracy: 0.3375\n",
            "Epoch 23/25\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5182 - accuracy: 0.3441\n",
            "Epoch 00023: loss improved from 1.51900 to 1.51820, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59c422fa58>_Batch25_LR0.1_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5182 - accuracy: 0.3439 - val_loss: 1.5042 - val_accuracy: 0.3291\n",
            "Epoch 24/25\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5170 - accuracy: 0.3444\n",
            "Epoch 00024: loss improved from 1.51820 to 1.51781, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59c422fa58>_Batch25_LR0.1_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5178 - accuracy: 0.3442 - val_loss: 1.4884 - val_accuracy: 0.3372\n",
            "Epoch 25/25\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5179 - accuracy: 0.3443\n",
            "Epoch 00025: loss did not improve from 1.51781\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5179 - accuracy: 0.3443 - val_loss: 1.5057 - val_accuracy: 0.3375\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/25\n",
            "  2/595 [..............................] - ETA: 2:01 - loss: 46.0505 - accuracy: 0.2800WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0155s vs `on_train_batch_end` time: 0.3925s). Check your callbacks.\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.8809 - accuracy: 0.3316\n",
            "Epoch 00001: loss improved from inf to 1.87838, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f59beee5978>_Batch25_LR0.1_Epochs25.hdf5\n",
            "595/595 [==============================] - 9s 15ms/step - loss: 1.8784 - accuracy: 0.3318 - val_loss: 1.4994 - val_accuracy: 0.3399\n",
            "Epoch 2/25\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5389 - accuracy: 0.3349\n",
            "Epoch 00002: loss improved from 1.87838 to 1.53868, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f59beee5978>_Batch25_LR0.1_Epochs25.hdf5\n",
            "595/595 [==============================] - 9s 14ms/step - loss: 1.5387 - accuracy: 0.3350 - val_loss: 1.5049 - val_accuracy: 0.3399\n",
            "Epoch 3/25\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5392 - accuracy: 0.3371\n",
            "Epoch 00003: loss did not improve from 1.53868\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5393 - accuracy: 0.3371 - val_loss: 1.5011 - val_accuracy: 0.3399\n",
            "Epoch 4/25\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5402 - accuracy: 0.3350\n",
            "Epoch 00004: loss did not improve from 1.53868\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5402 - accuracy: 0.3350 - val_loss: 1.4915 - val_accuracy: 0.3399\n",
            "Epoch 5/25\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5401 - accuracy: 0.3361\n",
            "Epoch 00005: loss did not improve from 1.53868\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5401 - accuracy: 0.3361 - val_loss: 1.5057 - val_accuracy: 0.3399\n",
            "Epoch 6/25\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5379 - accuracy: 0.3353\n",
            "Epoch 00006: loss improved from 1.53868 to 1.53809, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f59beee5978>_Batch25_LR0.1_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5381 - accuracy: 0.3352 - val_loss: 1.5420 - val_accuracy: 0.3399\n",
            "Epoch 7/25\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5385 - accuracy: 0.3364\n",
            "Epoch 00007: loss did not improve from 1.53809\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5385 - accuracy: 0.3364 - val_loss: 1.4961 - val_accuracy: 0.3399\n",
            "Epoch 8/25\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5392 - accuracy: 0.3366\n",
            "Epoch 00008: loss did not improve from 1.53809\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5393 - accuracy: 0.3365 - val_loss: 1.5192 - val_accuracy: 0.3022\n",
            "Epoch 9/25\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5373 - accuracy: 0.3354\n",
            "Epoch 00009: loss improved from 1.53809 to 1.53736, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f59beee5978>_Batch25_LR0.1_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5374 - accuracy: 0.3352 - val_loss: 1.5028 - val_accuracy: 0.3022\n",
            "Epoch 10/25\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5391 - accuracy: 0.3346\n",
            "Epoch 00010: loss did not improve from 1.53736\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5391 - accuracy: 0.3346 - val_loss: 1.4968 - val_accuracy: 0.3399\n",
            "Epoch 11/25\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5378 - accuracy: 0.3357\n",
            "Epoch 00011: loss did not improve from 1.53736\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5377 - accuracy: 0.3360 - val_loss: 1.4977 - val_accuracy: 0.3399\n",
            "Epoch 12/25\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5391 - accuracy: 0.3364\n",
            "Epoch 00012: loss did not improve from 1.53736\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5391 - accuracy: 0.3365 - val_loss: 1.5129 - val_accuracy: 0.3399\n",
            "Epoch 13/25\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5384 - accuracy: 0.3349\n",
            "Epoch 00013: loss did not improve from 1.53736\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5385 - accuracy: 0.3350 - val_loss: 1.4928 - val_accuracy: 0.3399\n",
            "Epoch 14/25\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5377 - accuracy: 0.3335\n",
            "Epoch 00014: loss did not improve from 1.53736\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5377 - accuracy: 0.3330 - val_loss: 1.4991 - val_accuracy: 0.3022\n",
            "Epoch 15/25\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5387 - accuracy: 0.3345\n",
            "Epoch 00015: loss did not improve from 1.53736\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5386 - accuracy: 0.3346 - val_loss: 1.5230 - val_accuracy: 0.3399\n",
            "Epoch 16/25\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5385 - accuracy: 0.3353\n",
            "Epoch 00016: loss did not improve from 1.53736\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5388 - accuracy: 0.3351 - val_loss: 1.5194 - val_accuracy: 0.3399\n",
            "Epoch 17/25\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5385 - accuracy: 0.3355\n",
            "Epoch 00017: loss did not improve from 1.53736\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5390 - accuracy: 0.3350 - val_loss: 1.5304 - val_accuracy: 0.3399\n",
            "Epoch 18/25\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5398 - accuracy: 0.3348\n",
            "Epoch 00018: loss did not improve from 1.53736\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5399 - accuracy: 0.3348 - val_loss: 1.4900 - val_accuracy: 0.3399\n",
            "Epoch 19/25\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5393 - accuracy: 0.3346\n",
            "Epoch 00019: loss did not improve from 1.53736\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5399 - accuracy: 0.3346 - val_loss: 1.4903 - val_accuracy: 0.3399\n",
            "Epoch 20/25\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5390 - accuracy: 0.3349\n",
            "Epoch 00020: loss did not improve from 1.53736\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5390 - accuracy: 0.3349 - val_loss: 1.5239 - val_accuracy: 0.3399\n",
            "Epoch 21/25\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5383 - accuracy: 0.3354\n",
            "Epoch 00021: loss did not improve from 1.53736\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5385 - accuracy: 0.3358 - val_loss: 1.5022 - val_accuracy: 0.3399\n",
            "Epoch 22/25\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5387 - accuracy: 0.3363\n",
            "Epoch 00022: loss did not improve from 1.53736\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5385 - accuracy: 0.3367 - val_loss: 1.4938 - val_accuracy: 0.3399\n",
            "Epoch 23/25\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5402 - accuracy: 0.3379\n",
            "Epoch 00023: loss did not improve from 1.53736\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5400 - accuracy: 0.3381 - val_loss: 1.5240 - val_accuracy: 0.3399\n",
            "Epoch 24/25\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5399 - accuracy: 0.3337\n",
            "Epoch 00024: loss did not improve from 1.53736\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5397 - accuracy: 0.3336 - val_loss: 1.4899 - val_accuracy: 0.3399\n",
            "Epoch 25/25\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5388 - accuracy: 0.3331\n",
            "Epoch 00025: loss did not improve from 1.53736\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5388 - accuracy: 0.3331 - val_loss: 1.5058 - val_accuracy: 0.3399\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/25\n",
            "  2/595 [..............................] - ETA: 34s - loss: 9.3191 - accuracy: 0.2000WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0168s vs `on_train_batch_end` time: 0.0999s). Check your callbacks.\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.6430 - accuracy: 0.3368\n",
            "Epoch 00001: loss improved from inf to 1.64303, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f59bed616d8>_Batch25_LR0.1_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.6430 - accuracy: 0.3368 - val_loss: 1.5229 - val_accuracy: 0.3399\n",
            "Epoch 2/25\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5355 - accuracy: 0.3358\n",
            "Epoch 00002: loss improved from 1.64303 to 1.53606, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f59bed616d8>_Batch25_LR0.1_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5361 - accuracy: 0.3355 - val_loss: 1.5037 - val_accuracy: 0.3399\n",
            "Epoch 3/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5376 - accuracy: 0.3331\n",
            "Epoch 00003: loss did not improve from 1.53606\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5375 - accuracy: 0.3332 - val_loss: 1.4957 - val_accuracy: 0.3399\n",
            "Epoch 4/25\n",
            "589/595 [============================>.] - ETA: 0s - loss: 1.5373 - accuracy: 0.3360\n",
            "Epoch 00004: loss did not improve from 1.53606\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5374 - accuracy: 0.3365 - val_loss: 1.5086 - val_accuracy: 0.3399\n",
            "Epoch 5/25\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5375 - accuracy: 0.3362\n",
            "Epoch 00005: loss did not improve from 1.53606\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5375 - accuracy: 0.3363 - val_loss: 1.4962 - val_accuracy: 0.3399\n",
            "Epoch 6/25\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5397 - accuracy: 0.3355\n",
            "Epoch 00006: loss did not improve from 1.53606\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5397 - accuracy: 0.3355 - val_loss: 1.5431 - val_accuracy: 0.3399\n",
            "Epoch 7/25\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5372 - accuracy: 0.3420\n",
            "Epoch 00007: loss did not improve from 1.53606\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5372 - accuracy: 0.3420 - val_loss: 1.4936 - val_accuracy: 0.3399\n",
            "Epoch 8/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5368 - accuracy: 0.3328\n",
            "Epoch 00008: loss did not improve from 1.53606\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5368 - accuracy: 0.3331 - val_loss: 1.4984 - val_accuracy: 0.3399\n",
            "Epoch 9/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5370 - accuracy: 0.3326\n",
            "Epoch 00009: loss did not improve from 1.53606\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5372 - accuracy: 0.3324 - val_loss: 1.4971 - val_accuracy: 0.3399\n",
            "Epoch 10/25\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5377 - accuracy: 0.3383\n",
            "Epoch 00010: loss did not improve from 1.53606\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5379 - accuracy: 0.3381 - val_loss: 1.5014 - val_accuracy: 0.3399\n",
            "Epoch 11/25\n",
            "589/595 [============================>.] - ETA: 0s - loss: 1.5373 - accuracy: 0.3362\n",
            "Epoch 00011: loss did not improve from 1.53606\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5371 - accuracy: 0.3364 - val_loss: 1.5107 - val_accuracy: 0.3399\n",
            "Epoch 12/25\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5362 - accuracy: 0.3387\n",
            "Epoch 00012: loss did not improve from 1.53606\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5361 - accuracy: 0.3389 - val_loss: 1.5404 - val_accuracy: 0.3399\n",
            "Epoch 13/25\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5357 - accuracy: 0.3388\n",
            "Epoch 00013: loss improved from 1.53606 to 1.53600, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f59bed616d8>_Batch25_LR0.1_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5360 - accuracy: 0.3385 - val_loss: 1.5036 - val_accuracy: 0.3399\n",
            "Epoch 14/25\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5370 - accuracy: 0.3368\n",
            "Epoch 00014: loss did not improve from 1.53600\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5371 - accuracy: 0.3369 - val_loss: 1.5017 - val_accuracy: 0.3399\n",
            "Epoch 15/25\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5364 - accuracy: 0.3370\n",
            "Epoch 00015: loss did not improve from 1.53600\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5365 - accuracy: 0.3368 - val_loss: 1.4927 - val_accuracy: 0.3399\n",
            "Epoch 16/25\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5391 - accuracy: 0.3318\n",
            "Epoch 00016: loss did not improve from 1.53600\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5396 - accuracy: 0.3315 - val_loss: 1.5038 - val_accuracy: 0.3399\n",
            "Epoch 17/25\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5377 - accuracy: 0.3361\n",
            "Epoch 00017: loss did not improve from 1.53600\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5375 - accuracy: 0.3365 - val_loss: 1.5100 - val_accuracy: 0.3399\n",
            "Epoch 18/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5371 - accuracy: 0.3326\n",
            "Epoch 00018: loss did not improve from 1.53600\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5374 - accuracy: 0.3326 - val_loss: 1.5012 - val_accuracy: 0.3399\n",
            "Epoch 19/25\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5364 - accuracy: 0.3367\n",
            "Epoch 00019: loss did not improve from 1.53600\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5364 - accuracy: 0.3367 - val_loss: 1.4994 - val_accuracy: 0.3022\n",
            "Epoch 20/25\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5381 - accuracy: 0.3343\n",
            "Epoch 00020: loss did not improve from 1.53600\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5381 - accuracy: 0.3344 - val_loss: 1.4956 - val_accuracy: 0.3399\n",
            "Epoch 21/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5366 - accuracy: 0.3376\n",
            "Epoch 00021: loss did not improve from 1.53600\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5368 - accuracy: 0.3378 - val_loss: 1.5114 - val_accuracy: 0.3399\n",
            "Epoch 22/25\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5379 - accuracy: 0.3362\n",
            "Epoch 00022: loss did not improve from 1.53600\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5378 - accuracy: 0.3363 - val_loss: 1.4975 - val_accuracy: 0.3399\n",
            "Epoch 23/25\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5374 - accuracy: 0.3362\n",
            "Epoch 00023: loss did not improve from 1.53600\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5374 - accuracy: 0.3362 - val_loss: 1.4947 - val_accuracy: 0.3399\n",
            "Epoch 24/25\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5363 - accuracy: 0.3410\n",
            "Epoch 00024: loss did not improve from 1.53600\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5367 - accuracy: 0.3406 - val_loss: 1.5083 - val_accuracy: 0.3399\n",
            "Epoch 25/25\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5376 - accuracy: 0.3354\n",
            "Epoch 00025: loss did not improve from 1.53600\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5375 - accuracy: 0.3353 - val_loss: 1.4928 - val_accuracy: 0.3399\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/25\n",
            "  2/595 [..............................] - ETA: 33s - loss: 3.6261 - accuracy: 0.0600   WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0144s vs `on_train_batch_end` time: 0.0973s). Check your callbacks.\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5532 - accuracy: 0.3406\n",
            "Epoch 00001: loss improved from inf to 1.55321, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59bf042630>_Batch25_LR0.1_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5532 - accuracy: 0.3406 - val_loss: 1.4941 - val_accuracy: 0.3399\n",
            "Epoch 2/25\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5320 - accuracy: 0.3419\n",
            "Epoch 00002: loss improved from 1.55321 to 1.53175, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59bf042630>_Batch25_LR0.1_Epochs25.hdf5\n",
            "595/595 [==============================] - 9s 14ms/step - loss: 1.5317 - accuracy: 0.3417 - val_loss: 1.4948 - val_accuracy: 0.3399\n",
            "Epoch 3/25\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5314 - accuracy: 0.3430\n",
            "Epoch 00003: loss improved from 1.53175 to 1.53146, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59bf042630>_Batch25_LR0.1_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5315 - accuracy: 0.3429 - val_loss: 1.4928 - val_accuracy: 0.3399\n",
            "Epoch 4/25\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5296 - accuracy: 0.3435\n",
            "Epoch 00004: loss improved from 1.53146 to 1.52946, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59bf042630>_Batch25_LR0.1_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5295 - accuracy: 0.3434 - val_loss: 1.5025 - val_accuracy: 0.3399\n",
            "Epoch 5/25\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5285 - accuracy: 0.3436\n",
            "Epoch 00005: loss improved from 1.52946 to 1.52846, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59bf042630>_Batch25_LR0.1_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5285 - accuracy: 0.3436 - val_loss: 1.5008 - val_accuracy: 0.3399\n",
            "Epoch 6/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5273 - accuracy: 0.3438\n",
            "Epoch 00006: loss improved from 1.52846 to 1.52747, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59bf042630>_Batch25_LR0.1_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5275 - accuracy: 0.3436 - val_loss: 1.4985 - val_accuracy: 0.3399\n",
            "Epoch 7/25\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5280 - accuracy: 0.3428\n",
            "Epoch 00007: loss improved from 1.52747 to 1.52710, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59bf042630>_Batch25_LR0.1_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5271 - accuracy: 0.3436 - val_loss: 1.4995 - val_accuracy: 0.3399\n",
            "Epoch 8/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5249 - accuracy: 0.3439\n",
            "Epoch 00008: loss improved from 1.52710 to 1.52520, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59bf042630>_Batch25_LR0.1_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5252 - accuracy: 0.3437 - val_loss: 1.5021 - val_accuracy: 0.3399\n",
            "Epoch 9/25\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5242 - accuracy: 0.3437\n",
            "Epoch 00009: loss improved from 1.52520 to 1.52397, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59bf042630>_Batch25_LR0.1_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5240 - accuracy: 0.3435 - val_loss: 1.4984 - val_accuracy: 0.3399\n",
            "Epoch 10/25\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5233 - accuracy: 0.3432\n",
            "Epoch 00010: loss improved from 1.52397 to 1.52304, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59bf042630>_Batch25_LR0.1_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5230 - accuracy: 0.3436 - val_loss: 1.5028 - val_accuracy: 0.3399\n",
            "Epoch 11/25\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5223 - accuracy: 0.3436\n",
            "Epoch 00011: loss improved from 1.52304 to 1.52224, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59bf042630>_Batch25_LR0.1_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5222 - accuracy: 0.3435 - val_loss: 1.4970 - val_accuracy: 0.3399\n",
            "Epoch 12/25\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5214 - accuracy: 0.3432\n",
            "Epoch 00012: loss improved from 1.52224 to 1.52139, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59bf042630>_Batch25_LR0.1_Epochs25.hdf5\n",
            "595/595 [==============================] - 9s 15ms/step - loss: 1.5214 - accuracy: 0.3432 - val_loss: 1.5031 - val_accuracy: 0.3399\n",
            "Epoch 13/25\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5191 - accuracy: 0.3440\n",
            "Epoch 00013: loss improved from 1.52139 to 1.51914, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59bf042630>_Batch25_LR0.1_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5191 - accuracy: 0.3436 - val_loss: 1.4992 - val_accuracy: 0.3399\n",
            "Epoch 14/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5184 - accuracy: 0.3431\n",
            "Epoch 00014: loss improved from 1.51914 to 1.51822, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59bf042630>_Batch25_LR0.1_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5182 - accuracy: 0.3432 - val_loss: 1.4970 - val_accuracy: 0.3399\n",
            "Epoch 15/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5184 - accuracy: 0.3427\n",
            "Epoch 00015: loss did not improve from 1.51822\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5185 - accuracy: 0.3429 - val_loss: 1.4963 - val_accuracy: 0.3399\n",
            "Epoch 16/25\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5157 - accuracy: 0.3436\n",
            "Epoch 00016: loss improved from 1.51822 to 1.51597, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59bf042630>_Batch25_LR0.1_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5160 - accuracy: 0.3434 - val_loss: 1.4996 - val_accuracy: 0.3399\n",
            "Epoch 17/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5161 - accuracy: 0.3435\n",
            "Epoch 00017: loss improved from 1.51597 to 1.51586, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59bf042630>_Batch25_LR0.1_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5159 - accuracy: 0.3436 - val_loss: 1.5035 - val_accuracy: 0.3399\n",
            "Epoch 18/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5164 - accuracy: 0.3436\n",
            "Epoch 00018: loss did not improve from 1.51586\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5167 - accuracy: 0.3432 - val_loss: 1.4981 - val_accuracy: 0.3399\n",
            "Epoch 19/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5156 - accuracy: 0.3439\n",
            "Epoch 00019: loss did not improve from 1.51586\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5159 - accuracy: 0.3436 - val_loss: 1.4948 - val_accuracy: 0.3262\n",
            "Epoch 20/25\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5148 - accuracy: 0.3444\n",
            "Epoch 00020: loss improved from 1.51586 to 1.51493, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59bf042630>_Batch25_LR0.1_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5149 - accuracy: 0.3444 - val_loss: 1.5132 - val_accuracy: 0.3410\n",
            "Epoch 21/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5143 - accuracy: 0.3437\n",
            "Epoch 00021: loss improved from 1.51493 to 1.51429, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59bf042630>_Batch25_LR0.1_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5143 - accuracy: 0.3437 - val_loss: 1.5013 - val_accuracy: 0.3399\n",
            "Epoch 22/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5138 - accuracy: 0.3447\n",
            "Epoch 00022: loss improved from 1.51429 to 1.51322, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59bf042630>_Batch25_LR0.1_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5132 - accuracy: 0.3451 - val_loss: 1.5113 - val_accuracy: 0.3402\n",
            "Epoch 23/25\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5127 - accuracy: 0.3459\n",
            "Epoch 00023: loss improved from 1.51322 to 1.51262, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59bf042630>_Batch25_LR0.1_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5126 - accuracy: 0.3461 - val_loss: 1.5067 - val_accuracy: 0.3399\n",
            "Epoch 24/25\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5126 - accuracy: 0.3453\n",
            "Epoch 00024: loss improved from 1.51262 to 1.51238, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59bf042630>_Batch25_LR0.1_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5124 - accuracy: 0.3455 - val_loss: 1.5047 - val_accuracy: 0.3385\n",
            "Epoch 25/25\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5120 - accuracy: 0.3444\n",
            "Epoch 00025: loss improved from 1.51238 to 1.51176, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59bf042630>_Batch25_LR0.1_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5118 - accuracy: 0.3444 - val_loss: 1.5084 - val_accuracy: 0.3410\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/25\n",
            "  2/595 [..............................] - ETA: 51s - loss: 14.8021 - accuracy: 0.1600WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0148s vs `on_train_batch_end` time: 0.1619s). Check your callbacks.\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.6659 - accuracy: 0.3361\n",
            "Epoch 00001: loss improved from inf to 1.66466, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f59c45e9fd0>_Batch25_LR0.1_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.6647 - accuracy: 0.3366 - val_loss: 1.4979 - val_accuracy: 0.3399\n",
            "Epoch 2/25\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5303 - accuracy: 0.3437\n",
            "Epoch 00002: loss improved from 1.66466 to 1.53024, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f59c45e9fd0>_Batch25_LR0.1_Epochs25.hdf5\n",
            "595/595 [==============================] - 9s 14ms/step - loss: 1.5302 - accuracy: 0.3436 - val_loss: 1.4979 - val_accuracy: 0.3399\n",
            "Epoch 3/25\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5308 - accuracy: 0.3396\n",
            "Epoch 00003: loss did not improve from 1.53024\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5309 - accuracy: 0.3395 - val_loss: 1.5025 - val_accuracy: 0.3399\n",
            "Epoch 4/25\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5315 - accuracy: 0.3407\n",
            "Epoch 00004: loss did not improve from 1.53024\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5316 - accuracy: 0.3408 - val_loss: 1.4961 - val_accuracy: 0.3399\n",
            "Epoch 5/25\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5309 - accuracy: 0.3401\n",
            "Epoch 00005: loss did not improve from 1.53024\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5307 - accuracy: 0.3404 - val_loss: 1.4961 - val_accuracy: 0.3399\n",
            "Epoch 6/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5313 - accuracy: 0.3434\n",
            "Epoch 00006: loss did not improve from 1.53024\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5312 - accuracy: 0.3436 - val_loss: 1.4991 - val_accuracy: 0.3399\n",
            "Epoch 7/25\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5309 - accuracy: 0.3436\n",
            "Epoch 00007: loss did not improve from 1.53024\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5309 - accuracy: 0.3436 - val_loss: 1.4947 - val_accuracy: 0.3399\n",
            "Epoch 8/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5312 - accuracy: 0.3439\n",
            "Epoch 00008: loss did not improve from 1.53024\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5311 - accuracy: 0.3436 - val_loss: 1.5021 - val_accuracy: 0.3399\n",
            "Epoch 9/25\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5319 - accuracy: 0.3423\n",
            "Epoch 00009: loss did not improve from 1.53024\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5317 - accuracy: 0.3422 - val_loss: 1.4939 - val_accuracy: 0.3399\n",
            "Epoch 10/25\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5324 - accuracy: 0.3436\n",
            "Epoch 00010: loss did not improve from 1.53024\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5324 - accuracy: 0.3436 - val_loss: 1.4992 - val_accuracy: 0.3399\n",
            "Epoch 11/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5306 - accuracy: 0.3435\n",
            "Epoch 00011: loss did not improve from 1.53024\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5307 - accuracy: 0.3436 - val_loss: 1.5000 - val_accuracy: 0.3399\n",
            "Epoch 12/25\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5319 - accuracy: 0.3423\n",
            "Epoch 00012: loss did not improve from 1.53024\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5319 - accuracy: 0.3427 - val_loss: 1.4903 - val_accuracy: 0.3399\n",
            "Epoch 13/25\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5309 - accuracy: 0.3426\n",
            "Epoch 00013: loss did not improve from 1.53024\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5314 - accuracy: 0.3424 - val_loss: 1.5094 - val_accuracy: 0.3399\n",
            "Epoch 14/25\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5320 - accuracy: 0.3433\n",
            "Epoch 00014: loss did not improve from 1.53024\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5319 - accuracy: 0.3436 - val_loss: 1.4959 - val_accuracy: 0.3399\n",
            "Epoch 15/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5322 - accuracy: 0.3422\n",
            "Epoch 00015: loss did not improve from 1.53024\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5320 - accuracy: 0.3422 - val_loss: 1.5034 - val_accuracy: 0.3399\n",
            "Epoch 16/25\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5321 - accuracy: 0.3426\n",
            "Epoch 00016: loss did not improve from 1.53024\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5317 - accuracy: 0.3428 - val_loss: 1.4961 - val_accuracy: 0.3399\n",
            "Epoch 17/25\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5315 - accuracy: 0.3438\n",
            "Epoch 00017: loss did not improve from 1.53024\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5316 - accuracy: 0.3436 - val_loss: 1.5029 - val_accuracy: 0.3399\n",
            "Epoch 18/25\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5317 - accuracy: 0.3421\n",
            "Epoch 00018: loss did not improve from 1.53024\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5315 - accuracy: 0.3424 - val_loss: 1.4906 - val_accuracy: 0.3399\n",
            "Epoch 19/25\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5315 - accuracy: 0.3428\n",
            "Epoch 00019: loss did not improve from 1.53024\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5316 - accuracy: 0.3424 - val_loss: 1.4917 - val_accuracy: 0.3399\n",
            "Epoch 20/25\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5312 - accuracy: 0.3430\n",
            "Epoch 00020: loss did not improve from 1.53024\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5313 - accuracy: 0.3430 - val_loss: 1.4960 - val_accuracy: 0.3399\n",
            "Epoch 21/25\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5320 - accuracy: 0.3373\n",
            "Epoch 00021: loss did not improve from 1.53024\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5319 - accuracy: 0.3375 - val_loss: 1.5046 - val_accuracy: 0.3399\n",
            "Epoch 22/25\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5317 - accuracy: 0.3393\n",
            "Epoch 00022: loss did not improve from 1.53024\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5317 - accuracy: 0.3397 - val_loss: 1.5141 - val_accuracy: 0.3399\n",
            "Epoch 23/25\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5317 - accuracy: 0.3436\n",
            "Epoch 00023: loss did not improve from 1.53024\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5316 - accuracy: 0.3436 - val_loss: 1.4998 - val_accuracy: 0.3399\n",
            "Epoch 24/25\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5311 - accuracy: 0.3417\n",
            "Epoch 00024: loss did not improve from 1.53024\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5309 - accuracy: 0.3418 - val_loss: 1.5043 - val_accuracy: 0.3399\n",
            "Epoch 25/25\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5315 - accuracy: 0.3433\n",
            "Epoch 00025: loss did not improve from 1.53024\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5313 - accuracy: 0.3436 - val_loss: 1.5071 - val_accuracy: 0.3399\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/25\n",
            "  2/595 [..............................] - ETA: 34s - loss: 2.0317 - accuracy: 0.2000WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0144s vs `on_train_batch_end` time: 0.1007s). Check your callbacks.\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5444 - accuracy: 0.3372\n",
            "Epoch 00001: loss improved from inf to 1.54445, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f59bebb3f60>_Batch25_LR0.1_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5445 - accuracy: 0.3372 - val_loss: 1.4944 - val_accuracy: 0.3399\n",
            "Epoch 2/25\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5341 - accuracy: 0.3412\n",
            "Epoch 00002: loss improved from 1.54445 to 1.53384, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f59bebb3f60>_Batch25_LR0.1_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5338 - accuracy: 0.3414 - val_loss: 1.4945 - val_accuracy: 0.3399\n",
            "Epoch 3/25\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5304 - accuracy: 0.3422\n",
            "Epoch 00003: loss improved from 1.53384 to 1.53029, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f59bebb3f60>_Batch25_LR0.1_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5303 - accuracy: 0.3423 - val_loss: 1.4987 - val_accuracy: 0.3399\n",
            "Epoch 4/25\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5280 - accuracy: 0.3436\n",
            "Epoch 00004: loss improved from 1.53029 to 1.52804, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f59bebb3f60>_Batch25_LR0.1_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5280 - accuracy: 0.3436 - val_loss: 1.5025 - val_accuracy: 0.3399\n",
            "Epoch 5/25\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5285 - accuracy: 0.3435\n",
            "Epoch 00005: loss did not improve from 1.52804\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5285 - accuracy: 0.3435 - val_loss: 1.4985 - val_accuracy: 0.3399\n",
            "Epoch 6/25\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5259 - accuracy: 0.3437\n",
            "Epoch 00006: loss improved from 1.52804 to 1.52648, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f59bebb3f60>_Batch25_LR0.1_Epochs25.hdf5\n",
            "595/595 [==============================] - 9s 15ms/step - loss: 1.5265 - accuracy: 0.3436 - val_loss: 1.5180 - val_accuracy: 0.3399\n",
            "Epoch 7/25\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5252 - accuracy: 0.3436\n",
            "Epoch 00007: loss improved from 1.52648 to 1.52508, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f59bebb3f60>_Batch25_LR0.1_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5251 - accuracy: 0.3436 - val_loss: 1.5060 - val_accuracy: 0.3399\n",
            "Epoch 8/25\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5244 - accuracy: 0.3435\n",
            "Epoch 00008: loss improved from 1.52508 to 1.52425, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f59bebb3f60>_Batch25_LR0.1_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5243 - accuracy: 0.3436 - val_loss: 1.4930 - val_accuracy: 0.3399\n",
            "Epoch 9/25\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5230 - accuracy: 0.3437\n",
            "Epoch 00009: loss improved from 1.52425 to 1.52300, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f59bebb3f60>_Batch25_LR0.1_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5230 - accuracy: 0.3436 - val_loss: 1.4994 - val_accuracy: 0.3399\n",
            "Epoch 10/25\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5208 - accuracy: 0.3431\n",
            "Epoch 00010: loss improved from 1.52300 to 1.52039, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f59bebb3f60>_Batch25_LR0.1_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5204 - accuracy: 0.3434 - val_loss: 1.4962 - val_accuracy: 0.3399\n",
            "Epoch 11/25\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5208 - accuracy: 0.3438\n",
            "Epoch 00011: loss did not improve from 1.52039\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5206 - accuracy: 0.3442 - val_loss: 1.4993 - val_accuracy: 0.3399\n",
            "Epoch 12/25\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5202 - accuracy: 0.3434\n",
            "Epoch 00012: loss improved from 1.52039 to 1.52011, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f59bebb3f60>_Batch25_LR0.1_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5201 - accuracy: 0.3435 - val_loss: 1.5054 - val_accuracy: 0.3399\n",
            "Epoch 13/25\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5193 - accuracy: 0.3434\n",
            "Epoch 00013: loss improved from 1.52011 to 1.51957, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f59bebb3f60>_Batch25_LR0.1_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5196 - accuracy: 0.3432 - val_loss: 1.5074 - val_accuracy: 0.3399\n",
            "Epoch 14/25\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5184 - accuracy: 0.3439\n",
            "Epoch 00014: loss improved from 1.51957 to 1.51878, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f59bebb3f60>_Batch25_LR0.1_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5188 - accuracy: 0.3440 - val_loss: 1.5065 - val_accuracy: 0.3399\n",
            "Epoch 15/25\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5180 - accuracy: 0.3433\n",
            "Epoch 00015: loss improved from 1.51878 to 1.51763, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f59bebb3f60>_Batch25_LR0.1_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5176 - accuracy: 0.3439 - val_loss: 1.5077 - val_accuracy: 0.3399\n",
            "Epoch 16/25\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5166 - accuracy: 0.3436\n",
            "Epoch 00016: loss improved from 1.51763 to 1.51656, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f59bebb3f60>_Batch25_LR0.1_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5166 - accuracy: 0.3439 - val_loss: 1.5037 - val_accuracy: 0.3399\n",
            "Epoch 17/25\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5146 - accuracy: 0.3444\n",
            "Epoch 00017: loss improved from 1.51656 to 1.51479, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f59bebb3f60>_Batch25_LR0.1_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5148 - accuracy: 0.3443 - val_loss: 1.5019 - val_accuracy: 0.3399\n",
            "Epoch 18/25\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5148 - accuracy: 0.3447\n",
            "Epoch 00018: loss improved from 1.51479 to 1.51468, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f59bebb3f60>_Batch25_LR0.1_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5147 - accuracy: 0.3448 - val_loss: 1.5070 - val_accuracy: 0.3399\n",
            "Epoch 19/25\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5148 - accuracy: 0.3456\n",
            "Epoch 00019: loss did not improve from 1.51468\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5147 - accuracy: 0.3455 - val_loss: 1.4981 - val_accuracy: 0.3399\n",
            "Epoch 20/25\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5139 - accuracy: 0.3437\n",
            "Epoch 00020: loss improved from 1.51468 to 1.51410, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f59bebb3f60>_Batch25_LR0.1_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5141 - accuracy: 0.3434 - val_loss: 1.5058 - val_accuracy: 0.3399\n",
            "Epoch 21/25\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5142 - accuracy: 0.3446\n",
            "Epoch 00021: loss improved from 1.51410 to 1.51384, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f59bebb3f60>_Batch25_LR0.1_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5138 - accuracy: 0.3447 - val_loss: 1.5191 - val_accuracy: 0.3348\n",
            "Epoch 22/25\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5117 - accuracy: 0.3433\n",
            "Epoch 00022: loss improved from 1.51384 to 1.51178, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f59bebb3f60>_Batch25_LR0.1_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5118 - accuracy: 0.3432 - val_loss: 1.5181 - val_accuracy: 0.3407\n",
            "Epoch 23/25\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5117 - accuracy: 0.3442\n",
            "Epoch 00023: loss did not improve from 1.51178\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5123 - accuracy: 0.3439 - val_loss: 1.5160 - val_accuracy: 0.3407\n",
            "Epoch 24/25\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5112 - accuracy: 0.3427\n",
            "Epoch 00024: loss improved from 1.51178 to 1.51093, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f59bebb3f60>_Batch25_LR0.1_Epochs25.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5109 - accuracy: 0.3432 - val_loss: 1.5018 - val_accuracy: 0.3399\n",
            "Epoch 25/25\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5110 - accuracy: 0.3419\n",
            "Epoch 00025: loss did not improve from 1.51093\n",
            "595/595 [==============================] - 7s 12ms/step - loss: 1.5110 - accuracy: 0.3419 - val_loss: 1.4985 - val_accuracy: 0.3399\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/50\n",
            "  2/595 [..............................] - ETA: 42s - loss: 2.3351 - accuracy: 0.0600WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0154s vs `on_train_batch_end` time: 0.1259s). Check your callbacks.\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.6065 - accuracy: 0.3098\n",
            "Epoch 00001: loss improved from inf to 1.60648, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59b97fbf28>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.6065 - accuracy: 0.3095 - val_loss: 1.5196 - val_accuracy: 0.3399\n",
            "Epoch 2/50\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5625 - accuracy: 0.3265\n",
            "Epoch 00002: loss improved from 1.60648 to 1.56251, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59b97fbf28>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5625 - accuracy: 0.3265 - val_loss: 1.5098 - val_accuracy: 0.3399\n",
            "Epoch 3/50\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5525 - accuracy: 0.3343\n",
            "Epoch 00003: loss improved from 1.56251 to 1.55234, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59b97fbf28>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5523 - accuracy: 0.3342 - val_loss: 1.5095 - val_accuracy: 0.3399\n",
            "Epoch 4/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5487 - accuracy: 0.3321\n",
            "Epoch 00004: loss improved from 1.55234 to 1.54854, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59b97fbf28>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5485 - accuracy: 0.3321 - val_loss: 1.5078 - val_accuracy: 0.3399\n",
            "Epoch 5/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5428 - accuracy: 0.3359\n",
            "Epoch 00005: loss improved from 1.54854 to 1.54251, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59b97fbf28>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5425 - accuracy: 0.3362 - val_loss: 1.5071 - val_accuracy: 0.3399\n",
            "Epoch 6/50\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5403 - accuracy: 0.3355\n",
            "Epoch 00006: loss improved from 1.54251 to 1.54046, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59b97fbf28>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5405 - accuracy: 0.3355 - val_loss: 1.5058 - val_accuracy: 0.3399\n",
            "Epoch 7/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5391 - accuracy: 0.3374\n",
            "Epoch 00007: loss improved from 1.54046 to 1.53896, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59b97fbf28>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5390 - accuracy: 0.3376 - val_loss: 1.5050 - val_accuracy: 0.3399\n",
            "Epoch 8/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5379 - accuracy: 0.3426\n",
            "Epoch 00008: loss improved from 1.53896 to 1.53789, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59b97fbf28>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5379 - accuracy: 0.3425 - val_loss: 1.5012 - val_accuracy: 0.3399\n",
            "Epoch 9/50\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5368 - accuracy: 0.3389\n",
            "Epoch 00009: loss improved from 1.53789 to 1.53665, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59b97fbf28>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5366 - accuracy: 0.3389 - val_loss: 1.5054 - val_accuracy: 0.3399\n",
            "Epoch 10/50\n",
            "589/595 [============================>.] - ETA: 0s - loss: 1.5375 - accuracy: 0.3357\n",
            "Epoch 00010: loss did not improve from 1.53665\n",
            "595/595 [==============================] - 7s 12ms/step - loss: 1.5369 - accuracy: 0.3362 - val_loss: 1.5060 - val_accuracy: 0.3399\n",
            "Epoch 11/50\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5350 - accuracy: 0.3386\n",
            "Epoch 00011: loss improved from 1.53665 to 1.53507, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59b97fbf28>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5351 - accuracy: 0.3385 - val_loss: 1.5057 - val_accuracy: 0.3399\n",
            "Epoch 12/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5320 - accuracy: 0.3431\n",
            "Epoch 00012: loss improved from 1.53507 to 1.53211, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59b97fbf28>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5321 - accuracy: 0.3430 - val_loss: 1.5056 - val_accuracy: 0.3399\n",
            "Epoch 13/50\n",
            "589/595 [============================>.] - ETA: 0s - loss: 1.5311 - accuracy: 0.3410\n",
            "Epoch 00013: loss improved from 1.53211 to 1.53190, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59b97fbf28>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5319 - accuracy: 0.3402 - val_loss: 1.5020 - val_accuracy: 0.3399\n",
            "Epoch 14/50\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5342 - accuracy: 0.3392\n",
            "Epoch 00014: loss did not improve from 1.53190\n",
            "595/595 [==============================] - 7s 12ms/step - loss: 1.5340 - accuracy: 0.3391 - val_loss: 1.5023 - val_accuracy: 0.3399\n",
            "Epoch 15/50\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5316 - accuracy: 0.3408\n",
            "Epoch 00015: loss improved from 1.53190 to 1.53089, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59b97fbf28>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5309 - accuracy: 0.3409 - val_loss: 1.4996 - val_accuracy: 0.3399\n",
            "Epoch 16/50\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5297 - accuracy: 0.3418\n",
            "Epoch 00016: loss improved from 1.53089 to 1.53003, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59b97fbf28>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5300 - accuracy: 0.3412 - val_loss: 1.5029 - val_accuracy: 0.3399\n",
            "Epoch 17/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5313 - accuracy: 0.3418\n",
            "Epoch 00017: loss did not improve from 1.53003\n",
            "595/595 [==============================] - 7s 13ms/step - loss: 1.5312 - accuracy: 0.3418 - val_loss: 1.5032 - val_accuracy: 0.3399\n",
            "Epoch 18/50\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5303 - accuracy: 0.3443\n",
            "Epoch 00018: loss did not improve from 1.53003\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5303 - accuracy: 0.3443 - val_loss: 1.5041 - val_accuracy: 0.3399\n",
            "Epoch 19/50\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5298 - accuracy: 0.3418\n",
            "Epoch 00019: loss improved from 1.53003 to 1.52972, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59b97fbf28>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5297 - accuracy: 0.3420 - val_loss: 1.4993 - val_accuracy: 0.3399\n",
            "Epoch 20/50\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5287 - accuracy: 0.3397\n",
            "Epoch 00020: loss improved from 1.52972 to 1.52872, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59b97fbf28>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5287 - accuracy: 0.3397 - val_loss: 1.5041 - val_accuracy: 0.3399\n",
            "Epoch 21/50\n",
            "589/595 [============================>.] - ETA: 0s - loss: 1.5303 - accuracy: 0.3444\n",
            "Epoch 00021: loss did not improve from 1.52872\n",
            "595/595 [==============================] - 7s 12ms/step - loss: 1.5300 - accuracy: 0.3442 - val_loss: 1.4988 - val_accuracy: 0.3399\n",
            "Epoch 22/50\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5288 - accuracy: 0.3429\n",
            "Epoch 00022: loss did not improve from 1.52872\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5288 - accuracy: 0.3430 - val_loss: 1.4982 - val_accuracy: 0.3399\n",
            "Epoch 23/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5276 - accuracy: 0.3426\n",
            "Epoch 00023: loss improved from 1.52872 to 1.52765, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59b97fbf28>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5277 - accuracy: 0.3424 - val_loss: 1.5030 - val_accuracy: 0.3399\n",
            "Epoch 24/50\n",
            "589/595 [============================>.] - ETA: 0s - loss: 1.5279 - accuracy: 0.3428\n",
            "Epoch 00024: loss did not improve from 1.52765\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5277 - accuracy: 0.3433 - val_loss: 1.5051 - val_accuracy: 0.3399\n",
            "Epoch 25/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5270 - accuracy: 0.3421\n",
            "Epoch 00025: loss improved from 1.52765 to 1.52694, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59b97fbf28>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5269 - accuracy: 0.3420 - val_loss: 1.5011 - val_accuracy: 0.3399\n",
            "Epoch 26/50\n",
            "589/595 [============================>.] - ETA: 0s - loss: 1.5272 - accuracy: 0.3429\n",
            "Epoch 00026: loss did not improve from 1.52694\n",
            "595/595 [==============================] - 7s 13ms/step - loss: 1.5273 - accuracy: 0.3431 - val_loss: 1.5014 - val_accuracy: 0.3399\n",
            "Epoch 27/50\n",
            "589/595 [============================>.] - ETA: 0s - loss: 1.5279 - accuracy: 0.3432\n",
            "Epoch 00027: loss did not improve from 1.52694\n",
            "595/595 [==============================] - 7s 12ms/step - loss: 1.5280 - accuracy: 0.3434 - val_loss: 1.5021 - val_accuracy: 0.3399\n",
            "Epoch 28/50\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5270 - accuracy: 0.3426\n",
            "Epoch 00028: loss did not improve from 1.52694\n",
            "595/595 [==============================] - 7s 12ms/step - loss: 1.5271 - accuracy: 0.3429 - val_loss: 1.5011 - val_accuracy: 0.3399\n",
            "Epoch 29/50\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5270 - accuracy: 0.3436\n",
            "Epoch 00029: loss improved from 1.52694 to 1.52684, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59b97fbf28>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5268 - accuracy: 0.3432 - val_loss: 1.4991 - val_accuracy: 0.3399\n",
            "Epoch 30/50\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5266 - accuracy: 0.3425\n",
            "Epoch 00030: loss did not improve from 1.52684\n",
            "595/595 [==============================] - 7s 13ms/step - loss: 1.5268 - accuracy: 0.3420 - val_loss: 1.4988 - val_accuracy: 0.3399\n",
            "Epoch 31/50\n",
            "589/595 [============================>.] - ETA: 0s - loss: 1.5278 - accuracy: 0.3429\n",
            "Epoch 00031: loss did not improve from 1.52684\n",
            "595/595 [==============================] - 7s 13ms/step - loss: 1.5274 - accuracy: 0.3432 - val_loss: 1.5006 - val_accuracy: 0.3399\n",
            "Epoch 32/50\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5273 - accuracy: 0.3425\n",
            "Epoch 00032: loss did not improve from 1.52684\n",
            "595/595 [==============================] - 7s 12ms/step - loss: 1.5276 - accuracy: 0.3428 - val_loss: 1.5044 - val_accuracy: 0.3399\n",
            "Epoch 33/50\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5244 - accuracy: 0.3437\n",
            "Epoch 00033: loss improved from 1.52684 to 1.52508, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59b97fbf28>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5251 - accuracy: 0.3437 - val_loss: 1.4996 - val_accuracy: 0.3399\n",
            "Epoch 34/50\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5272 - accuracy: 0.3422\n",
            "Epoch 00034: loss did not improve from 1.52508\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5274 - accuracy: 0.3420 - val_loss: 1.5001 - val_accuracy: 0.3399\n",
            "Epoch 35/50\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5261 - accuracy: 0.3426\n",
            "Epoch 00035: loss did not improve from 1.52508\n",
            "595/595 [==============================] - 7s 12ms/step - loss: 1.5266 - accuracy: 0.3425 - val_loss: 1.5043 - val_accuracy: 0.3399\n",
            "Epoch 36/50\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5258 - accuracy: 0.3434\n",
            "Epoch 00036: loss did not improve from 1.52508\n",
            "595/595 [==============================] - 7s 13ms/step - loss: 1.5258 - accuracy: 0.3434 - val_loss: 1.5010 - val_accuracy: 0.3399\n",
            "Epoch 37/50\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5246 - accuracy: 0.3442\n",
            "Epoch 00037: loss improved from 1.52508 to 1.52491, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59b97fbf28>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5249 - accuracy: 0.3437 - val_loss: 1.4982 - val_accuracy: 0.3399\n",
            "Epoch 38/50\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5248 - accuracy: 0.3418\n",
            "Epoch 00038: loss improved from 1.52491 to 1.52474, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59b97fbf28>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5247 - accuracy: 0.3417 - val_loss: 1.4975 - val_accuracy: 0.3399\n",
            "Epoch 39/50\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5234 - accuracy: 0.3438\n",
            "Epoch 00039: loss improved from 1.52474 to 1.52315, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59b97fbf28>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5231 - accuracy: 0.3440 - val_loss: 1.4962 - val_accuracy: 0.3399\n",
            "Epoch 40/50\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5248 - accuracy: 0.3428\n",
            "Epoch 00040: loss did not improve from 1.52315\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5247 - accuracy: 0.3427 - val_loss: 1.4970 - val_accuracy: 0.3399\n",
            "Epoch 41/50\n",
            "589/595 [============================>.] - ETA: 0s - loss: 1.5243 - accuracy: 0.3432\n",
            "Epoch 00041: loss did not improve from 1.52315\n",
            "595/595 [==============================] - 7s 12ms/step - loss: 1.5243 - accuracy: 0.3435 - val_loss: 1.4986 - val_accuracy: 0.3399\n",
            "Epoch 42/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5257 - accuracy: 0.3423\n",
            "Epoch 00042: loss did not improve from 1.52315\n",
            "595/595 [==============================] - 7s 12ms/step - loss: 1.5256 - accuracy: 0.3423 - val_loss: 1.5012 - val_accuracy: 0.3399\n",
            "Epoch 43/50\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5237 - accuracy: 0.3427\n",
            "Epoch 00043: loss did not improve from 1.52315\n",
            "595/595 [==============================] - 7s 12ms/step - loss: 1.5237 - accuracy: 0.3426 - val_loss: 1.5006 - val_accuracy: 0.3399\n",
            "Epoch 44/50\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5234 - accuracy: 0.3437\n",
            "Epoch 00044: loss did not improve from 1.52315\n",
            "595/595 [==============================] - 7s 12ms/step - loss: 1.5233 - accuracy: 0.3436 - val_loss: 1.5021 - val_accuracy: 0.3399\n",
            "Epoch 45/50\n",
            "589/595 [============================>.] - ETA: 0s - loss: 1.5238 - accuracy: 0.3434\n",
            "Epoch 00045: loss did not improve from 1.52315\n",
            "595/595 [==============================] - 7s 12ms/step - loss: 1.5235 - accuracy: 0.3439 - val_loss: 1.5009 - val_accuracy: 0.3399\n",
            "Epoch 46/50\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5232 - accuracy: 0.3449\n",
            "Epoch 00046: loss did not improve from 1.52315\n",
            "595/595 [==============================] - 7s 12ms/step - loss: 1.5233 - accuracy: 0.3449 - val_loss: 1.5000 - val_accuracy: 0.3399\n",
            "Epoch 47/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5229 - accuracy: 0.3438\n",
            "Epoch 00047: loss improved from 1.52315 to 1.52275, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59b97fbf28>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5228 - accuracy: 0.3439 - val_loss: 1.4996 - val_accuracy: 0.3399\n",
            "Epoch 48/50\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5220 - accuracy: 0.3438\n",
            "Epoch 00048: loss improved from 1.52275 to 1.52268, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59b97fbf28>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5227 - accuracy: 0.3436 - val_loss: 1.4985 - val_accuracy: 0.3399\n",
            "Epoch 49/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5223 - accuracy: 0.3432\n",
            "Epoch 00049: loss did not improve from 1.52268\n",
            "595/595 [==============================] - 7s 13ms/step - loss: 1.5228 - accuracy: 0.3430 - val_loss: 1.5006 - val_accuracy: 0.3399\n",
            "Epoch 50/50\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5221 - accuracy: 0.3433\n",
            "Epoch 00050: loss improved from 1.52268 to 1.52242, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59b97fbf28>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 10s 17ms/step - loss: 1.5224 - accuracy: 0.3432 - val_loss: 1.5030 - val_accuracy: 0.3399\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/50\n",
            "  2/595 [..............................] - ETA: 52s - loss: 2.1366 - accuracy: 0.1600WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0158s vs `on_train_batch_end` time: 0.1613s). Check your callbacks.\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5460 - accuracy: 0.3316\n",
            "Epoch 00001: loss improved from inf to 1.54612, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f59b9879470>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5461 - accuracy: 0.3313 - val_loss: 1.5033 - val_accuracy: 0.3399\n",
            "Epoch 2/50\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5286 - accuracy: 0.3405\n",
            "Epoch 00002: loss improved from 1.54612 to 1.52856, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f59b9879470>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5286 - accuracy: 0.3404 - val_loss: 1.4959 - val_accuracy: 0.3399\n",
            "Epoch 3/50\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5234 - accuracy: 0.3431\n",
            "Epoch 00003: loss improved from 1.52856 to 1.52350, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f59b9879470>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5235 - accuracy: 0.3432 - val_loss: 1.4909 - val_accuracy: 0.3399\n",
            "Epoch 4/50\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5203 - accuracy: 0.3426\n",
            "Epoch 00004: loss improved from 1.52350 to 1.52067, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f59b9879470>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5207 - accuracy: 0.3426 - val_loss: 1.4865 - val_accuracy: 0.3399\n",
            "Epoch 5/50\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5175 - accuracy: 0.3423\n",
            "Epoch 00005: loss improved from 1.52067 to 1.51755, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f59b9879470>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5176 - accuracy: 0.3423 - val_loss: 1.5161 - val_accuracy: 0.3372\n",
            "Epoch 6/50\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5139 - accuracy: 0.3458\n",
            "Epoch 00006: loss improved from 1.51755 to 1.51391, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f59b9879470>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5139 - accuracy: 0.3458 - val_loss: 1.4960 - val_accuracy: 0.3399\n",
            "Epoch 7/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5138 - accuracy: 0.3434\n",
            "Epoch 00007: loss improved from 1.51391 to 1.51385, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f59b9879470>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5139 - accuracy: 0.3434 - val_loss: 1.4899 - val_accuracy: 0.3372\n",
            "Epoch 8/50\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5102 - accuracy: 0.3466\n",
            "Epoch 00008: loss improved from 1.51385 to 1.51018, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f59b9879470>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5102 - accuracy: 0.3462 - val_loss: 1.4943 - val_accuracy: 0.3321\n",
            "Epoch 9/50\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5088 - accuracy: 0.3460\n",
            "Epoch 00009: loss improved from 1.51018 to 1.50911, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f59b9879470>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5091 - accuracy: 0.3460 - val_loss: 1.5073 - val_accuracy: 0.3348\n",
            "Epoch 10/50\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5083 - accuracy: 0.3461\n",
            "Epoch 00010: loss improved from 1.50911 to 1.50829, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f59b9879470>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5083 - accuracy: 0.3461 - val_loss: 1.4933 - val_accuracy: 0.3337\n",
            "Epoch 11/50\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5053 - accuracy: 0.3492\n",
            "Epoch 00011: loss improved from 1.50829 to 1.50524, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f59b9879470>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5052 - accuracy: 0.3491 - val_loss: 1.4981 - val_accuracy: 0.3138\n",
            "Epoch 12/50\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5022 - accuracy: 0.3454\n",
            "Epoch 00012: loss improved from 1.50524 to 1.50208, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f59b9879470>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5021 - accuracy: 0.3453 - val_loss: 1.5023 - val_accuracy: 0.3270\n",
            "Epoch 13/50\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5034 - accuracy: 0.3448\n",
            "Epoch 00013: loss did not improve from 1.50208\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5036 - accuracy: 0.3448 - val_loss: 1.5023 - val_accuracy: 0.3407\n",
            "Epoch 14/50\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5023 - accuracy: 0.3484\n",
            "Epoch 00014: loss did not improve from 1.50208\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5023 - accuracy: 0.3484 - val_loss: 1.5032 - val_accuracy: 0.3321\n",
            "Epoch 15/50\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5005 - accuracy: 0.3484\n",
            "Epoch 00015: loss improved from 1.50208 to 1.50048, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f59b9879470>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5005 - accuracy: 0.3484 - val_loss: 1.4884 - val_accuracy: 0.3305\n",
            "Epoch 16/50\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.4993 - accuracy: 0.3491\n",
            "Epoch 00016: loss improved from 1.50048 to 1.49936, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f59b9879470>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4994 - accuracy: 0.3487 - val_loss: 1.5012 - val_accuracy: 0.3122\n",
            "Epoch 17/50\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.4980 - accuracy: 0.3478\n",
            "Epoch 00017: loss improved from 1.49936 to 1.49815, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f59b9879470>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4982 - accuracy: 0.3477 - val_loss: 1.4997 - val_accuracy: 0.3256\n",
            "Epoch 18/50\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.4998 - accuracy: 0.3485\n",
            "Epoch 00018: loss did not improve from 1.49815\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4998 - accuracy: 0.3485 - val_loss: 1.5157 - val_accuracy: 0.3248\n",
            "Epoch 19/50\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.4945 - accuracy: 0.3569\n",
            "Epoch 00019: loss improved from 1.49815 to 1.49437, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f59b9879470>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.4944 - accuracy: 0.3569 - val_loss: 1.5051 - val_accuracy: 0.3307\n",
            "Epoch 20/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.4955 - accuracy: 0.3519\n",
            "Epoch 00020: loss did not improve from 1.49437\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4956 - accuracy: 0.3519 - val_loss: 1.5244 - val_accuracy: 0.3237\n",
            "Epoch 21/50\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.4950 - accuracy: 0.3540\n",
            "Epoch 00021: loss did not improve from 1.49437\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4952 - accuracy: 0.3543 - val_loss: 1.5356 - val_accuracy: 0.3353\n",
            "Epoch 22/50\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.4942 - accuracy: 0.3526\n",
            "Epoch 00022: loss improved from 1.49437 to 1.49422, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f59b9879470>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.4942 - accuracy: 0.3525 - val_loss: 1.5225 - val_accuracy: 0.3178\n",
            "Epoch 23/50\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.4904 - accuracy: 0.3538\n",
            "Epoch 00023: loss improved from 1.49422 to 1.49062, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f59b9879470>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4906 - accuracy: 0.3536 - val_loss: 1.5259 - val_accuracy: 0.3369\n",
            "Epoch 24/50\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.4913 - accuracy: 0.3539\n",
            "Epoch 00024: loss did not improve from 1.49062\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4910 - accuracy: 0.3543 - val_loss: 1.5472 - val_accuracy: 0.3127\n",
            "Epoch 25/50\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.4916 - accuracy: 0.3600\n",
            "Epoch 00025: loss did not improve from 1.49062\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4917 - accuracy: 0.3600 - val_loss: 1.5451 - val_accuracy: 0.3202\n",
            "Epoch 26/50\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.4902 - accuracy: 0.3572\n",
            "Epoch 00026: loss improved from 1.49062 to 1.49008, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f59b9879470>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.4901 - accuracy: 0.3574 - val_loss: 1.5259 - val_accuracy: 0.3227\n",
            "Epoch 27/50\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.4898 - accuracy: 0.3540\n",
            "Epoch 00027: loss improved from 1.49008 to 1.48953, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f59b9879470>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4895 - accuracy: 0.3545 - val_loss: 1.5468 - val_accuracy: 0.3229\n",
            "Epoch 28/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.4896 - accuracy: 0.3556\n",
            "Epoch 00028: loss did not improve from 1.48953\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4897 - accuracy: 0.3555 - val_loss: 1.5496 - val_accuracy: 0.3205\n",
            "Epoch 29/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.4889 - accuracy: 0.3593\n",
            "Epoch 00029: loss improved from 1.48953 to 1.48903, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f59b9879470>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.4890 - accuracy: 0.3591 - val_loss: 1.5435 - val_accuracy: 0.3450\n",
            "Epoch 30/50\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.4868 - accuracy: 0.3560\n",
            "Epoch 00030: loss improved from 1.48903 to 1.48654, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f59b9879470>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4865 - accuracy: 0.3559 - val_loss: 1.5485 - val_accuracy: 0.3248\n",
            "Epoch 31/50\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.4846 - accuracy: 0.3618\n",
            "Epoch 00031: loss improved from 1.48654 to 1.48472, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f59b9879470>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4847 - accuracy: 0.3615 - val_loss: 1.5656 - val_accuracy: 0.3399\n",
            "Epoch 32/50\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.4828 - accuracy: 0.3589\n",
            "Epoch 00032: loss improved from 1.48472 to 1.48311, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f59b9879470>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4831 - accuracy: 0.3588 - val_loss: 1.5578 - val_accuracy: 0.3315\n",
            "Epoch 33/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.4839 - accuracy: 0.3646\n",
            "Epoch 00033: loss did not improve from 1.48311\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4841 - accuracy: 0.3644 - val_loss: 1.5585 - val_accuracy: 0.3402\n",
            "Epoch 34/50\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.4831 - accuracy: 0.3621\n",
            "Epoch 00034: loss improved from 1.48311 to 1.48309, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f59b9879470>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.4831 - accuracy: 0.3621 - val_loss: 1.5644 - val_accuracy: 0.3380\n",
            "Epoch 35/50\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.4863 - accuracy: 0.3641\n",
            "Epoch 00035: loss did not improve from 1.48309\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4861 - accuracy: 0.3642 - val_loss: 1.5996 - val_accuracy: 0.3186\n",
            "Epoch 36/50\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.4834 - accuracy: 0.3628\n",
            "Epoch 00036: loss did not improve from 1.48309\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4841 - accuracy: 0.3626 - val_loss: 1.6068 - val_accuracy: 0.3219\n",
            "Epoch 37/50\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.4822 - accuracy: 0.3614\n",
            "Epoch 00037: loss improved from 1.48309 to 1.48163, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f59b9879470>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.4816 - accuracy: 0.3617 - val_loss: 1.5950 - val_accuracy: 0.3219\n",
            "Epoch 38/50\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.4813 - accuracy: 0.3644\n",
            "Epoch 00038: loss improved from 1.48163 to 1.48112, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f59b9879470>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4811 - accuracy: 0.3644 - val_loss: 1.6051 - val_accuracy: 0.3318\n",
            "Epoch 39/50\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.4818 - accuracy: 0.3610\n",
            "Epoch 00039: loss did not improve from 1.48112\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4817 - accuracy: 0.3611 - val_loss: 1.6593 - val_accuracy: 0.3130\n",
            "Epoch 40/50\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.4805 - accuracy: 0.3683\n",
            "Epoch 00040: loss improved from 1.48112 to 1.48046, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f59b9879470>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.4805 - accuracy: 0.3683 - val_loss: 1.6470 - val_accuracy: 0.3149\n",
            "Epoch 41/50\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.4799 - accuracy: 0.3651\n",
            "Epoch 00041: loss improved from 1.48046 to 1.48022, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f59b9879470>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4802 - accuracy: 0.3651 - val_loss: 1.6367 - val_accuracy: 0.3170\n",
            "Epoch 42/50\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.4770 - accuracy: 0.3632\n",
            "Epoch 00042: loss improved from 1.48022 to 1.47775, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f59b9879470>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4778 - accuracy: 0.3634 - val_loss: 1.6119 - val_accuracy: 0.3248\n",
            "Epoch 43/50\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.4770 - accuracy: 0.3607\n",
            "Epoch 00043: loss improved from 1.47775 to 1.47708, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f59b9879470>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4771 - accuracy: 0.3605 - val_loss: 1.6690 - val_accuracy: 0.3315\n",
            "Epoch 44/50\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.4766 - accuracy: 0.3664\n",
            "Epoch 00044: loss improved from 1.47708 to 1.47662, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f59b9879470>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4766 - accuracy: 0.3662 - val_loss: 1.6762 - val_accuracy: 0.3235\n",
            "Epoch 45/50\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.4753 - accuracy: 0.3686\n",
            "Epoch 00045: loss improved from 1.47662 to 1.47584, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f59b9879470>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4758 - accuracy: 0.3681 - val_loss: 1.6771 - val_accuracy: 0.3087\n",
            "Epoch 46/50\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.4750 - accuracy: 0.3685\n",
            "Epoch 00046: loss improved from 1.47584 to 1.47517, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f59b9879470>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4752 - accuracy: 0.3683 - val_loss: 1.7080 - val_accuracy: 0.3251\n",
            "Epoch 47/50\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.4763 - accuracy: 0.3665\n",
            "Epoch 00047: loss did not improve from 1.47517\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4763 - accuracy: 0.3665 - val_loss: 1.6730 - val_accuracy: 0.3235\n",
            "Epoch 48/50\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.4746 - accuracy: 0.3641\n",
            "Epoch 00048: loss improved from 1.47517 to 1.47514, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f59b9879470>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.4751 - accuracy: 0.3642 - val_loss: 1.7208 - val_accuracy: 0.3232\n",
            "Epoch 49/50\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.4778 - accuracy: 0.3703\n",
            "Epoch 00049: loss did not improve from 1.47514\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4778 - accuracy: 0.3703 - val_loss: 1.7109 - val_accuracy: 0.3127\n",
            "Epoch 50/50\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.4761 - accuracy: 0.3666\n",
            "Epoch 00050: loss did not improve from 1.47514\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4761 - accuracy: 0.3666 - val_loss: 1.7159 - val_accuracy: 0.3184\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/50\n",
            "  2/595 [..............................] - ETA: 34s - loss: 2.1142 - accuracy: 0.2200WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0160s vs `on_train_batch_end` time: 0.1006s). Check your callbacks.\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5489 - accuracy: 0.3312\n",
            "Epoch 00001: loss improved from inf to 1.54839, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f59c41d7fd0>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5484 - accuracy: 0.3314 - val_loss: 1.4996 - val_accuracy: 0.3399\n",
            "Epoch 2/50\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5272 - accuracy: 0.3434\n",
            "Epoch 00002: loss improved from 1.54839 to 1.52717, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f59c41d7fd0>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5272 - accuracy: 0.3434 - val_loss: 1.4991 - val_accuracy: 0.3399\n",
            "Epoch 3/50\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5214 - accuracy: 0.3435\n",
            "Epoch 00003: loss improved from 1.52717 to 1.52144, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f59c41d7fd0>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5214 - accuracy: 0.3435 - val_loss: 1.4975 - val_accuracy: 0.3372\n",
            "Epoch 4/50\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5188 - accuracy: 0.3401\n",
            "Epoch 00004: loss improved from 1.52144 to 1.51883, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f59c41d7fd0>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5188 - accuracy: 0.3401 - val_loss: 1.4923 - val_accuracy: 0.3372\n",
            "Epoch 5/50\n",
            "589/595 [============================>.] - ETA: 0s - loss: 1.5171 - accuracy: 0.3447\n",
            "Epoch 00005: loss improved from 1.51883 to 1.51661, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f59c41d7fd0>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5166 - accuracy: 0.3451 - val_loss: 1.4929 - val_accuracy: 0.3372\n",
            "Epoch 6/50\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5143 - accuracy: 0.3436\n",
            "Epoch 00006: loss improved from 1.51661 to 1.51436, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f59c41d7fd0>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5144 - accuracy: 0.3436 - val_loss: 1.5010 - val_accuracy: 0.3372\n",
            "Epoch 7/50\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5124 - accuracy: 0.3463\n",
            "Epoch 00007: loss improved from 1.51436 to 1.51254, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f59c41d7fd0>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5125 - accuracy: 0.3461 - val_loss: 1.4939 - val_accuracy: 0.3367\n",
            "Epoch 8/50\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5105 - accuracy: 0.3396\n",
            "Epoch 00008: loss improved from 1.51254 to 1.51046, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f59c41d7fd0>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5105 - accuracy: 0.3396 - val_loss: 1.4925 - val_accuracy: 0.3372\n",
            "Epoch 9/50\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5080 - accuracy: 0.3465\n",
            "Epoch 00009: loss improved from 1.51046 to 1.50846, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f59c41d7fd0>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5085 - accuracy: 0.3463 - val_loss: 1.4923 - val_accuracy: 0.3372\n",
            "Epoch 10/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5069 - accuracy: 0.3414\n",
            "Epoch 00010: loss improved from 1.50846 to 1.50677, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f59c41d7fd0>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5068 - accuracy: 0.3416 - val_loss: 1.4932 - val_accuracy: 0.3245\n",
            "Epoch 11/50\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5065 - accuracy: 0.3462\n",
            "Epoch 00011: loss improved from 1.50677 to 1.50629, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f59c41d7fd0>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5063 - accuracy: 0.3464 - val_loss: 1.4920 - val_accuracy: 0.3259\n",
            "Epoch 12/50\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5030 - accuracy: 0.3505\n",
            "Epoch 00012: loss improved from 1.50629 to 1.50314, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f59c41d7fd0>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5031 - accuracy: 0.3504 - val_loss: 1.4959 - val_accuracy: 0.3332\n",
            "Epoch 13/50\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5007 - accuracy: 0.3443\n",
            "Epoch 00013: loss improved from 1.50314 to 1.50113, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f59c41d7fd0>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5011 - accuracy: 0.3440 - val_loss: 1.5004 - val_accuracy: 0.3364\n",
            "Epoch 14/50\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.4992 - accuracy: 0.3470\n",
            "Epoch 00014: loss improved from 1.50113 to 1.49960, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f59c41d7fd0>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4996 - accuracy: 0.3468 - val_loss: 1.5030 - val_accuracy: 0.3358\n",
            "Epoch 15/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5011 - accuracy: 0.3430\n",
            "Epoch 00015: loss did not improve from 1.49960\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5015 - accuracy: 0.3429 - val_loss: 1.4969 - val_accuracy: 0.3297\n",
            "Epoch 16/50\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.4987 - accuracy: 0.3448\n",
            "Epoch 00016: loss improved from 1.49960 to 1.49812, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f59c41d7fd0>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.4981 - accuracy: 0.3448 - val_loss: 1.5037 - val_accuracy: 0.3385\n",
            "Epoch 17/50\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.4949 - accuracy: 0.3480\n",
            "Epoch 00017: loss improved from 1.49812 to 1.49487, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f59c41d7fd0>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4949 - accuracy: 0.3480 - val_loss: 1.5027 - val_accuracy: 0.3092\n",
            "Epoch 18/50\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.4927 - accuracy: 0.3526\n",
            "Epoch 00018: loss improved from 1.49487 to 1.49322, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f59c41d7fd0>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.4932 - accuracy: 0.3522 - val_loss: 1.4928 - val_accuracy: 0.3189\n",
            "Epoch 19/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.4925 - accuracy: 0.3500\n",
            "Epoch 00019: loss improved from 1.49322 to 1.49267, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f59c41d7fd0>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4927 - accuracy: 0.3497 - val_loss: 1.5023 - val_accuracy: 0.3270\n",
            "Epoch 20/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.4903 - accuracy: 0.3536\n",
            "Epoch 00020: loss improved from 1.49267 to 1.49038, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f59c41d7fd0>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4904 - accuracy: 0.3535 - val_loss: 1.4957 - val_accuracy: 0.3143\n",
            "Epoch 21/50\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.4893 - accuracy: 0.3513\n",
            "Epoch 00021: loss improved from 1.49038 to 1.48934, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f59c41d7fd0>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4893 - accuracy: 0.3513 - val_loss: 1.4833 - val_accuracy: 0.3302\n",
            "Epoch 22/50\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.4881 - accuracy: 0.3514\n",
            "Epoch 00022: loss improved from 1.48934 to 1.48806, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f59c41d7fd0>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4881 - accuracy: 0.3514 - val_loss: 1.4888 - val_accuracy: 0.3348\n",
            "Epoch 23/50\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.4865 - accuracy: 0.3543\n",
            "Epoch 00023: loss improved from 1.48806 to 1.48650, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f59c41d7fd0>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4865 - accuracy: 0.3543 - val_loss: 1.5094 - val_accuracy: 0.3108\n",
            "Epoch 24/50\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.4876 - accuracy: 0.3522\n",
            "Epoch 00024: loss did not improve from 1.48650\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4876 - accuracy: 0.3521 - val_loss: 1.5056 - val_accuracy: 0.3345\n",
            "Epoch 25/50\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.4864 - accuracy: 0.3555\n",
            "Epoch 00025: loss did not improve from 1.48650\n",
            "595/595 [==============================] - 7s 13ms/step - loss: 1.4868 - accuracy: 0.3554 - val_loss: 1.4891 - val_accuracy: 0.3393\n",
            "Epoch 26/50\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.4838 - accuracy: 0.3561\n",
            "Epoch 00026: loss improved from 1.48650 to 1.48367, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f59c41d7fd0>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.4837 - accuracy: 0.3566 - val_loss: 1.4946 - val_accuracy: 0.3089\n",
            "Epoch 27/50\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.4830 - accuracy: 0.3530\n",
            "Epoch 00027: loss improved from 1.48367 to 1.48297, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f59c41d7fd0>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4830 - accuracy: 0.3532 - val_loss: 1.5004 - val_accuracy: 0.3272\n",
            "Epoch 28/50\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.4812 - accuracy: 0.3550\n",
            "Epoch 00028: loss improved from 1.48297 to 1.48077, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f59c41d7fd0>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4808 - accuracy: 0.3549 - val_loss: 1.5266 - val_accuracy: 0.3221\n",
            "Epoch 29/50\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.4809 - accuracy: 0.3589\n",
            "Epoch 00029: loss improved from 1.48077 to 1.48072, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f59c41d7fd0>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4807 - accuracy: 0.3591 - val_loss: 1.5171 - val_accuracy: 0.3216\n",
            "Epoch 30/50\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.4800 - accuracy: 0.3616\n",
            "Epoch 00030: loss improved from 1.48072 to 1.47967, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f59c41d7fd0>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4797 - accuracy: 0.3616 - val_loss: 1.5120 - val_accuracy: 0.3391\n",
            "Epoch 31/50\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.4767 - accuracy: 0.3636\n",
            "Epoch 00031: loss improved from 1.47967 to 1.47647, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f59c41d7fd0>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4765 - accuracy: 0.3636 - val_loss: 1.5117 - val_accuracy: 0.3353\n",
            "Epoch 32/50\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.4758 - accuracy: 0.3671\n",
            "Epoch 00032: loss improved from 1.47647 to 1.47612, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f59c41d7fd0>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4761 - accuracy: 0.3668 - val_loss: 1.5309 - val_accuracy: 0.3157\n",
            "Epoch 33/50\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.4751 - accuracy: 0.3640\n",
            "Epoch 00033: loss improved from 1.47612 to 1.47511, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f59c41d7fd0>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4751 - accuracy: 0.3638 - val_loss: 1.5156 - val_accuracy: 0.3399\n",
            "Epoch 34/50\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.4754 - accuracy: 0.3634\n",
            "Epoch 00034: loss did not improve from 1.47511\n",
            "595/595 [==============================] - 7s 13ms/step - loss: 1.4759 - accuracy: 0.3634 - val_loss: 1.5284 - val_accuracy: 0.3235\n",
            "Epoch 35/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.4707 - accuracy: 0.3696\n",
            "Epoch 00035: loss improved from 1.47511 to 1.47077, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f59c41d7fd0>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.4708 - accuracy: 0.3696 - val_loss: 1.5433 - val_accuracy: 0.3229\n",
            "Epoch 36/50\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.4745 - accuracy: 0.3657\n",
            "Epoch 00036: loss did not improve from 1.47077\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4745 - accuracy: 0.3657 - val_loss: 1.5182 - val_accuracy: 0.3345\n",
            "Epoch 37/50\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.4733 - accuracy: 0.3620\n",
            "Epoch 00037: loss did not improve from 1.47077\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4731 - accuracy: 0.3622 - val_loss: 1.5358 - val_accuracy: 0.3216\n",
            "Epoch 38/50\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.4728 - accuracy: 0.3642\n",
            "Epoch 00038: loss did not improve from 1.47077\n",
            "595/595 [==============================] - 7s 13ms/step - loss: 1.4729 - accuracy: 0.3644 - val_loss: 1.5747 - val_accuracy: 0.3159\n",
            "Epoch 39/50\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.4717 - accuracy: 0.3657\n",
            "Epoch 00039: loss did not improve from 1.47077\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4717 - accuracy: 0.3657 - val_loss: 1.5523 - val_accuracy: 0.3264\n",
            "Epoch 40/50\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.4688 - accuracy: 0.3667\n",
            "Epoch 00040: loss improved from 1.47077 to 1.46867, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f59c41d7fd0>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.4687 - accuracy: 0.3667 - val_loss: 1.5319 - val_accuracy: 0.3385\n",
            "Epoch 41/50\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.4670 - accuracy: 0.3681\n",
            "Epoch 00041: loss improved from 1.46867 to 1.46697, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f59c41d7fd0>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4670 - accuracy: 0.3681 - val_loss: 1.5752 - val_accuracy: 0.3275\n",
            "Epoch 42/50\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.4677 - accuracy: 0.3696\n",
            "Epoch 00042: loss did not improve from 1.46697\n",
            "595/595 [==============================] - 7s 13ms/step - loss: 1.4678 - accuracy: 0.3693 - val_loss: 1.5681 - val_accuracy: 0.3469\n",
            "Epoch 43/50\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.4671 - accuracy: 0.3643\n",
            "Epoch 00043: loss did not improve from 1.46697\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4671 - accuracy: 0.3646 - val_loss: 1.5685 - val_accuracy: 0.3297\n",
            "Epoch 44/50\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.4643 - accuracy: 0.3661\n",
            "Epoch 00044: loss improved from 1.46697 to 1.46454, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f59c41d7fd0>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.4645 - accuracy: 0.3659 - val_loss: 1.5665 - val_accuracy: 0.3367\n",
            "Epoch 45/50\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.4648 - accuracy: 0.3704\n",
            "Epoch 00045: loss did not improve from 1.46454\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4648 - accuracy: 0.3700 - val_loss: 1.5553 - val_accuracy: 0.3393\n",
            "Epoch 46/50\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.4630 - accuracy: 0.3654\n",
            "Epoch 00046: loss improved from 1.46454 to 1.46255, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f59c41d7fd0>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.4626 - accuracy: 0.3657 - val_loss: 1.5682 - val_accuracy: 0.3213\n",
            "Epoch 47/50\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.4625 - accuracy: 0.3659\n",
            "Epoch 00047: loss did not improve from 1.46255\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4626 - accuracy: 0.3656 - val_loss: 1.5984 - val_accuracy: 0.3377\n",
            "Epoch 48/50\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.4617 - accuracy: 0.3690\n",
            "Epoch 00048: loss improved from 1.46255 to 1.46157, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f59c41d7fd0>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.4616 - accuracy: 0.3692 - val_loss: 1.6402 - val_accuracy: 0.3270\n",
            "Epoch 49/50\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.4582 - accuracy: 0.3743\n",
            "Epoch 00049: loss improved from 1.46157 to 1.45834, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f59c41d7fd0>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4583 - accuracy: 0.3743 - val_loss: 1.5950 - val_accuracy: 0.3375\n",
            "Epoch 50/50\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.4600 - accuracy: 0.3749\n",
            "Epoch 00050: loss did not improve from 1.45834\n",
            "595/595 [==============================] - 7s 13ms/step - loss: 1.4599 - accuracy: 0.3752 - val_loss: 1.5681 - val_accuracy: 0.3469\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/50\n",
            "  2/595 [..............................] - ETA: 31s - loss: 2.3347 - accuracy: 0.1200WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0151s vs `on_train_batch_end` time: 0.0912s). Check your callbacks.\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.6021 - accuracy: 0.3112\n",
            "Epoch 00001: loss improved from inf to 1.60236, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59b9872be0>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.6024 - accuracy: 0.3110 - val_loss: 1.5213 - val_accuracy: 0.3399\n",
            "Epoch 2/50\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5546 - accuracy: 0.3298\n",
            "Epoch 00002: loss improved from 1.60236 to 1.55455, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59b9872be0>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5545 - accuracy: 0.3297 - val_loss: 1.5087 - val_accuracy: 0.3399\n",
            "Epoch 3/50\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5539 - accuracy: 0.3283\n",
            "Epoch 00003: loss improved from 1.55455 to 1.55411, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59b9872be0>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5541 - accuracy: 0.3282 - val_loss: 1.5104 - val_accuracy: 0.3399\n",
            "Epoch 4/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5501 - accuracy: 0.3276\n",
            "Epoch 00004: loss improved from 1.55411 to 1.54999, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59b9872be0>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5500 - accuracy: 0.3276 - val_loss: 1.5069 - val_accuracy: 0.3399\n",
            "Epoch 5/50\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5471 - accuracy: 0.3255\n",
            "Epoch 00005: loss improved from 1.54999 to 1.54706, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59b9872be0>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5471 - accuracy: 0.3255 - val_loss: 1.5065 - val_accuracy: 0.3399\n",
            "Epoch 6/50\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5439 - accuracy: 0.3280\n",
            "Epoch 00006: loss improved from 1.54706 to 1.54387, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59b9872be0>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5439 - accuracy: 0.3277 - val_loss: 1.5065 - val_accuracy: 0.3399\n",
            "Epoch 7/50\n",
            "589/595 [============================>.] - ETA: 0s - loss: 1.5399 - accuracy: 0.3330\n",
            "Epoch 00007: loss improved from 1.54387 to 1.54005, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59b9872be0>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5400 - accuracy: 0.3325 - val_loss: 1.5049 - val_accuracy: 0.3399\n",
            "Epoch 8/50\n",
            "589/595 [============================>.] - ETA: 0s - loss: 1.5431 - accuracy: 0.3358\n",
            "Epoch 00008: loss did not improve from 1.54005\n",
            "595/595 [==============================] - 7s 13ms/step - loss: 1.5432 - accuracy: 0.3357 - val_loss: 1.5042 - val_accuracy: 0.3399\n",
            "Epoch 9/50\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5408 - accuracy: 0.3307\n",
            "Epoch 00009: loss did not improve from 1.54005\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5407 - accuracy: 0.3307 - val_loss: 1.5043 - val_accuracy: 0.3399\n",
            "Epoch 10/50\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5409 - accuracy: 0.3351\n",
            "Epoch 00010: loss did not improve from 1.54005\n",
            "595/595 [==============================] - 7s 12ms/step - loss: 1.5407 - accuracy: 0.3350 - val_loss: 1.5040 - val_accuracy: 0.3399\n",
            "Epoch 11/50\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5352 - accuracy: 0.3389\n",
            "Epoch 00011: loss improved from 1.54005 to 1.53548, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59b9872be0>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5355 - accuracy: 0.3385 - val_loss: 1.5036 - val_accuracy: 0.3399\n",
            "Epoch 12/50\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5358 - accuracy: 0.3374\n",
            "Epoch 00012: loss did not improve from 1.53548\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5361 - accuracy: 0.3370 - val_loss: 1.5042 - val_accuracy: 0.3399\n",
            "Epoch 13/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5358 - accuracy: 0.3363\n",
            "Epoch 00013: loss did not improve from 1.53548\n",
            "595/595 [==============================] - 7s 13ms/step - loss: 1.5358 - accuracy: 0.3363 - val_loss: 1.5036 - val_accuracy: 0.3399\n",
            "Epoch 14/50\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5356 - accuracy: 0.3385\n",
            "Epoch 00014: loss improved from 1.53548 to 1.53489, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59b9872be0>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5349 - accuracy: 0.3391 - val_loss: 1.5046 - val_accuracy: 0.3399\n",
            "Epoch 15/50\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5333 - accuracy: 0.3394\n",
            "Epoch 00015: loss improved from 1.53489 to 1.53339, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59b9872be0>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5334 - accuracy: 0.3395 - val_loss: 1.5042 - val_accuracy: 0.3399\n",
            "Epoch 16/50\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5339 - accuracy: 0.3346\n",
            "Epoch 00016: loss did not improve from 1.53339\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5339 - accuracy: 0.3346 - val_loss: 1.5036 - val_accuracy: 0.3399\n",
            "Epoch 17/50\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5356 - accuracy: 0.3394\n",
            "Epoch 00017: loss did not improve from 1.53339\n",
            "595/595 [==============================] - 7s 12ms/step - loss: 1.5357 - accuracy: 0.3392 - val_loss: 1.5040 - val_accuracy: 0.3399\n",
            "Epoch 18/50\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5341 - accuracy: 0.3347\n",
            "Epoch 00018: loss did not improve from 1.53339\n",
            "595/595 [==============================] - 7s 12ms/step - loss: 1.5341 - accuracy: 0.3348 - val_loss: 1.5035 - val_accuracy: 0.3399\n",
            "Epoch 19/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5329 - accuracy: 0.3395\n",
            "Epoch 00019: loss improved from 1.53339 to 1.53306, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59b9872be0>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5331 - accuracy: 0.3394 - val_loss: 1.5033 - val_accuracy: 0.3399\n",
            "Epoch 20/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5326 - accuracy: 0.3364\n",
            "Epoch 00020: loss improved from 1.53306 to 1.53253, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59b9872be0>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5325 - accuracy: 0.3364 - val_loss: 1.5032 - val_accuracy: 0.3399\n",
            "Epoch 21/50\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5326 - accuracy: 0.3389\n",
            "Epoch 00021: loss did not improve from 1.53253\n",
            "595/595 [==============================] - 7s 12ms/step - loss: 1.5328 - accuracy: 0.3388 - val_loss: 1.5030 - val_accuracy: 0.3399\n",
            "Epoch 22/50\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5315 - accuracy: 0.3381\n",
            "Epoch 00022: loss improved from 1.53253 to 1.53179, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59b9872be0>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5318 - accuracy: 0.3380 - val_loss: 1.5043 - val_accuracy: 0.3399\n",
            "Epoch 23/50\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5311 - accuracy: 0.3376\n",
            "Epoch 00023: loss improved from 1.53179 to 1.53145, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59b9872be0>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5315 - accuracy: 0.3377 - val_loss: 1.5030 - val_accuracy: 0.3399\n",
            "Epoch 24/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5312 - accuracy: 0.3387\n",
            "Epoch 00024: loss improved from 1.53145 to 1.53125, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59b9872be0>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5313 - accuracy: 0.3387 - val_loss: 1.5038 - val_accuracy: 0.3399\n",
            "Epoch 25/50\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5319 - accuracy: 0.3410\n",
            "Epoch 00025: loss did not improve from 1.53125\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5319 - accuracy: 0.3413 - val_loss: 1.5033 - val_accuracy: 0.3399\n",
            "Epoch 26/50\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5325 - accuracy: 0.3401\n",
            "Epoch 00026: loss did not improve from 1.53125\n",
            "595/595 [==============================] - 7s 13ms/step - loss: 1.5325 - accuracy: 0.3401 - val_loss: 1.5032 - val_accuracy: 0.3399\n",
            "Epoch 27/50\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5306 - accuracy: 0.3423\n",
            "Epoch 00027: loss improved from 1.53125 to 1.53047, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59b9872be0>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5305 - accuracy: 0.3423 - val_loss: 1.5033 - val_accuracy: 0.3399\n",
            "Epoch 28/50\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5298 - accuracy: 0.3420\n",
            "Epoch 00028: loss improved from 1.53047 to 1.52983, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59b9872be0>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5298 - accuracy: 0.3420 - val_loss: 1.5035 - val_accuracy: 0.3399\n",
            "Epoch 29/50\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5269 - accuracy: 0.3410\n",
            "Epoch 00029: loss improved from 1.52983 to 1.52705, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59b9872be0>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5271 - accuracy: 0.3411 - val_loss: 1.5023 - val_accuracy: 0.3399\n",
            "Epoch 30/50\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5293 - accuracy: 0.3418\n",
            "Epoch 00030: loss did not improve from 1.52705\n",
            "595/595 [==============================] - 7s 13ms/step - loss: 1.5293 - accuracy: 0.3418 - val_loss: 1.5026 - val_accuracy: 0.3399\n",
            "Epoch 31/50\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5297 - accuracy: 0.3398\n",
            "Epoch 00031: loss did not improve from 1.52705\n",
            "595/595 [==============================] - 7s 12ms/step - loss: 1.5295 - accuracy: 0.3402 - val_loss: 1.5033 - val_accuracy: 0.3399\n",
            "Epoch 32/50\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5292 - accuracy: 0.3431\n",
            "Epoch 00032: loss did not improve from 1.52705\n",
            "595/595 [==============================] - 7s 13ms/step - loss: 1.5288 - accuracy: 0.3432 - val_loss: 1.5029 - val_accuracy: 0.3399\n",
            "Epoch 33/50\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5287 - accuracy: 0.3434\n",
            "Epoch 00033: loss did not improve from 1.52705\n",
            "595/595 [==============================] - 7s 12ms/step - loss: 1.5285 - accuracy: 0.3432 - val_loss: 1.5023 - val_accuracy: 0.3399\n",
            "Epoch 34/50\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5272 - accuracy: 0.3427\n",
            "Epoch 00034: loss did not improve from 1.52705\n",
            "595/595 [==============================] - 7s 12ms/step - loss: 1.5272 - accuracy: 0.3424 - val_loss: 1.5025 - val_accuracy: 0.3399\n",
            "Epoch 35/50\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5280 - accuracy: 0.3401\n",
            "Epoch 00035: loss did not improve from 1.52705\n",
            "595/595 [==============================] - 7s 12ms/step - loss: 1.5284 - accuracy: 0.3400 - val_loss: 1.5022 - val_accuracy: 0.3399\n",
            "Epoch 36/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5302 - accuracy: 0.3397\n",
            "Epoch 00036: loss did not improve from 1.52705\n",
            "595/595 [==============================] - 7s 12ms/step - loss: 1.5301 - accuracy: 0.3396 - val_loss: 1.5025 - val_accuracy: 0.3399\n",
            "Epoch 37/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5285 - accuracy: 0.3422\n",
            "Epoch 00037: loss did not improve from 1.52705\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5285 - accuracy: 0.3421 - val_loss: 1.5020 - val_accuracy: 0.3399\n",
            "Epoch 38/50\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5280 - accuracy: 0.3402\n",
            "Epoch 00038: loss did not improve from 1.52705\n",
            "595/595 [==============================] - 7s 12ms/step - loss: 1.5276 - accuracy: 0.3405 - val_loss: 1.5015 - val_accuracy: 0.3399\n",
            "Epoch 39/50\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5276 - accuracy: 0.3431\n",
            "Epoch 00039: loss improved from 1.52705 to 1.52695, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59b9872be0>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5269 - accuracy: 0.3436 - val_loss: 1.5016 - val_accuracy: 0.3399\n",
            "Epoch 40/50\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5274 - accuracy: 0.3432\n",
            "Epoch 00040: loss did not improve from 1.52695\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5273 - accuracy: 0.3428 - val_loss: 1.5012 - val_accuracy: 0.3399\n",
            "Epoch 41/50\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5291 - accuracy: 0.3409\n",
            "Epoch 00041: loss did not improve from 1.52695\n",
            "595/595 [==============================] - 7s 13ms/step - loss: 1.5291 - accuracy: 0.3411 - val_loss: 1.5016 - val_accuracy: 0.3399\n",
            "Epoch 42/50\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5260 - accuracy: 0.3444\n",
            "Epoch 00042: loss improved from 1.52695 to 1.52564, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59b9872be0>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5256 - accuracy: 0.3449 - val_loss: 1.5019 - val_accuracy: 0.3399\n",
            "Epoch 43/50\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5266 - accuracy: 0.3411\n",
            "Epoch 00043: loss did not improve from 1.52564\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5269 - accuracy: 0.3410 - val_loss: 1.5016 - val_accuracy: 0.3399\n",
            "Epoch 44/50\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5261 - accuracy: 0.3432\n",
            "Epoch 00044: loss did not improve from 1.52564\n",
            "595/595 [==============================] - 7s 13ms/step - loss: 1.5259 - accuracy: 0.3432 - val_loss: 1.5015 - val_accuracy: 0.3399\n",
            "Epoch 45/50\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5254 - accuracy: 0.3432\n",
            "Epoch 00045: loss did not improve from 1.52564\n",
            "595/595 [==============================] - 7s 13ms/step - loss: 1.5259 - accuracy: 0.3426 - val_loss: 1.5016 - val_accuracy: 0.3399\n",
            "Epoch 46/50\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5272 - accuracy: 0.3396\n",
            "Epoch 00046: loss did not improve from 1.52564\n",
            "595/595 [==============================] - 7s 12ms/step - loss: 1.5270 - accuracy: 0.3399 - val_loss: 1.5017 - val_accuracy: 0.3399\n",
            "Epoch 47/50\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5263 - accuracy: 0.3411\n",
            "Epoch 00047: loss did not improve from 1.52564\n",
            "595/595 [==============================] - 7s 13ms/step - loss: 1.5265 - accuracy: 0.3410 - val_loss: 1.5016 - val_accuracy: 0.3399\n",
            "Epoch 48/50\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5267 - accuracy: 0.3412\n",
            "Epoch 00048: loss did not improve from 1.52564\n",
            "595/595 [==============================] - 7s 13ms/step - loss: 1.5260 - accuracy: 0.3418 - val_loss: 1.5014 - val_accuracy: 0.3399\n",
            "Epoch 49/50\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5263 - accuracy: 0.3438\n",
            "Epoch 00049: loss did not improve from 1.52564\n",
            "595/595 [==============================] - 7s 12ms/step - loss: 1.5262 - accuracy: 0.3436 - val_loss: 1.5012 - val_accuracy: 0.3399\n",
            "Epoch 50/50\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5254 - accuracy: 0.3403\n",
            "Epoch 00050: loss improved from 1.52564 to 1.52495, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59b9872be0>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5250 - accuracy: 0.3404 - val_loss: 1.5010 - val_accuracy: 0.3399\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/50\n",
            "  2/595 [..............................] - ETA: 33s - loss: 2.0763 - accuracy: 0.1400WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0143s vs `on_train_batch_end` time: 0.0976s). Check your callbacks.\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5553 - accuracy: 0.3291\n",
            "Epoch 00001: loss improved from inf to 1.55545, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f59b980be10>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5554 - accuracy: 0.3291 - val_loss: 1.5041 - val_accuracy: 0.3399\n",
            "Epoch 2/50\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5335 - accuracy: 0.3389\n",
            "Epoch 00002: loss improved from 1.55545 to 1.53351, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f59b980be10>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5335 - accuracy: 0.3389 - val_loss: 1.5014 - val_accuracy: 0.3399\n",
            "Epoch 3/50\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5284 - accuracy: 0.3379\n",
            "Epoch 00003: loss improved from 1.53351 to 1.52836, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f59b980be10>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5284 - accuracy: 0.3379 - val_loss: 1.5152 - val_accuracy: 0.3399\n",
            "Epoch 4/50\n",
            "589/595 [============================>.] - ETA: 0s - loss: 1.5258 - accuracy: 0.3400\n",
            "Epoch 00004: loss improved from 1.52836 to 1.52622, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f59b980be10>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5262 - accuracy: 0.3392 - val_loss: 1.5033 - val_accuracy: 0.3399\n",
            "Epoch 5/50\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5199 - accuracy: 0.3424\n",
            "Epoch 00005: loss improved from 1.52622 to 1.51986, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f59b980be10>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5199 - accuracy: 0.3424 - val_loss: 1.4914 - val_accuracy: 0.3399\n",
            "Epoch 6/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5199 - accuracy: 0.3426\n",
            "Epoch 00006: loss improved from 1.51986 to 1.51983, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f59b980be10>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5198 - accuracy: 0.3427 - val_loss: 1.5032 - val_accuracy: 0.3399\n",
            "Epoch 7/50\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5173 - accuracy: 0.3423\n",
            "Epoch 00007: loss improved from 1.51983 to 1.51749, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f59b980be10>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5175 - accuracy: 0.3425 - val_loss: 1.4980 - val_accuracy: 0.3399\n",
            "Epoch 8/50\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5161 - accuracy: 0.3434\n",
            "Epoch 00008: loss improved from 1.51749 to 1.51585, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f59b980be10>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5159 - accuracy: 0.3432 - val_loss: 1.4876 - val_accuracy: 0.3407\n",
            "Epoch 9/50\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5131 - accuracy: 0.3417\n",
            "Epoch 00009: loss improved from 1.51585 to 1.51286, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f59b980be10>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5129 - accuracy: 0.3418 - val_loss: 1.4944 - val_accuracy: 0.3372\n",
            "Epoch 10/50\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5123 - accuracy: 0.3444\n",
            "Epoch 00010: loss improved from 1.51286 to 1.51260, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f59b980be10>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5126 - accuracy: 0.3442 - val_loss: 1.4970 - val_accuracy: 0.3372\n",
            "Epoch 11/50\n",
            "589/595 [============================>.] - ETA: 0s - loss: 1.5111 - accuracy: 0.3473\n",
            "Epoch 00011: loss improved from 1.51260 to 1.51063, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f59b980be10>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5106 - accuracy: 0.3476 - val_loss: 1.4914 - val_accuracy: 0.3205\n",
            "Epoch 12/50\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5104 - accuracy: 0.3449\n",
            "Epoch 00012: loss improved from 1.51063 to 1.51050, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f59b980be10>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5105 - accuracy: 0.3449 - val_loss: 1.4974 - val_accuracy: 0.3372\n",
            "Epoch 13/50\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5096 - accuracy: 0.3428\n",
            "Epoch 00013: loss improved from 1.51050 to 1.50957, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f59b980be10>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5096 - accuracy: 0.3428 - val_loss: 1.4949 - val_accuracy: 0.3372\n",
            "Epoch 14/50\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5062 - accuracy: 0.3465\n",
            "Epoch 00014: loss improved from 1.50957 to 1.50615, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f59b980be10>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5061 - accuracy: 0.3464 - val_loss: 1.5026 - val_accuracy: 0.3372\n",
            "Epoch 15/50\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5055 - accuracy: 0.3471\n",
            "Epoch 00015: loss improved from 1.50615 to 1.50546, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f59b980be10>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5055 - accuracy: 0.3471 - val_loss: 1.4993 - val_accuracy: 0.3372\n",
            "Epoch 16/50\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5056 - accuracy: 0.3492\n",
            "Epoch 00016: loss did not improve from 1.50546\n",
            "595/595 [==============================] - 7s 13ms/step - loss: 1.5056 - accuracy: 0.3495 - val_loss: 1.4980 - val_accuracy: 0.3399\n",
            "Epoch 17/50\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5024 - accuracy: 0.3489\n",
            "Epoch 00017: loss improved from 1.50546 to 1.50244, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f59b980be10>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5024 - accuracy: 0.3489 - val_loss: 1.4937 - val_accuracy: 0.3367\n",
            "Epoch 18/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5023 - accuracy: 0.3465\n",
            "Epoch 00018: loss did not improve from 1.50244\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5026 - accuracy: 0.3464 - val_loss: 1.4954 - val_accuracy: 0.3205\n",
            "Epoch 19/50\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.4989 - accuracy: 0.3542\n",
            "Epoch 00019: loss improved from 1.50244 to 1.49865, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f59b980be10>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.4986 - accuracy: 0.3544 - val_loss: 1.5002 - val_accuracy: 0.3367\n",
            "Epoch 20/50\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.4982 - accuracy: 0.3518\n",
            "Epoch 00020: loss improved from 1.49865 to 1.49848, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f59b980be10>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4985 - accuracy: 0.3519 - val_loss: 1.4951 - val_accuracy: 0.3227\n",
            "Epoch 21/50\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.4991 - accuracy: 0.3511\n",
            "Epoch 00021: loss did not improve from 1.49848\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4988 - accuracy: 0.3510 - val_loss: 1.4979 - val_accuracy: 0.3143\n",
            "Epoch 22/50\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.4967 - accuracy: 0.3492\n",
            "Epoch 00022: loss improved from 1.49848 to 1.49667, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f59b980be10>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.4967 - accuracy: 0.3492 - val_loss: 1.4914 - val_accuracy: 0.3243\n",
            "Epoch 23/50\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.4951 - accuracy: 0.3516\n",
            "Epoch 00023: loss improved from 1.49667 to 1.49511, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f59b980be10>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4951 - accuracy: 0.3516 - val_loss: 1.4950 - val_accuracy: 0.3065\n",
            "Epoch 24/50\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.4959 - accuracy: 0.3535\n",
            "Epoch 00024: loss did not improve from 1.49511\n",
            "595/595 [==============================] - 7s 13ms/step - loss: 1.4961 - accuracy: 0.3535 - val_loss: 1.4951 - val_accuracy: 0.3369\n",
            "Epoch 25/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.4945 - accuracy: 0.3521\n",
            "Epoch 00025: loss improved from 1.49511 to 1.49430, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f59b980be10>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.4943 - accuracy: 0.3523 - val_loss: 1.4991 - val_accuracy: 0.3358\n",
            "Epoch 26/50\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.4938 - accuracy: 0.3506\n",
            "Epoch 00026: loss improved from 1.49430 to 1.49425, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f59b980be10>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4943 - accuracy: 0.3504 - val_loss: 1.4865 - val_accuracy: 0.3326\n",
            "Epoch 27/50\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.4939 - accuracy: 0.3527\n",
            "Epoch 00027: loss improved from 1.49425 to 1.49390, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f59b980be10>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.4939 - accuracy: 0.3527 - val_loss: 1.4908 - val_accuracy: 0.3213\n",
            "Epoch 28/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.4909 - accuracy: 0.3533\n",
            "Epoch 00028: loss improved from 1.49390 to 1.49083, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f59b980be10>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4908 - accuracy: 0.3532 - val_loss: 1.4918 - val_accuracy: 0.3135\n",
            "Epoch 29/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.4891 - accuracy: 0.3523\n",
            "Epoch 00029: loss improved from 1.49083 to 1.48911, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f59b980be10>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4891 - accuracy: 0.3522 - val_loss: 1.4934 - val_accuracy: 0.3175\n",
            "Epoch 30/50\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.4910 - accuracy: 0.3548\n",
            "Epoch 00030: loss did not improve from 1.48911\n",
            "595/595 [==============================] - 7s 13ms/step - loss: 1.4905 - accuracy: 0.3550 - val_loss: 1.5024 - val_accuracy: 0.3219\n",
            "Epoch 31/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.4887 - accuracy: 0.3515\n",
            "Epoch 00031: loss improved from 1.48911 to 1.48862, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f59b980be10>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.4886 - accuracy: 0.3515 - val_loss: 1.5028 - val_accuracy: 0.3165\n",
            "Epoch 32/50\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.4880 - accuracy: 0.3565\n",
            "Epoch 00032: loss improved from 1.48862 to 1.48799, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f59b980be10>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.4880 - accuracy: 0.3565 - val_loss: 1.4962 - val_accuracy: 0.3358\n",
            "Epoch 33/50\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.4857 - accuracy: 0.3543\n",
            "Epoch 00033: loss improved from 1.48799 to 1.48555, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f59b980be10>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4856 - accuracy: 0.3542 - val_loss: 1.4972 - val_accuracy: 0.3116\n",
            "Epoch 34/50\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.4866 - accuracy: 0.3557\n",
            "Epoch 00034: loss did not improve from 1.48555\n",
            "595/595 [==============================] - 7s 13ms/step - loss: 1.4864 - accuracy: 0.3560 - val_loss: 1.4973 - val_accuracy: 0.3326\n",
            "Epoch 35/50\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.4833 - accuracy: 0.3616\n",
            "Epoch 00035: loss improved from 1.48555 to 1.48334, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f59b980be10>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.4833 - accuracy: 0.3617 - val_loss: 1.4953 - val_accuracy: 0.3423\n",
            "Epoch 36/50\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.4840 - accuracy: 0.3608\n",
            "Epoch 00036: loss did not improve from 1.48334\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4839 - accuracy: 0.3613 - val_loss: 1.5000 - val_accuracy: 0.3189\n",
            "Epoch 37/50\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.4825 - accuracy: 0.3614\n",
            "Epoch 00037: loss improved from 1.48334 to 1.48232, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f59b980be10>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.4823 - accuracy: 0.3617 - val_loss: 1.5010 - val_accuracy: 0.3348\n",
            "Epoch 38/50\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.4834 - accuracy: 0.3639\n",
            "Epoch 00038: loss did not improve from 1.48232\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4836 - accuracy: 0.3639 - val_loss: 1.5014 - val_accuracy: 0.3291\n",
            "Epoch 39/50\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.4818 - accuracy: 0.3583\n",
            "Epoch 00039: loss improved from 1.48232 to 1.48190, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f59b980be10>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.4819 - accuracy: 0.3586 - val_loss: 1.4979 - val_accuracy: 0.3079\n",
            "Epoch 40/50\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.4813 - accuracy: 0.3637\n",
            "Epoch 00040: loss improved from 1.48190 to 1.48129, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f59b980be10>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4813 - accuracy: 0.3637 - val_loss: 1.5017 - val_accuracy: 0.3140\n",
            "Epoch 41/50\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.4789 - accuracy: 0.3597\n",
            "Epoch 00041: loss improved from 1.48129 to 1.47887, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f59b980be10>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.4789 - accuracy: 0.3597 - val_loss: 1.5018 - val_accuracy: 0.3259\n",
            "Epoch 42/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.4804 - accuracy: 0.3587\n",
            "Epoch 00042: loss did not improve from 1.47887\n",
            "595/595 [==============================] - 7s 13ms/step - loss: 1.4802 - accuracy: 0.3587 - val_loss: 1.4961 - val_accuracy: 0.3227\n",
            "Epoch 43/50\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.4788 - accuracy: 0.3599\n",
            "Epoch 00043: loss improved from 1.47887 to 1.47880, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f59b980be10>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.4788 - accuracy: 0.3600 - val_loss: 1.4985 - val_accuracy: 0.3221\n",
            "Epoch 44/50\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.4790 - accuracy: 0.3605\n",
            "Epoch 00044: loss did not improve from 1.47880\n",
            "595/595 [==============================] - 7s 12ms/step - loss: 1.4792 - accuracy: 0.3603 - val_loss: 1.5130 - val_accuracy: 0.3278\n",
            "Epoch 45/50\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.4783 - accuracy: 0.3635\n",
            "Epoch 00045: loss improved from 1.47880 to 1.47768, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f59b980be10>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.4777 - accuracy: 0.3638 - val_loss: 1.4963 - val_accuracy: 0.3310\n",
            "Epoch 46/50\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.4771 - accuracy: 0.3639\n",
            "Epoch 00046: loss improved from 1.47768 to 1.47717, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f59b980be10>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.4772 - accuracy: 0.3637 - val_loss: 1.4970 - val_accuracy: 0.3264\n",
            "Epoch 47/50\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.4787 - accuracy: 0.3628\n",
            "Epoch 00047: loss did not improve from 1.47717\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4781 - accuracy: 0.3634 - val_loss: 1.5040 - val_accuracy: 0.3213\n",
            "Epoch 48/50\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.4762 - accuracy: 0.3661\n",
            "Epoch 00048: loss improved from 1.47717 to 1.47640, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f59b980be10>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.4764 - accuracy: 0.3661 - val_loss: 1.4992 - val_accuracy: 0.3208\n",
            "Epoch 49/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.4754 - accuracy: 0.3651\n",
            "Epoch 00049: loss improved from 1.47640 to 1.47536, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f59b980be10>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4754 - accuracy: 0.3650 - val_loss: 1.5013 - val_accuracy: 0.3251\n",
            "Epoch 50/50\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.4726 - accuracy: 0.3676\n",
            "Epoch 00050: loss improved from 1.47536 to 1.47272, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f59b980be10>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.4727 - accuracy: 0.3675 - val_loss: 1.4998 - val_accuracy: 0.3367\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/50\n",
            "  2/595 [..............................] - ETA: 33s - loss: 2.1722 - accuracy: 0.0400   WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0142s vs `on_train_batch_end` time: 0.0968s). Check your callbacks.\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.6596 - accuracy: 0.3032\n",
            "Epoch 00001: loss improved from inf to 1.65915, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f59b2f7e080>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.6591 - accuracy: 0.3035 - val_loss: 1.5447 - val_accuracy: 0.3399\n",
            "Epoch 2/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5574 - accuracy: 0.3436\n",
            "Epoch 00002: loss improved from 1.65915 to 1.55745, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f59b2f7e080>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5574 - accuracy: 0.3435 - val_loss: 1.5183 - val_accuracy: 0.3399\n",
            "Epoch 3/50\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5435 - accuracy: 0.3435\n",
            "Epoch 00003: loss improved from 1.55745 to 1.54326, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f59b2f7e080>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5433 - accuracy: 0.3437 - val_loss: 1.5096 - val_accuracy: 0.3399\n",
            "Epoch 4/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5368 - accuracy: 0.3437\n",
            "Epoch 00004: loss improved from 1.54326 to 1.53677, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f59b2f7e080>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5368 - accuracy: 0.3437 - val_loss: 1.5056 - val_accuracy: 0.3399\n",
            "Epoch 5/50\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5348 - accuracy: 0.3443\n",
            "Epoch 00005: loss improved from 1.53677 to 1.53525, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f59b2f7e080>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5352 - accuracy: 0.3438 - val_loss: 1.5030 - val_accuracy: 0.3399\n",
            "Epoch 6/50\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5325 - accuracy: 0.3437\n",
            "Epoch 00006: loss improved from 1.53525 to 1.53254, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f59b2f7e080>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5325 - accuracy: 0.3433 - val_loss: 1.5013 - val_accuracy: 0.3399\n",
            "Epoch 7/50\n",
            "589/595 [============================>.] - ETA: 0s - loss: 1.5307 - accuracy: 0.3439\n",
            "Epoch 00007: loss improved from 1.53254 to 1.53099, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f59b2f7e080>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5310 - accuracy: 0.3436 - val_loss: 1.5011 - val_accuracy: 0.3399\n",
            "Epoch 8/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5310 - accuracy: 0.3438\n",
            "Epoch 00008: loss did not improve from 1.53099\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5310 - accuracy: 0.3437 - val_loss: 1.5000 - val_accuracy: 0.3399\n",
            "Epoch 9/50\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5302 - accuracy: 0.3437\n",
            "Epoch 00009: loss improved from 1.53099 to 1.53016, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f59b2f7e080>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5302 - accuracy: 0.3436 - val_loss: 1.4995 - val_accuracy: 0.3399\n",
            "Epoch 10/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5298 - accuracy: 0.3436\n",
            "Epoch 00010: loss improved from 1.53016 to 1.52974, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f59b2f7e080>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5297 - accuracy: 0.3436 - val_loss: 1.4991 - val_accuracy: 0.3399\n",
            "Epoch 11/50\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5308 - accuracy: 0.3437\n",
            "Epoch 00011: loss did not improve from 1.52974\n",
            "595/595 [==============================] - 7s 13ms/step - loss: 1.5307 - accuracy: 0.3434 - val_loss: 1.4995 - val_accuracy: 0.3399\n",
            "Epoch 12/50\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5300 - accuracy: 0.3431\n",
            "Epoch 00012: loss did not improve from 1.52974\n",
            "595/595 [==============================] - 7s 13ms/step - loss: 1.5301 - accuracy: 0.3434 - val_loss: 1.4995 - val_accuracy: 0.3399\n",
            "Epoch 13/50\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5300 - accuracy: 0.3436\n",
            "Epoch 00013: loss did not improve from 1.52974\n",
            "595/595 [==============================] - 7s 12ms/step - loss: 1.5300 - accuracy: 0.3436 - val_loss: 1.4989 - val_accuracy: 0.3399\n",
            "Epoch 14/50\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5299 - accuracy: 0.3436\n",
            "Epoch 00014: loss improved from 1.52974 to 1.52948, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f59b2f7e080>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5295 - accuracy: 0.3440 - val_loss: 1.4983 - val_accuracy: 0.3399\n",
            "Epoch 15/50\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5290 - accuracy: 0.3439\n",
            "Epoch 00015: loss improved from 1.52948 to 1.52879, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f59b2f7e080>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5288 - accuracy: 0.3440 - val_loss: 1.4984 - val_accuracy: 0.3399\n",
            "Epoch 16/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5290 - accuracy: 0.3436\n",
            "Epoch 00016: loss did not improve from 1.52879\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5292 - accuracy: 0.3434 - val_loss: 1.4985 - val_accuracy: 0.3399\n",
            "Epoch 17/50\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5282 - accuracy: 0.3437\n",
            "Epoch 00017: loss improved from 1.52879 to 1.52853, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f59b2f7e080>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5285 - accuracy: 0.3435 - val_loss: 1.4985 - val_accuracy: 0.3399\n",
            "Epoch 18/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5290 - accuracy: 0.3438\n",
            "Epoch 00018: loss did not improve from 1.52853\n",
            "595/595 [==============================] - 7s 13ms/step - loss: 1.5293 - accuracy: 0.3436 - val_loss: 1.4980 - val_accuracy: 0.3399\n",
            "Epoch 19/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5290 - accuracy: 0.3436\n",
            "Epoch 00019: loss did not improve from 1.52853\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5289 - accuracy: 0.3435 - val_loss: 1.4983 - val_accuracy: 0.3399\n",
            "Epoch 20/50\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5285 - accuracy: 0.3437\n",
            "Epoch 00020: loss did not improve from 1.52853\n",
            "595/595 [==============================] - 7s 12ms/step - loss: 1.5286 - accuracy: 0.3437 - val_loss: 1.4985 - val_accuracy: 0.3399\n",
            "Epoch 21/50\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5292 - accuracy: 0.3436\n",
            "Epoch 00021: loss did not improve from 1.52853\n",
            "595/595 [==============================] - 7s 12ms/step - loss: 1.5294 - accuracy: 0.3432 - val_loss: 1.4985 - val_accuracy: 0.3399\n",
            "Epoch 22/50\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5300 - accuracy: 0.3435\n",
            "Epoch 00022: loss did not improve from 1.52853\n",
            "595/595 [==============================] - 7s 13ms/step - loss: 1.5300 - accuracy: 0.3433 - val_loss: 1.4987 - val_accuracy: 0.3399\n",
            "Epoch 23/50\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5278 - accuracy: 0.3438\n",
            "Epoch 00023: loss improved from 1.52853 to 1.52793, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f59b2f7e080>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5279 - accuracy: 0.3436 - val_loss: 1.4985 - val_accuracy: 0.3399\n",
            "Epoch 24/50\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5281 - accuracy: 0.3440\n",
            "Epoch 00024: loss did not improve from 1.52793\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5281 - accuracy: 0.3440 - val_loss: 1.4986 - val_accuracy: 0.3399\n",
            "Epoch 25/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5285 - accuracy: 0.3434\n",
            "Epoch 00025: loss did not improve from 1.52793\n",
            "595/595 [==============================] - 7s 12ms/step - loss: 1.5284 - accuracy: 0.3434 - val_loss: 1.4983 - val_accuracy: 0.3399\n",
            "Epoch 26/50\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5282 - accuracy: 0.3436\n",
            "Epoch 00026: loss did not improve from 1.52793\n",
            "595/595 [==============================] - 7s 12ms/step - loss: 1.5282 - accuracy: 0.3436 - val_loss: 1.4984 - val_accuracy: 0.3399\n",
            "Epoch 27/50\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5283 - accuracy: 0.3437\n",
            "Epoch 00027: loss did not improve from 1.52793\n",
            "595/595 [==============================] - 7s 12ms/step - loss: 1.5281 - accuracy: 0.3436 - val_loss: 1.4982 - val_accuracy: 0.3399\n",
            "Epoch 28/50\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5298 - accuracy: 0.3432\n",
            "Epoch 00028: loss did not improve from 1.52793\n",
            "595/595 [==============================] - 7s 12ms/step - loss: 1.5295 - accuracy: 0.3435 - val_loss: 1.4982 - val_accuracy: 0.3399\n",
            "Epoch 29/50\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5284 - accuracy: 0.3436\n",
            "Epoch 00029: loss did not improve from 1.52793\n",
            "595/595 [==============================] - 7s 12ms/step - loss: 1.5286 - accuracy: 0.3436 - val_loss: 1.4984 - val_accuracy: 0.3399\n",
            "Epoch 30/50\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5290 - accuracy: 0.3438\n",
            "Epoch 00030: loss did not improve from 1.52793\n",
            "595/595 [==============================] - 7s 12ms/step - loss: 1.5286 - accuracy: 0.3436 - val_loss: 1.4982 - val_accuracy: 0.3399\n",
            "Epoch 31/50\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5286 - accuracy: 0.3427\n",
            "Epoch 00031: loss did not improve from 1.52793\n",
            "595/595 [==============================] - 7s 12ms/step - loss: 1.5283 - accuracy: 0.3436 - val_loss: 1.4988 - val_accuracy: 0.3399\n",
            "Epoch 32/50\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5283 - accuracy: 0.3439\n",
            "Epoch 00032: loss did not improve from 1.52793\n",
            "595/595 [==============================] - 7s 13ms/step - loss: 1.5285 - accuracy: 0.3435 - val_loss: 1.4985 - val_accuracy: 0.3399\n",
            "Epoch 33/50\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5294 - accuracy: 0.3427\n",
            "Epoch 00033: loss did not improve from 1.52793\n",
            "595/595 [==============================] - 7s 12ms/step - loss: 1.5288 - accuracy: 0.3434 - val_loss: 1.4987 - val_accuracy: 0.3399\n",
            "Epoch 34/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5284 - accuracy: 0.3436\n",
            "Epoch 00034: loss did not improve from 1.52793\n",
            "595/595 [==============================] - 7s 13ms/step - loss: 1.5285 - accuracy: 0.3435 - val_loss: 1.4988 - val_accuracy: 0.3399\n",
            "Epoch 35/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5286 - accuracy: 0.3436\n",
            "Epoch 00035: loss did not improve from 1.52793\n",
            "595/595 [==============================] - 7s 12ms/step - loss: 1.5286 - accuracy: 0.3436 - val_loss: 1.4989 - val_accuracy: 0.3399\n",
            "Epoch 36/50\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5276 - accuracy: 0.3435\n",
            "Epoch 00036: loss improved from 1.52793 to 1.52740, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f59b2f7e080>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5274 - accuracy: 0.3437 - val_loss: 1.4987 - val_accuracy: 0.3399\n",
            "Epoch 37/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5273 - accuracy: 0.3434\n",
            "Epoch 00037: loss improved from 1.52740 to 1.52715, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f59b2f7e080>_Batch25_LR0.001_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5272 - accuracy: 0.3435 - val_loss: 1.4988 - val_accuracy: 0.3399\n",
            "Epoch 38/50\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5272 - accuracy: 0.3445\n",
            "Epoch 00038: loss did not improve from 1.52715\n",
            "595/595 [==============================] - 7s 12ms/step - loss: 1.5278 - accuracy: 0.3439 - val_loss: 1.4990 - val_accuracy: 0.3399\n",
            "Epoch 39/50\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5288 - accuracy: 0.3437\n",
            "Epoch 00039: loss did not improve from 1.52715\n",
            "595/595 [==============================] - 7s 12ms/step - loss: 1.5288 - accuracy: 0.3438 - val_loss: 1.4988 - val_accuracy: 0.3399\n",
            "Epoch 40/50\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5273 - accuracy: 0.3437\n",
            "Epoch 00040: loss did not improve from 1.52715\n",
            "595/595 [==============================] - 7s 12ms/step - loss: 1.5274 - accuracy: 0.3435 - val_loss: 1.4991 - val_accuracy: 0.3399\n",
            "Epoch 41/50\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5273 - accuracy: 0.3440\n",
            "Epoch 00041: loss did not improve from 1.52715\n",
            "595/595 [==============================] - 7s 12ms/step - loss: 1.5274 - accuracy: 0.3436 - val_loss: 1.4991 - val_accuracy: 0.3399\n",
            "Epoch 42/50\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5276 - accuracy: 0.3437\n",
            "Epoch 00042: loss did not improve from 1.52715\n",
            "595/595 [==============================] - 7s 12ms/step - loss: 1.5274 - accuracy: 0.3436 - val_loss: 1.4991 - val_accuracy: 0.3399\n",
            "Epoch 43/50\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5283 - accuracy: 0.3434\n",
            "Epoch 00043: loss did not improve from 1.52715\n",
            "595/595 [==============================] - 7s 12ms/step - loss: 1.5280 - accuracy: 0.3437 - val_loss: 1.4989 - val_accuracy: 0.3399\n",
            "Epoch 44/50\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5275 - accuracy: 0.3434\n",
            "Epoch 00044: loss did not improve from 1.52715\n",
            "595/595 [==============================] - 7s 13ms/step - loss: 1.5275 - accuracy: 0.3434 - val_loss: 1.4990 - val_accuracy: 0.3399\n",
            "Epoch 45/50\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5273 - accuracy: 0.3440\n",
            "Epoch 00045: loss did not improve from 1.52715\n",
            "595/595 [==============================] - 7s 13ms/step - loss: 1.5276 - accuracy: 0.3436 - val_loss: 1.4991 - val_accuracy: 0.3399\n",
            "Epoch 46/50\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5278 - accuracy: 0.3436\n",
            "Epoch 00046: loss did not improve from 1.52715\n",
            "595/595 [==============================] - 7s 12ms/step - loss: 1.5280 - accuracy: 0.3435 - val_loss: 1.4990 - val_accuracy: 0.3399\n",
            "Epoch 47/50\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5281 - accuracy: 0.3434\n",
            "Epoch 00047: loss did not improve from 1.52715\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5278 - accuracy: 0.3436 - val_loss: 1.4992 - val_accuracy: 0.3399\n",
            "Epoch 48/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5279 - accuracy: 0.3436\n",
            "Epoch 00048: loss did not improve from 1.52715\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5279 - accuracy: 0.3436 - val_loss: 1.4991 - val_accuracy: 0.3399\n",
            "Epoch 49/50\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5276 - accuracy: 0.3437\n",
            "Epoch 00049: loss did not improve from 1.52715\n",
            "595/595 [==============================] - 7s 12ms/step - loss: 1.5276 - accuracy: 0.3437 - val_loss: 1.4992 - val_accuracy: 0.3399\n",
            "Epoch 50/50\n",
            "589/595 [============================>.] - ETA: 0s - loss: 1.5268 - accuracy: 0.3440\n",
            "Epoch 00050: loss did not improve from 1.52715\n",
            "595/595 [==============================] - 7s 12ms/step - loss: 1.5273 - accuracy: 0.3436 - val_loss: 1.4991 - val_accuracy: 0.3399\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/50\n",
            "  2/595 [..............................] - ETA: 31s - loss: 2.1827 - accuracy: 0.1000WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0144s vs `on_train_batch_end` time: 0.0926s). Check your callbacks.\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5557 - accuracy: 0.3273\n",
            "Epoch 00001: loss improved from inf to 1.55562, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59b0bdc0b8>_Batch25_LR0.01_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5556 - accuracy: 0.3274 - val_loss: 1.5055 - val_accuracy: 0.3399\n",
            "Epoch 2/50\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5370 - accuracy: 0.3372\n",
            "Epoch 00002: loss improved from 1.55562 to 1.53693, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59b0bdc0b8>_Batch25_LR0.01_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5369 - accuracy: 0.3377 - val_loss: 1.5081 - val_accuracy: 0.3375\n",
            "Epoch 3/50\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5326 - accuracy: 0.3397\n",
            "Epoch 00003: loss improved from 1.53693 to 1.53259, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59b0bdc0b8>_Batch25_LR0.01_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5326 - accuracy: 0.3397 - val_loss: 1.5073 - val_accuracy: 0.3399\n",
            "Epoch 4/50\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5301 - accuracy: 0.3424\n",
            "Epoch 00004: loss improved from 1.53259 to 1.52969, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59b0bdc0b8>_Batch25_LR0.01_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5297 - accuracy: 0.3424 - val_loss: 1.5038 - val_accuracy: 0.3399\n",
            "Epoch 5/50\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5298 - accuracy: 0.3429\n",
            "Epoch 00005: loss improved from 1.52969 to 1.52939, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59b0bdc0b8>_Batch25_LR0.01_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5294 - accuracy: 0.3431 - val_loss: 1.5054 - val_accuracy: 0.3399\n",
            "Epoch 6/50\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5284 - accuracy: 0.3415\n",
            "Epoch 00006: loss improved from 1.52939 to 1.52830, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59b0bdc0b8>_Batch25_LR0.01_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5283 - accuracy: 0.3413 - val_loss: 1.5034 - val_accuracy: 0.3399\n",
            "Epoch 7/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5273 - accuracy: 0.3422\n",
            "Epoch 00007: loss improved from 1.52830 to 1.52718, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59b0bdc0b8>_Batch25_LR0.01_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5272 - accuracy: 0.3422 - val_loss: 1.5039 - val_accuracy: 0.3399\n",
            "Epoch 8/50\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5266 - accuracy: 0.3432\n",
            "Epoch 00008: loss improved from 1.52718 to 1.52615, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59b0bdc0b8>_Batch25_LR0.01_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5262 - accuracy: 0.3433 - val_loss: 1.4998 - val_accuracy: 0.3399\n",
            "Epoch 9/50\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5259 - accuracy: 0.3419\n",
            "Epoch 00009: loss improved from 1.52615 to 1.52535, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59b0bdc0b8>_Batch25_LR0.01_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5254 - accuracy: 0.3424 - val_loss: 1.4999 - val_accuracy: 0.3399\n",
            "Epoch 10/50\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5241 - accuracy: 0.3438\n",
            "Epoch 00010: loss improved from 1.52535 to 1.52465, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59b0bdc0b8>_Batch25_LR0.01_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5247 - accuracy: 0.3439 - val_loss: 1.5060 - val_accuracy: 0.3399\n",
            "Epoch 11/50\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5229 - accuracy: 0.3438\n",
            "Epoch 00011: loss improved from 1.52465 to 1.52328, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59b0bdc0b8>_Batch25_LR0.01_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5233 - accuracy: 0.3433 - val_loss: 1.4973 - val_accuracy: 0.3399\n",
            "Epoch 12/50\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5247 - accuracy: 0.3429\n",
            "Epoch 00012: loss did not improve from 1.52328\n",
            "595/595 [==============================] - 7s 12ms/step - loss: 1.5243 - accuracy: 0.3432 - val_loss: 1.4952 - val_accuracy: 0.3399\n",
            "Epoch 13/50\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5233 - accuracy: 0.3427\n",
            "Epoch 00013: loss improved from 1.52328 to 1.52327, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59b0bdc0b8>_Batch25_LR0.01_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5233 - accuracy: 0.3429 - val_loss: 1.5010 - val_accuracy: 0.3399\n",
            "Epoch 14/50\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5223 - accuracy: 0.3444\n",
            "Epoch 00014: loss improved from 1.52327 to 1.52237, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59b0bdc0b8>_Batch25_LR0.01_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5224 - accuracy: 0.3444 - val_loss: 1.4972 - val_accuracy: 0.3399\n",
            "Epoch 15/50\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5215 - accuracy: 0.3441\n",
            "Epoch 00015: loss improved from 1.52237 to 1.52176, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59b0bdc0b8>_Batch25_LR0.01_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5218 - accuracy: 0.3439 - val_loss: 1.4977 - val_accuracy: 0.3399\n",
            "Epoch 16/50\n",
            "589/595 [============================>.] - ETA: 0s - loss: 1.5216 - accuracy: 0.3443\n",
            "Epoch 00016: loss improved from 1.52176 to 1.52147, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59b0bdc0b8>_Batch25_LR0.01_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5215 - accuracy: 0.3439 - val_loss: 1.4912 - val_accuracy: 0.3369\n",
            "Epoch 17/50\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5215 - accuracy: 0.3429\n",
            "Epoch 00017: loss improved from 1.52147 to 1.52134, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59b0bdc0b8>_Batch25_LR0.01_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5213 - accuracy: 0.3428 - val_loss: 1.4945 - val_accuracy: 0.3399\n",
            "Epoch 18/50\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5203 - accuracy: 0.3422\n",
            "Epoch 00018: loss improved from 1.52134 to 1.52010, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59b0bdc0b8>_Batch25_LR0.01_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5201 - accuracy: 0.3424 - val_loss: 1.4996 - val_accuracy: 0.3399\n",
            "Epoch 19/50\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5197 - accuracy: 0.3429\n",
            "Epoch 00019: loss improved from 1.52010 to 1.51972, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59b0bdc0b8>_Batch25_LR0.01_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5197 - accuracy: 0.3429 - val_loss: 1.4925 - val_accuracy: 0.3399\n",
            "Epoch 20/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5208 - accuracy: 0.3427\n",
            "Epoch 00020: loss did not improve from 1.51972\n",
            "595/595 [==============================] - 7s 12ms/step - loss: 1.5207 - accuracy: 0.3426 - val_loss: 1.5184 - val_accuracy: 0.3399\n",
            "Epoch 21/50\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5184 - accuracy: 0.3430\n",
            "Epoch 00021: loss improved from 1.51972 to 1.51848, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59b0bdc0b8>_Batch25_LR0.01_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5185 - accuracy: 0.3434 - val_loss: 1.5268 - val_accuracy: 0.3399\n",
            "Epoch 22/50\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5204 - accuracy: 0.3429\n",
            "Epoch 00022: loss did not improve from 1.51848\n",
            "595/595 [==============================] - 7s 12ms/step - loss: 1.5198 - accuracy: 0.3433 - val_loss: 1.4964 - val_accuracy: 0.3399\n",
            "Epoch 23/50\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5192 - accuracy: 0.3428\n",
            "Epoch 00023: loss did not improve from 1.51848\n",
            "595/595 [==============================] - 7s 13ms/step - loss: 1.5188 - accuracy: 0.3432 - val_loss: 1.5109 - val_accuracy: 0.3399\n",
            "Epoch 24/50\n",
            "589/595 [============================>.] - ETA: 0s - loss: 1.5180 - accuracy: 0.3442\n",
            "Epoch 00024: loss improved from 1.51848 to 1.51811, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59b0bdc0b8>_Batch25_LR0.01_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5181 - accuracy: 0.3441 - val_loss: 1.5014 - val_accuracy: 0.3399\n",
            "Epoch 25/50\n",
            "589/595 [============================>.] - ETA: 0s - loss: 1.5170 - accuracy: 0.3432\n",
            "Epoch 00025: loss improved from 1.51811 to 1.51700, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59b0bdc0b8>_Batch25_LR0.01_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5170 - accuracy: 0.3430 - val_loss: 1.4958 - val_accuracy: 0.3399\n",
            "Epoch 26/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5170 - accuracy: 0.3428\n",
            "Epoch 00026: loss improved from 1.51700 to 1.51689, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59b0bdc0b8>_Batch25_LR0.01_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5169 - accuracy: 0.3428 - val_loss: 1.4952 - val_accuracy: 0.3399\n",
            "Epoch 27/50\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5143 - accuracy: 0.3433\n",
            "Epoch 00027: loss improved from 1.51689 to 1.51445, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59b0bdc0b8>_Batch25_LR0.01_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5144 - accuracy: 0.3432 - val_loss: 1.5125 - val_accuracy: 0.3399\n",
            "Epoch 28/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5167 - accuracy: 0.3424\n",
            "Epoch 00028: loss did not improve from 1.51445\n",
            "595/595 [==============================] - 7s 13ms/step - loss: 1.5169 - accuracy: 0.3424 - val_loss: 1.5033 - val_accuracy: 0.3399\n",
            "Epoch 29/50\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5160 - accuracy: 0.3436\n",
            "Epoch 00029: loss did not improve from 1.51445\n",
            "595/595 [==============================] - 7s 13ms/step - loss: 1.5158 - accuracy: 0.3434 - val_loss: 1.5016 - val_accuracy: 0.3399\n",
            "Epoch 30/50\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5159 - accuracy: 0.3429\n",
            "Epoch 00030: loss did not improve from 1.51445\n",
            "595/595 [==============================] - 7s 13ms/step - loss: 1.5157 - accuracy: 0.3431 - val_loss: 1.4935 - val_accuracy: 0.3399\n",
            "Epoch 31/50\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5144 - accuracy: 0.3415\n",
            "Epoch 00031: loss improved from 1.51445 to 1.51441, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59b0bdc0b8>_Batch25_LR0.01_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5144 - accuracy: 0.3415 - val_loss: 1.5011 - val_accuracy: 0.3399\n",
            "Epoch 32/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5143 - accuracy: 0.3418\n",
            "Epoch 00032: loss improved from 1.51441 to 1.51427, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59b0bdc0b8>_Batch25_LR0.01_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5143 - accuracy: 0.3418 - val_loss: 1.5067 - val_accuracy: 0.3399\n",
            "Epoch 33/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5144 - accuracy: 0.3447\n",
            "Epoch 00033: loss did not improve from 1.51427\n",
            "595/595 [==============================] - 7s 12ms/step - loss: 1.5144 - accuracy: 0.3447 - val_loss: 1.5019 - val_accuracy: 0.3399\n",
            "Epoch 34/50\n",
            "589/595 [============================>.] - ETA: 0s - loss: 1.5133 - accuracy: 0.3423\n",
            "Epoch 00034: loss improved from 1.51427 to 1.51376, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59b0bdc0b8>_Batch25_LR0.01_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5138 - accuracy: 0.3422 - val_loss: 1.4979 - val_accuracy: 0.3399\n",
            "Epoch 35/50\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5135 - accuracy: 0.3448\n",
            "Epoch 00035: loss improved from 1.51376 to 1.51330, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59b0bdc0b8>_Batch25_LR0.01_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5133 - accuracy: 0.3449 - val_loss: 1.4936 - val_accuracy: 0.3399\n",
            "Epoch 36/50\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5127 - accuracy: 0.3447\n",
            "Epoch 00036: loss improved from 1.51330 to 1.51267, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59b0bdc0b8>_Batch25_LR0.01_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5127 - accuracy: 0.3447 - val_loss: 1.4984 - val_accuracy: 0.3399\n",
            "Epoch 37/50\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5128 - accuracy: 0.3458\n",
            "Epoch 00037: loss improved from 1.51267 to 1.51266, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59b0bdc0b8>_Batch25_LR0.01_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5127 - accuracy: 0.3456 - val_loss: 1.4895 - val_accuracy: 0.3399\n",
            "Epoch 38/50\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5113 - accuracy: 0.3430\n",
            "Epoch 00038: loss improved from 1.51266 to 1.51157, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59b0bdc0b8>_Batch25_LR0.01_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5116 - accuracy: 0.3428 - val_loss: 1.4925 - val_accuracy: 0.3393\n",
            "Epoch 39/50\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5118 - accuracy: 0.3432\n",
            "Epoch 00039: loss did not improve from 1.51157\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5117 - accuracy: 0.3436 - val_loss: 1.5276 - val_accuracy: 0.3340\n",
            "Epoch 40/50\n",
            "589/595 [============================>.] - ETA: 0s - loss: 1.5109 - accuracy: 0.3451\n",
            "Epoch 00040: loss improved from 1.51157 to 1.51091, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59b0bdc0b8>_Batch25_LR0.01_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5109 - accuracy: 0.3450 - val_loss: 1.4986 - val_accuracy: 0.3399\n",
            "Epoch 41/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5118 - accuracy: 0.3463\n",
            "Epoch 00041: loss did not improve from 1.51091\n",
            "595/595 [==============================] - 7s 12ms/step - loss: 1.5117 - accuracy: 0.3464 - val_loss: 1.5011 - val_accuracy: 0.3399\n",
            "Epoch 42/50\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5109 - accuracy: 0.3439\n",
            "Epoch 00042: loss did not improve from 1.51091\n",
            "595/595 [==============================] - 7s 12ms/step - loss: 1.5110 - accuracy: 0.3437 - val_loss: 1.5008 - val_accuracy: 0.3372\n",
            "Epoch 43/50\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5107 - accuracy: 0.3448\n",
            "Epoch 00043: loss improved from 1.51091 to 1.51050, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59b0bdc0b8>_Batch25_LR0.01_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5105 - accuracy: 0.3449 - val_loss: 1.5099 - val_accuracy: 0.3399\n",
            "Epoch 44/50\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5113 - accuracy: 0.3439\n",
            "Epoch 00044: loss did not improve from 1.51050\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5113 - accuracy: 0.3439 - val_loss: 1.5022 - val_accuracy: 0.3372\n",
            "Epoch 45/50\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5101 - accuracy: 0.3443\n",
            "Epoch 00045: loss improved from 1.51050 to 1.51000, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59b0bdc0b8>_Batch25_LR0.01_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5100 - accuracy: 0.3443 - val_loss: 1.5027 - val_accuracy: 0.3372\n",
            "Epoch 46/50\n",
            "589/595 [============================>.] - ETA: 0s - loss: 1.5095 - accuracy: 0.3438\n",
            "Epoch 00046: loss improved from 1.51000 to 1.50932, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59b0bdc0b8>_Batch25_LR0.01_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5093 - accuracy: 0.3445 - val_loss: 1.5084 - val_accuracy: 0.3375\n",
            "Epoch 47/50\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5095 - accuracy: 0.3437\n",
            "Epoch 00047: loss did not improve from 1.50932\n",
            "595/595 [==============================] - 7s 12ms/step - loss: 1.5094 - accuracy: 0.3436 - val_loss: 1.4981 - val_accuracy: 0.3245\n",
            "Epoch 48/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5093 - accuracy: 0.3433\n",
            "Epoch 00048: loss did not improve from 1.50932\n",
            "595/595 [==============================] - 7s 13ms/step - loss: 1.5098 - accuracy: 0.3432 - val_loss: 1.5083 - val_accuracy: 0.3375\n",
            "Epoch 49/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5088 - accuracy: 0.3468\n",
            "Epoch 00049: loss improved from 1.50932 to 1.50881, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f59b0bdc0b8>_Batch25_LR0.01_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5088 - accuracy: 0.3468 - val_loss: 1.5093 - val_accuracy: 0.3372\n",
            "Epoch 50/50\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5091 - accuracy: 0.3438\n",
            "Epoch 00050: loss did not improve from 1.50881\n",
            "595/595 [==============================] - 7s 12ms/step - loss: 1.5090 - accuracy: 0.3439 - val_loss: 1.4919 - val_accuracy: 0.3372\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/50\n",
            "  2/595 [..............................] - ETA: 42s - loss: 3.1488 - accuracy: 0.2200   WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0150s vs `on_train_batch_end` time: 0.1315s). Check your callbacks.\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5630 - accuracy: 0.3333\n",
            "Epoch 00001: loss improved from inf to 1.56282, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f59b0bce5c0>_Batch25_LR0.01_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5628 - accuracy: 0.3334 - val_loss: 1.5065 - val_accuracy: 0.3399\n",
            "Epoch 2/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5301 - accuracy: 0.3427\n",
            "Epoch 00002: loss improved from 1.56282 to 1.53018, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f59b0bce5c0>_Batch25_LR0.01_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5302 - accuracy: 0.3426 - val_loss: 1.4938 - val_accuracy: 0.3399\n",
            "Epoch 3/50\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5294 - accuracy: 0.3434\n",
            "Epoch 00003: loss improved from 1.53018 to 1.52923, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f59b0bce5c0>_Batch25_LR0.01_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5292 - accuracy: 0.3436 - val_loss: 1.4991 - val_accuracy: 0.3399\n",
            "Epoch 4/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5298 - accuracy: 0.3438\n",
            "Epoch 00004: loss did not improve from 1.52923\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5298 - accuracy: 0.3436 - val_loss: 1.4925 - val_accuracy: 0.3399\n",
            "Epoch 5/50\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5290 - accuracy: 0.3438\n",
            "Epoch 00005: loss did not improve from 1.52923\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5296 - accuracy: 0.3436 - val_loss: 1.4962 - val_accuracy: 0.3399\n",
            "Epoch 6/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5298 - accuracy: 0.3436\n",
            "Epoch 00006: loss did not improve from 1.52923\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5298 - accuracy: 0.3436 - val_loss: 1.4986 - val_accuracy: 0.3399\n",
            "Epoch 7/50\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5300 - accuracy: 0.3433\n",
            "Epoch 00007: loss did not improve from 1.52923\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5298 - accuracy: 0.3436 - val_loss: 1.4970 - val_accuracy: 0.3399\n",
            "Epoch 8/50\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5296 - accuracy: 0.3436\n",
            "Epoch 00008: loss did not improve from 1.52923\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5297 - accuracy: 0.3436 - val_loss: 1.5001 - val_accuracy: 0.3399\n",
            "Epoch 9/50\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5298 - accuracy: 0.3439\n",
            "Epoch 00009: loss did not improve from 1.52923\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5295 - accuracy: 0.3436 - val_loss: 1.4960 - val_accuracy: 0.3399\n",
            "Epoch 10/50\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5302 - accuracy: 0.3438\n",
            "Epoch 00010: loss did not improve from 1.52923\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5303 - accuracy: 0.3436 - val_loss: 1.4957 - val_accuracy: 0.3399\n",
            "Epoch 11/50\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5304 - accuracy: 0.3437\n",
            "Epoch 00011: loss did not improve from 1.52923\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5304 - accuracy: 0.3436 - val_loss: 1.4980 - val_accuracy: 0.3399\n",
            "Epoch 12/50\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5302 - accuracy: 0.3442\n",
            "Epoch 00012: loss did not improve from 1.52923\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5304 - accuracy: 0.3436 - val_loss: 1.4941 - val_accuracy: 0.3399\n",
            "Epoch 13/50\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5294 - accuracy: 0.3441\n",
            "Epoch 00013: loss did not improve from 1.52923\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5296 - accuracy: 0.3436 - val_loss: 1.4961 - val_accuracy: 0.3399\n",
            "Epoch 14/50\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5298 - accuracy: 0.3433\n",
            "Epoch 00014: loss did not improve from 1.52923\n",
            "595/595 [==============================] - 7s 13ms/step - loss: 1.5297 - accuracy: 0.3436 - val_loss: 1.4979 - val_accuracy: 0.3399\n",
            "Epoch 15/50\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5294 - accuracy: 0.3438\n",
            "Epoch 00015: loss did not improve from 1.52923\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5294 - accuracy: 0.3436 - val_loss: 1.4927 - val_accuracy: 0.3399\n",
            "Epoch 16/50\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5297 - accuracy: 0.3436\n",
            "Epoch 00016: loss did not improve from 1.52923\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5296 - accuracy: 0.3436 - val_loss: 1.4921 - val_accuracy: 0.3399\n",
            "Epoch 17/50\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5303 - accuracy: 0.3434\n",
            "Epoch 00017: loss did not improve from 1.52923\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5299 - accuracy: 0.3436 - val_loss: 1.4927 - val_accuracy: 0.3399\n",
            "Epoch 18/50\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5300 - accuracy: 0.3431\n",
            "Epoch 00018: loss did not improve from 1.52923\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5296 - accuracy: 0.3436 - val_loss: 1.4993 - val_accuracy: 0.3399\n",
            "Epoch 19/50\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5305 - accuracy: 0.3434\n",
            "Epoch 00019: loss did not improve from 1.52923\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5304 - accuracy: 0.3436 - val_loss: 1.4951 - val_accuracy: 0.3399\n",
            "Epoch 20/50\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5301 - accuracy: 0.3436\n",
            "Epoch 00020: loss did not improve from 1.52923\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5301 - accuracy: 0.3436 - val_loss: 1.4947 - val_accuracy: 0.3399\n",
            "Epoch 21/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5299 - accuracy: 0.3438\n",
            "Epoch 00021: loss did not improve from 1.52923\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5301 - accuracy: 0.3436 - val_loss: 1.4925 - val_accuracy: 0.3399\n",
            "Epoch 22/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5298 - accuracy: 0.3436\n",
            "Epoch 00022: loss did not improve from 1.52923\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5298 - accuracy: 0.3436 - val_loss: 1.4903 - val_accuracy: 0.3399\n",
            "Epoch 23/50\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5303 - accuracy: 0.3435\n",
            "Epoch 00023: loss did not improve from 1.52923\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5300 - accuracy: 0.3436 - val_loss: 1.4915 - val_accuracy: 0.3399\n",
            "Epoch 24/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5299 - accuracy: 0.3438\n",
            "Epoch 00024: loss did not improve from 1.52923\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5300 - accuracy: 0.3436 - val_loss: 1.4985 - val_accuracy: 0.3399\n",
            "Epoch 25/50\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5293 - accuracy: 0.3438\n",
            "Epoch 00025: loss did not improve from 1.52923\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5299 - accuracy: 0.3436 - val_loss: 1.4931 - val_accuracy: 0.3399\n",
            "Epoch 26/50\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5296 - accuracy: 0.3440\n",
            "Epoch 00026: loss did not improve from 1.52923\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5299 - accuracy: 0.3436 - val_loss: 1.4970 - val_accuracy: 0.3399\n",
            "Epoch 27/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5297 - accuracy: 0.3436\n",
            "Epoch 00027: loss did not improve from 1.52923\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5297 - accuracy: 0.3436 - val_loss: 1.4943 - val_accuracy: 0.3399\n",
            "Epoch 28/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5292 - accuracy: 0.3438\n",
            "Epoch 00028: loss did not improve from 1.52923\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5295 - accuracy: 0.3436 - val_loss: 1.4958 - val_accuracy: 0.3399\n",
            "Epoch 29/50\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5293 - accuracy: 0.3437\n",
            "Epoch 00029: loss did not improve from 1.52923\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5293 - accuracy: 0.3436 - val_loss: 1.4972 - val_accuracy: 0.3399\n",
            "Epoch 30/50\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5299 - accuracy: 0.3434\n",
            "Epoch 00030: loss did not improve from 1.52923\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5301 - accuracy: 0.3436 - val_loss: 1.4938 - val_accuracy: 0.3399\n",
            "Epoch 31/50\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5301 - accuracy: 0.3437\n",
            "Epoch 00031: loss did not improve from 1.52923\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5301 - accuracy: 0.3436 - val_loss: 1.4920 - val_accuracy: 0.3399\n",
            "Epoch 32/50\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5304 - accuracy: 0.3436\n",
            "Epoch 00032: loss did not improve from 1.52923\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5303 - accuracy: 0.3436 - val_loss: 1.4928 - val_accuracy: 0.3399\n",
            "Epoch 33/50\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5304 - accuracy: 0.3435\n",
            "Epoch 00033: loss did not improve from 1.52923\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5306 - accuracy: 0.3436 - val_loss: 1.4918 - val_accuracy: 0.3399\n",
            "Epoch 34/50\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5302 - accuracy: 0.3435\n",
            "Epoch 00034: loss did not improve from 1.52923\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5300 - accuracy: 0.3436 - val_loss: 1.4975 - val_accuracy: 0.3399\n",
            "Epoch 35/50\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5301 - accuracy: 0.3438\n",
            "Epoch 00035: loss did not improve from 1.52923\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5300 - accuracy: 0.3436 - val_loss: 1.4917 - val_accuracy: 0.3399\n",
            "Epoch 36/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5308 - accuracy: 0.3437\n",
            "Epoch 00036: loss did not improve from 1.52923\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5308 - accuracy: 0.3436 - val_loss: 1.4920 - val_accuracy: 0.3399\n",
            "Epoch 37/50\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5305 - accuracy: 0.3432\n",
            "Epoch 00037: loss did not improve from 1.52923\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5301 - accuracy: 0.3436 - val_loss: 1.4959 - val_accuracy: 0.3399\n",
            "Epoch 38/50\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5304 - accuracy: 0.3437\n",
            "Epoch 00038: loss did not improve from 1.52923\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5303 - accuracy: 0.3436 - val_loss: 1.4928 - val_accuracy: 0.3399\n",
            "Epoch 39/50\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5304 - accuracy: 0.3436\n",
            "Epoch 00039: loss did not improve from 1.52923\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5302 - accuracy: 0.3436 - val_loss: 1.4941 - val_accuracy: 0.3399\n",
            "Epoch 40/50\n",
            "589/595 [============================>.] - ETA: 0s - loss: 1.5302 - accuracy: 0.3435\n",
            "Epoch 00040: loss did not improve from 1.52923\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5299 - accuracy: 0.3436 - val_loss: 1.4980 - val_accuracy: 0.3399\n",
            "Epoch 41/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5302 - accuracy: 0.3436\n",
            "Epoch 00041: loss did not improve from 1.52923\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5302 - accuracy: 0.3436 - val_loss: 1.4994 - val_accuracy: 0.3399\n",
            "Epoch 42/50\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5299 - accuracy: 0.3431\n",
            "Epoch 00042: loss did not improve from 1.52923\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5299 - accuracy: 0.3436 - val_loss: 1.5012 - val_accuracy: 0.3399\n",
            "Epoch 43/50\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5302 - accuracy: 0.3436\n",
            "Epoch 00043: loss did not improve from 1.52923\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5302 - accuracy: 0.3436 - val_loss: 1.4931 - val_accuracy: 0.3399\n",
            "Epoch 44/50\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5298 - accuracy: 0.3436\n",
            "Epoch 00044: loss did not improve from 1.52923\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5297 - accuracy: 0.3436 - val_loss: 1.4945 - val_accuracy: 0.3399\n",
            "Epoch 45/50\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5296 - accuracy: 0.3439\n",
            "Epoch 00045: loss did not improve from 1.52923\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5298 - accuracy: 0.3436 - val_loss: 1.4929 - val_accuracy: 0.3399\n",
            "Epoch 46/50\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5299 - accuracy: 0.3436\n",
            "Epoch 00046: loss did not improve from 1.52923\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5299 - accuracy: 0.3436 - val_loss: 1.4917 - val_accuracy: 0.3399\n",
            "Epoch 47/50\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5293 - accuracy: 0.3439\n",
            "Epoch 00047: loss did not improve from 1.52923\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5297 - accuracy: 0.3436 - val_loss: 1.4967 - val_accuracy: 0.3399\n",
            "Epoch 48/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5295 - accuracy: 0.3438\n",
            "Epoch 00048: loss did not improve from 1.52923\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5296 - accuracy: 0.3436 - val_loss: 1.4945 - val_accuracy: 0.3399\n",
            "Epoch 49/50\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5293 - accuracy: 0.3439\n",
            "Epoch 00049: loss did not improve from 1.52923\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5300 - accuracy: 0.3436 - val_loss: 1.4967 - val_accuracy: 0.3399\n",
            "Epoch 50/50\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5298 - accuracy: 0.3437\n",
            "Epoch 00050: loss did not improve from 1.52923\n",
            "595/595 [==============================] - 7s 13ms/step - loss: 1.5299 - accuracy: 0.3436 - val_loss: 1.4948 - val_accuracy: 0.3399\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/50\n",
            "  2/595 [..............................] - ETA: 39s - loss: 1.9916 - accuracy: 0.2000WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0142s vs `on_train_batch_end` time: 0.1169s). Check your callbacks.\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5508 - accuracy: 0.3316\n",
            "Epoch 00001: loss improved from inf to 1.55038, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f59b0a1cf60>_Batch25_LR0.01_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5504 - accuracy: 0.3317 - val_loss: 1.4961 - val_accuracy: 0.3399\n",
            "Epoch 2/50\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5343 - accuracy: 0.3438\n",
            "Epoch 00002: loss improved from 1.55038 to 1.53427, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f59b0a1cf60>_Batch25_LR0.01_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5343 - accuracy: 0.3438 - val_loss: 1.4989 - val_accuracy: 0.3399\n",
            "Epoch 3/50\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5289 - accuracy: 0.3436\n",
            "Epoch 00003: loss improved from 1.53427 to 1.52891, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f59b0a1cf60>_Batch25_LR0.01_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5289 - accuracy: 0.3436 - val_loss: 1.4961 - val_accuracy: 0.3399\n",
            "Epoch 4/50\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5287 - accuracy: 0.3441\n",
            "Epoch 00004: loss improved from 1.52891 to 1.52884, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f59b0a1cf60>_Batch25_LR0.01_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5288 - accuracy: 0.3436 - val_loss: 1.5011 - val_accuracy: 0.3399\n",
            "Epoch 5/50\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5290 - accuracy: 0.3436\n",
            "Epoch 00005: loss did not improve from 1.52884\n",
            "595/595 [==============================] - 7s 13ms/step - loss: 1.5290 - accuracy: 0.3436 - val_loss: 1.4964 - val_accuracy: 0.3399\n",
            "Epoch 6/50\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5292 - accuracy: 0.3438\n",
            "Epoch 00006: loss did not improve from 1.52884\n",
            "595/595 [==============================] - 7s 12ms/step - loss: 1.5292 - accuracy: 0.3436 - val_loss: 1.4989 - val_accuracy: 0.3399\n",
            "Epoch 7/50\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5288 - accuracy: 0.3436\n",
            "Epoch 00007: loss improved from 1.52884 to 1.52880, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f59b0a1cf60>_Batch25_LR0.01_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5288 - accuracy: 0.3436 - val_loss: 1.5025 - val_accuracy: 0.3399\n",
            "Epoch 8/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5289 - accuracy: 0.3437\n",
            "Epoch 00008: loss did not improve from 1.52880\n",
            "595/595 [==============================] - 7s 13ms/step - loss: 1.5291 - accuracy: 0.3436 - val_loss: 1.4910 - val_accuracy: 0.3399\n",
            "Epoch 9/50\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5286 - accuracy: 0.3435\n",
            "Epoch 00009: loss did not improve from 1.52880\n",
            "595/595 [==============================] - 7s 13ms/step - loss: 1.5290 - accuracy: 0.3436 - val_loss: 1.4977 - val_accuracy: 0.3399\n",
            "Epoch 10/50\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5291 - accuracy: 0.3437\n",
            "Epoch 00010: loss did not improve from 1.52880\n",
            "595/595 [==============================] - 7s 13ms/step - loss: 1.5289 - accuracy: 0.3436 - val_loss: 1.4922 - val_accuracy: 0.3399\n",
            "Epoch 11/50\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5292 - accuracy: 0.3436\n",
            "Epoch 00011: loss did not improve from 1.52880\n",
            "595/595 [==============================] - 7s 12ms/step - loss: 1.5292 - accuracy: 0.3436 - val_loss: 1.4986 - val_accuracy: 0.3399\n",
            "Epoch 12/50\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5293 - accuracy: 0.3437\n",
            "Epoch 00012: loss did not improve from 1.52880\n",
            "595/595 [==============================] - 7s 12ms/step - loss: 1.5291 - accuracy: 0.3436 - val_loss: 1.4996 - val_accuracy: 0.3399\n",
            "Epoch 13/50\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5291 - accuracy: 0.3437\n",
            "Epoch 00013: loss did not improve from 1.52880\n",
            "595/595 [==============================] - 7s 12ms/step - loss: 1.5290 - accuracy: 0.3436 - val_loss: 1.4966 - val_accuracy: 0.3399\n",
            "Epoch 14/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5293 - accuracy: 0.3434\n",
            "Epoch 00014: loss did not improve from 1.52880\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5291 - accuracy: 0.3436 - val_loss: 1.4958 - val_accuracy: 0.3399\n",
            "Epoch 15/50\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5289 - accuracy: 0.3435\n",
            "Epoch 00015: loss did not improve from 1.52880\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5288 - accuracy: 0.3436 - val_loss: 1.4971 - val_accuracy: 0.3399\n",
            "Epoch 16/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5291 - accuracy: 0.3436\n",
            "Epoch 00016: loss did not improve from 1.52880\n",
            "595/595 [==============================] - 7s 13ms/step - loss: 1.5290 - accuracy: 0.3436 - val_loss: 1.4943 - val_accuracy: 0.3399\n",
            "Epoch 17/50\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5289 - accuracy: 0.3441\n",
            "Epoch 00017: loss did not improve from 1.52880\n",
            "595/595 [==============================] - 7s 13ms/step - loss: 1.5289 - accuracy: 0.3436 - val_loss: 1.4955 - val_accuracy: 0.3399\n",
            "Epoch 18/50\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5292 - accuracy: 0.3436\n",
            "Epoch 00018: loss did not improve from 1.52880\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5290 - accuracy: 0.3436 - val_loss: 1.4960 - val_accuracy: 0.3399\n",
            "Epoch 19/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5291 - accuracy: 0.3435\n",
            "Epoch 00019: loss did not improve from 1.52880\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5290 - accuracy: 0.3436 - val_loss: 1.4981 - val_accuracy: 0.3399\n",
            "Epoch 20/50\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5292 - accuracy: 0.3436\n",
            "Epoch 00020: loss did not improve from 1.52880\n",
            "595/595 [==============================] - 7s 13ms/step - loss: 1.5290 - accuracy: 0.3436 - val_loss: 1.4983 - val_accuracy: 0.3399\n",
            "Epoch 21/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5293 - accuracy: 0.3436\n",
            "Epoch 00021: loss did not improve from 1.52880\n",
            "595/595 [==============================] - 7s 12ms/step - loss: 1.5293 - accuracy: 0.3436 - val_loss: 1.5002 - val_accuracy: 0.3399\n",
            "Epoch 22/50\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5289 - accuracy: 0.3436\n",
            "Epoch 00022: loss did not improve from 1.52880\n",
            "595/595 [==============================] - 7s 12ms/step - loss: 1.5289 - accuracy: 0.3436 - val_loss: 1.4922 - val_accuracy: 0.3399\n",
            "Epoch 23/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5291 - accuracy: 0.3437\n",
            "Epoch 00023: loss did not improve from 1.52880\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5290 - accuracy: 0.3436 - val_loss: 1.4981 - val_accuracy: 0.3399\n",
            "Epoch 24/50\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5288 - accuracy: 0.3439\n",
            "Epoch 00024: loss did not improve from 1.52880\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5290 - accuracy: 0.3436 - val_loss: 1.4967 - val_accuracy: 0.3399\n",
            "Epoch 25/50\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5286 - accuracy: 0.3438\n",
            "Epoch 00025: loss improved from 1.52880 to 1.52876, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f59b0a1cf60>_Batch25_LR0.01_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5288 - accuracy: 0.3436 - val_loss: 1.5009 - val_accuracy: 0.3399\n",
            "Epoch 26/50\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5295 - accuracy: 0.3436\n",
            "Epoch 00026: loss did not improve from 1.52876\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5293 - accuracy: 0.3436 - val_loss: 1.4980 - val_accuracy: 0.3399\n",
            "Epoch 27/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5291 - accuracy: 0.3437\n",
            "Epoch 00027: loss did not improve from 1.52876\n",
            "595/595 [==============================] - 7s 13ms/step - loss: 1.5292 - accuracy: 0.3436 - val_loss: 1.4943 - val_accuracy: 0.3399\n",
            "Epoch 28/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5290 - accuracy: 0.3435\n",
            "Epoch 00028: loss did not improve from 1.52876\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5289 - accuracy: 0.3436 - val_loss: 1.4981 - val_accuracy: 0.3399\n",
            "Epoch 29/50\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5278 - accuracy: 0.3438\n",
            "Epoch 00029: loss improved from 1.52876 to 1.52829, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f59b0a1cf60>_Batch25_LR0.01_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5283 - accuracy: 0.3436 - val_loss: 1.5012 - val_accuracy: 0.3399\n",
            "Epoch 30/50\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5290 - accuracy: 0.3440\n",
            "Epoch 00030: loss did not improve from 1.52829\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5294 - accuracy: 0.3436 - val_loss: 1.4978 - val_accuracy: 0.3399\n",
            "Epoch 31/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5287 - accuracy: 0.3434\n",
            "Epoch 00031: loss did not improve from 1.52829\n",
            "595/595 [==============================] - 7s 13ms/step - loss: 1.5285 - accuracy: 0.3436 - val_loss: 1.4966 - val_accuracy: 0.3399\n",
            "Epoch 32/50\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5291 - accuracy: 0.3437\n",
            "Epoch 00032: loss did not improve from 1.52829\n",
            "595/595 [==============================] - 7s 12ms/step - loss: 1.5290 - accuracy: 0.3436 - val_loss: 1.5004 - val_accuracy: 0.3399\n",
            "Epoch 33/50\n",
            "589/595 [============================>.] - ETA: 0s - loss: 1.5294 - accuracy: 0.3436\n",
            "Epoch 00033: loss did not improve from 1.52829\n",
            "595/595 [==============================] - 7s 12ms/step - loss: 1.5291 - accuracy: 0.3436 - val_loss: 1.4977 - val_accuracy: 0.3399\n",
            "Epoch 34/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5293 - accuracy: 0.3436\n",
            "Epoch 00034: loss did not improve from 1.52829\n",
            "595/595 [==============================] - 7s 12ms/step - loss: 1.5291 - accuracy: 0.3436 - val_loss: 1.4964 - val_accuracy: 0.3399\n",
            "Epoch 35/50\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5293 - accuracy: 0.3436\n",
            "Epoch 00035: loss did not improve from 1.52829\n",
            "595/595 [==============================] - 7s 12ms/step - loss: 1.5293 - accuracy: 0.3436 - val_loss: 1.4951 - val_accuracy: 0.3399\n",
            "Epoch 36/50\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5285 - accuracy: 0.3444\n",
            "Epoch 00036: loss did not improve from 1.52829\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5290 - accuracy: 0.3436 - val_loss: 1.4942 - val_accuracy: 0.3399\n",
            "Epoch 37/50\n",
            "589/595 [============================>.] - ETA: 0s - loss: 1.5298 - accuracy: 0.3429\n",
            "Epoch 00037: loss did not improve from 1.52829\n",
            "595/595 [==============================] - 7s 12ms/step - loss: 1.5288 - accuracy: 0.3436 - val_loss: 1.5000 - val_accuracy: 0.3399\n",
            "Epoch 38/50\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5291 - accuracy: 0.3438\n",
            "Epoch 00038: loss did not improve from 1.52829\n",
            "595/595 [==============================] - 7s 12ms/step - loss: 1.5290 - accuracy: 0.3436 - val_loss: 1.4989 - val_accuracy: 0.3399\n",
            "Epoch 39/50\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5291 - accuracy: 0.3437\n",
            "Epoch 00039: loss did not improve from 1.52829\n",
            "595/595 [==============================] - 7s 12ms/step - loss: 1.5291 - accuracy: 0.3436 - val_loss: 1.4964 - val_accuracy: 0.3399\n",
            "Epoch 40/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5289 - accuracy: 0.3434\n",
            "Epoch 00040: loss did not improve from 1.52829\n",
            "595/595 [==============================] - 7s 13ms/step - loss: 1.5287 - accuracy: 0.3436 - val_loss: 1.4915 - val_accuracy: 0.3399\n",
            "Epoch 41/50\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5294 - accuracy: 0.3432\n",
            "Epoch 00041: loss did not improve from 1.52829\n",
            "595/595 [==============================] - 7s 13ms/step - loss: 1.5291 - accuracy: 0.3436 - val_loss: 1.4953 - val_accuracy: 0.3399\n",
            "Epoch 42/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5290 - accuracy: 0.3434\n",
            "Epoch 00042: loss did not improve from 1.52829\n",
            "595/595 [==============================] - 7s 13ms/step - loss: 1.5289 - accuracy: 0.3436 - val_loss: 1.4994 - val_accuracy: 0.3399\n",
            "Epoch 43/50\n",
            "595/595 [==============================] - ETA: 0s - loss: 1.5291 - accuracy: 0.3436\n",
            "Epoch 00043: loss did not improve from 1.52829\n",
            "595/595 [==============================] - 7s 12ms/step - loss: 1.5291 - accuracy: 0.3436 - val_loss: 1.4933 - val_accuracy: 0.3399\n",
            "Epoch 44/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5286 - accuracy: 0.3435\n",
            "Epoch 00044: loss did not improve from 1.52829\n",
            "595/595 [==============================] - 7s 13ms/step - loss: 1.5285 - accuracy: 0.3436 - val_loss: 1.4920 - val_accuracy: 0.3399\n",
            "Epoch 45/50\n",
            "590/595 [============================>.] - ETA: 0s - loss: 1.5293 - accuracy: 0.3433\n",
            "Epoch 00045: loss did not improve from 1.52829\n",
            "595/595 [==============================] - 7s 12ms/step - loss: 1.5290 - accuracy: 0.3436 - val_loss: 1.5013 - val_accuracy: 0.3399\n",
            "Epoch 46/50\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5292 - accuracy: 0.3437\n",
            "Epoch 00046: loss did not improve from 1.52829\n",
            "595/595 [==============================] - 7s 12ms/step - loss: 1.5288 - accuracy: 0.3436 - val_loss: 1.4958 - val_accuracy: 0.3399\n",
            "Epoch 47/50\n",
            "589/595 [============================>.] - ETA: 0s - loss: 1.5295 - accuracy: 0.3432\n",
            "Epoch 00047: loss did not improve from 1.52829\n",
            "595/595 [==============================] - 7s 13ms/step - loss: 1.5290 - accuracy: 0.3436 - val_loss: 1.4961 - val_accuracy: 0.3399\n",
            "Epoch 48/50\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5288 - accuracy: 0.3439\n",
            "Epoch 00048: loss did not improve from 1.52829\n",
            "595/595 [==============================] - 7s 12ms/step - loss: 1.5290 - accuracy: 0.3436 - val_loss: 1.4963 - val_accuracy: 0.3399\n",
            "Epoch 49/50\n",
            "589/595 [============================>.] - ETA: 0s - loss: 1.5292 - accuracy: 0.3432\n",
            "Epoch 00049: loss did not improve from 1.52829\n",
            "595/595 [==============================] - 7s 12ms/step - loss: 1.5291 - accuracy: 0.3436 - val_loss: 1.4929 - val_accuracy: 0.3399\n",
            "Epoch 50/50\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5294 - accuracy: 0.3435\n",
            "Epoch 00050: loss did not improve from 1.52829\n",
            "595/595 [==============================] - 7s 12ms/step - loss: 1.5292 - accuracy: 0.3436 - val_loss: 1.4950 - val_accuracy: 0.3399\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/50\n",
            "  2/595 [..............................] - ETA: 36s - loss: 2.0207 - accuracy: 0.1600WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0135s vs `on_train_batch_end` time: 0.1105s). Check your callbacks.\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5496 - accuracy: 0.3290\n",
            "Epoch 00001: loss improved from inf to 1.55009, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59b0a265c0>_Batch25_LR0.01_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5501 - accuracy: 0.3284 - val_loss: 1.5087 - val_accuracy: 0.3399\n",
            "Epoch 2/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5323 - accuracy: 0.3405\n",
            "Epoch 00002: loss improved from 1.55009 to 1.53219, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59b0a265c0>_Batch25_LR0.01_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5322 - accuracy: 0.3405 - val_loss: 1.4982 - val_accuracy: 0.3399\n",
            "Epoch 3/50\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5279 - accuracy: 0.3443\n",
            "Epoch 00003: loss improved from 1.53219 to 1.52812, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59b0a265c0>_Batch25_LR0.01_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5281 - accuracy: 0.3443 - val_loss: 1.5020 - val_accuracy: 0.3399\n",
            "Epoch 4/50\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5245 - accuracy: 0.3429\n",
            "Epoch 00004: loss improved from 1.52812 to 1.52459, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59b0a265c0>_Batch25_LR0.01_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5246 - accuracy: 0.3429 - val_loss: 1.4988 - val_accuracy: 0.3399\n",
            "Epoch 5/50\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5230 - accuracy: 0.3443\n",
            "Epoch 00005: loss improved from 1.52459 to 1.52275, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59b0a265c0>_Batch25_LR0.01_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5228 - accuracy: 0.3442 - val_loss: 1.4977 - val_accuracy: 0.3399\n",
            "Epoch 6/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5240 - accuracy: 0.3432\n",
            "Epoch 00006: loss did not improve from 1.52275\n",
            "595/595 [==============================] - 7s 13ms/step - loss: 1.5240 - accuracy: 0.3431 - val_loss: 1.5002 - val_accuracy: 0.3399\n",
            "Epoch 7/50\n",
            "592/595 [============================>.] - ETA: 0s - loss: 1.5237 - accuracy: 0.3427\n",
            "Epoch 00007: loss did not improve from 1.52275\n",
            "595/595 [==============================] - 7s 12ms/step - loss: 1.5234 - accuracy: 0.3430 - val_loss: 1.5044 - val_accuracy: 0.3399\n",
            "Epoch 8/50\n",
            "591/595 [============================>.] - ETA: 0s - loss: 1.5201 - accuracy: 0.3441\n",
            "Epoch 00008: loss improved from 1.52275 to 1.52077, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59b0a265c0>_Batch25_LR0.01_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 14ms/step - loss: 1.5208 - accuracy: 0.3438 - val_loss: 1.5031 - val_accuracy: 0.3399\n",
            "Epoch 9/50\n",
            "594/595 [============================>.] - ETA: 0s - loss: 1.5207 - accuracy: 0.3435\n",
            "Epoch 00009: loss improved from 1.52077 to 1.52043, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59b0a265c0>_Batch25_LR0.01_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5204 - accuracy: 0.3437 - val_loss: 1.4988 - val_accuracy: 0.3399\n",
            "Epoch 10/50\n",
            "593/595 [============================>.] - ETA: 0s - loss: 1.5195 - accuracy: 0.3438\n",
            "Epoch 00010: loss improved from 1.52043 to 1.51951, saving model to model/best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59b0a265c0>_Batch25_LR0.01_Epochs50.hdf5\n",
            "595/595 [==============================] - 8s 13ms/step - loss: 1.5195 - accuracy: 0.3439 - val_loss: 1.5025 - val_accuracy: 0.3399\n",
            "Epoch 11/50\n",
            "288/595 [=============>................] - ETA: 2s - loss: 1.5143 - accuracy: 0.3432"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8lTHN_5ZpzC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f7f916b7-daa2-43bc-bb9e-fd19fd5f3de2"
      },
      "source": [
        "import json\n",
        "\n",
        "# as requested in comment\n",
        "with open('result_training.txt', 'w') as file:\n",
        "     file.write(json.dumps(Tabres)) # use `json.loads` to do the reverse"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fUVybHIT4aA8",
        "colab_type": "text"
      },
      "source": [
        "Loss vs accuracy\n",
        "\n",
        "https://kharshit.github.io/blog/2018/12/07/loss-vs-accuracy\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fxXLslzA4V8j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "https://kharshit.github.io/blog/2018/12/07/loss-vs-accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fo3lfsYbZpcB",
        "colab_type": "text"
      },
      "source": [
        "####Improve the Model with GAN - NOT FUNCTIONAL SO FAR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Qltq67Ua9ac",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "https://keras.io/guides/customizing_what_happens_in_fit/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d9lf5VWAKZ2m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "\n",
        "# Create the discriminator\n",
        "discriminator = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=(28, 28, 1)),\n",
        "        layers.Conv2D(64, (3, 3), strides=(2, 2), padding=\"same\"),\n",
        "        layers.LeakyReLU(alpha=0.2),\n",
        "        layers.Conv2D(128, (3, 3), strides=(2, 2), padding=\"same\"),\n",
        "        layers.LeakyReLU(alpha=0.2),\n",
        "        layers.GlobalMaxPooling2D(),\n",
        "        layers.Dense(1),\n",
        "    ],\n",
        "    name=\"discriminator\",\n",
        ")\n",
        "\n",
        "# Create the generator\n",
        "latent_dim = 128\n",
        "generator = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=(latent_dim,)),\n",
        "        # We want to generate 128 coefficients to reshape into a 7x7x128 map\n",
        "        layers.Dense(7 * 7 * 128),\n",
        "        layers.LeakyReLU(alpha=0.2),\n",
        "        layers.Reshape((7, 7, 128)),\n",
        "        layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding=\"same\"),\n",
        "        layers.LeakyReLU(alpha=0.2),\n",
        "        layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding=\"same\"),\n",
        "        layers.LeakyReLU(alpha=0.2),\n",
        "        layers.Conv2D(1, (7, 7), padding=\"same\", activation=\"sigmoid\"),\n",
        "    ],\n",
        "    name=\"generator\",\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R4wpRPC5bTua",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class GAN(keras.Model):\n",
        "    def __init__(self, discriminator, generator, latent_dim):\n",
        "        super(GAN, self).__init__()\n",
        "        self.discriminator = discriminator\n",
        "        self.generator = generator\n",
        "        self.latent_dim = latent_dim\n",
        "\n",
        "    def compile(self, d_optimizer, g_optimizer, loss_fn):\n",
        "        super(GAN, self).compile()\n",
        "        self.d_optimizer = d_optimizer\n",
        "        self.g_optimizer = g_optimizer\n",
        "        self.loss_fn = loss_fn\n",
        "\n",
        "    def train_step(self, real_images):\n",
        "        if isinstance(real_images, tuple):\n",
        "            real_images = real_images[0]\n",
        "        # Sample random points in the latent space\n",
        "        batch_size = tf.shape(real_images)[0]\n",
        "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
        "\n",
        "        # Decode them to fake images\n",
        "        generated_images = self.generator(random_latent_vectors)\n",
        "\n",
        "        # Combine them with real images\n",
        "        combined_images = tf.concat([generated_images, real_images], axis=0)\n",
        "\n",
        "        # Assemble labels discriminating real from fake images\n",
        "        labels = tf.concat(\n",
        "            [tf.ones((batch_size, 1)), tf.zeros((batch_size, 1))], axis=0\n",
        "        )\n",
        "        # Add random noise to the labels - important trick!\n",
        "        labels += 0.05 * tf.random.uniform(tf.shape(labels))\n",
        "\n",
        "        # Train the discriminator\n",
        "        with tf.GradientTape() as tape:\n",
        "            predictions = self.discriminator(combined_images)\n",
        "            d_loss = self.loss_fn(labels, predictions)\n",
        "        grads = tape.gradient(d_loss, self.discriminator.trainable_weights)\n",
        "        self.d_optimizer.apply_gradients(\n",
        "            zip(grads, self.discriminator.trainable_weights)\n",
        "        )\n",
        "\n",
        "        # Sample random points in the latent space\n",
        "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
        "\n",
        "        # Assemble labels that say \"all real images\"\n",
        "        misleading_labels = tf.zeros((batch_size, 1))\n",
        "\n",
        "        # Train the generator (note that we should *not* update the weights\n",
        "        # of the discriminator)!\n",
        "        with tf.GradientTape() as tape:\n",
        "            predictions = self.discriminator(self.generator(random_latent_vectors))\n",
        "            g_loss = self.loss_fn(misleading_labels, predictions)\n",
        "        grads = tape.gradient(g_loss, self.generator.trainable_weights)\n",
        "        self.g_optimizer.apply_gradients(zip(grads, self.generator.trainable_weights))\n",
        "        return {\"d_loss\": d_loss, \"g_loss\": g_loss}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vOtZ0dD7bYhp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Prepare the dataset. We use both the training & test MNIST digits.\n",
        "batch_size = 64\n",
        "(x_train, _), (x_test, _) = keras.datasets.mnist.load_data()\n",
        "all_digits = np.concatenate([x_train, x_test])\n",
        "all_digits = all_digits.astype(\"float32\") / 255.0\n",
        "all_digits = np.reshape(all_digits, (-1, 28, 28, 1))\n",
        "dataset = tf.data.Dataset.from_tensor_slices(all_digits)\n",
        "dataset = dataset.shuffle(buffer_size=1024).batch(batch_size)\n",
        "\n",
        "gan = GAN(discriminator=discriminator, generator=generator, latent_dim=latent_dim)\n",
        "gan.compile(\n",
        "    d_optimizer=keras.optimizers.Adam(learning_rate=0.0003),\n",
        "    g_optimizer=keras.optimizers.Adam(learning_rate=0.0003),\n",
        "    loss_fn=keras.losses.BinaryCrossentropy(from_logits=True),\n",
        ")\n",
        "\n",
        "# To limit execution time, we only train on 100 batches. You can train on\n",
        "# the entire dataset. You will need about 20 epochs to get nice results.\n",
        "gan.fit(dataset.take(100), epochs=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cez5uqWb4SSc",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oyRJzUx_5DSF",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R2_xo8psY5Iy",
        "colab_type": "text"
      },
      "source": [
        "##Step 3: Evaluate the VGGsp500 model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PXXUYNbwZ4TX",
        "colab_type": "text"
      },
      "source": [
        "This part will evaluate the model with the testing dataset that we generated in first step. We show the accuracy, the confusion matrix and the classification report"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mUSUr5CdwPPz",
        "colab_type": "text"
      },
      "source": [
        "To improve learning after playing with all the parameters \n",
        "\n",
        "- get more dataset on stock and indice\n",
        "\n",
        "- work on vgg untrained \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eKbQ6tBAhlw8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        },
        "outputId": "84b52850-8f5a-4e5d-eeb5-0cc8628b0cf6"
      },
      "source": [
        "print(\"name of the best model for each set of parameters\")\n",
        "bestmodel=\"best_model\"+vggsp500loss+\"_\"+vggsp500optimizer_name+\"_Batch\"+str(batch_size)+\"_LR\"+str(initial_learning_rate)+\".hdf5\"\n",
        "print(bestmodel)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "name of the best model for each set of parameters\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-379eac6dc040>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"name of the best model for each set of parameters\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mbestmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"best_model\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mvggsp500loss\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"_\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mvggsp500optimizer_name\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"_Batch\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"_LR\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitial_learning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\".hdf5\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbestmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'vggsp500loss' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23kG1lJE5KqF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "7a92151c-ae13-4338-e07c-a1b8a5387089"
      },
      "source": [
        "%cd /content/drive/My Drive/A_transfertTFMVggSP500\n",
        "%cd model \n",
        "%cp best_modelcategorical_crossentropy_adam_Batch100_LR0.1_0.99.hdf5 /content/DL_Tools_For_Finance/model/\n",
        "%ls -l"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/A_transfertTFMVggSP500\n",
            "/content/drive/My Drive/A_transfertTFMVggSP500/model\n",
            "cp: cannot stat 'best_modelcategorical_crossentropy_adam_Batch100_LR0.1_0.99.hdf5': No such file or directory\n",
            "total 465803\n",
            "-rw------- 1 root root 59726904 Sep  5 06:04  best_modelcategorical_crossentropy_Adagrad_Batch32_LR0.01_0.98.hdf5\n",
            "-rw------- 1 root root 59456824 Sep  1 00:22 'best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x7f59b9654fd0>_Batch25_LR0.001_Epochs100vggforsp500.h5'\n",
            "-rw------- 1 root root 59726928 Sep  1 00:35 'best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f59b9808a20>_Batch25_LR0.001_Epochs100.hdf5'\n",
            "-rw------- 1 root root 59726928 Sep  1 00:35 'best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f59b9808a20>_Batch25_LR0.001_Epochs100vggforsp500.h5'\n",
            "-rw------- 1 root root 59725496 Sep  1 00:44 'best_modelcategorical_crossentropy_<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f599f76e400>_Batch25_LR0.001_Epochs100.hdf5'\n",
            "-rw------- 1 root root 59726920 Aug 31 08:06  final_modelcategorical_crossentropy_adam_32.h5\n",
            "-rw------- 1 root root 59161736 Sep  5 06:10  initial_weights.h5\n",
            "-rw------- 1 root root 59726904 Sep  5 06:04  vggforsp500.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HAQnQZoR6rD6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bd4d4adc-5751-4c3d-81a0-e3489531edda"
      },
      "source": [
        "%cd /content/DL_Tools_For_Finance/\n",
        "trained_model_path='/content/DL_Tools_For_Finance/model/final_modelcategorical_crossentropy_adam_32.h5'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/DL_Tools_For_Finance\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yxMUW3tCMVBM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 598
        },
        "outputId": "31913564-b148-4977-e387-9e10ea68b556"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from keras.utils import np_utils\n",
        "from keras.models import load_model\n",
        "from keras import backend as K\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "'''\n",
        "Here we have a trained model model/vggforsp500.h5 and datas for testing \n",
        "datas/X_test_image.csv\n",
        "datas/Y_test_StateClass_image.csv\n",
        "datas/Y_test_FutPredict_image.csv\n",
        "\n",
        "'''\n",
        "\n",
        "##\n",
        "'''\n",
        "UTILITY FUNCTIONS\n",
        "to put in another file\n",
        "'''\n",
        "\n",
        "def change_X_df__nparray_image(df_X_train_image_flattened ):\n",
        "  '''\n",
        "  setup_input_NN_image returns a dataframe of flaten image for x train and xtest\n",
        "  then this function will change each date into a nparray list of images with 32, 32, 3 size \n",
        "  '''\n",
        "  X_train_image=df_X_train_image_flattened\n",
        "  nb_train=len(X_train_image.index)\n",
        "  \n",
        "  x_train=np.zeros((nb_train,32,32,3))\n",
        "  for i in range(nb_train):\n",
        "    tmp=np.array(X_train_image.iloc[i])\n",
        "    tmp=tmp.reshape(32,32,3)\n",
        "    x_train[i]=tmp\n",
        "  return x_train\n",
        "##\n",
        "\n",
        "\n",
        "\n",
        "#recuperation of testing datas and organising it \n",
        "X_test_image=pd.read_csv('datas/X_test_image.csv')\n",
        "Y_test_StateClass_image=pd.read_csv('datas/Y_test_StateClass_image.csv')\n",
        "Y_test_FutPredict_image=pd.read_csv('datas/Y_test_FutPredict_image.csv')\n",
        "\n",
        "#setting up the index to Date\n",
        "X_test_image=X_test_image.set_index(\"Date\")\n",
        "Y_test_StateClass_image=Y_test_StateClass_image.set_index(\"Date\")\n",
        "Y_test_FutPredict_image=Y_test_FutPredict_image.set_index(\"Date\")\n",
        "\n",
        "#modify dataset to np array for input to NN\n",
        "x_test=change_X_df__nparray_image(X_test_image)\n",
        "y_test_state=np.array(Y_test_StateClass_image)\n",
        "y_test_value=np.array(Y_test_FutPredict_image)\n",
        "\n",
        "##Setting up xtest and ytest\n",
        "#Here we focus on predicting the future state Y_train_StateClass_image\n",
        "nb_test=len(X_test_image.index)\n",
        "x_test=np.zeros((nb_test,32,32,3))\n",
        "for i in range(nb_test):\n",
        "  tmp=np.array(X_test_image.iloc[i])\n",
        "  tmp=tmp.reshape(32,32,3)\n",
        "  x_test[i]=tmp\n",
        "\n",
        "y_test=np.array(Y_test_StateClass_image)\n",
        "#y_test=np.array(Y_test_FutPredict_image)\n",
        "\n",
        "#In our example we need to y into categorical as it has 6 categories\n",
        "nb_classes=6\n",
        "y_test_m = np_utils.to_categorical(y_test, nb_classes)\n",
        "############\n",
        "#recuperation of model\n",
        "vggsp500model = load_model(trained_model_path)\n",
        "\n",
        "#Evaluate the model on the test data\n",
        "score  = vggsp500model.evaluate(x_test, y_test_m)\n",
        "\n",
        "\n",
        "Y_pred = vggsp500model.predict(x_test)\n",
        "y_pred = np.argmax(Y_pred, axis=1)\n",
        "y= np.argmax(y_test_m,axis=1)\n",
        "\n",
        "\n",
        "print('Confusion Matrix')\n",
        "\n",
        "target_state = ['SS', 'SN', 'N','NB','BB','Error']\n",
        "\n",
        "def statetostring(x):\n",
        "  return target_state[int(x)]\n",
        "\n",
        "sY_pred=[statetostring(i) for i in y_pred]\n",
        "sY_real=[statetostring(i) for i in y]\n",
        "\n",
        "#matrice  de confusion\n",
        "mat=confusion_matrix(sY_real, sY_pred, normalize='true', labels=target_state)\n",
        "df_confmat=pd.DataFrame(mat,index=target_state, columns=target_state)\n",
        "\n",
        "#matrice  de confusion\n",
        "mat2=confusion_matrix(sY_real, sY_pred,  labels=target_state)\n",
        "df_confmat2=pd.DataFrame(mat2,index=target_state, columns=target_state)\n",
        "\n",
        "#Accuracy on test data\n",
        "print('Accuracy on the Test Images: ', score[1])\n",
        "#matrice  de confusion\n",
        "print(df_confmat)\n",
        "\n",
        "#matrice  de confusion\n",
        "print(df_confmat2)\n",
        "\n",
        "# Classification report\n",
        "print('classification report')\n",
        "print(classification_report(sY_real, sY_pred, target_names=target_state))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "146/146 [==============================] - 1s 5ms/step - loss: 1.4815 - accuracy: 0.3833\n",
            "Confusion Matrix\n",
            "Accuracy on the Test Images:  0.3833225667476654\n",
            "             SS        SN         N   NB        BB  Error\n",
            "SS     0.051780  0.000000  0.800971  0.0  0.147249    0.0\n",
            "SN     0.013834  0.023715  0.806324  0.0  0.156126    0.0\n",
            "N      0.007975  0.006135  0.712270  0.0  0.273620    0.0\n",
            "NB     0.007496  0.000000  0.659670  0.0  0.332834    0.0\n",
            "BB     0.004136  0.000000  0.521092  0.0  0.474773    0.0\n",
            "Error  0.000000  0.000000  0.454545  0.0  0.545455    0.0\n",
            "       SS  SN     N  NB   BB  Error\n",
            "SS     32   0   495   0   91      0\n",
            "SN      7  12   408   0   79      0\n",
            "N      13  10  1161   0  446      0\n",
            "NB      5   0   440   0  222      0\n",
            "BB      5   0   630   0  574      0\n",
            "Error   0   0     5   0    6      0\n",
            "classification report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          SS       0.40      0.47      0.44      1209\n",
            "          SN       0.00      0.00      0.00        11\n",
            "           N       0.37      0.71      0.49      1630\n",
            "          NB       0.00      0.00      0.00       667\n",
            "          BB       0.55      0.02      0.05       506\n",
            "       Error       0.52      0.05      0.09       618\n",
            "\n",
            "    accuracy                           0.38      4641\n",
            "   macro avg       0.31      0.21      0.18      4641\n",
            "weighted avg       0.36      0.38      0.30      4641\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TIz78gePZY76",
        "colab_type": "text"
      },
      "source": [
        "##Step 4: Guess future market state from random image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ulkwESoxZm1z",
        "colab_type": "text"
      },
      "source": [
        "Take an image of an historical graph from a market webpage like investing.com and save it to the ImageM/ folder with name image1.PNG or you can change the value of image_path to the link you need.\n",
        "\n",
        "This execution tell us which market state in the future is the best representative."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvqRijItZML8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "outputId": "c5063777-565a-44f7-82c8-2a53cb84637b"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from keras.utils import np_utils\n",
        "from keras.models import load_model\n",
        "from keras import backend as K\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "#path for trained model\n",
        "trained_model_path='model/vggforsp500.h5'\n",
        "\n",
        "#path for the image taken by the user\n",
        "#image_path='ImageM/image1.PNG'\n",
        "image_path =input(\"Enter the path of the image to check next state:\\n\")\n",
        "\n",
        "#Load the image and resize it to 32x32 and taking off the transparency\n",
        "load_img_rz = np.array(Image.open(image_path).resize((32,32)))\n",
        "#Image.fromarray(load_img_rz).save('/content/drive/My Drive/_sample_data/ImageM/image1.PNG')\n",
        "image=load_img_rz[:,:,:3]/255\n",
        "print(\"After resizing:\",image.shape)\n",
        "\n",
        "#petite astuce pour ne pas avoir d erreur avec les types list, tensors,  nparray et dataframe\n",
        "doubleimage=np.array([image,image])\n",
        "############\n",
        "#recuperation of the model\n",
        "vggsp500model = load_model(trained_model_path)\n",
        "Y_pred = vggsp500model.predict(doubleimage)\n",
        "y_pred = np.argmax(Y_pred, axis=1)\n",
        "\n",
        "target_state = ['SS', 'SN', 'N','NB','BB','Error']\n",
        "df_result=pd.DataFrame((Y_pred))\n",
        "\n",
        "df_result.columns=target_state\n",
        "df_result.index=[image_path, image_path+'1']\n",
        "print (\"for \",image_path, \"the best result is \", target_state[int(y_pred[0])] )\n",
        "\n",
        "df_result"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter the path of the image to check next state:\n",
            "/content/DL_Tools_For_Finance/ImageM/image2.PNG\n",
            "After resizing: (32, 32, 3)\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3286689ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "for  /content/DL_Tools_For_Finance/ImageM/image2.PNG the best result is  SS\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SS</th>\n",
              "      <th>SN</th>\n",
              "      <th>N</th>\n",
              "      <th>NB</th>\n",
              "      <th>BB</th>\n",
              "      <th>Error</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>/content/DL_Tools_For_Finance/ImageM/image2.PNG</th>\n",
              "      <td>0.31159</td>\n",
              "      <td>0.119561</td>\n",
              "      <td>0.263224</td>\n",
              "      <td>0.073631</td>\n",
              "      <td>0.231359</td>\n",
              "      <td>0.000636</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>/content/DL_Tools_For_Finance/ImageM/image2.PNG1</th>\n",
              "      <td>0.31159</td>\n",
              "      <td>0.119561</td>\n",
              "      <td>0.263224</td>\n",
              "      <td>0.073631</td>\n",
              "      <td>0.231359</td>\n",
              "      <td>0.000636</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                       SS  ...     Error\n",
              "/content/DL_Tools_For_Finance/ImageM/image2.PNG   0.31159  ...  0.000636\n",
              "/content/DL_Tools_For_Finance/ImageM/image2.PNG1  0.31159  ...  0.000636\n",
              "\n",
              "[2 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBOG00tVbHS7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "outputId": "686ec072-2661-4b03-c1a8-d4ea42ed5233"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(image)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f007032f1d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gXmOXke1hlip",
        "colab_type": "text"
      },
      "source": [
        "Give the results for all the PNG file of a directory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z0aDBnGTh6yi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 662
        },
        "outputId": "2a0aa2d4-3708-496b-9b3a-ecfcab9b7387"
      },
      "source": [
        "import os\n",
        "\n",
        "path = '/content/DL_Tools_For_Finance/ImageM/'\n",
        "\n",
        "#files = os.listdir(path)\n",
        "#l_file=[]\n",
        "#for f in files:\n",
        "#    l_file.append(f)\n",
        "\n",
        "l_file=glob.glob('**/*.PNG', recursive=True)\n",
        "l_image_input_NN=[]\n",
        "\n",
        "for x_image in l_file:  \n",
        "  #Load the image and resize it to 32x32 and taking off the transparency\n",
        "  load_img_rz = np.array(Image.open(x_image).resize((32,32)))\n",
        "\n",
        "  #Image.fromarray(load_img_rz).save('/content/drive/My Drive/_sample_data/ImageM/image1.PNG')\n",
        "  image=load_img_rz[:,:,:3]/255\n",
        "  print(\"After resizing:\",image.shape)\n",
        "\n",
        "  l_image_input_NN.append(image)\n",
        "\n",
        "############\n",
        "#recuperation of the model\n",
        "vggsp500model = load_model(trained_model_path)\n",
        "Y_pred = vggsp500model.predict(np.array(l_image_input_NN))\n",
        "y_pred = np.argmax(Y_pred, axis=1)\n",
        "\n",
        "target_state = ['SS', 'SN', 'N','NB','BB','Error']\n",
        "df_result=pd.DataFrame((Y_pred))\n",
        "\n",
        "df_result.columns=target_state\n",
        "df_result.index=l_file\n",
        "\n",
        "df_decision=pd.DataFrame([target_state[i] for i in  y_pred],index=l_file, columns=['Decision'])\n",
        "df_result=pd.concat([df_result,df_decision],axis=1)\n",
        "(df_result)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "After resizing: (32, 32, 3)\n",
            "After resizing: (32, 32, 3)\n",
            "After resizing: (32, 32, 3)\n",
            "After resizing: (32, 32, 3)\n",
            "After resizing: (32, 32, 3)\n",
            "After resizing: (32, 32, 3)\n",
            "After resizing: (32, 32, 3)\n",
            "After resizing: (32, 32, 3)\n",
            "After resizing: (32, 32, 3)\n",
            "After resizing: (32, 32, 3)\n",
            "After resizing: (32, 32, 3)\n",
            "After resizing: (32, 32, 3)\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f32888d3488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SS</th>\n",
              "      <th>SN</th>\n",
              "      <th>N</th>\n",
              "      <th>NB</th>\n",
              "      <th>BB</th>\n",
              "      <th>Error</th>\n",
              "      <th>Decision</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>ImageM/image3.PNG</th>\n",
              "      <td>0.301182</td>\n",
              "      <td>0.121881</td>\n",
              "      <td>0.264708</td>\n",
              "      <td>0.073682</td>\n",
              "      <td>0.237916</td>\n",
              "      <td>0.000632</td>\n",
              "      <td>SS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ImageM/image2.PNG</th>\n",
              "      <td>0.311591</td>\n",
              "      <td>0.119561</td>\n",
              "      <td>0.263224</td>\n",
              "      <td>0.073630</td>\n",
              "      <td>0.231358</td>\n",
              "      <td>0.000636</td>\n",
              "      <td>SS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ImageM/image1.PNG</th>\n",
              "      <td>0.209848</td>\n",
              "      <td>0.190190</td>\n",
              "      <td>0.379863</td>\n",
              "      <td>0.045567</td>\n",
              "      <td>0.174114</td>\n",
              "      <td>0.000418</td>\n",
              "      <td>N</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ImageM/image4.PNG</th>\n",
              "      <td>0.342570</td>\n",
              "      <td>0.142008</td>\n",
              "      <td>0.243726</td>\n",
              "      <td>0.072087</td>\n",
              "      <td>0.198942</td>\n",
              "      <td>0.000667</td>\n",
              "      <td>SS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ImageM/image5.PNG</th>\n",
              "      <td>0.194147</td>\n",
              "      <td>0.321485</td>\n",
              "      <td>0.290173</td>\n",
              "      <td>0.048638</td>\n",
              "      <td>0.144945</td>\n",
              "      <td>0.000611</td>\n",
              "      <td>SN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ImageM/graphsp500tocrop.PNG</th>\n",
              "      <td>0.001264</td>\n",
              "      <td>0.057363</td>\n",
              "      <td>0.833274</td>\n",
              "      <td>0.032646</td>\n",
              "      <td>0.075410</td>\n",
              "      <td>0.000044</td>\n",
              "      <td>N</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ImageM/ImageM/image3.PNG</th>\n",
              "      <td>0.301182</td>\n",
              "      <td>0.121881</td>\n",
              "      <td>0.264708</td>\n",
              "      <td>0.073682</td>\n",
              "      <td>0.237916</td>\n",
              "      <td>0.000632</td>\n",
              "      <td>SS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ImageM/ImageM/image2.PNG</th>\n",
              "      <td>0.311591</td>\n",
              "      <td>0.119561</td>\n",
              "      <td>0.263224</td>\n",
              "      <td>0.073630</td>\n",
              "      <td>0.231358</td>\n",
              "      <td>0.000636</td>\n",
              "      <td>SS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ImageM/ImageM/image1.PNG</th>\n",
              "      <td>0.209848</td>\n",
              "      <td>0.190190</td>\n",
              "      <td>0.379863</td>\n",
              "      <td>0.045567</td>\n",
              "      <td>0.174114</td>\n",
              "      <td>0.000418</td>\n",
              "      <td>N</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ImageM/ImageM/image4.PNG</th>\n",
              "      <td>0.342570</td>\n",
              "      <td>0.142008</td>\n",
              "      <td>0.243726</td>\n",
              "      <td>0.072087</td>\n",
              "      <td>0.198942</td>\n",
              "      <td>0.000667</td>\n",
              "      <td>SS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ImageM/ImageM/image5.PNG</th>\n",
              "      <td>0.194147</td>\n",
              "      <td>0.321485</td>\n",
              "      <td>0.290173</td>\n",
              "      <td>0.048638</td>\n",
              "      <td>0.144945</td>\n",
              "      <td>0.000611</td>\n",
              "      <td>SN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ImageM/ImageM/graphsp500tocrop.PNG</th>\n",
              "      <td>0.001264</td>\n",
              "      <td>0.057363</td>\n",
              "      <td>0.833274</td>\n",
              "      <td>0.032646</td>\n",
              "      <td>0.075410</td>\n",
              "      <td>0.000044</td>\n",
              "      <td>N</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                          SS        SN  ...     Error  Decision\n",
              "ImageM/image3.PNG                   0.301182  0.121881  ...  0.000632        SS\n",
              "ImageM/image2.PNG                   0.311591  0.119561  ...  0.000636        SS\n",
              "ImageM/image1.PNG                   0.209848  0.190190  ...  0.000418         N\n",
              "ImageM/image4.PNG                   0.342570  0.142008  ...  0.000667        SS\n",
              "ImageM/image5.PNG                   0.194147  0.321485  ...  0.000611        SN\n",
              "ImageM/graphsp500tocrop.PNG         0.001264  0.057363  ...  0.000044         N\n",
              "ImageM/ImageM/image3.PNG            0.301182  0.121881  ...  0.000632        SS\n",
              "ImageM/ImageM/image2.PNG            0.311591  0.119561  ...  0.000636        SS\n",
              "ImageM/ImageM/image1.PNG            0.209848  0.190190  ...  0.000418         N\n",
              "ImageM/ImageM/image4.PNG            0.342570  0.142008  ...  0.000667        SS\n",
              "ImageM/ImageM/image5.PNG            0.194147  0.321485  ...  0.000611        SN\n",
              "ImageM/ImageM/graphsp500tocrop.PNG  0.001264  0.057363  ...  0.000044         N\n",
              "\n",
              "[12 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8Rqf47ewbmk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "539f26c0-046f-495b-b3f6-b7e630e6ba9c"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter the path of the image to check next state:/content/DL_Tools_For_Finance/ImageM/image2.PNG\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QeXi5PdYxJ3r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "40bc8e51-f752-4868-d0a1-372f17cb57d9"
      },
      "source": [
        "direction"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/DL_Tools_For_Finance/ImageM/image2.PNG'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uE2TBYhJxQK7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}